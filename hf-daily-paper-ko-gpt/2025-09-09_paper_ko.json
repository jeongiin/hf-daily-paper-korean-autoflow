[
    {
        "paper": {
            "id": "2509.06160",
            "authors": [
                {
                    "_id": "68bf936f207285de11b07b79",
                    "name": "Haozhe Wang",
                    "hidden": false
                },
                {
                    "_id": "68bf936f207285de11b07b7a",
                    "name": "Haoran Que",
                    "hidden": false
                },
                {
                    "_id": "68bf936f207285de11b07b7b",
                    "user": {
                        "_id": "6680f0b20b72be136708af26",
                        "avatarUrl": "/avatars/5d8fd5be0cf94e246b46abb9d3cc8f5c.svg",
                        "isPro": false,
                        "fullname": "XuQixin",
                        "user": "Racktic",
                        "type": "user"
                    },
                    "name": "Qixin Xu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-09T13:48:04.349Z",
                    "hidden": false
                },
                {
                    "_id": "68bf936f207285de11b07b7c",
                    "user": {
                        "_id": "6417d9ea8f689506e7148417",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6417d9ea8f689506e7148417/bAYcruWNw4WvmuQcGgcwC.jpeg",
                        "isPro": false,
                        "fullname": "minghao",
                        "user": "Liam-Liu",
                        "type": "user"
                    },
                    "name": "Minghao Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-09T13:48:08.356Z",
                    "hidden": false
                },
                {
                    "_id": "68bf936f207285de11b07b7d",
                    "name": "Wangchunshu Zhou",
                    "hidden": false
                },
                {
                    "_id": "68bf936f207285de11b07b7e",
                    "name": "Jiazhan Feng",
                    "hidden": false
                },
                {
                    "_id": "68bf936f207285de11b07b7f",
                    "name": "Wanjun Zhong",
                    "hidden": false
                },
                {
                    "_id": "68bf936f207285de11b07b80",
                    "name": "Wei Ye",
                    "hidden": false
                },
                {
                    "_id": "68bf936f207285de11b07b81",
                    "name": "Tong Yang",
                    "hidden": false
                },
                {
                    "_id": "68bf936f207285de11b07b82",
                    "name": "Wenhao Huang",
                    "hidden": false
                },
                {
                    "_id": "68bf936f207285de11b07b83",
                    "user": {
                        "_id": "638efcf4c67af472d316d424",
                        "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
                        "isPro": false,
                        "fullname": "Ge Zhang",
                        "user": "zhangysk",
                        "type": "user"
                    },
                    "name": "Ge Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-09T13:47:57.642Z",
                    "hidden": false
                },
                {
                    "_id": "68bf936f207285de11b07b84",
                    "name": "Fangzhen Lin",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-07T18:07:58.000Z",
            "submittedOnDailyAt": "2025-09-09T01:10:01.643Z",
            "title": "Reverse-Engineered Reasoning for Open-Ended Generation",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "While the ``deep reasoning'' paradigm has spurred significant advances in\nverifiable domains like mathematics, its application to open-ended, creative\ngeneration remains a critical challenge. The two dominant methods for\ninstilling reasoning -- reinforcement learning (RL) and instruction\ndistillation -- falter in this area; RL struggles with the absence of clear\nreward signals and high-quality reward models, while distillation is\nprohibitively expensive and capped by the teacher model's capabilities. To\novercome these limitations, we introduce REverse-Engineered Reasoning (REER), a\nnew paradigm that fundamentally shifts the approach. Instead of building a\nreasoning process ``forwards'' through trial-and-error or imitation, REER works\n``backwards'' from known-good solutions to computationally discover the latent,\nstep-by-step deep reasoning process that could have produced them. Using this\nscalable, gradient-free approach, we curate and open-source DeepWriting-20K, a\nlarge-scale dataset of 20,000 deep reasoning trajectories for open-ended tasks.\nOur model, DeepWriter-8B, trained on this data, not only surpasses strong\nopen-source baselines but also achieves performance competitive with, and at\ntimes superior to, leading proprietary models like GPT-4o and Claude 3.5.",
            "upvotes": 90,
            "discussionId": "68bf9370207285de11b07b85",
            "projectPage": "https://m-a-p.ai/REER_DeepWriter/",
            "ai_summary": "REER, a new paradigm for deep reasoning, uses reverse engineering to discover step-by-step reasoning processes, enabling a model to perform competitively on open-ended tasks.",
            "ai_keywords": [
                "deep reasoning",
                "reinforcement learning",
                "instruction distillation",
                "REER",
                "gradient-free",
                "DeepWriting-20K",
                "DeepWriter-8B",
                "GPT-4o",
                "Claude 3.5"
            ]
        },
        "translation_title": "개방형 생성에 대한 역공학적 추론",
        "purpose": "개방형 생성에서의 추론 적용의 한계를 극복하기 위한 새로운 패러다임 개발",
        "method": [
            "REER라는 새로운 패러다임을 소개하여 기존의 방법 대신 역방향으로 추론 과정을 발견함(We introduce REverse-Engineered Reasoning (REER), a new paradigm that fundamentally shifts the approach.)",
            "20,000개의 깊은 추론 경로를 포함한 DeepWriting-20K라는 대규모 데이터셋을 생성하고 공개함(Using this scalable, gradient-free approach, we curate and open-source DeepWriting-20K, a large-scale dataset of 20,000 deep reasoning trajectories for open-ended tasks.)",
            "이 데이터로 학습한 모델 DeepWriter-8B가 강력한 오픈소스 기준을 초과하고 일부 선도적인 상용 모델과 경쟁할 수 있음을 입증함(Our model, DeepWriter-8B, trained on this data, not only surpasses strong open-source baselines but also achieves performance competitive with, and at times superior to, leading proprietary models like GPT-4o and Claude 3.5.)"
        ],
        "conclusion": "REER 방식은 개방형 생성 작업에서 뛰어난 성능을 달성하며, DeepWriter-8B가 여러 모델과 경쟁할 수 있는 능력을 가짐.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2509.06501",
            "authors": [
                {
                    "_id": "68bfb768207285de11b07d02",
                    "name": "Junteng Liu",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d03",
                    "user": {
                        "_id": "62ac3bcec35bb36ff0785962",
                        "avatarUrl": "/avatars/edd4f14556abc39739bac951043a3065.svg",
                        "isPro": false,
                        "fullname": "李云济",
                        "user": "awdrgyjilplij",
                        "type": "user"
                    },
                    "name": "Yunji Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-09T13:46:35.234Z",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d04",
                    "name": "Chi Zhang",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d05",
                    "name": "Jingyang Li",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d06",
                    "user": {
                        "_id": "63f86b099f87cc3e645b51d9",
                        "avatarUrl": "/avatars/27ca5ba425640bf67474cee871e8e53a.svg",
                        "isPro": false,
                        "fullname": "Ellie Chen",
                        "user": "sheep33333",
                        "type": "user"
                    },
                    "name": "Aili Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-09T13:46:37.221Z",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d07",
                    "name": "Ke Ji",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d08",
                    "name": "Weiyu Cheng",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d09",
                    "name": "Zijia Wu",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d0a",
                    "name": "Chengyu Du",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d0b",
                    "name": "Qidi Xu",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d0c",
                    "name": "Jiayuan Song",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d0d",
                    "name": "Zhengmao Zhu",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d0e",
                    "name": "Wenhu Chen",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d0f",
                    "name": "Pengyu Zhao",
                    "hidden": false
                },
                {
                    "_id": "68bfb768207285de11b07d10",
                    "name": "Junxian He",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-08T10:07:03.000Z",
            "submittedOnDailyAt": "2025-09-09T03:45:45.200Z",
            "title": "WebExplorer: Explore and Evolve for Training Long-Horizon Web Agents",
            "submittedOnDailyBy": {
                "_id": "6493fbb3085e14d7933b936d",
                "avatarUrl": "/avatars/85723bedac9e81fecc33b36ff94ecada.svg",
                "isPro": false,
                "fullname": "Junteng Liu",
                "user": "Junteng",
                "type": "user"
            },
            "summary": "The paradigm of Large Language Models (LLMs) has increasingly shifted toward\nagentic applications, where web browsing capabilities are fundamental for\nretrieving information from diverse online sources. However, existing\nopen-source web agents either demonstrate limited information-seeking abilities\non complex tasks or lack transparent implementations. In this work, we identify\nthat the key challenge lies in the scarcity of challenging data for information\nseeking. To address this limitation, we introduce WebExplorer: a systematic\ndata generation approach using model-based exploration and iterative,\nlong-to-short query evolution. This method creates challenging query-answer\npairs that require multi-step reasoning and complex web navigation. By\nleveraging our curated high-quality dataset, we successfully develop advanced\nweb agent WebExplorer-8B through supervised fine-tuning followed by\nreinforcement learning. Our model supports 128K context length and up to 100\ntool calling turns, enabling long-horizon problem solving. Across diverse\ninformation-seeking benchmarks, WebExplorer-8B achieves the state-of-the-art\nperformance at its scale. Notably, as an 8B-sized model, WebExplorer-8B is able\nto effectively search over an average of 16 turns after RL training, achieving\nhigher accuracy than WebSailor-72B on BrowseComp-en/zh and attaining the best\nperformance among models up to 100B parameters on WebWalkerQA and FRAMES.\nBeyond these information-seeking tasks, our model also achieves strong\ngeneralization on the HLE benchmark even though it is only trained on\nknowledge-intensive QA data. These results highlight our approach as a\npractical path toward long-horizon web agents.",
            "upvotes": 49,
            "discussionId": "68bfb768207285de11b07d11",
            "ai_summary": "WebExplorer, a data-driven approach for developing advanced web agents, achieves state-of-the-art performance in information-seeking tasks through systematic data generation and reinforcement learning.",
            "ai_keywords": [
                "Large Language Models",
                "agentic applications",
                "web browsing capabilities",
                "information-seeking abilities",
                "model-based exploration",
                "iterative query evolution",
                "query-answer pairs",
                "multi-step reasoning",
                "complex web navigation",
                "supervised fine-tuning",
                "reinforcement learning",
                "context length",
                "tool calling turns",
                "long-horizon problem solving",
                "BrowseComp-en/zh",
                "WebWalkerQA",
                "FRAMES",
                "HLE benchmark"
            ]
        },
        "translation_title": "WebExplorer: 장기간 웹 에이전트 훈련을 위한 탐색 및 발전",
        "purpose": "정보 검색을 위한 도전적인 데이터 생성 방안 제시",
        "method": [
            "모델 기반 탐색과 쿼리 발전을 통해 도전적인 쿼리-답변 쌍을 생성함(To address this limitation, we introduce WebExplorer: a systematic data generation approach using model-based exploration and iterative, long-to-short query evolution.)",
            "고급 웹 에이전트인 WebExplorer-8B를 엄격한 슈퍼바이즈드 미세 조정 및 강화 학습을 통해 개발함(By leveraging our curated high-quality dataset, we successfully develop advanced web agent WebExplorer-8B through supervised fine-tuning followed by reinforcement learning.)",
            "모델은 128K의 컨텍스트 길이와 최대 100회 도구 호출을 지원하여 장기 문제 해결이 가능함."
        ],
        "conclusion": "WebExplorer-8B는 다양한 정보 검색 벤치마크에서 최첨단 성능을 달성하며, 장기 웹 에이전트 훈련을 위한 실용적인 접근 방식을 제시함.",
        "keywords": [
            "Large Language Models",
            "Multimodal Learning",
            "Information Seeking"
        ]
    },
    {
        "paper": {
            "id": "2509.06949",
            "authors": [
                {
                    "_id": "68bf87ff207285de11b07b39",
                    "name": "Yinjie Wang",
                    "hidden": false
                },
                {
                    "_id": "68bf87ff207285de11b07b3a",
                    "user": {
                        "_id": "64fde4e252e82dd432b74ce9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64fde4e252e82dd432b74ce9/-CQZbBP7FsPPyawYrsi4z.jpeg",
                        "isPro": false,
                        "fullname": "Ling Yang",
                        "user": "Lingaaaaaaa",
                        "type": "user"
                    },
                    "name": "Ling Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-09T13:48:22.774Z",
                    "hidden": false
                },
                {
                    "_id": "68bf87ff207285de11b07b3b",
                    "name": "Bowen Li",
                    "hidden": false
                },
                {
                    "_id": "68bf87ff207285de11b07b3c",
                    "name": "Ye Tian",
                    "hidden": false
                },
                {
                    "_id": "68bf87ff207285de11b07b3d",
                    "name": "Ke Shen",
                    "hidden": false
                },
                {
                    "_id": "68bf87ff207285de11b07b3e",
                    "name": "Mengdi Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-08T17:58:06.000Z",
            "submittedOnDailyAt": "2025-09-09T00:25:38.536Z",
            "title": "Revolutionizing Reinforcement Learning Framework for Diffusion Large\n  Language Models",
            "submittedOnDailyBy": {
                "_id": "64fde4e252e82dd432b74ce9",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64fde4e252e82dd432b74ce9/-CQZbBP7FsPPyawYrsi4z.jpeg",
                "isPro": false,
                "fullname": "Ling Yang",
                "user": "Lingaaaaaaa",
                "type": "user"
            },
            "summary": "We propose TraceRL, a trajectory-aware reinforcement learning framework for\ndiffusion language models (DLMs) that incorporates preferred inference\ntrajectory into post-training, and is applicable across different\narchitectures. Equipped with a diffusion-based value model that enhances\ntraining stability, we demonstrate improved reasoning performance on complex\nmath and coding tasks. Besides, it can also be applied to adapt block-specific\nmodels to larger blocks, which improves sampling flexibility. Employing\nTraceRL, we derive a series of state-of-the-art diffusion language models,\nnamely TraDo. Although smaller than 7B-scale AR models, TraDo-4B-Instruct still\nconsistently outperforms them across complex math reasoning tasks.\nTraDo-8B-Instruct achieves relative accuracy improvements of 6.1% over\nQwen2.5-7B-Instruct and 51.3% over Llama3.1-8B-Instruct on mathematical\nreasoning benchmarks. Through curriculum learning, we also derive the first\nlong-CoT DLM, outperforming Qwen2.5-7B-Instruct on MATH500 with an 18.1%\nrelative accuracy gain. To facilitate reproducible research and practical\napplications, we release a comprehensive open-source framework for building,\ntraining, and deploying diffusion LLMs across diverse architectures. The\nframework integrates accelerated KV-cache techniques and inference engines for\nboth inference and reinforcement learning, and includes implementations of\nvarious supervised fine-tuning and RL methods for mathematics, coding, and\ngeneral tasks. Code and Models: https://github.com/Gen-Verse/dLLM-RL",
            "upvotes": 29,
            "discussionId": "68bf87ff207285de11b07b3f",
            "projectPage": "https://huggingface.co/collections/Gen-Verse/trado-series-68beb6cd6a26c27cde9fe3af",
            "githubRepo": "https://github.com/Gen-Verse/dLLM-RL",
            "ai_summary": "TraceRL enhances diffusion language models with trajectory-aware reinforcement learning, improving reasoning performance on complex tasks and enabling flexible sampling.",
            "ai_keywords": [
                "trajectory-aware reinforcement learning",
                "diffusion language models",
                "diffusion-based value model",
                "sampling flexibility",
                "curriculum learning",
                "long-CoT DLM",
                "KV-cache techniques",
                "inference engines",
                "supervised fine-tuning",
                "RL methods"
            ],
            "githubStars": 62
        },
        "translation_title": "Diffusion 대형 언어 모델을 위한 강화 학습 프레임워크 혁신하기",
        "purpose": "Diffusion 언어 모델의 후속 훈련에서 선호하는 추론 경로를 통합하여 성능을 향상시키기 위한 새로운 프레임워크 개발",
        "method": [
            "TraceRL이라는 경로 인식 강화 학습 프레임워크를 제안함(We propose TraceRL, a trajectory-aware reinforcement learning framework for diffusion language models (DLMs) that incorporates preferred inference trajectory into post-training.)",
            "훈련 안정성을 높이는 diffusion 기반 가치 모델을 장착하고 복잡한 수학 및 코딩 작업에서 개선된 추론 성능을 입증함(Equipped with a diffusion-based value model that enhances training stability, we demonstrate improved reasoning performance on complex math and coding tasks.)",
            "TraceRL을 활용하여 다양한 state-of-the-art diffusion 언어 모델을 개발함(Employing TraceRL, we derive a series of state-of-the-art diffusion language models, namely TraDo.)"
        ],
        "conclusion": "TraDo 모델은 복잡한 수학 추론 작업에서 7B 규모의 AR 모델보다 consistently 부각되는 성과를 내었으며, 오픈소스 프레임워크를 통해 다양한 아키텍처에서의 확실한 연구 및 응용이 가능해짐.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Reinforcement Learning"
        ]
    },
    {
        "paper": {
            "id": "2509.06467",
            "authors": [
                {
                    "_id": "68bf97aa207285de11b07ba5",
                    "name": "Che Liu",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07ba6",
                    "name": "Yinda Chen",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07ba7",
                    "name": "Haoyuan Shi",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07ba8",
                    "name": "Jinpeng Lu",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07ba9",
                    "name": "Bailiang Jian",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07baa",
                    "name": "Jiazhen Pan",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07bab",
                    "name": "Linghan Cai",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07bac",
                    "name": "Jiayi Wang",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07bad",
                    "name": "Yundi Zhang",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07bae",
                    "name": "Jun Li",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07baf",
                    "name": "Cosmin I. Bercea",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07bb0",
                    "name": "Cheng Ouyang",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07bb1",
                    "name": "Chen Chen",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07bb2",
                    "name": "Zhiwei Xiong",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07bb3",
                    "name": "Benedikt Wiestler",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07bb4",
                    "name": "Christian Wachinger",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07bb5",
                    "name": "Daniel Rueckert",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07bb6",
                    "name": "Wenjia Bai",
                    "hidden": false
                },
                {
                    "_id": "68bf97aa207285de11b07bb7",
                    "name": "Rossella Arcucci",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-08T09:28:57.000Z",
            "submittedOnDailyAt": "2025-09-09T01:28:11.725Z",
            "title": "Does DINOv3 Set a New Medical Vision Standard?",
            "submittedOnDailyBy": {
                "_id": "631b9ff5824f2502e3557c7e",
                "avatarUrl": "/avatars/076043c9dba07644a570692563ef8114.svg",
                "isPro": true,
                "fullname": "liu",
                "user": "che111",
                "type": "user"
            },
            "summary": "The advent of large-scale vision foundation models, pre-trained on diverse\nnatural images, has marked a paradigm shift in computer vision. However, how\nthe frontier vision foundation models' efficacies transfer to specialized\ndomains remains such as medical imaging remains an open question. This report\ninvestigates whether DINOv3, a state-of-the-art self-supervised vision\ntransformer (ViT) that features strong capability in dense prediction tasks,\ncan directly serve as a powerful, unified encoder for medical vision tasks\nwithout domain-specific pre-training. To answer this, we benchmark DINOv3\nacross common medical vision tasks, including 2D/3D classification and\nsegmentation on a wide range of medical imaging modalities. We systematically\nanalyze its scalability by varying model sizes and input image resolutions. Our\nfindings reveal that DINOv3 shows impressive performance and establishes a\nformidable new baseline. Remarkably, it can even outperform medical-specific\nfoundation models like BiomedCLIP and CT-Net on several tasks, despite being\ntrained solely on natural images. However, we identify clear limitations: The\nmodel's features degrade in scenarios requiring deep domain specialization,\nsuch as in Whole-Slide Pathological Images (WSIs), Electron Microscopy (EM),\nand Positron Emission Tomography (PET). Furthermore, we observe that DINOv3\ndoes not consistently obey scaling law in the medical domain; performance does\nnot reliably increase with larger models or finer feature resolutions, showing\ndiverse scaling behaviors across tasks. Ultimately, our work establishes DINOv3\nas a strong baseline, whose powerful visual features can serve as a robust\nprior for multiple complex medical tasks. This opens promising future\ndirections, such as leveraging its features to enforce multiview consistency in\n3D reconstruction.",
            "upvotes": 26,
            "discussionId": "68bf97ab207285de11b07bb8",
            "ai_summary": "DINOv3, a self-supervised vision transformer, demonstrates strong performance across various medical vision tasks without domain-specific pre-training, though it shows limitations in deeply specialized domains and does not consistently follow scaling laws in the medical domain.",
            "ai_keywords": [
                "self-supervised vision transformer",
                "ViT",
                "dense prediction tasks",
                "medical vision tasks",
                "2D/3D classification",
                "segmentation",
                "medical imaging modalities",
                "scalability",
                "model sizes",
                "input image resolutions",
                "BiomedCLIP",
                "CT-Net",
                "Whole-Slide Pathological Images",
                "Electron Microscopy",
                "Positron Emission Tomography",
                "scaling law",
                "multiview consistency",
                "3D reconstruction"
            ]
        },
        "translation_title": "DINOv3가 새로운 의료 비전 기준을 설정하는가?",
        "purpose": "DINOv3가 의료 비전 작업에 강력한 인코더 역할을 할 수 있는지 확인하기 위해 연구",
        "method": [
            "DINOv3의 성능을 2D/3D 분류 및 세분화와 같은 다양한 의료 비전 작업에서 평가함(To answer this, we benchmark DINOv3 across common medical vision tasks, including 2D/3D classification and segmentation on a wide range of medical imaging modalities.)",
            "모델 크기와 입력 이미지 해상도를 다양화하여 DINOv3의 확장성을 체계적으로 분석함(We systematically analyze its scalability by varying model sizes and input image resolutions.)",
            "DINOv3가 자연 이미지에만 기반하여도 BiomedCLIP 및 CT-Net과 같은 의료 특정 모델보다 여러 작업에서 더 우수한 성능을 보임(Our findings reveal that DINOv3 shows impressive performance and establishes a formidable new baseline.)"
        ],
        "conclusion": "DINOv3는 강력한 시각적 특징을 바탕으로 여러 복잡한 의료 작업을 위해 강력한 기준을 설정하며, 3D 재구성에서 다중 뷰 일관성을 강화하는 등 미래의 유망한 방향을 제시함.",
        "keywords": [
            "Computer Vision",
            "Image Segmentation",
            "3D Vision"
        ]
    },
    {
        "paper": {
            "id": "2509.01656",
            "authors": [
                {
                    "_id": "68beda55c123124955ef6267",
                    "name": "Zetong Zhou",
                    "hidden": false
                },
                {
                    "_id": "68beda55c123124955ef6268",
                    "name": "Dongping Chen",
                    "hidden": false
                },
                {
                    "_id": "68beda55c123124955ef6269",
                    "name": "Zixian Ma",
                    "hidden": false
                },
                {
                    "_id": "68beda55c123124955ef626a",
                    "name": "Zhihan Hu",
                    "hidden": false
                },
                {
                    "_id": "68beda55c123124955ef626b",
                    "name": "Mingyang Fu",
                    "hidden": false
                },
                {
                    "_id": "68beda55c123124955ef626c",
                    "name": "Sinan Wang",
                    "hidden": false
                },
                {
                    "_id": "68beda55c123124955ef626d",
                    "name": "Yao Wan",
                    "hidden": false
                },
                {
                    "_id": "68beda55c123124955ef626e",
                    "name": "Zhou Zhao",
                    "hidden": false
                },
                {
                    "_id": "68beda55c123124955ef626f",
                    "name": "Ranjay Krishna",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-01T17:57:49.000Z",
            "submittedOnDailyAt": "2025-09-09T00:10:59.899Z",
            "title": "Reinforced Visual Perception with Tools",
            "submittedOnDailyBy": {
                "_id": "643be8879f5d314db2d9ed23",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/643be8879f5d314db2d9ed23/VrW2UtJ7ppOnGIYjTWd7b.png",
                "isPro": false,
                "fullname": "Chen Dongping",
                "user": "shuaishuaicdp",
                "type": "user"
            },
            "summary": "Visual reasoning, a cornerstone of human intelligence, encompasses complex\nperceptual and logical processes essential for solving diverse visual problems.\nWhile advances in computer vision have produced powerful models for various\nperceptual tasks, leveraging these for general visual reasoning remains\nchallenging. Prior work demonstrates that augmenting LLMs with vision models\nvia supervised finetuning improves performance, but faces key limitations such\nas expensive data generation, reliance on careful data filtering, and poor\ngeneralization. To address these issues, we propose ReVPT to enhance\nmulti-modal LLMs' abilities to reason about and use visual tools through\nreinforcement learning. We introduce a novel RL algorithm based on GRPO,\ndesigned to train models to reason with a suite of four visual tools. Through\nextensive experiments, we show that our method achieves state-of-the-art\nperformance on several perception-heavy benchmarks, including SAT, CV-Bench,\nBLINK and MMStar, significantly outperforming the supervised and text-based RL\nfinetuning baselines. Notably, Our ReVPT-3B and ReVPT-7B outperform the\ninstruct models by 9.03% and 9.44% on CV-Bench. Finally, we bring to the\ncommunity new insights on RL-based visual tool-usage through extensive\nablations. Our code is available at https://github.com/ls-kelvin/REVPT.",
            "upvotes": 24,
            "discussionId": "68beda55c123124955ef6270",
            "githubRepo": "https://github.com/ls-kelvin/REVPT",
            "ai_summary": "ReVPT enhances multi-modal LLMs' visual reasoning capabilities using reinforcement learning, achieving state-of-the-art performance on visual benchmarks.",
            "ai_keywords": [
                "LLMs",
                "vision models",
                "supervised finetuning",
                "reinforcement learning",
                "GRPO",
                "visual tools",
                "SAT",
                "CV-Bench",
                "BLINK",
                "MMStar",
                "instruct models"
            ],
            "githubStars": 27
        },
        "translation_title": "도구를 통한 강화된 시각적 인식",
        "purpose": "멀티모달 LLM이 시각적 도구를 사용하는 능력을 강화하기 위한 새로운 방법 연구",
        "method": [
            "강화 학습을 통해 LLM의 시각적 도구 사용 능력을 향상시키기 위해 ReVPT를 제안함(We propose ReVPT to enhance multi-modal LLMs' abilities to reason about and use visual tools through reinforcement learning.)",
            "GRPO를 기반으로 한 새로운 RL 알고리즘을 도입하여 모델이 네 가지 시각적 도구로 추론하도록 설계함(We introduce a novel RL algorithm based on GRPO, designed to train models to reason with a suite of four visual tools.)",
            "다양한 인식 중심 벤치마크에서 실험을 통해 최첨단 성능을 달성함(Through extensive experiments, we show that our method achieves state-of-the-art performance on several perception-heavy benchmarks, including SAT, CV-Bench, BLINK and MMStar.)"
        ],
        "conclusion": "ReVPT는 기존의 감독 학습 및 텍스트 기반 RL 미세 조정 방법보다 뛰어난 성능을 보이며, 시각적 도구 사용에 대한 새로운 통찰을 제공합니다.",
        "keywords": [
            "Computer Vision",
            "Multimodal Learning",
            "Vision-Language Models"
        ]
    }
]