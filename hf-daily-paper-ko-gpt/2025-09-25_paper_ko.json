[
    {
        "paper": {
            "id": "2509.20328",
            "authors": [
                {
                    "_id": "68d4a16436950a9dff15687e",
                    "user": {
                        "_id": "6635e88459d39b1afa736263",
                        "avatarUrl": "/avatars/0ebac4e2ba2420dfe7a852b873beb47a.svg",
                        "isPro": false,
                        "fullname": "Thaddäus Wiedemer",
                        "user": "ThaddaeusWiedemer",
                        "type": "user"
                    },
                    "name": "Thaddäus Wiedemer",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-09-25T11:35:38.955Z",
                    "hidden": false
                },
                {
                    "_id": "68d4a16436950a9dff15687f",
                    "user": {
                        "_id": "66d86ae34eb2eb8dc078f808",
                        "avatarUrl": "/avatars/4fb926729092ce69087343ce767387c8.svg",
                        "isPro": false,
                        "fullname": "Yuxuan Li",
                        "user": "yuxuanli",
                        "type": "user"
                    },
                    "name": "Yuxuan Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-09-25T11:35:47.314Z",
                    "hidden": false
                },
                {
                    "_id": "68d4a16436950a9dff156880",
                    "name": "Paul Vicol",
                    "hidden": false
                },
                {
                    "_id": "68d4a16436950a9dff156881",
                    "name": "Shixiang Shane Gu",
                    "hidden": false
                },
                {
                    "_id": "68d4a16436950a9dff156882",
                    "user": {
                        "_id": "63e2b8f0c123238b189b9fed",
                        "avatarUrl": "/avatars/4f403225d37c758fe680a2f8dc0795e0.svg",
                        "isPro": false,
                        "fullname": "Nick Matarese",
                        "user": "nmatares",
                        "type": "user"
                    },
                    "name": "Nick Matarese",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-09-25T11:36:02.770Z",
                    "hidden": false
                },
                {
                    "_id": "68d4a16436950a9dff156883",
                    "user": {
                        "_id": "630e6ef664f1f8d0c771b758",
                        "avatarUrl": "/avatars/1df2bfadb2b6fdf8307189936efc6ef0.svg",
                        "isPro": false,
                        "fullname": "Kevin Swersky",
                        "user": "kswersky",
                        "type": "user"
                    },
                    "name": "Kevin Swersky",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-09-25T11:36:10.350Z",
                    "hidden": false
                },
                {
                    "_id": "68d4a16436950a9dff156884",
                    "name": "Been Kim",
                    "hidden": false
                },
                {
                    "_id": "68d4a16436950a9dff156885",
                    "name": "Priyank Jaini",
                    "hidden": false
                },
                {
                    "_id": "68d4a16436950a9dff156886",
                    "user": {
                        "_id": "673bbe0d7dfcdedd52619ec2",
                        "avatarUrl": "/avatars/531a44f05d0c738bbe3e028c76c2e948.svg",
                        "isPro": false,
                        "fullname": "Robert Geirhos",
                        "user": "rgeirhos",
                        "type": "user"
                    },
                    "name": "Robert Geirhos",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-09-25T11:36:26.093Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-24T17:17:27.000Z",
            "submittedOnDailyAt": "2025-09-25T00:27:00.745Z",
            "title": "Video models are zero-shot learners and reasoners",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "The remarkable zero-shot capabilities of Large Language Models (LLMs) have\npropelled natural language processing from task-specific models to unified,\ngeneralist foundation models. This transformation emerged from simple\nprimitives: large, generative models trained on web-scale data. Curiously, the\nsame primitives apply to today's generative video models. Could video models be\non a trajectory towards general-purpose vision understanding, much like LLMs\ndeveloped general-purpose language understanding? We demonstrate that Veo 3 can\nsolve a broad variety of tasks it wasn't explicitly trained for: segmenting\nobjects, detecting edges, editing images, understanding physical properties,\nrecognizing object affordances, simulating tool use, and more. These abilities\nto perceive, model, and manipulate the visual world enable early forms of\nvisual reasoning like maze and symmetry solving. Veo's emergent zero-shot\ncapabilities indicate that video models are on a path to becoming unified,\ngeneralist vision foundation models.",
            "upvotes": 28,
            "discussionId": "68d4a16436950a9dff156887",
            "projectPage": "https://video-zero-shot.github.io/",
            "ai_summary": "Veo 3, a generative video model, exhibits zero-shot capabilities across various visual tasks, suggesting a trajectory towards becoming a unified, generalist vision foundation model.",
            "ai_keywords": [
                "Large Language Models",
                "LLMs",
                "generative models",
                "web-scale data",
                "generative video models",
                "zero-shot capabilities",
                "object segmentation",
                "edge detection",
                "image editing",
                "physical properties",
                "object affordances",
                "tool use simulation",
                "visual reasoning",
                "maze solving",
                "symmetry solving",
                "unified",
                "generalist vision foundation models"
            ]
        },
        "translation_title": "비디오 모델은 제로샷 학습자이자 추론자다",
        "purpose": "비디오 모델이 제로샷 환경에서 다양한 비전 이해 작업을 수행할 수 있는 가능성을 탐구하기 위함",
        "method": [
            "Veo 3를 사용하여 명시적으로 훈련되지 않은 다양한 작업을 해결할 수 있음을 입증함(We demonstrate that Veo 3 can solve a broad variety of tasks it wasn't explicitly trained for: segmenting objects, detecting edges, editing images, understanding physical properties, recognizing object affordances, simulating tool use, and more.)",
            "비주얼 세계를 인식하고 모델링 및 조작하는 능력을 통해 초기 형태의 비주얼 추론을 가능하게 함(These abilities to perceive, model, and manipulate the visual world enable early forms of visual reasoning like maze and symmetry solving.)"
        ],
        "conclusion": "Veo의 제로샷 능력은 비디오 모델이 통합된 일반 비전 기반 모델로 발전할 가능성이 있음을 나타낸다.",
        "keywords": [
            "Computer Vision",
            "Video Understanding",
            "Large Language Models"
        ]
    },
    {
        "paper": {
            "id": "2509.20317",
            "authors": [
                {
                    "_id": "68d4b42136950a9dff1568d1",
                    "user": {
                        "_id": "62eb70462f0f5e54df42f778",
                        "avatarUrl": "/avatars/456049dba67638d3cdb330cdf383f272.svg",
                        "isPro": false,
                        "fullname": "Xilin Wei",
                        "user": "Wiselnn",
                        "type": "user"
                    },
                    "name": "Xilin Wei",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-25T11:35:19.953Z",
                    "hidden": false
                },
                {
                    "_id": "68d4b42136950a9dff1568d2",
                    "user": {
                        "_id": "64f033ef82c6eea604c4da8b",
                        "avatarUrl": "/avatars/51b93fea7fd68b4274ee03701245dcca.svg",
                        "isPro": false,
                        "fullname": "Liu Xiaoran",
                        "user": "LiuXR",
                        "type": "user"
                    },
                    "name": "Xiaoran Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-25T07:10:49.956Z",
                    "hidden": false
                },
                {
                    "_id": "68d4b42136950a9dff1568d3",
                    "name": "Yuhang Zang",
                    "hidden": false
                },
                {
                    "_id": "68d4b42136950a9dff1568d4",
                    "name": "Xiaoyi Dong",
                    "hidden": false
                },
                {
                    "_id": "68d4b42136950a9dff1568d5",
                    "name": "Yuhang Cao",
                    "hidden": false
                },
                {
                    "_id": "68d4b42136950a9dff1568d6",
                    "name": "Jiaqi Wang",
                    "hidden": false
                },
                {
                    "_id": "68d4b42136950a9dff1568d7",
                    "name": "Xipeng Qiu",
                    "hidden": false
                },
                {
                    "_id": "68d4b42136950a9dff1568d8",
                    "name": "Dahua Lin",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-24T17:01:32.000Z",
            "submittedOnDailyAt": "2025-09-25T01:52:04.994Z",
            "title": "SIM-CoT: Supervised Implicit Chain-of-Thought",
            "submittedOnDailyBy": {
                "_id": "62eb70462f0f5e54df42f778",
                "avatarUrl": "/avatars/456049dba67638d3cdb330cdf383f272.svg",
                "isPro": false,
                "fullname": "Xilin Wei",
                "user": "Wiselnn",
                "type": "user"
            },
            "summary": "Implicit Chain-of-Thought (CoT) methods present a promising, token-efficient\nalternative to explicit CoT reasoning in Large Language Models (LLMs), but a\npersistent performance gap has limited the application of implicit CoT. We\nidentify a core latent instability issue by scaling the computational budget of\nimplicit CoT approaches: as we increase the number of implicit reasoning tokens\nto enhance performance, the training process often becomes unstable and\ncollapses. Our analysis reveals that this instability arises from the latent\nrepresentations becoming homogeneous and losing their semantic diversity, a\nfailure caused by insufficient step-level supervision in existing implicit CoT\napproaches. To address this issue, we propose SIM-CoT, a plug-and-play training\nmodule that introduces step-level supervision to stabilize and enrich the\nlatent reasoning space. Specifically, SIM-CoT employs an auxiliary decoder\nduring training to align each implicit token with its corresponding explicit\nreasoning step, ensuring that latent states capture distinct and meaningful\ninformation. The proposed auxiliary decoder is removed during inference,\npreserving the computational efficiency of implicit CoT methods with no added\noverhead. In addition, the auxiliary decoder affords interpretability of\nimplicit reasoning by projecting each latent token onto an explicit reasoning\nvocabulary, enabling per-step visualization of semantic roles and diagnosis.\nSIM-CoT significantly enhances both the in-domain accuracy and out-of-domain\nstability of various implicit CoT methods, boosting baselines like Coconut by\n+8.2% on GPT-2 and CODI by +3.0% on LLaMA-3.1 8B. Demonstrating strong\nscalability, SIM-CoT also surpasses the explicit CoT baseline on GPT-2 by 2.1%\nwith 2.3\\times greater token efficiency, while substantially closing the\nperformance gap on larger models like LLaMA-3.1 8B.",
            "upvotes": 24,
            "discussionId": "68d4b42136950a9dff1568d9",
            "githubRepo": "https://github.com/InternLM/SIM-CoT",
            "ai_summary": "SIM-CoT, a plug-and-play training module, introduces step-level supervision to stabilize and enrich the latent reasoning space of implicit Chain-of-Thought methods, enhancing their performance and efficiency.",
            "ai_keywords": [
                "implicit Chain-of-Thought",
                "explicit Chain-of-Thought",
                "Large Language Models",
                "latent instability",
                "step-level supervision",
                "SIM-CoT",
                "auxiliary decoder",
                "latent representations",
                "semantic diversity",
                "in-domain accuracy",
                "out-of-domain stability",
                "Coconut",
                "CODI",
                "GPT-2",
                "LLaMA-3.1 8B",
                "token efficiency"
            ],
            "githubStars": 28
        },
        "translation_title": "SIM-CoT: 감독된 암묵적 사고 과정",
        "purpose": "암묵적 Chain-of-Thought 방법의 성능 격차를 해소하고 안정성을 개선하기 위한 연구",
        "method": [
            "암묵적 CoT 방법의 계산 예산을 확대하여 핵심 잠재 불안정성 문제를 파악함(We identify a core latent instability issue by scaling the computational budget of implicit CoT approaches.)",
            "단계 수준의 감독을 도입하여 잠재 추론 공간을 안정화하고 풍부하게 하는 SIM-CoT를 제안함(we propose SIM-CoT, a plug-and-play training module that introduces step-level supervision to stabilize and enrich the latent reasoning space.)",
            "보조 디코더를 활용하여 각 암묵적 토큰을 대응하는 명시적 추론 단계와 정렬함(SIM-CoT employs an auxiliary decoder during training to align each implicit token with its corresponding explicit reasoning step.)"
        ],
        "conclusion": "SIM-CoT는 다양한 암묵적 CoT 방법의 정확도와 안정성을 크게 향상시켜, 기존 모델보다 성능을 개선함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2509.16990",
            "authors": [
                {
                    "_id": "68d4e0e836950a9dff156933",
                    "user": {
                        "_id": "644662145004f2cb3af08b27",
                        "avatarUrl": "/avatars/5f2af24c7410a5db46374d0b84fb479d.svg",
                        "isPro": false,
                        "fullname": "Avishai Elmakies",
                        "user": "avishai-elmakies",
                        "type": "user"
                    },
                    "name": "Avishai Elmakies",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-25T07:10:44.431Z",
                    "hidden": false
                },
                {
                    "_id": "68d4e0e836950a9dff156934",
                    "user": {
                        "_id": "643425b4a4c9c55871a7a02b",
                        "avatarUrl": "/avatars/eb2f357888159f5120bbf70a40cb089d.svg",
                        "isPro": false,
                        "fullname": "Hagai Aronowitz",
                        "user": "hagaia",
                        "type": "user"
                    },
                    "name": "Hagai Aronowitz",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-09-25T11:36:38.678Z",
                    "hidden": false
                },
                {
                    "_id": "68d4e0e836950a9dff156935",
                    "user": {
                        "_id": "62bedff7304b82a773bf8c1b",
                        "avatarUrl": "/avatars/f9e79dc196caa95c220127c6212e9944.svg",
                        "isPro": false,
                        "fullname": "Nimrod Shabtay",
                        "user": "NimrodShabtay1986",
                        "type": "user"
                    },
                    "name": "Nimrod Shabtay",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-25T07:10:41.442Z",
                    "hidden": false
                },
                {
                    "_id": "68d4e0e836950a9dff156936",
                    "name": "Eli Schwartz",
                    "hidden": false
                },
                {
                    "_id": "68d4e0e836950a9dff156937",
                    "user": {
                        "_id": "68b3fe80a9f319567d039ec0",
                        "avatarUrl": "/avatars/672f169213139d21c7767021a0110402.svg",
                        "isPro": false,
                        "fullname": "Ron Hoory",
                        "user": "rhoory",
                        "type": "user"
                    },
                    "name": "Ron Hoory",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-09-25T11:36:49.661Z",
                    "hidden": false
                },
                {
                    "_id": "68d4e0e836950a9dff156938",
                    "user": {
                        "_id": "63b7e09359060ca9f4c4de35",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b7e09359060ca9f4c4de35/0PH1dWNfcXTQ9H0QAeD91.jpeg",
                        "isPro": false,
                        "fullname": "Avihu Dekel",
                        "user": "Avihu",
                        "type": "user"
                    },
                    "name": "Avihu Dekel",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-09-25T11:36:56.726Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-21T09:09:36.000Z",
            "submittedOnDailyAt": "2025-09-25T05:04:00.310Z",
            "title": "Advancing Speech Understanding in Speech-Aware Language Models with GRPO",
            "submittedOnDailyBy": {
                "_id": "644662145004f2cb3af08b27",
                "avatarUrl": "/avatars/5f2af24c7410a5db46374d0b84fb479d.svg",
                "isPro": false,
                "fullname": "Avishai Elmakies",
                "user": "avishai-elmakies",
                "type": "user"
            },
            "summary": "In this paper, we introduce a Group Relative Policy Optimization (GRPO)-based\nmethod for training Speech-Aware Large Language Models (SALLMs) on open-format\nspeech understanding tasks, such as Spoken Question Answering and Automatic\nSpeech Translation. SALLMs have proven highly effective for speech\nunderstanding tasks. GRPO has recently gained traction for its efficiency in\ntraining LLMs, and prior work has explored its application to SALLMs, primarily\nin multiple-choice tasks. Building on this, we focus on open-format tasks that\nbetter reflect the generative abilities of the models. Our approach leverages\nGRPO with BLEU as the reward signal to optimize SALLMs, and we demonstrate\nempirically that it surpasses standard SFT across several key metrics. Finally,\nwe explore the potential of incorporating off-policy samples within GRPO for\nthese tasks, highlighting avenues for further improvement and further research.",
            "upvotes": 10,
            "discussionId": "68d4e0e836950a9dff156939",
            "ai_summary": "A Group Relative Policy Optimization (GRPO)-based method using BLEU as a reward signal outperforms standard SFT for open-format speech understanding tasks like Spoken Question Answering and Automatic Speech Translation.",
            "ai_keywords": [
                "Group Relative Policy Optimization",
                "GRPO",
                "Speech-Aware Large Language Models",
                "SALLMs",
                "Spoken Question Answering",
                "Automatic Speech Translation",
                "BLEU",
                "standard SFT",
                "off-policy samples"
            ]
        },
        "translation_title": "GRPO를 이용한 음성 인식을 위한 언어 모델의 발전",
        "purpose": "음성 인식 작업에서 Speech-Aware Large Language Models (SALLMs)의 성능을 개선하기 위한 방법론 연구",
        "method": [
            "Group Relative Policy Optimization (GRPO) 기반 방법을 도입하여 SALLMs를 훈련함(In this paper, we introduce a Group Relative Policy Optimization (GRPO)-based method for training Speech-Aware Large Language Models (SALLMs).)",
            "BLEU를 보상 신호로 활용하여 SALLMs 최적화(Our approach leverages GRPO with BLEU as the reward signal to optimize SALLMs.)",
            "기존의 SFT보다 여러 핵심 지표에서 뛰어난 성과를 보여줌(we demonstrate empirically that it surpasses standard SFT across several key metrics.)"
        ],
        "conclusion": "이 방법은 음성 인식 작업에서 SALLMs의 성능을 향상시키며, 향후 개선 및 연구 가능성을 제시함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Speech Understanding"
        ]
    },
    {
        "paper": {
            "id": "2509.19580",
            "authors": [
                {
                    "_id": "68d48efd36950a9dff1567d4",
                    "name": "Yanfang",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567d5",
                    "name": "Ye",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567d6",
                    "name": "Zheyuan Zhang",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567d7",
                    "user": {
                        "_id": "660c4dd73134c1a046d0bb23",
                        "avatarUrl": "/avatars/fbffd94ef6b2f60e0716b03301cdf9ee.svg",
                        "isPro": false,
                        "fullname": "Tianyi (Billy) Ma",
                        "user": "mtybilly",
                        "type": "user"
                    },
                    "name": "Tianyi Ma",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-25T07:11:12.087Z",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567d8",
                    "user": {
                        "_id": "659df2ea91519541cef3d42f",
                        "avatarUrl": "/avatars/cb8787ff43a32bd71b6b7bb2fe646f31.svg",
                        "isPro": false,
                        "fullname": "Zehong Wang",
                        "user": "ZehongWang",
                        "type": "user"
                    },
                    "name": "Zehong Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-25T07:11:14.638Z",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567d9",
                    "name": "Yiyang Li",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567da",
                    "name": "Shifu Hou",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567db",
                    "user": {
                        "_id": "6481a16f70ac5e1968a7bb97",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6481a16f70ac5e1968a7bb97/ith2d4CuhfJH1CeU92wzE.jpeg",
                        "isPro": false,
                        "fullname": "Weixiang Sun",
                        "user": "Sweson",
                        "type": "user"
                    },
                    "name": "Weixiang Sun",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-25T07:11:09.844Z",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567dc",
                    "name": "Kaiwen Shi",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567dd",
                    "name": "Yijun Ma",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567de",
                    "name": "Wei Song",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567df",
                    "name": "Ahmed Abbasi",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567e0",
                    "name": "Ying Cheng",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567e1",
                    "name": "Jane Cleland-Huang",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567e2",
                    "name": "Steven Corcelli",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567e3",
                    "name": "Patricia Culligan",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567e4",
                    "name": "Robert Goulding",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567e5",
                    "name": "Ming Hu",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567e6",
                    "name": "Ting Hua",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567e7",
                    "user": {
                        "_id": "62eaca4e7008acb2e95f8686",
                        "avatarUrl": "/avatars/8062c21f509e315d9df023d0e2e33e84.svg",
                        "isPro": false,
                        "fullname": "John Lalor",
                        "user": "lalor",
                        "type": "user"
                    },
                    "name": "John Lalor",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-09-25T11:42:50.724Z",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567e8",
                    "name": "Fang Liu",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567e9",
                    "name": "Tengfei Luo",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567ea",
                    "name": "Ed Maginn",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567eb",
                    "name": "Nuno Moniz",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567ec",
                    "name": "Jason Rohr",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567ed",
                    "name": "Brett Savoie",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567ee",
                    "name": "Daniel Slate",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567ef",
                    "name": "Tom Stapleford",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567f0",
                    "name": "Matthew Webber",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567f1",
                    "name": "Olaf Wiest",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567f2",
                    "name": "Johnny Zhang",
                    "hidden": false
                },
                {
                    "_id": "68d48efd36950a9dff1567f3",
                    "name": "Nitesh Chawla",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-23T21:09:24.000Z",
            "submittedOnDailyAt": "2025-09-25T02:35:24.658Z",
            "title": "LLMs4All: A Review on Large Language Models for Research and\n  Applications in Academic Disciplines",
            "submittedOnDailyBy": {
                "_id": "6481a16f70ac5e1968a7bb97",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6481a16f70ac5e1968a7bb97/ith2d4CuhfJH1CeU92wzE.jpeg",
                "isPro": false,
                "fullname": "Weixiang Sun",
                "user": "Sweson",
                "type": "user"
            },
            "summary": "Cutting-edge Artificial Intelligence (AI) techniques keep reshaping our view\nof the world. For example, Large Language Models (LLMs) based applications such\nas ChatGPT have shown the capability of generating human-like conversation on\nextensive topics. Due to the impressive performance on a variety of\nlanguage-related tasks (e.g., open-domain question answering, translation, and\ndocument summarization), one can envision the far-reaching impacts that can be\nbrought by the LLMs with broader real-world applications (e.g., customer\nservice, education and accessibility, and scientific discovery). Inspired by\ntheir success, this paper will offer an overview of state-of-the-art LLMs and\ntheir integration into a wide range of academic disciplines, including: (1)\narts, letters, and law (e.g., history, philosophy, political science, arts and\narchitecture, law), (2) economics and business (e.g., finance, economics,\naccounting, marketing), and (3) science and engineering (e.g., mathematics,\nphysics and mechanical engineering, chemistry and chemical engineering, life\nsciences and bioengineering, earth sciences and civil engineering, computer\nscience and electrical engineering). Integrating humanity and technology, in\nthis paper, we will explore how LLMs are shaping research and practice in these\nfields, while also discussing key limitations, open challenges, and future\ndirections in the era of generative AI. The review of how LLMs are engaged\nacross disciplines-along with key observations and insights-can help\nresearchers and practitioners interested in exploiting LLMs to advance their\nworks in diverse real-world applications.",
            "upvotes": 8,
            "discussionId": "68d48efe36950a9dff1567f4",
            "ai_summary": "Large Language Models are transforming various academic disciplines by enabling human-like conversation and enhancing performance in language-related tasks, while also presenting limitations and future challenges.",
            "ai_keywords": [
                "Large Language Models",
                "LLMs",
                "open-domain question answering",
                "translation",
                "document summarization",
                "customer service",
                "education",
                "accessibility",
                "scientific discovery",
                "generative AI"
            ]
        },
        "translation_title": "LLMs4All: 연구 및 학문 분야에서의 대형 언어 모델에 관한 리뷰",
        "purpose": "대형 언어 모델(LLMs)의 최신 동향과 연구 및 실제 응용 분야에서의 통합에 대해 개관하기 위함",
        "method": [
            "대형 언어 모델의 성공을 바탕으로 다양한 학문 분야에서의 응용을 탐구함(Inspired by their success, this paper will offer an overview of state-of-the-art LLMs and their integration into a wide range of academic disciplines.)",
            "예술, 경제, 과학 등 다양한 분야에서의 LLMs의 역할을 논의함(we will explore how LLMs are shaping research and practice in these fields.)",
            "LLMs의 한계와 도전과제, 미래 방향 등을 논의함(while also discussing key limitations, open challenges, and future directions in the era of generative AI.)"
        ],
        "conclusion": "LLMs에 대한 리뷰는 연구자와 실무자들이 다양한 실제 응용 작업을 발전시키는 데 도움이 될 수 있는 중요한 통찰을 제공함.",
        "keywords": [
            "Large Language Models",
            "Natural Language Processing",
            "Multimodal Learning"
        ]
    }
]