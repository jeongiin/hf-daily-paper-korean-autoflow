[
    {
        "paper": {
            "id": "2504.13837",
            "authors": [
                {
                    "_id": "6805b9ec7c5fa8020f595642",
                    "name": "Yang Yue",
                    "hidden": false
                },
                {
                    "_id": "6805b9ec7c5fa8020f595643",
                    "name": "Zhiqi Chen",
                    "hidden": false
                },
                {
                    "_id": "6805b9ec7c5fa8020f595644",
                    "name": "Rui Lu",
                    "hidden": false
                },
                {
                    "_id": "6805b9ec7c5fa8020f595645",
                    "name": "Andrew Zhao",
                    "hidden": false
                },
                {
                    "_id": "6805b9ec7c5fa8020f595646",
                    "name": "Zhaokai Wang",
                    "hidden": false
                },
                {
                    "_id": "6805b9ec7c5fa8020f595647",
                    "name": "Yang Yue",
                    "hidden": false
                },
                {
                    "_id": "6805b9ec7c5fa8020f595648",
                    "name": "Shiji Song",
                    "hidden": false
                },
                {
                    "_id": "6805b9ec7c5fa8020f595649",
                    "name": "Gao Huang",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/649d475111592b1a765ac1a3/2KWQqFdVDUCAu-kSu87fa.jpeg",
                "https://cdn-uploads.huggingface.co/production/uploads/649d475111592b1a765ac1a3/rF4cAa6DAI3EaejDV_dgG.mp4"
            ],
            "publishedAt": "2025-04-18T17:59:56.000Z",
            "submittedOnDailyAt": "2025-04-21T01:54:36.096Z",
            "title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in\n  LLMs Beyond the Base Model?",
            "submittedOnDailyBy": {
                "_id": "649d475111592b1a765ac1a3",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/649d475111592b1a765ac1a3/rjORJjErJq-mthghan08U.jpeg",
                "isPro": false,
                "fullname": "Yang Yue",
                "user": "Yang130",
                "type": "user"
            },
            "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) has recently\ndemonstrated notable success in enhancing the reasoning capabilities of LLMs,\nparticularly in mathematics and programming tasks. It is widely believed that\nRLVR enables LLMs to continuously self-improve, thus acquiring novel reasoning\nabilities that exceed corresponding base models' capacity. In this study,\nhowever, we critically re-examines this assumption by measuring the\npass@k metric with large values of k to explore the reasoning\ncapability boundary of the models across a wide range of model families and\nbenchmarks. Surprisingly, the RL does not, in fact, elicit fundamentally\nnew reasoning patterns. While RL-trained models outperform their base models at\nsmaller values of k (\\eg, k=1), base models can achieve a comparable or\neven higher pass@k score compared to their RL counterparts at large k\nvalues. The reasoning paths generated by RL-trained models are already included\nin the base models' sampling distribution, suggesting that most reasoning\nabilities manifested in RL-trained models are already obtained by base models.\nFurther analysis shows that RL training boosts the performance by biasing the\nmodel's output distribution toward paths that are more likely to yield rewards,\ntherefore sampling correct responses more efficiently. But this also results in\na narrower reasoning capability boundary compared to base models. Similar\nresults are observed in visual reasoning tasks trained with RLVR. Moreover, we\nfind that distillation can genuinely introduce new knowledge into the model,\ndifferent from RLVR. These findings underscore a critical limitation of RLVR in\nadvancing LLM reasoning abilities which requires us to fundamentally rethink\nthe impact of RL training in reasoning LLMs and the need of a better paradigm.\nProject Page: https://limit-of-RLVR.github.io",
            "upvotes": 47,
            "discussionId": "6805b9ed7c5fa8020f59568c",
            "projectPage": "https://limit-of-rlvr.github.io/",
            "githubRepo": "https://github.com/LeapLabTHU/limit-of-RLVR",
            "ai_keywords": [
                "Reinforcement Learning",
                "Verifiable Rewards",
                "RLVR",
                "LLMs (Large Language Models)",
                "reasoning capabilities",
                "mathematics",
                "programming tasks",
                "pass@\\textit{k}",
                "benchmark",
                "RL-trained models",
                "base models",
                "reasoning paths",
                "sampling distribution",
                "performance",
                "biasing",
                "output distribution",
                "visual reasoning tasks",
                "distillation"
            ]
        },
        "translation_title": "강화 학습이 LLM의 추론 능력을 기본 모델 이상으로 자극하는가?",
        "purpose": "LLM의 추론 능력 향상에 대한 강화 학습의 실제 효과를 평가하고 재조명",
        "method": [
            "패스@k 메트릭을 측정하여 다양한 모델 패밀리와 벤치마크에서 모델의 추론 능력 경계를 탐구함(we critically re-examines this assumption by measuring the pass@k metric with large values of k to explore the reasoning capability boundary of the models across a wide range of model families and benchmarks.)",
            "RL 훈련 모델이 기본 모델보다 낮은 k 값에서는 성능이 우수하지만, 큰 k 값에서는 비슷하거나 더 나은 점수를 얻는 사례를 확인함(while RL-trained models outperform their base models at smaller values of k, base models can achieve a comparable or even higher pass@k score compared to their RL counterparts at large k values.)",
            "RL 훈련이 모델 출력 분포를 보상에 더 유리한 경로로 편향시키는 것을 분석하며, 이는 모델의 성능을 향상시키지만 추론 능력 경계를 좁히는 결과를 초래함(biasing the model's output distribution toward paths that are more likely to yield rewards, therefore sampling correct responses more efficiently.)"
        ],
        "conclusion": "강화 학습이 LLM의 추론 능력 향상에 있어 중요한 한계를 가지고 있음을 보여주며, LLM의 훈련에서 강화 학습의 영향을 재고할 필요가 있음.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2504.13835",
            "authors": [
                {
                    "_id": "6805b38355d3c792e1a9d0dd",
                    "name": "Yicheng Chen",
                    "hidden": false
                },
                {
                    "_id": "6805b38355d3c792e1a9d0de",
                    "name": "Yining Li",
                    "hidden": false
                },
                {
                    "_id": "6805b38355d3c792e1a9d0df",
                    "name": "Kai Hu",
                    "hidden": false
                },
                {
                    "_id": "6805b38355d3c792e1a9d0e0",
                    "name": "Zerun Ma",
                    "hidden": false
                },
                {
                    "_id": "6805b38355d3c792e1a9d0e1",
                    "name": "Haochen Ye",
                    "hidden": false
                },
                {
                    "_id": "6805b38355d3c792e1a9d0e2",
                    "name": "Kai Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-04-18T17:59:46.000Z",
            "submittedOnDailyAt": "2025-04-21T01:39:08.191Z",
            "title": "MIG: Automatic Data Selection for Instruction Tuning by Maximizing\n  Information Gain in Semantic Space",
            "submittedOnDailyBy": {
                "_id": "649988726677f66c2b486392",
                "avatarUrl": "/avatars/b649a77370660e129726e29504daba34.svg",
                "isPro": false,
                "fullname": "Yining Li",
                "user": "ly015",
                "type": "user"
            },
            "summary": "Data quality and diversity are key to the construction of effective\ninstruction-tuning datasets. % With the increasing availability of open-source\ninstruction-tuning datasets, it is advantageous to automatically select\nhigh-quality and diverse subsets from a vast amount of data. % Existing methods\ntypically prioritize instance quality and use heuristic rules to maintain\ndiversity. % However, this absence of a comprehensive view of the entire\ncollection often leads to suboptimal results. % Moreover, heuristic rules\ngenerally focus on distance or clustering within the embedding space, which\nfails to accurately capture the intent of complex instructions in the semantic\nspace. % To bridge this gap, we propose a unified method for quantifying the\ninformation content of datasets. This method models the semantic space by\nconstructing a label graph and quantifies diversity based on the distribution\nof information within the graph. % Based on such a measurement, we further\nintroduce an efficient sampling method that selects data samples iteratively to\nMaximize the Information Gain (MIG) in semantic\nspace. % Experiments on various datasets and base models demonstrate that MIG\nconsistently outperforms state-of-the-art methods. % Notably, the model\nfine-tuned with 5\\% Tulu3 data sampled by MIG achieves comparable performance\nto the official SFT model trained on the full dataset, with improvements of\n+5.73\\% on AlpacaEval and +6.89\\% on Wildbench.",
            "upvotes": 28,
            "discussionId": "6805b38555d3c792e1a9d155",
            "projectPage": "https://yichengchen24.github.io/projects/mig",
            "githubRepo": "https://github.com/yichengchen24/MIG",
            "ai_keywords": [
                "label graph",
                "semantic space",
                "information content",
                "Maximize the Information Gain (MIG)"
            ]
        },
        "translation_title": "MIG: 의미 공간에서 정보 이득 극대화를 통한 자동 데이터 선택",
        "purpose": "효과적인 instruction-tuning 데이터셋 구축을 위해 높은 품질과 다양성을 갖춘 데이터의 자동 선택을 연구",
        "method": [
            "데이터셋의 정보 내용을 정량화하는 방법을 제안함(we propose a unified method for quantifying the information content of datasets.)",
            "라벨 그래프를 구축하여 의미 공간을 모델링하고, 그래프 내 정보 분포를 기반으로 다양성을 정량화함(This method models the semantic space by constructing a label graph and quantifies diversity based on the distribution of information within the graph.)",
            "정보 이득을 극대화하기 위해 데이터를 반복적으로 선택하는 효율적인 샘플링 방법을 도입함(we further introduce an efficient sampling method that selects data samples iteratively to Maximize the Information Gain (MIG) in semantic space.)",
            "여러 데이터셋과 기본 모델을 대상으로 실험을 수행하여 MIG의 우수성을 입증함(Experiments on various datasets and base models demonstrate that MIG consistently outperforms state-of-the-art methods.)"
        ],
        "conclusion": "MIG는 최첨단 방법들보다 높은 성능을 발휘하며, 5%의 Tulu3 데이터를 사용해 미세 조정한 모델이 전체 데이터셋으로 훈련한 공식 SFT 모델과 유사한 성능을 달성함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2504.11544",
            "authors": [
                {
                    "_id": "6804ca9fd8538baa1c39ca93",
                    "name": "Tianyang Xu",
                    "hidden": false
                },
                {
                    "_id": "6804ca9fd8538baa1c39ca94",
                    "name": "Haojie Zheng",
                    "hidden": false
                },
                {
                    "_id": "6804ca9fd8538baa1c39ca95",
                    "name": "Chengze Li",
                    "hidden": false
                },
                {
                    "_id": "6804ca9fd8538baa1c39ca96",
                    "name": "Haoxiang Chen",
                    "hidden": false
                },
                {
                    "_id": "6804ca9fd8538baa1c39ca97",
                    "name": "Yixin Liu",
                    "hidden": false
                },
                {
                    "_id": "6804ca9fd8538baa1c39ca98",
                    "name": "Ruoxi Chen",
                    "hidden": false
                },
                {
                    "_id": "6804ca9fd8538baa1c39ca99",
                    "name": "Lichao Sun",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-04-15T18:24:00.000Z",
            "submittedOnDailyAt": "2025-04-21T01:38:46.380Z",
            "title": "NodeRAG: Structuring Graph-based RAG with Heterogeneous Nodes",
            "submittedOnDailyBy": {
                "_id": "6610fb736504d9bed5890d58",
                "avatarUrl": "/avatars/832b186fc51c639f1709025d442b3f4b.svg",
                "isPro": false,
                "fullname": "Tianyang Xu",
                "user": "TerryXu666",
                "type": "user"
            },
            "summary": "Retrieval-augmented generation (RAG) empowers large language models to access\nexternal and private corpus, enabling factually consistent responses in\nspecific domains. By exploiting the inherent structure of the corpus,\ngraph-based RAG methods further enrich this process by building a knowledge\ngraph index and leveraging the structural nature of graphs. However, current\ngraph-based RAG approaches seldom prioritize the design of graph structures.\nInadequately designed graph not only impede the seamless integration of diverse\ngraph algorithms but also result in workflow inconsistencies and degraded\nperformance. To further unleash the potential of graph for RAG, we propose\nNodeRAG, a graph-centric framework introducing heterogeneous graph structures\nthat enable the seamless and holistic integration of graph-based methodologies\ninto the RAG workflow. By aligning closely with the capabilities of LLMs, this\nframework ensures a fully cohesive and efficient end-to-end process. Through\nextensive experiments, we demonstrate that NodeRAG exhibits performance\nadvantages over previous methods, including GraphRAG and LightRAG, not only in\nindexing time, query time, and storage efficiency but also in delivering\nsuperior question-answering performance on multi-hop benchmarks and open-ended\nhead-to-head evaluations with minimal retrieval tokens. Our GitHub repository\ncould be seen at https://github.com/Terry-Xu-666/NodeRAG.",
            "upvotes": 17,
            "discussionId": "6804caa0d8538baa1c39cac2",
            "projectPage": "https://terry-xu-666.github.io/NodeRAG_web/",
            "githubRepo": "https://github.com/Terry-Xu-666/NodeRAG",
            "ai_keywords": [
                "Retrieval-augmented generation (RAG)",
                "external and private corpus",
                "factually consistent responses",
                "knowledge graph index",
                "graph-based RAG methods",
                "heterogeneous graph structures",
                "seamless and holistic integration",
                "end-to-end process",
                "question-answering performance",
                "multi-hop benchmarks",
                "open-ended head-to-head evaluations",
                "retrieval tokens"
            ]
        },
        "translation_title": "NodeRAG: 이종 노드를 활용한 그래프 기반 RAG 구조화",
        "purpose": "RAG 프로세스에 그래프 기반 방법론을 통합하기 위한 이종 그래프 구조를 제안하여 성능 개선",
        "method": [
            "NodeRAG라는 그래프 중심 프레임워크를 도입하여 이종 그래프 구조를 생성함(we propose NodeRAG, a graph-centric framework introducing heterogeneous graph structures)",
            "이 프레임워크는 LLM의 능력과 밀접하게 연계되어 RAG 작업 흐름의 통합을 촉진함(By aligning closely with the capabilities of LLMs, this framework ensures a fully cohesive and efficient end-to-end process.)",
            "광범위한 실험을 통해 NodeRAG가 이전 방법 대비 성능 이점을 보여줌(Through extensive experiments, we demonstrate that NodeRAG exhibits performance advantages over previous methods)"
        ],
        "conclusion": "NodeRAG는 이전의 GraphRAG 및 LightRAG보다 인덱싱 시간, 쿼리 시간, 저장 효율성에서 우수하며, 다양한 질문-응답 성능을 제공함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2504.11833",
            "authors": [
                {
                    "_id": "6805bb01747a412bca737b53",
                    "name": "Changjiang Gao",
                    "hidden": false
                },
                {
                    "_id": "6805bb01747a412bca737b54",
                    "name": "Xu Huang",
                    "hidden": false
                },
                {
                    "_id": "6805bb01747a412bca737b55",
                    "name": "Wenhao Zhu",
                    "hidden": false
                },
                {
                    "_id": "6805bb01747a412bca737b56",
                    "name": "Shujian Huang",
                    "hidden": false
                },
                {
                    "_id": "6805bb01747a412bca737b57",
                    "name": "Lei Li",
                    "hidden": false
                },
                {
                    "_id": "6805bb01747a412bca737b58",
                    "name": "Fei Yuan",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-04-16T07:45:10.000Z",
            "submittedOnDailyAt": "2025-04-21T01:57:09.327Z",
            "title": "Could Thinking Multilingually Empower LLM Reasoning?",
            "submittedOnDailyBy": {
                "_id": "65fed45b08d35929362dd651",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65fed45b08d35929362dd651/KLMxsyRN6_HhCZP1iDw6K.png",
                "isPro": false,
                "fullname": "FeiYuan",
                "user": "FeYuan",
                "type": "user"
            },
            "summary": "Previous work indicates that large language models exhibit a significant\n\"English bias\", i.e. they often perform better when tasks are presented in\nEnglish. Interestingly, we have observed that using certain other languages in\nreasoning tasks can yield better performance than English. However, this\nphenomenon remains under-explored. In this paper, we explore the upper bound of\nharnessing multilingualism in reasoning tasks, suggesting that multilingual\nreasoning promises significantly (by nearly 10 Acc@k points) and robustly\n(tolerance for variations in translation quality and language choice) higher\nupper bounds than English-only reasoning. Besides analyzing the reason behind\nthe upper bound and challenges in reaching it, we also find that common answer\nselection methods cannot achieve this upper bound, due to their limitations and\nbiases. These insights could pave the way for future research aimed at fully\nharnessing the potential of multilingual reasoning in LLMs.",
            "upvotes": 14,
            "discussionId": "6805bb02747a412bca737b7e",
            "githubRepo": "https://github.com/CONE-MT/multilingual_reasoning"
        },
        "translation_title": "다국어 사용이 LLM 추론을 강화할 수 있을까?",
        "purpose": "다국어 추론이 영어 단일 추론보다 더 높은 성능을 발휘할 가능성을 탐구하고 이를 최대한 활용하기 위한 연구",
        "method": [
            "여러 언어를 사용한 추론 작업의 성능을 분석하고 영어 단일 언어 사용과 비교함(we explore the upper bound of harnessing multilingualism in reasoning tasks).",
            "다국어 추론이 영어-only 추론보다 약 10 Acc@k 포인트 이상 높은 성과를 가져온다는 주장을 제시함(multilingual reasoning promises significantly higher upper bounds than English-only reasoning).",
            "기존의 일반적인 답변 선택 방법의 한계와 편향을 분석하여, 이 방법들이 다국어 추론의 최상한을 달성하지 못한다는 것을 발견함(common answer selection methods cannot achieve this upper bound)."
        ],
        "conclusion": "다국어 추론은 LLM의 잠재력을 완전히 활용하는 방향으로 연구를 위한 기초를 마련할 수 있음.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2504.10823",
            "authors": [
                {
                    "_id": "68003da4c771c307fec04da7",
                    "user": {
                        "_id": "66d079d94b3b38cefaf1dc4e",
                        "avatarUrl": "/avatars/f680a19fb7b8e52c811eb6df218a2cea.svg",
                        "isPro": false,
                        "fullname": "Lee",
                        "user": "Ayoung01",
                        "type": "user"
                    },
                    "name": "Ayoung Lee",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-04-20T15:03:37.028Z",
                    "hidden": false
                },
                {
                    "_id": "68003da4c771c307fec04da8",
                    "name": "Ryan Sungmo Kwon",
                    "hidden": false
                },
                {
                    "_id": "68003da4c771c307fec04da9",
                    "name": "Peter Railton",
                    "hidden": false
                },
                {
                    "_id": "68003da4c771c307fec04daa",
                    "name": "Lu Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-04-15T02:54:16.000Z",
            "submittedOnDailyAt": "2025-04-21T11:29:39.399Z",
            "title": "CLASH: Evaluating Language Models on Judging High-Stakes Dilemmas from\n  Multiple Perspectives",
            "submittedOnDailyBy": {
                "_id": "66d079d94b3b38cefaf1dc4e",
                "avatarUrl": "/avatars/f680a19fb7b8e52c811eb6df218a2cea.svg",
                "isPro": false,
                "fullname": "Lee",
                "user": "Ayoung01",
                "type": "user"
            },
            "summary": "Navigating high-stakes dilemmas involving conflicting values is challenging\neven for humans, let alone for AI. Yet prior work in evaluating the reasoning\ncapabilities of large language models (LLMs) in such situations has been\nlimited to everyday scenarios. To close this gap, this work first introduces\nCLASH (Character perspective-based LLM Assessments in Situations with\nHigh-stakes), a meticulously curated dataset consisting of 345 high-impact\ndilemmas along with 3,795 individual perspectives of diverse values. In\nparticular, we design CLASH in a way to support the study of critical aspects\nof value-based decision-making processes which are missing from prior work,\nincluding understanding decision ambivalence and psychological discomfort as\nwell as capturing the temporal shifts of values in characters' perspectives. By\nbenchmarking 10 open and closed frontier models, we uncover several key\nfindings. (1) Even the strongest models, such as GPT-4o and Claude-Sonnet,\nachieve less than 50% accuracy in identifying situations where the decision\nshould be ambivalent, while they perform significantly better in clear-cut\nscenarios. (2) While LLMs reasonably predict psychological discomfort as marked\nby human, they inadequately comprehend perspectives involving value shifts,\nindicating a need for LLMs to reason over complex values. (3) Our experiments\nalso reveal a significant correlation between LLMs' value preferences and their\nsteerability towards a given value. (4) Finally, LLMs exhibit greater\nsteerability when engaged in value reasoning from a third-party perspective,\ncompared to a first-person setup, though certain value pairs benefit uniquely\nfrom the first-person framing.",
            "upvotes": 8,
            "discussionId": "68003da5c771c307fec04df1",
            "ai_keywords": [
                "large language models (LLMs)",
                "CLASH (Character perspective-based LLM Assessments in Situations with High-stakes)",
                "decision ambivalence",
                "psychological discomfort",
                "value shifts"
            ]
        },
        "translation_title": "CLASH: 고위험 딜레마를 다각적 관점에서 평가하는 언어 모델 평가",
        "purpose": "AI가 고위험 딜레마에서 인간의 가치 충돌을 다루는 능력을 평가하기 위한 데이터세트 구축",
        "method": [
            "345개의 고위험 딜레마와 3,795개의 다양한 가치 관점을 포함하는 CLASH 데이터세트를 제시함(To close this gap, this work first introduces CLASH, a meticulously curated dataset consisting of 345 high-impact dilemmas along with 3,795 individual perspectives of diverse values.)",
            "가치 기반 의사결정 과정의 중요한 측면을 연구하기 위해 CLASH를 설계함(we design CLASH in a way to support the study of critical aspects of value-based decision-making processes which are missing from prior work.)",
            "10개의 개방형 및 폐쇄형 모델을 벤치마킹하고 여러 주요 발견을 밝혀냄(By benchmarking 10 open and closed frontier models, we uncover several key findings.)"
        ],
        "conclusion": "언어 모델은 가치 충돌 상황에서의 독립적 결정을 충분히 이해하지 못하며, 가치 관점의 변화에 대한 이해가 필요하다는 것을 발견함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    }
]