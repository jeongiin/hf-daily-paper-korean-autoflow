[
    {
        "paper": {
            "id": "2601.06789",
            "authors": [
                {
                    "_id": "69671036c5e371f6b235d143",
                    "user": {
                        "_id": "692881094c3f4293dfe29e3d",
                        "avatarUrl": "/avatars/bddfaae8041a45498d46ef65ba17c920.svg",
                        "isPro": false,
                        "fullname": "qihao wang",
                        "user": "jimson991",
                        "type": "user"
                    },
                    "name": "Qihao Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-14T12:48:07.079Z",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d144",
                    "user": {
                        "_id": "64b74fca17570fdff9b2aded",
                        "avatarUrl": "/avatars/8b3519a7011af52dadc87ffef700c77c.svg",
                        "isPro": false,
                        "fullname": "Ziming Cheng",
                        "user": "cadche",
                        "type": "user"
                    },
                    "name": "Ziming Cheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-14T12:48:13.370Z",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d145",
                    "user": {
                        "_id": "6513ee3c9af40a65586b43f5",
                        "avatarUrl": "/avatars/815ed3876cefa12b25bf955edcbf71a3.svg",
                        "isPro": false,
                        "fullname": "shuo zhang",
                        "user": "shuozhang",
                        "type": "user"
                    },
                    "name": "Shuo Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-14T12:48:18.640Z",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d146",
                    "name": "Fan Liu",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d147",
                    "name": "Rui Xu",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d148",
                    "name": "Heng Lian",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d149",
                    "user": {
                        "_id": "65bb3c545a5dbabc818e9044",
                        "avatarUrl": "/avatars/4c239557bd5e33179cbf4f3a440bbf33.svg",
                        "isPro": false,
                        "fullname": "Kunyi Wang",
                        "user": "KunyiWang",
                        "type": "user"
                    },
                    "name": "Kunyi Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-14T12:48:25.411Z",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d14a",
                    "user": {
                        "_id": "64084fa192033c150738e4f2",
                        "avatarUrl": "/avatars/dfff2216eb235c635e5abe6fda3084f0.svg",
                        "isPro": false,
                        "fullname": "Yu_xm",
                        "user": "Yu2020",
                        "type": "user"
                    },
                    "name": "Xiaoming Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-14T12:48:47.145Z",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d14b",
                    "name": "Jianghao Yin",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d14c",
                    "name": "Sen Hu",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d14d",
                    "name": "Yue Hu",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d14e",
                    "user": {
                        "_id": "64803e5dc57f629056c601f1",
                        "avatarUrl": "/avatars/a9e9c97c70714e3a29bef2cf929ee6b3.svg",
                        "isPro": false,
                        "fullname": "Shaolei Zhang",
                        "user": "zhangshaolei",
                        "type": "user"
                    },
                    "name": "Shaolei Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-14T12:49:13.491Z",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d14f",
                    "name": "Yanbing Liu",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d150",
                    "user": {
                        "_id": "6874f7f0f8e67e9b5714adf2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/g2bltqJmCR7MY3zEaQHr6.png",
                        "isPro": false,
                        "fullname": "RongHao Chen",
                        "user": "SuPA4ki",
                        "type": "user"
                    },
                    "name": "Ronghao Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-14T12:49:02.800Z",
                    "hidden": false
                },
                {
                    "_id": "69671036c5e371f6b235d151",
                    "user": {
                        "_id": "6603d56ab4344a2b07cd6d21",
                        "avatarUrl": "/avatars/1569bb60166532317c85e80da722ba1c.svg",
                        "isPro": false,
                        "fullname": "Huacan Wang",
                        "user": "Huacan-Wang",
                        "type": "user"
                    },
                    "name": "Huacan Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-14T12:48:57.426Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-11T06:41:26.000Z",
            "submittedOnDailyAt": "2026-01-14T01:40:39.607Z",
            "title": "MemGovern: Enhancing Code Agents through Learning from Governed Human Experiences",
            "submittedOnDailyBy": {
                "_id": "64084fa192033c150738e4f2",
                "avatarUrl": "/avatars/dfff2216eb235c635e5abe6fda3084f0.svg",
                "isPro": false,
                "fullname": "Yu_xm",
                "user": "Yu2020",
                "type": "user"
            },
            "summary": "While autonomous software engineering (SWE) agents are reshaping programming paradigms, they currently suffer from a \"closed-world\" limitation: they attempt to fix bugs from scratch or solely using local context, ignoring the immense historical human experience available on platforms like GitHub. Accessing this open-world experience is hindered by the unstructured and fragmented nature of real-world issue-tracking data. In this paper, we introduce MemGovern, a framework designed to govern and transform raw GitHub data into actionable experiential memory for agents. MemGovern employs experience governance to convert human experience into agent-friendly experience cards and introduces an agentic experience search strategy that enables logic-driven retrieval of human expertise. By producing 135K governed experience cards, MemGovern achieves a significant performance boost, improving resolution rates on the SWE-bench Verified by 4.65%. As a plug-in approach, MemGovern provides a solution for agent-friendly memory infrastructure.",
            "upvotes": 53,
            "discussionId": "69671036c5e371f6b235d152",
            "githubRepo": "https://github.com/QuantaAlpha/MemGovern",
            "githubRepoAddedBy": "user",
            "ai_summary": "MemGovern framework transforms unstructured GitHub data into structured experiential memory for autonomous software engineering agents, improving bug resolution rates through enhanced experience retrieval.",
            "ai_keywords": [
                "autonomous software engineering",
                "SWE agents",
                "closed-world limitation",
                "open-world experience",
                "GitHub",
                "experience governance",
                "experience cards",
                "agentic experience search",
                "SWE-bench Verified"
            ],
            "githubStars": 11
        },
        "translation_title": "MemGovern: 인간 경험 학습을 통한 코드 에이전트 강화",
        "purpose": "GitHub의 방대한 인간 경험을 활용하여 코드 에이전트의 버그 수정 성능을 향상시키기 위한 프레임워크 개발",
        "method": [
            "MemGovern을 도입하여 GitHub 데이터를 행동 가능한 경험 메모리로 변환함.(In this paper, we introduce MemGovern, a framework designed to govern and transform raw GitHub data into actionable experiential memory for agents.)",
            "경험 거버넌스를 통해 인간 경험을 에이전트 친화적인 경험 카드로 변환함.(MemGovern employs experience governance to convert human experience into agent-friendly experience cards.)",
            "논리 기반의 인간 전문 지식 검색 전략을 도입하여 에이전트가 효율적으로 경험을 검색할 수 있도록 함.(and introduces an agentic experience search strategy that enables logic-driven retrieval of human expertise.)"
        ],
        "conclusion": "MemGovern은 135K의 경험 카드를 생성하여 SWE-bench에서 4.65% 성능 향상을 달성하며 에이전트 친화적인 메모리 구조에 대한 솔루션을 제공함.",
        "keywords": [
            "Natural Language Processing",
            "Robotics",
            "Image Understanding"
        ]
    },
    {
        "paper": {
            "id": "2601.07022",
            "authors": [
                {
                    "_id": "6966474587c71000b5a910d2",
                    "user": {
                        "_id": "65446c938737c799e9ad6f83",
                        "avatarUrl": "/avatars/6ade251e01442b14cbf8cd7888358fd1.svg",
                        "isPro": false,
                        "fullname": "Sungrae Park",
                        "user": "sungrae-park",
                        "type": "user"
                    },
                    "name": "Sungrae Park",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-14T12:41:08.385Z",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910d3",
                    "name": "Sanghoon Kim",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910d4",
                    "name": "Jungho Cho",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910d5",
                    "name": "Gyoungjin Gim",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910d6",
                    "name": "Dawoon Jung",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910d7",
                    "name": "Mikyoung Cha",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910d8",
                    "name": "Eunhae Choo",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910d9",
                    "name": "Taekgyu Hong",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910da",
                    "name": "Minbyul Jeong",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910db",
                    "name": "SeHwan Joo",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910dc",
                    "name": "Minsoo Khang",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910dd",
                    "name": "Eunwon Kim",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910de",
                    "name": "Minjeong Kim",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910df",
                    "name": "Sujeong Kim",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910e0",
                    "name": "Yunsu Kim",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910e1",
                    "name": "Hyeonju Lee",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910e2",
                    "name": "Seunghyun Lee",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910e3",
                    "name": "Sukyung Lee",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910e4",
                    "name": "Siyoung Park",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910e5",
                    "name": "Gyungin Shin",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910e6",
                    "user": {
                        "_id": "64f04fa29a957782e2224dea",
                        "avatarUrl": "/avatars/db853c30ceb59ddabc9a83dc25845690.svg",
                        "isPro": false,
                        "fullname": "Inseo Song",
                        "user": "SSON9",
                        "type": "user"
                    },
                    "name": "Inseo Song",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-14T09:52:53.501Z",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910e7",
                    "name": "Wonho Song",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910e8",
                    "name": "Seonghoon Yang",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910e9",
                    "user": {
                        "_id": "66e0d4bf290df82f137de44c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66e0d4bf290df82f137de44c/RJ43RxY56_OvZmauF88Tw.jpeg",
                        "isPro": false,
                        "fullname": "Kyle Yi",
                        "user": "younatics",
                        "type": "user"
                    },
                    "name": "Seungyoun Yi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-14T12:42:43.424Z",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910ea",
                    "name": "Sanghoon Yoon",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910eb",
                    "name": "Jeonghyun Ko",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910ec",
                    "name": "Seyoung Song",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910ed",
                    "name": "Keunwoo Choi",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910ee",
                    "name": "Hwalsuk Lee",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910ef",
                    "name": "Sunghun Kim",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910f0",
                    "name": "Du-Seong Chang",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910f1",
                    "name": "Kyunghyun Cho",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910f2",
                    "name": "Junsuk Choe",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910f3",
                    "name": "Hwaran Lee",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910f4",
                    "name": "Jae-Gil Lee",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910f5",
                    "name": "KyungTae Lim",
                    "hidden": false
                },
                {
                    "_id": "6966474587c71000b5a910f6",
                    "name": "Alice Oh",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-11T18:33:09.000Z",
            "submittedOnDailyAt": "2026-01-14T02:22:03.363Z",
            "title": "Solar Open Technical Report",
            "submittedOnDailyBy": {
                "_id": "64587be872b60ae7a3817858",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64587be872b60ae7a3817858/BbdOOxOCEzWTvEpkWp8MM.png",
                "isPro": false,
                "fullname": "Minbyul Jeong",
                "user": "Minbyul",
                "type": "user"
            },
            "summary": "We introduce Solar Open, a 102B-parameter bilingual Mixture-of-Experts language model for underserved languages. Solar Open demonstrates a systematic methodology for building competitive LLMs by addressing three interconnected challenges. First, to train effectively despite data scarcity for underserved languages, we synthesize 4.5T tokens of high-quality, domain-specific, and RL-oriented data. Second, we coordinate this data through a progressive curriculum jointly optimizing composition, quality thresholds, and domain coverage across 20 trillion tokens. Third, to enable reasoning capabilities through scalable RL, we apply our proposed framework SnapPO for efficient optimization. Across benchmarks in English and Korean, Solar Open achieves competitive performance, demonstrating the effectiveness of this methodology for underserved language AI development.",
            "upvotes": 46,
            "discussionId": "6966474587c71000b5a910f7",
            "ai_summary": "Solar Open presents a 102B-parameter bilingual Mixture-of-Experts language model that addresses data scarcity in underserved languages through synthetic data generation, progressive curriculum coordination, and scalable reinforcement learning optimization.",
            "ai_keywords": [
                "Mixture-of-Experts",
                "language model",
                "underserved languages",
                "data synthesis",
                "progressive curriculum",
                "reinforcement learning",
                "SnapPO",
                "domain-specific data",
                "quality thresholds",
                "composition optimization"
            ],
            "organization": {
                "_id": "62940d125d1c94a62e838db2",
                "name": "upstage",
                "fullname": "upstage",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/649144feeb13c70f7671c603/bUxWC5jKltd-MyrrCNCv5.png"
            }
        },
        "translation_title": "Solar Open 기술 보고서",
        "purpose": "소외된 언어를 위한 경쟁력 있는 대형 언어 모델(LLM)을 구축하기 위한 체계적인 방법론 제시",
        "method": [
            "소외된 언어에 대한 데이터 부족 문제를 극복하기 위해 4.5T의 고품질, 도메인 특화, RL 지향 데이터 생성함(we synthesize 4.5T tokens of high-quality, domain-specific, and RL-oriented data.)",
            "20조 토큰 전반에 걸쳐 구성, 품질 기준 및 도메인 범위를 최적화하는 점진적 커리큘럼을 통해 데이터를 조정함(we coordinate this data through a progressive curriculum jointly optimizing composition, quality thresholds, and domain coverage across 20 trillion tokens.)",
            "효율적인 최적화를 위해 SnapPO라는 프레임워크를 적용하여 확장 가능한 RL을 통해 추론 능력을 가능하게 함(we apply our proposed framework SnapPO for efficient optimization.)"
        ],
        "conclusion": "Solar Open은 영어와 한국어 벤치마크에서 경쟁력 있는 성능을 달성하여 소외된 언어 AI 개발을 위한 방법론의 효과를 입증함.",
        "keywords": [
            "Large Language Models",
            "Natural Language Processing",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2601.08225",
            "authors": [
                {
                    "_id": "6967202cc5e371f6b235d1cc",
                    "name": "Jungho Cho",
                    "hidden": false
                },
                {
                    "_id": "6967202cc5e371f6b235d1cd",
                    "name": "Minbyul Jeong",
                    "hidden": false
                },
                {
                    "_id": "6967202cc5e371f6b235d1ce",
                    "user": {
                        "_id": "65446c938737c799e9ad6f83",
                        "avatarUrl": "/avatars/6ade251e01442b14cbf8cd7888358fd1.svg",
                        "isPro": false,
                        "fullname": "Sungrae Park",
                        "user": "sungrae-park",
                        "type": "user"
                    },
                    "name": "Sungrae Park",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-14T12:49:29.339Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-13T05:14:09.000Z",
            "submittedOnDailyAt": "2026-01-14T02:19:55.431Z",
            "title": "User-Oriented Multi-Turn Dialogue Generation with Tool Use at scale",
            "submittedOnDailyBy": {
                "_id": "64587be872b60ae7a3817858",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64587be872b60ae7a3817858/BbdOOxOCEzWTvEpkWp8MM.png",
                "isPro": false,
                "fullname": "Minbyul Jeong",
                "user": "Minbyul",
                "type": "user"
            },
            "summary": "The recent paradigm shift toward large reasoning models (LRMs) as autonomous agents has intensified the demand for sophisticated, multi-turn tool-use capabilities. Yet, existing datasets and data-generation approaches are limited by static, predefined toolsets that cannot scale to the complexity of open-ended human-agent collaboration. To address this, we initially developed a framework for automated task-oriented multi-turn dialogue generation at scale, utilizing an LRM-based simulator to dynamically generate high-value, domain-specific tools to solve specified tasks. However, we observe that a purely task-oriented design often results in \"solely task-solving\" trajectories, where the agent completes the objective with minimal interaction, failing to generate the high turn-count conversations seen in realistic scenarios. To bridge this gap, we shift toward a user-oriented simulation paradigm. By decoupling task generation from a dedicated user simulator that mimics human behavioral rules - such as incremental request-making and turn-by-turn feedback - we facilitate more authentic, extended multi-turn dialogues that reflect the iterative nature of real-world problem solving. Our generation pipeline operates as a versatile, plug-and-play module capable of initiating generation from any state, ensuring high scalability in producing extended tool-use data. Furthermore, by facilitating multiple task completions within a single trajectory, it yields a high-density dataset that reflects the multifaceted demands of real-world human-agent interaction.",
            "upvotes": 39,
            "discussionId": "6967202dc5e371f6b235d1cf",
            "ai_summary": "Large reasoning models enable scalable multi-turn dialogue generation through automated task-oriented simulation and user-oriented behavioral modeling for enhanced human-agent interaction datasets.",
            "ai_keywords": [
                "large reasoning models",
                "multi-turn dialogue generation",
                "task-oriented simulation",
                "user simulator",
                "behavioral rules",
                "turn-by-turn feedback",
                "automated task generation",
                "high-density dataset",
                "human-agent interaction"
            ],
            "organization": {
                "_id": "62940d125d1c94a62e838db2",
                "name": "upstage",
                "fullname": "upstage",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/649144feeb13c70f7671c603/bUxWC5jKltd-MyrrCNCv5.png"
            }
        },
        "translation_title": "사용자 중심의 다중 턴 대화 생성과 도구 사용",
        "purpose": "고급 다중 턴 도구 사용 기능을 갖춘 대화 생성을 통해 사용자 중심의 상호작용 향상",
        "method": [
            "LRM 기반 시뮬레이터를 사용해 고급 도구를 동적으로 생성하여 자동화된 과제 기반 다중 턴 대화를 생성함(we initially developed a framework for automated task-oriented multi-turn dialogue generation at scale, utilizing an LRM-based simulator to dynamically generate high-value, domain-specific tools to solve specified tasks.)",
            "사용자 행동 규칙을 모방한 전용 사용자 시뮬레이터를 도입하여 실제 시나리오에서의 대화와 유사한 상호작용을 도모함(we decouple task generation from a dedicated user simulator that mimics human behavioral rules - such as incremental request-making and turn-by-turn feedback - to facilitate more authentic, extended multi-turn dialogues.)",
            "모듈형 생성 파이프라인을 통해 임의 상태에서 생성 초기화가 가능하며, 다양한 과제 완료를 위한 고밀도 데이터셋을 생성함(Our generation pipeline operates as a versatile, plug-and-play module capable of initiating generation from any state, ensuring high scalability in producing extended tool-use data.)"
        ],
        "conclusion": "이 연구를 통해 더 현실적인 다중 턴 대화가 가능해지고, 실제 인간-에이전트 상호작용의 복잡한 요구를 반영한 고밀도 데이터셋을 확보할 수 있었다.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2512.24965",
            "authors": [
                {
                    "_id": "6958946b832867f253525a3a",
                    "name": "Siyuan Hu",
                    "hidden": false
                },
                {
                    "_id": "6958946b832867f253525a3b",
                    "user": {
                        "_id": "64440be5af034cdfd69ca3a7",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64440be5af034cdfd69ca3a7/qmx24QiDFT29vleCxL9TX.jpeg",
                        "isPro": false,
                        "fullname": "Qinghong (Kevin) Lin",
                        "user": "KevinQHLin",
                        "type": "user"
                    },
                    "name": "Kevin Qinghong Lin",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-14T09:53:47.889Z",
                    "hidden": false
                },
                {
                    "_id": "6958946b832867f253525a3c",
                    "user": {
                        "_id": "661ab3da2b14565c7acccf5c",
                        "avatarUrl": "/avatars/fa4fc03664803e02aede4d4c3d50b393.svg",
                        "isPro": false,
                        "fullname": "Mike Zheng Shou",
                        "user": "AnalMom",
                        "type": "user"
                    },
                    "name": "Mike Zheng Shou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-14T12:51:00.387Z",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/64440be5af034cdfd69ca3a7/_OdaniV8mAw_Y2nQ85G_I.mp4"
            ],
            "publishedAt": "2025-12-31T16:51:14.000Z",
            "submittedOnDailyAt": "2026-01-14T02:46:22.550Z",
            "title": "ShowUI-π: Flow-based Generative Models as GUI Dexterous Hands",
            "submittedOnDailyBy": {
                "_id": "64440be5af034cdfd69ca3a7",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64440be5af034cdfd69ca3a7/qmx24QiDFT29vleCxL9TX.jpeg",
                "isPro": false,
                "fullname": "Qinghong (Kevin) Lin",
                "user": "KevinQHLin",
                "type": "user"
            },
            "summary": "Building intelligent agents capable of dexterous manipulation is essential for achieving human-like automation in both robotics and digital environments. However, existing GUI agents rely on discrete click predictions (x,y), which prohibits free-form, closed-loop trajectories (e.g. dragging a progress bar) that require continuous, on-the-fly perception and adjustment. In this work, we develop ShowUI-π, the first flow-based generative model as GUI dexterous hand, featuring the following designs: (i) Unified Discrete-Continuous Actions, integrating discrete clicks and continuous drags within a shared model, enabling flexible adaptation across diverse interaction modes; (ii) Flow-based Action Generation for drag modeling, which predicts incremental cursor adjustments from continuous visual observations via a lightweight action expert, ensuring smooth and stable trajectories; (iii) Drag Training data and Benchmark, where we manually collect and synthesize 20K drag trajectories across five domains (e.g. PowerPoint, Adobe Premiere Pro), and introduce ScreenDrag, a benchmark with comprehensive online and offline evaluation protocols for assessing GUI agents' drag capabilities. Our experiments show that proprietary GUI agents still struggle on ScreenDrag (e.g. Operator scores 13.27, and the best Gemini-2.5-CUA reaches 22.18). In contrast, ShowUI-π achieves 26.98 with only 450M parameters, underscoring both the difficulty of the task and the effectiveness of our approach. We hope this work advances GUI agents toward human-like dexterous control in digital world. The code is available at https://github.com/showlab/showui-pi.",
            "upvotes": 31,
            "discussionId": "6958946b832867f253525a3f",
            "projectPage": "https://showlab.github.io/showui-pi",
            "githubRepo": "https://github.com/showlab/showui-pi",
            "githubRepoAddedBy": "auto",
            "githubStars": 14,
            "organization": {
                "_id": "63a553c4ce5763e06f78669c",
                "name": "showlab",
                "fullname": "Show Lab",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1671779505215-63a55320ce5763e06f78519c.png"
            }
        },
        "translation_title": "ShowUI-π: 흐름 기반 생성 모델을 GUI의 능숙한 손으로 활용하기",
        "purpose": "로봇 및 디지털 환경에서 인간과 유사한 자동화를 목표로 하는 능숙한 조작 기능을 가진 지능형 에이전트를 개발하는 것",
        "method": [
            "이 논문에서는 통합된 이산-연속 액션을 통해 다양한 상호작용 모드에서 적응할 수 있는 모델을 개발함(i) Unified Discrete-Continuous Actions, integrating discrete clicks and continuous drags within a shared model, enabling flexible adaptation across diverse interaction modes;)",
            "무게가 가벼운 액션 전문가를 통해 연속적인 시각적 관찰에서 커서 조정값을 예측하는 흐름 기반 액션 생성 방식을 사용함(ii) Flow-based Action Generation for drag modeling, which predicts incremental cursor adjustments from continuous visual observations via a lightweight action expert, ensuring smooth and stable trajectories;",
            "20K개의 드래그 궤적을 수집 및 합성하여 Drag Training 데이터와 Benchmark를 수립하고, GUI 에이전트의 드래그 능력을 평가하기 위한 ScreenDrag라는 벤치마크를 도입함(iii) Drag Training data and Benchmark, where we manually collect and synthesize 20K drag trajectories across five domains (e.g. PowerPoint, Adobe Premiere Pro)"
        ],
        "conclusion": "ShowUI-π는 450M 파라미터로도 높은 성능을 달성하여 GUI 에이전트가 디지털 세계에서 인간처럼 능숙하게 제어할 수 있는 방향으로 나아갈 수 있도록 한다.",
        "keywords": [
            "Robotics",
            "Computer Vision",
            "Image Generation"
        ]
    }
]