[
    {
        "paper": {
            "id": "2601.03252",
            "authors": [
                {
                    "_id": "695dc956c03d6d81e4399ea4",
                    "name": "Hao Yu",
                    "hidden": false
                },
                {
                    "_id": "695dc956c03d6d81e4399ea5",
                    "user": {
                        "_id": "6489a01b8de3f9d810b0154f",
                        "avatarUrl": "/avatars/f7a0fc6816535945e11bac1212dd7b57.svg",
                        "isPro": false,
                        "fullname": "Haotong Lin",
                        "user": "haotongl",
                        "type": "user"
                    },
                    "name": "Haotong Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:15:04.783Z",
                    "hidden": false
                },
                {
                    "_id": "695dc956c03d6d81e4399ea6",
                    "name": "Jiawei Wang",
                    "hidden": false
                },
                {
                    "_id": "695dc956c03d6d81e4399ea7",
                    "name": "Jiaxin Li",
                    "hidden": false
                },
                {
                    "_id": "695dc956c03d6d81e4399ea8",
                    "name": "Yida Wang",
                    "hidden": false
                },
                {
                    "_id": "695dc956c03d6d81e4399ea9",
                    "user": {
                        "_id": "6791a6c19ce382eae861ed61",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6791a6c19ce382eae861ed61/zerctN-RdeP4hSrWidtyN.jpeg",
                        "isPro": false,
                        "fullname": "Xueyang Zhang",
                        "user": "zhangxueyang001",
                        "type": "user"
                    },
                    "name": "Xueyang Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:15:39.946Z",
                    "hidden": false
                },
                {
                    "_id": "695dc956c03d6d81e4399eaa",
                    "name": "Yue Wang",
                    "hidden": false
                },
                {
                    "_id": "695dc956c03d6d81e4399eab",
                    "name": "Xiaowei Zhou",
                    "hidden": false
                },
                {
                    "_id": "695dc956c03d6d81e4399eac",
                    "name": "Ruizhen Hu",
                    "hidden": false
                },
                {
                    "_id": "695dc956c03d6d81e4399ead",
                    "user": {
                        "_id": "62986ca2b58e71e2ac9b8f01",
                        "avatarUrl": "/avatars/83944db5f3dbb6f47c47c46fb2cb2849.svg",
                        "isPro": false,
                        "fullname": "Sida Peng",
                        "user": "pengsida",
                        "type": "user"
                    },
                    "name": "Sida Peng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:16:12.074Z",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/6489a01b8de3f9d810b0154f/XlXUo1VjGVhePk-xHRmkj.mp4"
            ],
            "publishedAt": "2026-01-06T18:57:06.000Z",
            "submittedOnDailyAt": "2026-01-07T00:26:37.060Z",
            "title": "InfiniDepth: Arbitrary-Resolution and Fine-Grained Depth Estimation with Neural Implicit Fields",
            "submittedOnDailyBy": {
                "_id": "6489a01b8de3f9d810b0154f",
                "avatarUrl": "/avatars/f7a0fc6816535945e11bac1212dd7b57.svg",
                "isPro": false,
                "fullname": "Haotong Lin",
                "user": "haotongl",
                "type": "user"
            },
            "summary": "Existing depth estimation methods are fundamentally limited to predicting depth on discrete image grids. Such representations restrict their scalability to arbitrary output resolutions and hinder the geometric detail recovery. This paper introduces InfiniDepth, which represents depth as neural implicit fields. Through a simple yet effective local implicit decoder, we can query depth at continuous 2D coordinates, enabling arbitrary-resolution and fine-grained depth estimation. To better assess our method's capabilities, we curate a high-quality 4K synthetic benchmark from five different games, spanning diverse scenes with rich geometric and appearance details. Extensive experiments demonstrate that InfiniDepth achieves state-of-the-art performance on both synthetic and real-world benchmarks across relative and metric depth estimation tasks, particularly excelling in fine-detail regions. It also benefits the task of novel view synthesis under large viewpoint shifts, producing high-quality results with fewer holes and artifacts.",
            "upvotes": 70,
            "discussionId": "695dc956c03d6d81e4399eae",
            "ai_summary": "InfiniDepth represents depth as neural implicit fields using a local implicit decoder, enabling continuous 2D coordinate querying for arbitrary-resolution depth estimation and superior performance in fine-detail regions.",
            "ai_keywords": [
                "neural implicit fields",
                "local implicit decoder",
                "continuous 2D coordinates",
                "arbitrary-resolution depth estimation",
                "synthetic benchmark",
                "4K synthetic benchmark",
                "novel view synthesis",
                "viewpoint shifts"
            ],
            "organization": {
                "_id": "61bac2af530e5c78d7b99667",
                "name": "zju",
                "fullname": "Zhejiang University",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/5e1058e9fcf41d740b69966d/7G1xjlxwCdMEmKcxNR0n5.png"
            }
        },
        "translation_title": "InfiniDepth: 신경 암시 필드를 이용한 임의 해상도 및 세밀한 깊이 추정",
        "purpose": "임의 해상도에서 깊이 추정의 정확성을 높이고 기하학적 세부 정보를 회복하기 위한 방법론 개발",
        "method": [
            "깊이를 신경 암시 필드로 표현하여 연속 2D 좌표에서 깊이를 쿼리하도록 하는 지역 암시 디코더를 구현함(Through a simple yet effective local implicit decoder, we can query depth at continuous 2D coordinates, enabling arbitrary-resolution and fine-grained depth estimation.)",
            "다양한 장면의 고품질 4K 합성 벤치마크를 작성하여 방법의 성능을 평가함(To better assess our method's capabilities, we curate a high-quality 4K synthetic benchmark from five different games, spanning diverse scenes with rich geometric and appearance details.)",
            "광범위한 실험을 통해 InfiniDepth가 상대 및 메트릭 깊이 추정 작업에서 최첨단 성능을 달성함(Extensive experiments demonstrate that InfiniDepth achieves state-of-the-art performance on both synthetic and real-world benchmarks across relative and metric depth estimation tasks.)"
        ],
        "conclusion": "InfiniDepth는 세밀한 형상 영역에서 특히 뛰어난 성능을 보이며, 새로운 시점 합성 작업에서도 고품질 결과를 생성함.",
        "keywords": [
            "3D Vision",
            "Depth Estimation",
            "Image Understanding"
        ]
    },
    {
        "paper": {
            "id": "2601.01554",
            "authors": [
                {
                    "_id": "695dcda5c03d6d81e4399eb8",
                    "name": "MOSI. AI",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399eb9",
                    "name": "Donghua Yu",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399eba",
                    "name": "Zhengyuan Lin",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ebb",
                    "user": {
                        "_id": "660c345da15ab85523ad00d1",
                        "avatarUrl": "/avatars/b0bfdee89a6c62ff12140b9e85de499a.svg",
                        "isPro": false,
                        "fullname": "Chen Yang",
                        "user": "kiiic",
                        "type": "user"
                    },
                    "name": "Chen Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-07T09:25:58.894Z",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ebc",
                    "name": "Yiyang Zhang",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ebd",
                    "name": "Hanfu Chen",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ebe",
                    "name": "Jingqi Chen",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ebf",
                    "name": "Ke Chen",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ec0",
                    "name": "Liwei Fan",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ec1",
                    "name": "Yi Jiang",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ec2",
                    "name": "Jie Zhu",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ec3",
                    "name": "Muchen Li",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ec4",
                    "name": "Wenxuan Wang",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ec5",
                    "name": "Yang Wang",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ec6",
                    "user": {
                        "_id": "6443f7bf1bc692d87b25e234",
                        "avatarUrl": "/avatars/fa9e62d96d0691a9a48e3db499a61557.svg",
                        "isPro": false,
                        "fullname": "Xu Zhe",
                        "user": "Phospheneser",
                        "type": "user"
                    },
                    "name": "Zhe Xu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-07T09:25:55.950Z",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ec7",
                    "name": "Yitian Gong",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ec8",
                    "name": "Yuqian Zhang",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ec9",
                    "name": "Wenbo Zhang",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399eca",
                    "user": {
                        "_id": "629ef8544313a7c1dd671130",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/629ef8544313a7c1dd671130/i5xfHIgELcuO1Ew19ebTw.png",
                        "isPro": false,
                        "fullname": "Zhaoye Fei",
                        "user": "ngc7293",
                        "type": "user"
                    },
                    "name": "Zhaoye Fei",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:17:10.124Z",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ecb",
                    "user": {
                        "_id": "695757e4fd9dc6e9bac27935",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/_uZEu4oOlKJVYqrG763Z-.jpeg",
                        "isPro": false,
                        "fullname": "aa",
                        "user": "qinyuancheng",
                        "type": "user"
                    },
                    "name": "Qinyuan Cheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:17:03.749Z",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ecc",
                    "name": "Shimin Li",
                    "hidden": false
                },
                {
                    "_id": "695dcda5c03d6d81e4399ecd",
                    "user": {
                        "_id": "61457b8deff2c9fdb4de4988",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1632381702899-61457b8deff2c9fdb4de4988.jpeg",
                        "isPro": false,
                        "fullname": "Xipeng Qiu",
                        "user": "xpqiu",
                        "type": "user"
                    },
                    "name": "Xipeng Qiu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:16:50.004Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-04T15:01:10.000Z",
            "submittedOnDailyAt": "2026-01-07T00:52:16.123Z",
            "title": "MOSS Transcribe Diarize: Accurate Transcription with Speaker Diarization",
            "submittedOnDailyBy": {
                "_id": "629ef8544313a7c1dd671130",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/629ef8544313a7c1dd671130/i5xfHIgELcuO1Ew19ebTw.png",
                "isPro": false,
                "fullname": "Zhaoye Fei",
                "user": "ngc7293",
                "type": "user"
            },
            "summary": "Speaker-Attributed, Time-Stamped Transcription (SATS) aims to transcribe what is said and to precisely determine the timing of each speaker, which is particularly valuable for meeting transcription. Existing SATS systems rarely adopt an end-to-end formulation and are further constrained by limited context windows, weak long-range speaker memory, and the inability to output timestamps. To address these limitations, we present MOSS Transcribe Diarize, a unified multimodal large language model that jointly performs Speaker-Attributed, Time-Stamped Transcription in an end-to-end paradigm. Trained on extensive real wild data and equipped with a 128k context window for up to 90-minute inputs, MOSS Transcribe Diarize scales well and generalizes robustly. Across comprehensive evaluations, it outperforms state-of-the-art commercial systems on multiple public and in-house benchmarks.",
            "upvotes": 44,
            "discussionId": "695dcda6c03d6d81e4399ece",
            "projectPage": "https://mosi.cn/models/moss-transcribe-diarize",
            "ai_summary": "A unified multimodal large language model for end-to-end speaker-attributed, time-stamped transcription with extended context window and strong generalization across benchmarks.",
            "ai_keywords": [
                "multimodal large language model",
                "end-to-end paradigm",
                "speaker diarization",
                "time-stamped transcription",
                "context window",
                "robust generalization"
            ],
            "organization": {
                "_id": "613b0dee83ec35d460684607",
                "name": "OpenMOSS-Team",
                "fullname": "OpenMOSS",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61457b8deff2c9fdb4de4988/N5b9663zQ4uq5_OTNlnmw.png"
            }
        },
        "translation_title": "MOSS Transcribe Diarize: 화자 구분이 포함된 정확한 전사",
        "purpose": "회의 전사를 위한 화자 구분 및 타임스탬프 전사 모델의 정확도 향상",
        "method": [
            "MOSS Transcribe Diarize라는 통합된 멀티모달 Large Language Model을 제시하고, 이를 통해 화자 구분 및 타임스탬프 전사를 엔드 투 엔드로 수행함(To address these limitations, we present MOSS Transcribe Diarize, a unified multimodal large language model that jointly performs Speaker-Attributed, Time-Stamped Transcription in an end-to-end paradigm.)",
            "실제 데이터로 훈련하고 128k의 컨텍스트 윈도우를 사용하여 최대 90분의 입력을 처리할 수 있도록 함(Trained on extensive real wild data and equipped with a 128k context window for up to 90-minute inputs, MOSS Transcribe Diarize scales well and generalizes robustly.)"
        ],
        "conclusion": "MOSS Transcribe Diarize는 여러 공개 및 자체 벤치마크에서 기존 상업 시스템보다 우수한 성능을 보여줌.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2512.22334",
            "authors": [
                {
                    "_id": "695e0748c03d6d81e439a027",
                    "user": {
                        "_id": "67d2a001919e3b981ad45066",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67d2a001919e3b981ad45066/KxaYKOGgLVbVhN6EsYGRG.jpeg",
                        "isPro": false,
                        "fullname": "wyh",
                        "user": "naonaowyh",
                        "type": "user"
                    },
                    "name": "Yiheng Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-07T09:25:26.201Z",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a028",
                    "user": {
                        "_id": "64c396def6fe448b1ad553d6",
                        "avatarUrl": "/avatars/b2ce4739f42dc00ee974fff7ee1cb301.svg",
                        "isPro": false,
                        "fullname": "Yixin Chen",
                        "user": "YixinChen",
                        "type": "user"
                    },
                    "name": "Yixin Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T14:25:35.753Z",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a029",
                    "name": "Shuo Li",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a02a",
                    "user": {
                        "_id": "659d2dff20cf0b934bbee513",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/659d2dff20cf0b934bbee513/9e9R852Zr2R82h64eUUQl.jpeg",
                        "isPro": false,
                        "fullname": "Yifan Zhou",
                        "user": "yingmanji",
                        "type": "user"
                    },
                    "name": "Yifan Zhou",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-07T09:25:19.089Z",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a02b",
                    "name": "Bo Liu",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a02c",
                    "user": {
                        "_id": "66d19399b26010e571b1fcf0",
                        "avatarUrl": "/avatars/9d0998fc38f6659305bcbcecaf0a1c96.svg",
                        "isPro": false,
                        "fullname": "Hengjian Gao",
                        "user": "Talthy",
                        "type": "user"
                    },
                    "name": "Hengjian Gao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-07T09:25:28.254Z",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a02d",
                    "user": {
                        "_id": "64a3d1ddb3239f3e3892b24b",
                        "avatarUrl": "/avatars/7ce585f5fc1d077fb1d70cc18c4da2c1.svg",
                        "isPro": false,
                        "fullname": "Jiakang Yuan",
                        "user": "JiakangYuan",
                        "type": "user"
                    },
                    "name": "Jiakang Yuan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T14:25:23.256Z",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a02e",
                    "name": "Jia Bu",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a02f",
                    "user": {
                        "_id": "65f3f43fc9940817ca9a427b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65f3f43fc9940817ca9a427b/02NN3XjSsbgWDhjrJWtVL.jpeg",
                        "isPro": false,
                        "fullname": "Wanghan Xu",
                        "user": "CoCoOne",
                        "type": "user"
                    },
                    "name": "Wanghan Xu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-07T09:25:21.127Z",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a030",
                    "user": {
                        "_id": "63bab9c1bb6a2fabd14421bd",
                        "avatarUrl": "/avatars/c47030cf167072bf6ce3421f025c7746.svg",
                        "isPro": false,
                        "fullname": "Yuhao Zhou",
                        "user": "Soptq",
                        "type": "user"
                    },
                    "name": "Yuhao Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:18:03.373Z",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a031",
                    "name": "Xiangyu Zhao",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a032",
                    "name": "Zhiwang Zhou",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a033",
                    "name": "Fengxiang Wang",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a034",
                    "user": {
                        "_id": "63ee1379190ddd6214efd73a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676546883247-noauth.png",
                        "isPro": false,
                        "fullname": "HAODONG DUAN",
                        "user": "KennyUTC",
                        "type": "user"
                    },
                    "name": "Haodong Duan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:18:16.943Z",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a035",
                    "name": "Songyang Zhang",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a036",
                    "name": "Jun Yao",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a037",
                    "name": "Han Deng",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a038",
                    "name": "Yizhou Wang",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a039",
                    "user": {
                        "_id": "650d2f798ffe1f53bdd4ae71",
                        "avatarUrl": "/avatars/4c733681f8301d801023105c0b3aba38.svg",
                        "isPro": false,
                        "fullname": "Xiao Jiabei",
                        "user": "Xiao-Youth",
                        "type": "user"
                    },
                    "name": "Jiabei Xiao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T14:25:59.280Z",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a03a",
                    "name": "Jiaqi Liu",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a03b",
                    "user": {
                        "_id": "6784a79c5ffcc118504ed99c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/eL4kAIp_oi9Q7si5--uVl.png",
                        "isPro": false,
                        "fullname": "Encheng Su",
                        "user": "EncSU",
                        "type": "user"
                    },
                    "name": "Encheng Su",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:18:31.162Z",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a03c",
                    "name": "Yujie Liu",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a03d",
                    "user": {
                        "_id": "661b9d96c153e4a0a25adc3e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/661b9d96c153e4a0a25adc3e/VRt7kCQ0KdJp-lhPLOajO.jpeg",
                        "isPro": false,
                        "fullname": "Weida Wang",
                        "user": "weidawang",
                        "type": "user"
                    },
                    "name": "Weida Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-07T09:25:23.748Z",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a03e",
                    "name": "Junchi Yao",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a03f",
                    "name": "Shenghe Zheng",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a040",
                    "name": "Haoran Sun",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a041",
                    "name": "Runmin Ma",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a042",
                    "name": "Xiangchao Yan",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a043",
                    "name": "Bo Zhang",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a044",
                    "name": "Dongzhan Zhou",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a045",
                    "user": {
                        "_id": "68f8924f4278c8968587dfea",
                        "avatarUrl": "/avatars/b48d7899881a14ca68cc9feb2643ad8c.svg",
                        "isPro": false,
                        "fullname": "shufei zhang",
                        "user": "ShufeiZhang",
                        "type": "user"
                    },
                    "name": "Shufei Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:18:24.428Z",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a046",
                    "name": "Peng Ye",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a047",
                    "name": "Xiaosong Wang",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a048",
                    "name": "Shixiang Tang",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a049",
                    "name": "Wenlong Zhang",
                    "hidden": false
                },
                {
                    "_id": "695e0748c03d6d81e439a04a",
                    "name": "Lei Bai",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-26T17:36:02.000Z",
            "submittedOnDailyAt": "2026-01-07T05:09:43.722Z",
            "title": "SciEvalKit: An Open-source Evaluation Toolkit for Scientific General Intelligence",
            "submittedOnDailyBy": {
                "_id": "63bab9c1bb6a2fabd14421bd",
                "avatarUrl": "/avatars/c47030cf167072bf6ce3421f025c7746.svg",
                "isPro": false,
                "fullname": "Yuhao Zhou",
                "user": "Soptq",
                "type": "user"
            },
            "summary": "We introduce SciEvalKit, a unified benchmarking toolkit designed to evaluate AI models for science across a broad range of scientific disciplines and task capabilities. Unlike general-purpose evaluation platforms, SciEvalKit focuses on the core competencies of scientific intelligence, including Scientific Multimodal Perception, Scientific Multimodal Reasoning, Scientific Multimodal Understanding, Scientific Symbolic Reasoning, Scientific Code Generation, Science Hypothesis Generation and Scientific Knowledge Understanding. It supports six major scientific domains, spanning from physics and chemistry to astronomy and materials science. SciEvalKit builds a foundation of expert-grade scientific benchmarks, curated from real-world, domain-specific datasets, ensuring that tasks reflect authentic scientific challenges. The toolkit features a flexible, extensible evaluation pipeline that enables batch evaluation across models and datasets, supports custom model and dataset integration, and provides transparent, reproducible, and comparable results. By bridging capability-based evaluation and disciplinary diversity, SciEvalKit offers a standardized yet customizable infrastructure to benchmark the next generation of scientific foundation models and intelligent agents. The toolkit is open-sourced and actively maintained to foster community-driven development and progress in AI4Science.",
            "upvotes": 28,
            "discussionId": "695e0748c03d6d81e439a04b",
            "projectPage": "https://opencompass.org.cn/Intern-Discovery-Eval/rank",
            "githubRepo": "https://github.com/InternScience/SciEvalKit",
            "githubRepoAddedBy": "user",
            "ai_summary": "SciEvalKit is a unified benchmarking toolkit for evaluating AI models across scientific disciplines, focusing on core scientific intelligence competencies and supporting diverse domains from physics to materials science.",
            "ai_keywords": [
                "AI models",
                "scientific intelligence",
                "Scientific Multimodal Perception",
                "Scientific Multimodal Reasoning",
                "Scientific Multimodal Understanding",
                "Scientific Symbolic Reasoning",
                "Scientific Code Generation",
                "Science Hypothesis Generation",
                "Scientific Knowledge Understanding",
                "scientific foundation models",
                "intelligent agents"
            ],
            "githubStars": 55,
            "organization": {
                "_id": "690af7a885f71496ea396393",
                "name": "InternScience",
                "fullname": "Intern Science",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/65f2a4198404ac0e4c0f175f/XIPU4aCPBogXSrj6NrfLk.png"
            }
        },
        "translation_title": "SciEvalKit: 과학 일반 지능을 위한 오픈소스 평가 툴킷",
        "purpose": "과학 분야의 다양한 AI 모델 성능을 평가하기 위한 통합 벤치마킹 툴킷 개발",
        "method": [
            "과학적 지능의 핵심 역량을 평가하기 위해 설계된 SciEvalKit을 소개함(We introduce SciEvalKit, a unified benchmarking toolkit designed to evaluate AI models for science across a broad range of scientific disciplines and task capabilities.)",
            "물리학, 화학, 천문학 등 여섯 가지 주요 과학 도메인을 지원함(It supports six major scientific domains, spanning from physics and chemistry to astronomy and materials science.)",
            "진짜 과학적 도전 과제를 반영하는 전문가급 벤치마크를 구축함(SciEvalKit builds a foundation of expert-grade scientific benchmarks, curated from real-world, domain-specific datasets, ensuring that tasks reflect authentic scientific challenges.)",
            "모델과 데이터셋 통합 및 투명한 결과 제공을 지원하는 확장 가능한 평가 파이프라인을 특징으로 함(The toolkit features a flexible, extensible evaluation pipeline that enables batch evaluation across models and datasets, supports custom model and dataset integration, and provides transparent, reproducible, and comparable results.)"
        ],
        "conclusion": "SciEvalKit은 과학 분야 AI 모델의 평가를 표준화하였으며, 오픈소스로 커뮤니티 주도의 발전을 촉진함.",
        "keywords": [
            "Multimodal Learning",
            "Robotics",
            "Natural Language Processing"
        ]
    },
    {
        "paper": {
            "id": "2601.03233",
            "authors": [
                {
                    "_id": "695dc6d9c03d6d81e4399e85",
                    "user": {
                        "_id": "6303cc5e0547362a22a51af0",
                        "avatarUrl": "/avatars/8f3348f121565bf6c5e1af0e559a43a3.svg",
                        "isPro": false,
                        "fullname": "Yoav HaCohen",
                        "user": "yoavhacohen",
                        "type": "user"
                    },
                    "name": "Yoav HaCohen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:19:29.722Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e86",
                    "user": {
                        "_id": "6489c487b9e9258ba065418f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6489c487b9e9258ba065418f/6rzmV3bQ3YxswG6NP2hDW.png",
                        "isPro": false,
                        "fullname": "Benny Brazowski",
                        "user": "benibraz",
                        "type": "user"
                    },
                    "name": "Benny Brazowski",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:19:35.981Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e87",
                    "user": {
                        "_id": "62dd30a8d43078cd49ac8ad8",
                        "avatarUrl": "/avatars/ad599719290637f7817b7508a91c2e2c.svg",
                        "isPro": false,
                        "fullname": "Nisan Chiprut",
                        "user": "nisan",
                        "type": "user"
                    },
                    "name": "Nisan Chiprut",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:19:41.634Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e88",
                    "user": {
                        "_id": "64a7adc087cbd4dc7301fdd6",
                        "avatarUrl": "/avatars/b4ec4c3a0409af8ec4a5de05db453034.svg",
                        "isPro": false,
                        "fullname": "Yaki Bitterman",
                        "user": "jacobitterman",
                        "type": "user"
                    },
                    "name": "Yaki Bitterman",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:19:46.749Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e89",
                    "user": {
                        "_id": "65897258509bcae23fa162c9",
                        "avatarUrl": "/avatars/29d277a0c425c936e25e82e79caa10a4.svg",
                        "isPro": false,
                        "fullname": "Andrew Kvochko",
                        "user": "kvochko",
                        "type": "user"
                    },
                    "name": "Andrew Kvochko",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:19:51.722Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e8a",
                    "name": "Avishai Berkowitz",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e8b",
                    "name": "Daniel Shalem",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e8c",
                    "user": {
                        "_id": "681af83e2f4aaa88639e703d",
                        "avatarUrl": "/avatars/d69b664daad0afb529440c14fdb9bc3a.svg",
                        "isPro": false,
                        "fullname": "Daphna Lifschitz",
                        "user": "Daphnal",
                        "type": "user"
                    },
                    "name": "Daphna Lifschitz",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:20:04.180Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e8d",
                    "user": {
                        "_id": "636b97a57631fe5e86fe1fa2",
                        "avatarUrl": "/avatars/c568ae26fd4fc2655cd12f15d539db58.svg",
                        "isPro": false,
                        "fullname": "Dudu Moshe",
                        "user": "dudumoshe",
                        "type": "user"
                    },
                    "name": "Dudu Moshe",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:20:13.512Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e8e",
                    "name": "Eitan Porat",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e8f",
                    "user": {
                        "_id": "677a422979d3c32a5dd87a0a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/WUa6E68GpnT2mEMJ41nDd.png",
                        "isPro": false,
                        "fullname": "Eitan Richardson",
                        "user": "eitanrich",
                        "type": "user"
                    },
                    "name": "Eitan Richardson",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:20:22.677Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e90",
                    "user": {
                        "_id": "673f6911d83832a6ce15e7bf",
                        "avatarUrl": "/avatars/0da6cded3b0e785241a6ba5fdb5d8ceb.svg",
                        "isPro": false,
                        "fullname": "Guy Shiran",
                        "user": "guysrn",
                        "type": "user"
                    },
                    "name": "Guy Shiran",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:20:28.250Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e91",
                    "user": {
                        "_id": "65744a2fe09de6aa74026d80",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65744a2fe09de6aa74026d80/kCxIKdeBJwAPKmvlm7fDP.jpeg",
                        "isPro": false,
                        "fullname": "Itay Chachy",
                        "user": "ItayChachy",
                        "type": "user"
                    },
                    "name": "Itay Chachy",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:20:36.781Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e92",
                    "name": "Jonathan Chetboun",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e93",
                    "user": {
                        "_id": "6678365ac411b340b32d6148",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6678365ac411b340b32d6148/7OhHzbu65pa95eYrAbbLW.jpeg",
                        "isPro": false,
                        "fullname": "Michael Finkelson",
                        "user": "MichaelFinkelson",
                        "type": "user"
                    },
                    "name": "Michael Finkelson",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:20:53.574Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e94",
                    "user": {
                        "_id": "6318aa43cb4ca740c4c55651",
                        "avatarUrl": "/avatars/24082c776d284393a5a38a99e5c0bab8.svg",
                        "isPro": false,
                        "fullname": "michael kupchick",
                        "user": "michaellightricks",
                        "type": "user"
                    },
                    "name": "Michael Kupchick",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:20:59.945Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e95",
                    "user": {
                        "_id": "673f29b568595672b8d3e90e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/673f29b568595672b8d3e90e/4sYADg3mpqMKmJ4fQwaTl.png",
                        "isPro": false,
                        "fullname": "Nir Zabari",
                        "user": "NirZabariLTX",
                        "type": "user"
                    },
                    "name": "Nir Zabari",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:21:07.297Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e96",
                    "user": {
                        "_id": "64ae89c043dda9449a1eb1ba",
                        "avatarUrl": "/avatars/12cf3de929d38ddd92cc3f3337dc2ed2.svg",
                        "isPro": false,
                        "fullname": "Nitzan Guetta",
                        "user": "nitzanguetta",
                        "type": "user"
                    },
                    "name": "Nitzan Guetta",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:21:14.712Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e97",
                    "name": "Noa Kotler",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e98",
                    "user": {
                        "_id": "631f58935ba8c026340b377c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631f58935ba8c026340b377c/4yoHLdNE99VBb7ji_Mzzj.jpeg",
                        "isPro": false,
                        "fullname": "Ofir Bibi",
                        "user": "ofirbibi",
                        "type": "user"
                    },
                    "name": "Ofir Bibi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:21:27.196Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e99",
                    "user": {
                        "_id": "674348b46215a2c0878e219b",
                        "avatarUrl": "/avatars/8a213e431a1583d1a93377410907c059.svg",
                        "isPro": false,
                        "fullname": "Ori Gordon",
                        "user": "origordon",
                        "type": "user"
                    },
                    "name": "Ori Gordon",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:21:34.878Z",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e9a",
                    "name": "Poriya Panet",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e9b",
                    "name": "Roi Benita",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e9c",
                    "name": "Shahar Armon",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e9d",
                    "name": "Victor Kulikov",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e9e",
                    "name": "Yaron Inger",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399e9f",
                    "name": "Yonatan Shiftan",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399ea0",
                    "name": "Zeev Melumian",
                    "hidden": false
                },
                {
                    "_id": "695dc6d9c03d6d81e4399ea1",
                    "name": "Zeev Farbman",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/6039478ab3ecf716b1a5fd4d/cYoXYuK3pjt85pl5-fvUv.mp4"
            ],
            "publishedAt": "2026-01-06T18:24:41.000Z",
            "submittedOnDailyAt": "2026-01-07T00:07:29.528Z",
            "title": "LTX-2: Efficient Joint Audio-Visual Foundation Model",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Recent text-to-video diffusion models can generate compelling video sequences, yet they remain silent -- missing the semantic, emotional, and atmospheric cues that audio provides. We introduce LTX-2, an open-source foundational model capable of generating high-quality, temporally synchronized audiovisual content in a unified manner. LTX-2 consists of an asymmetric dual-stream transformer with a 14B-parameter video stream and a 5B-parameter audio stream, coupled through bidirectional audio-video cross-attention layers with temporal positional embeddings and cross-modality AdaLN for shared timestep conditioning. This architecture enables efficient training and inference of a unified audiovisual model while allocating more capacity for video generation than audio generation. We employ a multilingual text encoder for broader prompt understanding and introduce a modality-aware classifier-free guidance (modality-CFG) mechanism for improved audiovisual alignment and controllability. Beyond generating speech, LTX-2 produces rich, coherent audio tracks that follow the characters, environment, style, and emotion of each scene -- complete with natural background and foley elements. In our evaluations, the model achieves state-of-the-art audiovisual quality and prompt adherence among open-source systems, while delivering results comparable to proprietary models at a fraction of their computational cost and inference time. All model weights and code are publicly released.",
            "upvotes": 27,
            "discussionId": "695dc6d9c03d6d81e4399ea2",
            "projectPage": "https://app.ltx.studio/ltx-2-playground/i2v",
            "githubRepo": "https://github.com/Lightricks/LTX-2",
            "githubRepoAddedBy": "user",
            "ai_summary": "LTX-2 is an open-source audiovisual diffusion model that generates synchronized video and audio content using a dual-stream transformer architecture with cross-modal attention and classifier-free guidance.",
            "ai_keywords": [
                "text-to-video diffusion models",
                "audiovisual content",
                "dual-stream transformer",
                "cross-attention layers",
                "temporal positional embeddings",
                "AdaLN",
                "classifier-free guidance",
                "modality-aware classifier-free guidance",
                "multilingual text encoder",
                "diffusion models"
            ],
            "githubStars": 738
        },
        "translation_title": "LTX-2: 효율적인 공동 오디오-비주얼 기초 모델",
        "purpose": "고품질, 동기화된 오디오-비주얼 콘텐츠를 생성하기 위한 오픈소스 기초 모델 개발",
        "method": [
            "14B 파라미터의 비디오 스트림과 5B 파라미터의 오디오 스트림을 갖춘 비대칭 듀얼 스트림 트랜스포머를 구성함(we introduce LTX-2, an open-source foundational model capable of generating high-quality, temporally synchronized audiovisual content in a unified manner.)",
            "양방향 오디오-비디오 크로스 어텐션 레이어 및 시간적 위치 임베딩을 통해 두 스트림을 연결함(LTX-2 consists of an asymmetric dual-stream transformer with a 14B-parameter video stream and a 5B-parameter audio stream, coupled through bidirectional audio-video cross-attention layers with temporal positional embeddings.)",
            "다국어 텍스트 인코더를 사용하여 더 넓은 프롬프트 이해를 도모하고, 오디오-비주얼 정렬 및 제어를 개선하기 위한 모달리티 인식 분류기 프리 가이던스 메커니즘을 도입함(We employ a multilingual text encoder for broader prompt understanding and introduce a modality-aware classifier-free guidance mechanism for improved audiovisual alignment and controllability.)"
        ],
        "conclusion": "LTX-2는 오픈소스 시스템 중에서 최첨단의 오디오-비주얼 품질과 프롬프트 준수를 달성하였으며, 상용 모델과 비슷한 결과를 훨씬 적은 계산 비용과 추론 시간으로 제공함.",
        "keywords": [
            "Video Generation",
            "Audio-Visual",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2601.03193",
            "authors": [
                {
                    "_id": "695de87dc03d6d81e4399fd2",
                    "user": {
                        "_id": "6723369dc09be95d8c49c605",
                        "avatarUrl": "/avatars/797df409537c07cbf894f1c027cddbb1.svg",
                        "isPro": false,
                        "fullname": "Ruiyan Han",
                        "user": "Hungryyan",
                        "type": "user"
                    },
                    "name": "Ruiyan Han",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:21:53.416Z",
                    "hidden": false
                },
                {
                    "_id": "695de87dc03d6d81e4399fd3",
                    "user": {
                        "_id": "64b0a5037a475fba70a7260d",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b0a5037a475fba70a7260d/MauBbb6raMA23yrR1Zq21.jpeg",
                        "isPro": false,
                        "fullname": "Zhen Fang",
                        "user": "CostaliyA",
                        "type": "user"
                    },
                    "name": "Zhen Fang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-07T13:13:51.100Z",
                    "hidden": false
                },
                {
                    "_id": "695de87dc03d6d81e4399fd4",
                    "name": "XinYu Sun",
                    "hidden": false
                },
                {
                    "_id": "695de87dc03d6d81e4399fd5",
                    "name": "Yuchen Ma",
                    "hidden": false
                },
                {
                    "_id": "695de87dc03d6d81e4399fd6",
                    "name": "Ziheng Wang",
                    "hidden": false
                },
                {
                    "_id": "695de87dc03d6d81e4399fd7",
                    "user": {
                        "_id": "665d652e0f35c005de892108",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/665d652e0f35c005de892108/OGLbgZekX-3XTBkwS8k86.jpeg",
                        "isPro": false,
                        "fullname": "Yu Zeng",
                        "user": "YuZeng260",
                        "type": "user"
                    },
                    "name": "Yu Zeng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-07T09:25:35.308Z",
                    "hidden": false
                },
                {
                    "_id": "695de87dc03d6d81e4399fd8",
                    "user": {
                        "_id": "64892d31cbda0d1cdb956897",
                        "avatarUrl": "/avatars/3cdafe03a8295124636347d15a099aaf.svg",
                        "isPro": false,
                        "fullname": "Zehui Chen",
                        "user": "lovesnowbest",
                        "type": "user"
                    },
                    "name": "Zehui Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-07T13:22:13.382Z",
                    "hidden": false
                },
                {
                    "_id": "695de87dc03d6d81e4399fd9",
                    "user": {
                        "_id": "64b02ec0e5000ae8a572ced5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b02ec0e5000ae8a572ced5/6ifLntBU2ICQK7SW8WxKU.png",
                        "isPro": false,
                        "fullname": "Lin Chen",
                        "user": "Lin-Chen",
                        "type": "user"
                    },
                    "name": "Lin Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-07T09:25:37.096Z",
                    "hidden": false
                },
                {
                    "_id": "695de87dc03d6d81e4399fda",
                    "user": {
                        "_id": "67dc162ec8c00778e8689f42",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67dc162ec8c00778e8689f42/_y_tO6W3ONOkOWbumAFXA.png",
                        "isPro": false,
                        "fullname": "Wenxuan Huang",
                        "user": "Osilly",
                        "type": "user"
                    },
                    "name": "Wenxuan Huang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-07T13:37:57.684Z",
                    "hidden": false
                },
                {
                    "_id": "695de87dc03d6d81e4399fdb",
                    "name": "Wei-Jie Xu",
                    "hidden": false
                },
                {
                    "_id": "695de87dc03d6d81e4399fdc",
                    "name": "Yi Cao",
                    "hidden": false
                },
                {
                    "_id": "695de87dc03d6d81e4399fdd",
                    "name": "Feng Zhao",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-06T17:15:50.000Z",
            "submittedOnDailyAt": "2026-01-07T02:31:26.744Z",
            "title": "UniCorn: Towards Self-Improving Unified Multimodal Models through Self-Generated Supervision",
            "submittedOnDailyBy": {
                "_id": "64b02ec0e5000ae8a572ced5",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64b02ec0e5000ae8a572ced5/6ifLntBU2ICQK7SW8WxKU.png",
                "isPro": false,
                "fullname": "Lin Chen",
                "user": "Lin-Chen",
                "type": "user"
            },
            "summary": "While Unified Multimodal Models (UMMs) have achieved remarkable success in cross-modal comprehension, a significant gap persists in their ability to leverage such internal knowledge for high-quality generation. We formalize this discrepancy as Conduction Aphasia, a phenomenon where models accurately interpret multimodal inputs but struggle to translate that understanding into faithful and controllable synthesis. To address this, we propose UniCorn, a simple yet elegant self-improvement framework that eliminates the need for external data or teacher supervision. By partitioning a single UMM into three collaborative roles: Proposer, Solver, and Judge, UniCorn generates high-quality interactions via self-play and employs cognitive pattern reconstruction to distill latent understanding into explicit generative signals. To validate the restoration of multimodal coherence, we introduce UniCycle, a cycle-consistency benchmark based on a Text to Image to Text reconstruction loop. Extensive experiments demonstrate that UniCorn achieves comprehensive and substantial improvements over the base model across six general image generation benchmarks. Notably, it achieves SOTA performance on TIIF(73.8), DPG(86.8), CompBench(88.5), and UniCycle while further delivering substantial gains of +5.0 on WISE and +6.5 on OneIG. These results highlight that our method significantly enhances T2I generation while maintaining robust comprehension, demonstrating the scalability of fully self-supervised refinement for unified multimodal intelligence.",
            "upvotes": 23,
            "discussionId": "695de87dc03d6d81e4399fde",
            "projectPage": "https://costaliya.github.io/UniCorn.github.io/",
            "githubRepo": "https://github.com/Hungryyan1/UniCorn",
            "githubRepoAddedBy": "user",
            "ai_summary": "UniCorn, a self-improvement framework for unified multimodal models, addresses generation gaps through self-play and cognitive pattern reconstruction, achieving state-of-the-art results in text-to-image generation.",
            "ai_keywords": [
                "Unified Multimodal Models",
                "Conduction Aphasia",
                "UniCorn",
                "self-improvement framework",
                "self-play",
                "cognitive pattern reconstruction",
                "Text to Image",
                "cycle-consistency",
                "UniCycle",
                "T2I generation"
            ],
            "githubStars": 20
        },
        "translation_title": "UniCorn: 자가 생성된 감독을 통한 자기 개선 통합 다중 모달 모델 개발",
        "purpose": "UMMs의 내부 지식을 활용하여 높은 품질의 생성을 이루기 위한 자기 개선 프레임워크 연구",
        "method": [
            "단일 UMM을 제안자(Proposer), 해결자(Solver), 판별자(Judge)라는 세 가지 협력 역할로 나누어 고품질 상호작용을 생성함(we propose UniCorn, a simple yet elegant self-improvement framework that eliminates the need for external data or teacher supervision.)",
            "자가 학습을 통해 다중 모달 일관성을 검증하기 위한 사이클 일관성 벤치마크인 UniCycle을 도입함(To validate the restoration of multimodal coherence, we introduce UniCycle, a cycle-consistency benchmark based on a Text to Image to Text reconstruction loop.)",
            "기반 모델에 비해 6개의 일반 이미지 생성 벤치마크에서 포괄적이고 상당한 개선을 달성함(Extensive experiments demonstrate that UniCorn achieves comprehensive and substantial improvements over the base model across six general image generation benchmarks.)"
        ],
        "conclusion": "UniCorn 방법이 T2I 생성 성능을 크게 향상시키며 통합 다중 모달 지능에 대한 완전 자기 감독 세련의 확장 가능성을 보여줌.",
        "keywords": [
            "Multimodal Learning",
            "Image Generation",
            "Vision-Language Models"
        ]
    }
]