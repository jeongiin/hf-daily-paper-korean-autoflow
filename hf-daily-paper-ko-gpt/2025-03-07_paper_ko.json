[
    {
        "paper": {
            "id": "2503.04625",
            "authors": [
                {
                    "_id": "67ca670d3e81e3344dc4c2d9",
                    "user": {
                        "_id": "65294b334d7cf551ac50d6a6",
                        "avatarUrl": "/avatars/75d21e20b711b871616ef3850bb900b7.svg",
                        "isPro": false,
                        "fullname": "ChengpengLi",
                        "user": "ChengpengLi",
                        "type": "user"
                    },
                    "name": "Chengpeng Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:12:37.350Z",
                    "hidden": false
                },
                {
                    "_id": "67ca670d3e81e3344dc4c2da",
                    "user": {
                        "_id": "5f8946925d083370c711f296",
                        "avatarUrl": "/avatars/14246aae3b1f8b7ad050f8ff2c8b260e.svg",
                        "isPro": false,
                        "fullname": "Mingfeng Xue",
                        "user": "mingfengxue",
                        "type": "user"
                    },
                    "name": "Mingfeng Xue",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:12:28.354Z",
                    "hidden": false
                },
                {
                    "_id": "67ca670d3e81e3344dc4c2db",
                    "user": {
                        "_id": "64704e973601bb7b06643e98",
                        "avatarUrl": "/avatars/52e51f4d1be6769e4397b8be2799cf32.svg",
                        "isPro": false,
                        "fullname": "Zhang",
                        "user": "Zhenru",
                        "type": "user"
                    },
                    "name": "Zhenru Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:12:48.194Z",
                    "hidden": false
                },
                {
                    "_id": "67ca670d3e81e3344dc4c2dc",
                    "user": {
                        "_id": "646df403ad20c6fa4f30b7ec",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/646df403ad20c6fa4f30b7ec/Q64-XMghOcBoo3itZDGYA.jpeg",
                        "isPro": false,
                        "fullname": "Jiaxi Yang",
                        "user": "jx-yang",
                        "type": "user"
                    },
                    "name": "Jiaxi Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:12:57.082Z",
                    "hidden": false
                },
                {
                    "_id": "67ca670d3e81e3344dc4c2dd",
                    "user": {
                        "_id": "64b93578ee257c3a4cfceed1",
                        "avatarUrl": "/avatars/e6188562254f75a09b4048b800860016.svg",
                        "isPro": false,
                        "fullname": "Beichen Zhang",
                        "user": "BeichenZhang",
                        "type": "user"
                    },
                    "name": "Beichen Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:13:11.641Z",
                    "hidden": false
                },
                {
                    "_id": "67ca670d3e81e3344dc4c2de",
                    "name": "Xiang Wang",
                    "hidden": false
                },
                {
                    "_id": "67ca670d3e81e3344dc4c2df",
                    "user": {
                        "_id": "6583ab7983a9e1460c67d876",
                        "avatarUrl": "/avatars/74400bc448c3f07e23a4cd53d68a6af7.svg",
                        "isPro": false,
                        "fullname": "bowen",
                        "user": "bowenYu",
                        "type": "user"
                    },
                    "name": "Bowen Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:13:30.530Z",
                    "hidden": false
                },
                {
                    "_id": "67ca670d3e81e3344dc4c2e0",
                    "user": {
                        "_id": "61e4c4ca1ab24785ac11ba69",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61e4c4ca1ab24785ac11ba69/1Q1zhhyGSJ9RJG9MzwxVv.jpeg",
                        "isPro": false,
                        "fullname": "Binyuan Hui",
                        "user": "huybery",
                        "type": "user"
                    },
                    "name": "Binyuan Hui",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:13:37.341Z",
                    "hidden": false
                },
                {
                    "_id": "67ca670d3e81e3344dc4c2e1",
                    "user": {
                        "_id": "620760a26e3b7210c2ff1943",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/620760a26e3b7210c2ff1943/VC-rKqimF6yxGESNVlPoR.jpeg",
                        "isPro": false,
                        "fullname": "Junyang Lin",
                        "user": "JustinLin610",
                        "type": "user"
                    },
                    "name": "Junyang Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:13:44.084Z",
                    "hidden": false
                },
                {
                    "_id": "67ca670d3e81e3344dc4c2e2",
                    "user": {
                        "_id": "6434d4989bd5a84b5dd0b0f5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6434d4989bd5a84b5dd0b0f5/0Elf9qbfG9Hkgypm9pTGm.jpeg",
                        "isPro": false,
                        "fullname": "Dayiheng Liu",
                        "user": "Losin94",
                        "type": "user"
                    },
                    "name": "Dayiheng Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:13:52.711Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-06T17:11:51.000Z",
            "title": "START: Self-taught Reasoner with Tools",
            "summary": "Large reasoning models (LRMs) like OpenAI-o1 and DeepSeek-R1 have\ndemonstrated remarkable capabilities in complex reasoning tasks through the\nutilization of long Chain-of-thought (CoT). However, these models often suffer\nfrom hallucinations and inefficiencies due to their reliance solely on internal\nreasoning processes. In this paper, we introduce START (Self-Taught Reasoner\nwith Tools), a novel tool-integrated long CoT reasoning LLM that significantly\nenhances reasoning capabilities by leveraging external tools. Through code\nexecution, START is capable of performing complex computations, self-checking,\nexploring diverse methods, and self-debugging, thereby addressing the\nlimitations of LRMs. The core innovation of START lies in its self-learning\nframework, which comprises two key techniques: 1) Hint-infer: We demonstrate\nthat inserting artificially designed hints (e.g., ``Wait, maybe using Python\nhere is a good idea.'') during the inference process of a LRM effectively\nstimulates its ability to utilize external tools without the need for any\ndemonstration data. Hint-infer can also serve as a simple and effective\nsequential test-time scaling method; 2) Hint Rejection Sampling Fine-Tuning\n(Hint-RFT): Hint-RFT combines Hint-infer and RFT by scoring, filtering, and\nmodifying the reasoning trajectories with tool invocation generated by a LRM\nvia Hint-infer, followed by fine-tuning the LRM. Through this framework, we\nhave fine-tuned the QwQ-32B model to achieve START. On PhD-level science QA\n(GPQA), competition-level math benchmarks (AMC23, AIME24, AIME25), and the\ncompetition-level code benchmark (LiveCodeBench), START achieves accuracy rates\nof 63.6%, 95.0%, 66.7%, 47.1%, and 47.3%, respectively. It significantly\noutperforms the base QwQ-32B and achieves performance comparable to the\nstate-of-the-art open-weight model R1-Distill-Qwen-32B and the proprietary\nmodel o1-Preview.",
            "upvotes": 42,
            "discussionId": "67ca67103e81e3344dc4c366"
        },
        "translation_title": "START: 도구를 활용한 자기 학습 추론기",
        "purpose": "복잡한 추론 작업에서 모델의 능력을 향상시키기 위해 외부 도구를 활용하려는 목표",
        "method": [
            "START는 외부 도구를 활용하여 복잡한 계산, 자기 점검, 다양한 방법 탐색 및 자기 디버깅을 수행함으로써 LRM의 한계를 해결함(Through code execution, START is capable of performing complex computations, self-checking, exploring diverse methods, and self-debugging, thereby addressing the limitations of LRMs.)",
            "Hint-infer 기법을 통해 LRM의 추론 과정 중에 인위적으로 설계된 힌트를 삽입하여 외부 도구 활용을 촉진함(Hint-infer: We demonstrate that inserting artificially designed hints during the inference process of a LRM effectively stimulates its ability to utilize external tools without the need for any demonstration data.)",
            "Hint-RFT를 통해 힌트와 도구 사용을 조합하여 LRM의 추론 경로를 조정하고 미세 조정함(Hint Rejection Sampling Fine-Tuning (Hint-RFT): Hint-RFT combines Hint-infer and RFT by scoring, filtering, and modifying the reasoning trajectories with tool invocation generated by a LRM via Hint-infer, followed by fine-tuning the LRM.)"
        ],
        "conclusion": "START는 QwQ-32B 모델을 미세 조정하여 과학 QA와 수학 benchmarks에서 뛰어난 성능을 달성하고, 기존 모델보다 더 높은 정확도를 보임.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2503.04724",
            "authors": [
                {
                    "_id": "67cacfd85dc0bf8f5e6fc803",
                    "name": "Sambal Shikhar",
                    "hidden": false
                },
                {
                    "_id": "67cacfd85dc0bf8f5e6fc804",
                    "user": {
                        "_id": "650289dbc130d99814b34dc5",
                        "avatarUrl": "/avatars/ff0cf5add144cd79c41a255f41f34efb.svg",
                        "isPro": false,
                        "fullname": "K Mohammed Irfan",
                        "user": "k-m-irfan",
                        "type": "user"
                    },
                    "name": "Mohammed Irfan Kurpath",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-07T13:37:55.973Z",
                    "hidden": false
                },
                {
                    "_id": "67cacfd85dc0bf8f5e6fc805",
                    "user": {
                        "_id": "62e23c7f555a866437a53cd0",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e23c7f555a866437a53cd0/UaAsYZQXuwb4NSG5WnvdG.jpeg",
                        "isPro": false,
                        "fullname": "Sahal Shaji",
                        "user": "sahalshajim",
                        "type": "user"
                    },
                    "name": "Sahal Shaji Mullappilly",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-07T13:37:53.972Z",
                    "hidden": false
                },
                {
                    "_id": "67cacfd85dc0bf8f5e6fc806",
                    "name": "Jean Lahoud",
                    "hidden": false
                },
                {
                    "_id": "67cacfd85dc0bf8f5e6fc807",
                    "name": "Fahad Khan",
                    "hidden": false
                },
                {
                    "_id": "67cacfd85dc0bf8f5e6fc808",
                    "name": "Rao Muhammad Anwer",
                    "hidden": false
                },
                {
                    "_id": "67cacfd85dc0bf8f5e6fc809",
                    "name": "Salman Khan",
                    "hidden": false
                },
                {
                    "_id": "67cacfd85dc0bf8f5e6fc80a",
                    "name": "Hisham Cholakkal",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-06T18:59:38.000Z",
            "title": "LLMVoX: Autoregressive Streaming Text-to-Speech Model for Any LLM",
            "summary": "Recent advancements in speech-to-speech dialogue systems leverage LLMs for\nmultimodal interactions, yet they remain hindered by fine-tuning requirements,\nhigh computational overhead, and text-speech misalignment. Existing\nspeech-enabled LLMs often degrade conversational quality by modifying the LLM,\nthereby compromising its linguistic capabilities. In contrast, we propose\nLLMVoX, a lightweight 30M-parameter, LLM-agnostic, autoregressive streaming TTS\nsystem that generates high-quality speech with low latency, while fully\npreserving the capabilities of the base LLM. Our approach achieves a\nsignificantly lower Word Error Rate compared to speech-enabled LLMs, while\noperating at comparable latency and UTMOS score. By decoupling speech synthesis\nfrom LLM processing via a multi-queue token streaming system, LLMVoX supports\nseamless, infinite-length dialogues. Its plug-and-play design also facilitates\nextension to various tasks with different backbones. Furthermore, LLMVoX\ngeneralizes to new languages with only dataset adaptation, attaining a low\nCharacter Error Rate on an Arabic speech task. Additionally, we have integrated\nLLMVoX with a Vision-Language Model to create an omni-model with speech, text,\nand vision capabilities, without requiring additional multimodal training. Our\ncode base and project page is available at https://mbzuai-oryx.github.io/LLMVoX .",
            "upvotes": 21,
            "discussionId": "67cacfd95dc0bf8f5e6fc84e",
            "projectPage": "https://mbzuai-oryx.github.io/LLMVoX/",
            "githubRepo": "https://github.com/mbzuai-oryx/LLMVoX"
        },
        "translation_title": "LLMVoX: 모든 LLM을 위한 자가 회귀 스트리밍 텍스트-음성 변환 모델",
        "purpose": "고품질 음성을 생성하면서도 LLM의 능력을 완전히 보존하는 스트리밍 TTS 시스템 개발",
        "method": [
            "경량화된 30M-파라미터의 LLM-비의존성 자가 회귀 텍스트-음성 변환 시스템 제안(we propose LLMVoX, a lightweight 30M-parameter, LLM-agnostic, autoregressive streaming TTS system that generates high-quality speech with low latency.)",
            "멀티 큐 토큰 스트리밍 시스템을 통해 음성 합성을 LLM 처리와 분리함(By decoupling speech synthesis from LLM processing via a multi-queue token streaming system.)",
            "다양한 작업에 쉽게 확장할 수 있도록 플러그 앤 플레이 디자인을 채택함(Its plug-and-play design also facilitates extension to various tasks with different backbones.)"
        ],
        "conclusion": "LLMVoX는 낮은 Word Error Rate와 낮은 Character Error Rate를 유지하며, 음성, 텍스트, 비전을 통합한 모델을 손쉽게 생성할 수 있게 함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Vision-Language Models"
        ]
    },
    {
        "paper": {
            "id": "2503.03803",
            "authors": [
                {
                    "_id": "67ca874c3ac187dbbed924d6",
                    "user": {
                        "_id": "62b5777f593a2c49da69dc02",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1658152070753-62b5777f593a2c49da69dc02.jpeg",
                        "isPro": false,
                        "fullname": "Jingkang Yang",
                        "user": "Jingkang",
                        "type": "user"
                    },
                    "name": "Jingkang Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-07T09:09:32.949Z",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924d7",
                    "user": {
                        "_id": "64f7f5b54101c731ca84ae05",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64f7f5b54101c731ca84ae05/13DwdxOo3tWbxKDLd44B9.jpeg",
                        "isPro": false,
                        "fullname": "Shuai Liu",
                        "user": "Choiszt",
                        "type": "user"
                    },
                    "name": "Shuai Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-07T13:38:04.320Z",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924d8",
                    "name": "Hongming Guo",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924d9",
                    "user": {
                        "_id": "652965773a416e1f2173443b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/652965773a416e1f2173443b/y9MB8YgHzbwCXAc4EI9T3.jpeg",
                        "isPro": false,
                        "fullname": "Yuhao Dong",
                        "user": "THUdyh",
                        "type": "user"
                    },
                    "name": "Yuhao Dong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:15:21.671Z",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924da",
                    "name": "Xiamengwei Zhang",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924db",
                    "user": {
                        "_id": "63f87c42b0ae1748524a9cfb",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63f87c42b0ae1748524a9cfb/I5ukv6iWoJVToWmcERmvx.jpeg",
                        "isPro": false,
                        "fullname": "Sicheng Zhang",
                        "user": "fesvhtr",
                        "type": "user"
                    },
                    "name": "Sicheng Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:15:37.377Z",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924dc",
                    "user": {
                        "_id": "62f113d3b58090c873d66481",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1659966415211-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Pengyun Wang",
                        "user": "Alarak",
                        "type": "user"
                    },
                    "name": "Pengyun Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:15:44.290Z",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924dd",
                    "user": {
                        "_id": "668eb3a1a2f3f9d5edf029eb",
                        "avatarUrl": "/avatars/383636e449f5e48c790f428818dd6863.svg",
                        "isPro": false,
                        "fullname": "zhou zitang",
                        "user": "Zzitang",
                        "type": "user"
                    },
                    "name": "Zitang Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:15:56.178Z",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924de",
                    "user": {
                        "_id": "63f886a99f87cc3e645c99a8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63f886a99f87cc3e645c99a8/qwj16BrFaDjN0DPFsJ-6v.jpeg",
                        "isPro": false,
                        "fullname": "Binzhu Xie",
                        "user": "Nicous",
                        "type": "user"
                    },
                    "name": "Binzhu Xie",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:16:02.570Z",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924df",
                    "name": "Ziyue Wang",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924e0",
                    "name": "Bei Ouyang",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924e1",
                    "name": "Zhengyu Lin",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924e2",
                    "name": "Marco Cominelli",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924e3",
                    "user": {
                        "_id": "652d06833b5997ed71ce5c46",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/xZTXEcnEogEmBm_ledJQr.jpeg",
                        "isPro": false,
                        "fullname": "Zhongang Cai",
                        "user": "caizhongang",
                        "type": "user"
                    },
                    "name": "Zhongang Cai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:16:33.666Z",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924e4",
                    "user": {
                        "_id": "62a993d80472c0b7f94027df",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62a993d80472c0b7f94027df/j5vp-IwLA2YBexylUHiQU.png",
                        "isPro": false,
                        "fullname": "Zhang Yuanhan",
                        "user": "ZhangYuanhan",
                        "type": "user"
                    },
                    "name": "Yuanhan Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:16:45.989Z",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924e5",
                    "user": {
                        "_id": "63565cc56d7fcf1bedb7d347",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63565cc56d7fcf1bedb7d347/XGcHP4VkO_oieA1gZ4IAX.jpeg",
                        "isPro": false,
                        "fullname": "Zhang Peiyuan",
                        "user": "PY007",
                        "type": "user"
                    },
                    "name": "Peiyuan Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:16:57.532Z",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924e6",
                    "user": {
                        "_id": "67443675924e80c3c8807b40",
                        "avatarUrl": "/avatars/fb45422391e51d2ad641f09c8535653c.svg",
                        "isPro": false,
                        "fullname": "fangzhou HONG",
                        "user": "h12345678",
                        "type": "user"
                    },
                    "name": "Fangzhou Hong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:17:05.845Z",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924e7",
                    "name": "Joerg Widmer",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924e8",
                    "name": "Francesco Gringoli",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924e9",
                    "name": "Lei Yang",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924ea",
                    "name": "Bo Li",
                    "hidden": false
                },
                {
                    "_id": "67ca874c3ac187dbbed924eb",
                    "user": {
                        "_id": "62ab1ac1d48b4d8b048a3473",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png",
                        "isPro": false,
                        "fullname": "Ziwei Liu",
                        "user": "liuziwei7",
                        "type": "user"
                    },
                    "name": "Ziwei Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:15:05.677Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-05T18:54:16.000Z",
            "title": "EgoLife: Towards Egocentric Life Assistant",
            "summary": "We introduce EgoLife, a project to develop an egocentric life assistant that\naccompanies and enhances personal efficiency through AI-powered wearable\nglasses. To lay the foundation for this assistant, we conducted a comprehensive\ndata collection study where six participants lived together for one week,\ncontinuously recording their daily activities - including discussions,\nshopping, cooking, socializing, and entertainment - using AI glasses for\nmultimodal egocentric video capture, along with synchronized third-person-view\nvideo references. This effort resulted in the EgoLife Dataset, a comprehensive\n300-hour egocentric, interpersonal, multiview, and multimodal daily life\ndataset with intensive annotation. Leveraging this dataset, we introduce\nEgoLifeQA, a suite of long-context, life-oriented question-answering tasks\ndesigned to provide meaningful assistance in daily life by addressing practical\nquestions such as recalling past relevant events, monitoring health habits, and\noffering personalized recommendations. To address the key technical challenges\nof (1) developing robust visual-audio models for egocentric data, (2) enabling\nidentity recognition, and (3) facilitating long-context question answering over\nextensive temporal information, we introduce EgoButler, an integrated system\ncomprising EgoGPT and EgoRAG. EgoGPT is an omni-modal model trained on\negocentric datasets, achieving state-of-the-art performance on egocentric video\nunderstanding. EgoRAG is a retrieval-based component that supports answering\nultra-long-context questions. Our experimental studies verify their working\nmechanisms and reveal critical factors and bottlenecks, guiding future\nimprovements. By releasing our datasets, models, and benchmarks, we aim to\nstimulate further research in egocentric AI assistants.",
            "upvotes": 15,
            "discussionId": "67ca874f3ac187dbbed925cc",
            "projectPage": "https://egolife-ai.github.io/",
            "githubRepo": "https://github.com/EvolvingLMMs-Lab/EgoLife"
        },
        "translation_title": "EgoLife: 에고 중심 라이프 어시스턴트 개발을 향하여",
        "purpose": "AI 기반의 착용형 안경을 통해 개인의 효율성을 높이는 에고 중심 라이프 어시스턴트 개발",
        "method": [
            "AI 안경을 사용하여 일주일 동안의 일상 활동을 기록하는 포괄적인 데이터 수집 연구 수행(We conducted a comprehensive data collection study where six participants lived together for one week, continuously recording their daily activities.)",
            "300시간 분량의 에고 중심 일상 데이터 세트인 EgoLife Dataset 생성(Effort resulted in the EgoLife Dataset, a comprehensive 300-hour egocentric, interpersonal, multiview, and multimodal daily life dataset with intensive annotation.)",
            "EgoButler라는 통합 시스템을 통해 에고 중심 데이터에 대한 강력한 시각-청각 모델 개발(EgoButler, an integrated system comprising EgoGPT and EgoRAG...)"
        ],
        "conclusion": "EgoLife는 일상 생활에서의 실질적인 질문에 의미 있는 도움을 제공할 수 있으며, 에고 중심 AI 어시스턴트 연구를 촉진할 수 있는 데이터세트와 모델을 공개할 계획.",
        "keywords": [
            "Multimodal Learning",
            "Video Understanding",
            "Natural Language Processing"
        ]
    },
    {
        "paper": {
            "id": "2502.20258",
            "authors": [
                {
                    "_id": "67ca7b557436e6327ca877ff",
                    "user": {
                        "_id": "655efd24afee0e00788bb589",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/655efd24afee0e00788bb589/22guLxIWNybbJR3jI-c4w.jpeg",
                        "isPro": false,
                        "fullname": "Amr Mohamed",
                        "user": "amr-mohamed",
                        "type": "user"
                    },
                    "name": "Amr Mohamed",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-07T09:09:41.298Z",
                    "hidden": false
                },
                {
                    "_id": "67ca7b557436e6327ca87800",
                    "user": {
                        "_id": "67890323f8796231c857231e",
                        "avatarUrl": "/avatars/f5ccd5186968d880fee9c36324a5f713.svg",
                        "isPro": false,
                        "fullname": "Mingmeng Geng",
                        "user": "mgeng",
                        "type": "user"
                    },
                    "name": "Mingmeng Geng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-07T09:34:23.443Z",
                    "hidden": false
                },
                {
                    "_id": "67ca7b557436e6327ca87801",
                    "name": "Michalis Vazirgiannis",
                    "hidden": false
                },
                {
                    "_id": "67ca7b557436e6327ca87802",
                    "user": {
                        "_id": "6087e598e2b7cc3a117b0dc5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6087e598e2b7cc3a117b0dc5/Ctz_W-uo1gOQRBHXalD1P.png",
                        "isPro": false,
                        "fullname": "Guokan Shang",
                        "user": "guokan-shang",
                        "type": "user"
                    },
                    "name": "Guokan Shang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-07T09:09:38.933Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-27T16:46:23.000Z",
            "title": "LLM as a Broken Telephone: Iterative Generation Distorts Information",
            "summary": "As large language models are increasingly responsible for online content,\nconcerns arise about the impact of repeatedly processing their own outputs.\nInspired by the \"broken telephone\" effect in chained human communication, this\nstudy investigates whether LLMs similarly distort information through iterative\ngeneration. Through translation-based experiments, we find that distortion\naccumulates over time, influenced by language choice and chain complexity.\nWhile degradation is inevitable, it can be mitigated through strategic\nprompting techniques. These findings contribute to discussions on the long-term\neffects of AI-mediated information propagation, raising important questions\nabout the reliability of LLM-generated content in iterative workflows.",
            "upvotes": 14,
            "discussionId": "67ca7b577436e6327ca878ec",
            "githubRepo": "https://github.com/amr-mohamedd/LLM-as-a-Broken-Telephone"
        },
        "translation_title": "흐트러진 전화기처럼: 반복 생성이 정보를 왜곡한다",
        "purpose": "LLM(대형 언어 모델)이 정보를 반복적으로 생성함에 따른 왜곡 현상 연구",
        "method": [
            "번역 기반 실험을 통해 LLM이 정보 왜곡이 축적되는지를 조사함(Through translation-based experiments, we find that distortion accumulates over time, influenced by language choice and chain complexity.)",
            "언어 선택과 체인 복잡성이 왜곡에 영향을 미친다는 사실을 발견함(Through translation-based experiments, we find that distortion accumulates over time, influenced by language choice and chain complexity.)",
            "전략적인 프롬프트 기법을 통해 정보를 왜곡 감소시킬 수 있는 방법을 탐구함(While degradation is inevitable, it can be mitigated through strategic prompting techniques.)"
        ],
        "conclusion": "정보의 왜곡 현상은 불가피하나, 전략적인 접근으로 개선할 수 있다는 것을 확인함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2503.02972",
            "authors": [
                {
                    "_id": "67c96a61df4d64bfebd396d4",
                    "name": "Jude Khouja",
                    "hidden": false
                },
                {
                    "_id": "67c96a61df4d64bfebd396d5",
                    "user": {
                        "_id": "64b92ae4ee257c3a4cfbc07a",
                        "avatarUrl": "/avatars/c4f91978749309c7805e3df1ced115b2.svg",
                        "isPro": false,
                        "fullname": "Karolina Korgul",
                        "user": "karotka",
                        "type": "user"
                    },
                    "name": "Karolina Korgul",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-07T13:38:07.551Z",
                    "hidden": false
                },
                {
                    "_id": "67c96a61df4d64bfebd396d6",
                    "name": "Simi Hellsten",
                    "hidden": false
                },
                {
                    "_id": "67c96a61df4d64bfebd396d7",
                    "name": "Lingyi Yang",
                    "hidden": false
                },
                {
                    "_id": "67c96a61df4d64bfebd396d8",
                    "name": "Vlad Neacs",
                    "hidden": false
                },
                {
                    "_id": "67c96a61df4d64bfebd396d9",
                    "name": "Harry Mayne",
                    "hidden": false
                },
                {
                    "_id": "67c96a61df4d64bfebd396da",
                    "user": {
                        "_id": "6751ea855b1cc8f5a14dcc27",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/Vw5XZptgrzw2en-xQekAs.png",
                        "isPro": false,
                        "fullname": "Ryan Othniel Kearns",
                        "user": "ryanothk",
                        "type": "user"
                    },
                    "name": "Ryan Kearns",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-07T13:38:05.914Z",
                    "hidden": false
                },
                {
                    "_id": "67c96a61df4d64bfebd396db",
                    "name": "Andrew Bean",
                    "hidden": false
                },
                {
                    "_id": "67c96a61df4d64bfebd396dc",
                    "name": "Adam Mahdi",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-04T19:57:47.000Z",
            "title": "LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic\n  Templatisation and Orthographic Obfuscation",
            "summary": "Effective evaluation of the reasoning capabilities of large language models\n(LLMs) are susceptible to overestimation due to data exposure of evaluation\nbenchmarks. We introduce a framework for producing linguistic reasoning\nproblems that reduces the effect of memorisation in model performance estimates\nand apply this framework to develop LINGOLY-TOO, a challenging evaluation\nbenchmark for linguistic reasoning. By developing orthographic templates, we\ndynamically obfuscate the writing systems of real languages to generate\nnumerous question variations. These variations preserve the reasoning steps\nrequired for each solution while reducing the likelihood of specific problem\ninstances appearing in model training data. Our experiments demonstrate that\nfrontier models, including OpenAI o1-preview and DeepSeem R1, struggle with\nadvanced reasoning. Our analysis also shows that LLMs exhibit noticeable\nvariance in accuracy across permutations of the same problem, and on average\nperform better on questions appearing in their original orthography. Our\nfindings highlight the opaque nature of response generation in LLMs and provide\nevidence that prior data exposure contributes to overestimating the reasoning\ncapabilities of frontier models.",
            "upvotes": 12,
            "discussionId": "67c96a62df4d64bfebd3976e",
            "projectPage": "https://huggingface.co/spaces/jkhouja/lingoly-too",
            "githubRepo": "https://github.com/jkhouja/L2"
        },
        "translation_title": "LINGOLY-TOO: 언어적 템플릿화와 철자 혼동을 통해 기억과 추론을 분리하기",
        "purpose": "대형 언어 모델(LLMs)의 추론 능력을 보다 정확하게 평가하기 위한 프레임워크 개발",
        "method": [
            "언어적 추론 문제를 생성하는 프레임워크를 도입함(We introduce a framework for producing linguistic reasoning problems that reduces the effect of memorisation in model performance estimates.)",
            "서로 다른 질문 변형을 만들기 위해 실제 언어의 쓰기 시스템을 동적으로 혼동시키는 정형 템플릿을 개발함(By developing orthographic templates, we dynamically obfuscate the writing systems of real languages to generate numerous question variations.)",
            "모델 훈련 데이터에 특정 문제 인스턴스가 나타날 가능성을 줄이면서 각 솔루션에 필요한 추론 단계를 유지함(these variations preserve the reasoning steps required for each solution while reducing the likelihood of specific problem instances appearing in model training data.)"
        ],
        "conclusion": "모델들이 고급 추론에 어려움을 겪었으며, 이전 데이터 노출이 LLM의 추론 능력을 과대평가하는 데 기여한다는 점을 입증함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Image Generation"
        ]
    }
]