[
    {
        "paper": {
            "id": "2601.20614",
            "authors": [
                {
                    "_id": "697ac91bdf3e800774f13c12",
                    "name": "Yanqi Dai",
                    "hidden": false
                },
                {
                    "_id": "697ac91bdf3e800774f13c13",
                    "name": "Yuxiang Ji",
                    "hidden": false
                },
                {
                    "_id": "697ac91bdf3e800774f13c14",
                    "name": "Xiao Zhang",
                    "hidden": false
                },
                {
                    "_id": "697ac91bdf3e800774f13c15",
                    "name": "Yong Wang",
                    "hidden": false
                },
                {
                    "_id": "697ac91bdf3e800774f13c16",
                    "name": "Xiangxiang Chu",
                    "hidden": false
                },
                {
                    "_id": "697ac91bdf3e800774f13c17",
                    "name": "Zhiwu Lu",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-28T13:49:23.000Z",
            "submittedOnDailyAt": "2026-01-29T00:15:35.371Z",
            "title": "Harder Is Better: Boosting Mathematical Reasoning via Difficulty-Aware GRPO and Multi-Aspect Question Reformulation",
            "submittedOnDailyBy": {
                "_id": "66cde57cb1fe4c78fe3ab770",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66cde57cb1fe4c78fe3ab770/0R1aA-f_XLjCfy1HwqZ-p.jpeg",
                "isPro": false,
                "fullname": "Yanqi Dai",
                "user": "YanqiDai",
                "type": "user"
            },
            "summary": "Reinforcement Learning with Verifiable Rewards (RLVR) offers a robust mechanism for enhancing mathematical reasoning in large models. However, we identify a systematic lack of emphasis on more challenging questions in existing methods from both algorithmic and data perspectives, despite their importance for refining underdeveloped capabilities. Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions. Data-wise, augmentation approaches primarily rephrase questions to enhance diversity without systematically increasing intrinsic difficulty. To address these issues, we propose a two-dual MathForge framework to improve mathematical reasoning by targeting harder questions from both perspectives, which comprises a Difficulty-Aware Group Policy Optimization (DGPO) algorithm and a Multi-Aspect Question Reformulation (MQR) strategy. Specifically, DGPO first rectifies the implicit imbalance in GRPO via difficulty-balanced group advantage estimation, and further prioritizes harder questions by difficulty-aware question-level weighting. Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer. Overall, MathForge forms a synergistic loop: MQR expands the data frontier, and DGPO effectively learns from the augmented data. Extensive experiments show that MathForge significantly outperforms existing methods on various mathematical reasoning tasks. The code and augmented data are all available at https://github.com/AMAP-ML/MathForge.",
            "upvotes": 91,
            "discussionId": "697ac91bdf3e800774f13c18",
            "githubRepo": "https://github.com/AMAP-ML/MathForge",
            "githubRepoAddedBy": "user",
            "ai_summary": "MathForge enhances mathematical reasoning in large models through a dual framework combining difficulty-aware policy optimization and multi-aspect question reformulation to address limitations in existing reinforcement learning methods.",
            "ai_keywords": [
                "Reinforcement Learning with Verifiable Rewards",
                "Group Relative Policy Optimization",
                "Difficulty-Aware Group Policy Optimization",
                "Multi-Aspect Question Reformulation",
                "mathematical reasoning",
                "policy updates",
                "group advantage estimation",
                "question-level weighting",
                "data augmentation"
            ],
            "githubStars": 81,
            "organization": {
                "_id": "67d11771890254196d3174e5",
                "name": "GD-ML",
                "fullname": "AMAP-ML",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67d116c47be76de1a40873ca/s5ukAx9E36ZZIKvbpBRi4.png"
            }
        },
        "translation_title": "더 어려운 것이 더 낫다: 난이도 인식 GRPO와 다각적 질문 재구성을 통한 수학적 사고 향상",
        "purpose": "수학적 추론 능력을 향상시키기 위해 어려운 질문에 대한 집중을 강화하려는 목표",
        "method": [
            "Difficulty-Aware Group Policy Optimization(DGPO) 알고리즘을 통해 GRPO의 암묵적인 불균형을 수정하고, 난이도 기반의 질문 가중치를 부여하여 어려운 질문의 우선순위를 높임(Algorithmically, widely used Group Relative Policy Optimization (GRPO) suffers from an implicit imbalance where the magnitude of policy updates is lower for harder questions.)",
            "Multi-Aspect Question Reformulation(MQR) 전략을 사용하여 질문을 여러 측면에서 재구성해 난이도를 증가시키지만 원래의 올바른 답을 유지함(Meanwhile, MQR reformulates questions across multiple aspects to increase difficulty while maintaining the original gold answer.)"
        ],
        "conclusion": "MathForge는 기존 방법보다 다양한 수학적 사고 과제를 성공적으로 개선하며, 데이터와 코드를 공개함으로써 연구 커뮤니티에 기여함.",
        "keywords": [
            "Natural Language Processing",
            "Reinforcement Learning",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2601.20540",
            "authors": [
                {
                    "_id": "697ac48cdf3e800774f13bc1",
                    "name": "Robbyant Team",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bc2",
                    "name": "Zelin Gao",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bc3",
                    "user": {
                        "_id": "64981bea09cea550852652af",
                        "avatarUrl": "/avatars/df528e9008972c8e5ae4d278e617476c.svg",
                        "isPro": false,
                        "fullname": "Qiuyu Wang",
                        "user": "qiuyuu",
                        "type": "user"
                    },
                    "name": "Qiuyu Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-29T09:16:29.190Z",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bc4",
                    "name": "Yanhong Zeng",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bc5",
                    "name": "Jiapeng Zhu",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bc6",
                    "user": {
                        "_id": "64acd2ec39fcfebff8c79c00",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64acd2ec39fcfebff8c79c00/Avq66l5hO-aggNtk4Y1ss.png",
                        "isPro": false,
                        "fullname": "Ka Leong Cheng",
                        "user": "felixcheng97",
                        "type": "user"
                    },
                    "name": "Ka Leong Cheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-29T13:56:36.041Z",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bc7",
                    "name": "Yixuan Li",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bc8",
                    "user": {
                        "_id": "665f059a8947302aa2c63afe",
                        "avatarUrl": "/avatars/50f560285946532321a0bd526494148d.svg",
                        "isPro": false,
                        "fullname": "hanlin wang",
                        "user": "hlwang06",
                        "type": "user"
                    },
                    "name": "Hanlin Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-29T09:18:10.952Z",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bc9",
                    "name": "Yinghao Xu",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bca",
                    "name": "Shuailei Ma",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bcb",
                    "name": "Yihang Chen",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bcc",
                    "name": "Jie Liu",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bcd",
                    "name": "Yansong Cheng",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bce",
                    "name": "Yao Yao",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bcf",
                    "name": "Jiayi Zhu",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bd0",
                    "user": {
                        "_id": "656084f44e8918182d4f07c8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/akAvCUCi7eR31PWOXrVPw.jpeg",
                        "isPro": false,
                        "fullname": "Yihao Meng",
                        "user": "Yhmeng1106",
                        "type": "user"
                    },
                    "name": "Yihao Meng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-29T13:56:37.840Z",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bd1",
                    "name": "Kecheng Zheng",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bd2",
                    "user": {
                        "_id": "63f0baf66309c84d5f4a2226",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63f0baf66309c84d5f4a2226/ihOgtwseRkfP1t-60IgyT.jpeg",
                        "isPro": true,
                        "fullname": "Qingyan",
                        "user": "QingyanBai",
                        "type": "user"
                    },
                    "name": "Qingyan Bai",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-29T09:16:24.535Z",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bd3",
                    "user": {
                        "_id": "6478a982256b62e219917d67",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/PUJ-N2cQxgEmDGfyjajyA.jpeg",
                        "isPro": false,
                        "fullname": "JingyeChen22",
                        "user": "JingyeChen22",
                        "type": "user"
                    },
                    "name": "Jingye Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-29T09:17:37.828Z",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bd4",
                    "name": "Zehong Shen",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bd5",
                    "user": {
                        "_id": "662128ec9ca2cd4e6db2fb44",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/662128ec9ca2cd4e6db2fb44/uUg1V-pVfxT3mLuFgJuAN.jpeg",
                        "isPro": false,
                        "fullname": "Bruce Yu",
                        "user": "bruceyyu",
                        "type": "user"
                    },
                    "name": "Yue Yu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-29T09:16:27.115Z",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bd6",
                    "name": "Xing Zhu",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bd7",
                    "name": "Yujun Shen",
                    "hidden": false
                },
                {
                    "_id": "697ac48cdf3e800774f13bd8",
                    "name": "Hao Ouyang",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/64981bea09cea550852652af/HObcL400nFnYaw2kOcjor.mp4"
            ],
            "publishedAt": "2026-01-28T12:37:01.000Z",
            "submittedOnDailyAt": "2026-01-29T00:09:39.166Z",
            "title": "Advancing Open-source World Models",
            "submittedOnDailyBy": {
                "_id": "64981bea09cea550852652af",
                "avatarUrl": "/avatars/df528e9008972c8e5ae4d278e617476c.svg",
                "isPro": false,
                "fullname": "Qiuyu Wang",
                "user": "qiuyuu",
                "type": "user"
            },
            "summary": "We present LingBot-World, an open-sourced world simulator stemming from video generation. Positioned as a top-tier world model, LingBot-World offers the following features. (1) It maintains high fidelity and robust dynamics in a broad spectrum of environments, including realism, scientific contexts, cartoon styles, and beyond. (2) It enables a minute-level horizon while preserving contextual consistency over time, which is also known as \"long-term memory\". (3) It supports real-time interactivity, achieving a latency of under 1 second when producing 16 frames per second. We provide public access to the code and model in an effort to narrow the divide between open-source and closed-source technologies. We believe our release will empower the community with practical applications across areas like content creation, gaming, and robot learning.",
            "upvotes": 58,
            "discussionId": "697ac48cdf3e800774f13bd9",
            "projectPage": "https://technology.robbyant.com/lingbot-world",
            "githubRepo": "https://github.com/Robbyant/lingbot-world/",
            "githubRepoAddedBy": "user",
            "ai_summary": "LingBot-World is an open-source world simulator with high-fidelity dynamics, long-term memory capabilities, and real-time interactivity for diverse environments.",
            "ai_keywords": [
                "world simulator",
                "video generation",
                "world model",
                "long-term memory",
                "real-time interactivity"
            ],
            "githubStars": 608,
            "organization": {
                "_id": "69709f892cd08371c1011a2e",
                "name": "robbyant",
                "fullname": "Robbyant",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67aeffda7330db26f93cd62f/ZTuImney4XzRmBHyUL47F.png"
            }
        },
        "translation_title": "오픈소스 세계 모델 발전하기",
        "purpose": "오픈소스와 클로즈드 소스 기술 간의 격차를 줄이기 위한 실용적인 세계 모델 개발",
        "method": [
            "LingBot-World라는 오픈소스 세계 시뮬레이터를 개발함(We present LingBot-World, an open-sourced world simulator stemming from video generation.)",
            "다양한 환경에서 높은 충실도와 강력한 동적 특성을 유지함(It maintains high fidelity and robust dynamics in a broad spectrum of environments.)",
            "시간에 따른 맥락 일관성을 유지하면서 빠른 속도로 실시간 상호작용을 지원함(It supports real-time interactivity, achieving a latency of under 1 second when producing 16 frames per second.)"
        ],
        "conclusion": "LingBot-World는 콘텐츠 제작, 게임, 로봇 학습 등의 분야에서 활용할 수 있는 강력한 도구가 될 것으로 기대됨.",
        "keywords": [
            "Video Generation",
            "Robotics",
            "Computer Vision"
        ]
    },
    {
        "paper": {
            "id": "2601.19325",
            "authors": [
                {
                    "_id": "69798298df44b75fa47e47a9",
                    "name": "Zichen Wen",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47aa",
                    "user": {
                        "_id": "688c72c011ef3399b561dee7",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/688c72c011ef3399b561dee7/puhgnTOAfZYetsC46hqGm.jpeg",
                        "isPro": false,
                        "fullname": "BoxueYang",
                        "user": "Boxue",
                        "type": "user"
                    },
                    "name": "Boxue Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-29T09:17:12.982Z",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47ab",
                    "name": "Shuang Chen",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47ac",
                    "name": "Yaojie Zhang",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47ad",
                    "name": "Yuhang Han",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47ae",
                    "name": "Junlong Ke",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47af",
                    "name": "Cong Wang",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47b0",
                    "name": "Yicheng Fu",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47b1",
                    "name": "Jiawang Zhao",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47b2",
                    "name": "Jiangchao Yao",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47b3",
                    "name": "Xi Fang",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47b4",
                    "name": "Zhen Wang",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47b5",
                    "name": "Henxing Cai",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47b6",
                    "name": "Lin Yao",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47b7",
                    "name": "Zhifeng Gao",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47b8",
                    "name": "Yanhui Hong",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47b9",
                    "name": "Nang Yuan",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47ba",
                    "name": "Yixuan Li",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47bb",
                    "name": "Guojiang Zhao",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47bc",
                    "name": "Haoyi Tao",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47bd",
                    "name": "Nan Wang",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47be",
                    "name": "Han Lyu",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47bf",
                    "name": "Guolin Ke",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47c0",
                    "name": "Ning Liao",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47c1",
                    "name": "Xiaoxing Wang",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47c2",
                    "name": "Kai Chen",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47c3",
                    "name": "Zhiyu Li",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47c4",
                    "name": "Feiyu Xiong",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47c5",
                    "name": "Sihan Hu",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47c6",
                    "name": "Kun Chen",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47c7",
                    "name": "Yanfeng Wang",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47c8",
                    "name": "Weinan E",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47c9",
                    "name": "Linfeng Zhang",
                    "hidden": false
                },
                {
                    "_id": "69798298df44b75fa47e47ca",
                    "name": "Linfeng Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-27T08:12:18.000Z",
            "submittedOnDailyAt": "2026-01-29T01:20:58.570Z",
            "title": "Innovator-VL: A Multimodal Large Language Model for Scientific Discovery",
            "submittedOnDailyBy": {
                "_id": "653b8c3e97a4d71d950e2f20",
                "avatarUrl": "/avatars/b68880022e14556d0be58c69615db3be.svg",
                "isPro": false,
                "fullname": "Zichen Wen",
                "user": "zichenwen",
                "type": "user"
            },
            "summary": "We present Innovator-VL, a scientific multimodal large language model designed to advance understanding and reasoning across diverse scientific domains while maintaining excellent performance on general vision tasks. Contrary to the trend of relying on massive domain-specific pretraining and opaque pipelines, our work demonstrates that principled training design and transparent methodology can yield strong scientific intelligence with substantially reduced data requirements. (i) First, we provide a fully transparent, end-to-end reproducible training pipeline, covering data collection, cleaning, preprocessing, supervised fine-tuning, reinforcement learning, and evaluation, along with detailed optimization recipes. This facilitates systematic extension by the community. (ii) Second, Innovator-VL exhibits remarkable data efficiency, achieving competitive performance on various scientific tasks using fewer than five million curated samples without large-scale pretraining. These results highlight that effective reasoning can be achieved through principled data selection rather than indiscriminate scaling. (iii) Third, Innovator-VL demonstrates strong generalization, achieving competitive performance on general vision, multimodal reasoning, and scientific benchmarks. This indicates that scientific alignment can be integrated into a unified model without compromising general-purpose capabilities. Our practices suggest that efficient, reproducible, and high-performing scientific multimodal models can be built even without large-scale data, providing a practical foundation for future research.",
            "upvotes": 47,
            "discussionId": "69798298df44b75fa47e47cb",
            "projectPage": "https://innovatorlm.github.io/Innovator-VL",
            "githubRepo": "https://github.com/InnovatorLM/Innovator-VL",
            "githubRepoAddedBy": "user",
            "ai_summary": "Innovator-VL demonstrates that principled training design and transparent methodology can achieve strong scientific intelligence with reduced data requirements while maintaining general vision performance.",
            "ai_keywords": [
                "multimodal large language model",
                "scientific multimodal large language model",
                "end-to-end reproducible training pipeline",
                "supervised fine-tuning",
                "reinforcement learning",
                "scientific reasoning",
                "data efficiency",
                "principled data selection",
                "generalization",
                "scientific alignment"
            ],
            "githubStars": 57,
            "organization": {
                "_id": "63e5ef7bf2e9a8f22c515654",
                "name": "SJTU",
                "fullname": "Shanghai Jiao Tong University",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1676013394657-63e5ee22b6a40bf941da0928.png"
            }
        },
        "translation_title": "Innovator-VL: 과학적 발견을 위한 다중 모달 대형 언어 모델",
        "purpose": "다양한 과학 분야에서 이해와 추론을 향상시키기 위한 다중 모달 대형 언어 모델 개발",
        "method": [
            "투명한 데이터 수집, 정제, 전처리, 감독된 파인튜닝, 강화 학습 및 평가를 포함하는 재현 가능한 교육 파이프라인 제공(we provide a fully transparent, end-to-end reproducible training pipeline, covering data collection, cleaning, preprocessing, supervised fine-tuning, reinforcement learning, and evaluation)",
            "500만 개의 선별된 샘플로 다양한 과학적 작업에서 경쟁력 있는 성능을 달성함(achieving competitive performance on various scientific tasks using fewer than five million curated samples without large-scale pretraining)",
            "일반 시각적 작업, 다중 모달 추론, 과학적 기준에서 강력한 일반화 성능을 보여줌(achieving competitive performance on general vision, multimodal reasoning, and scientific benchmarks)"
        ],
        "conclusion": "효율적이고 재현 가능한 고성능의 과학적 다중 모달 모델을 대규모 데이터 없이도 구축할 수 있음이 입증됨.",
        "keywords": [
            "Large Language Models",
            "Multimodal Learning",
            "Vision-Language Models"
        ]
    },
    {
        "paper": {
            "id": "2601.20552",
            "authors": [
                {
                    "_id": "697acf36df3e800774f13c41",
                    "name": "Haoran Wei",
                    "hidden": false
                },
                {
                    "_id": "697acf36df3e800774f13c42",
                    "name": "Yaofeng Sun",
                    "hidden": false
                },
                {
                    "_id": "697acf36df3e800774f13c43",
                    "name": "Yukun Li",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-28T12:46:07.000Z",
            "submittedOnDailyAt": "2026-01-29T00:38:50.729Z",
            "title": "DeepSeek-OCR 2: Visual Causal Flow",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "We present DeepSeek-OCR 2 to investigate the feasibility of a novel encoder-DeepEncoder V2-capable of dynamically reordering visual tokens upon image semantics. Conventional vision-language models (VLMs) invariably process visual tokens in a rigid raster-scan order (top-left to bottom-right) with fixed positional encoding when fed into LLMs. However, this contradicts human visual perception, which follows flexible yet semantically coherent scanning patterns driven by inherent logical structures. Particularly for images with complex layouts, human vision exhibits causally-informed sequential processing. Inspired by this cognitive mechanism, DeepEncoder V2 is designed to endow the encoder with causal reasoning capabilities, enabling it to intelligently reorder visual tokens prior to LLM-based content interpretation. This work explores a novel paradigm: whether 2D image understanding can be effectively achieved through two-cascaded 1D causal reasoning structures, thereby offering a new architectural approach with the potential to achieve genuine 2D reasoning. Codes and model weights are publicly accessible at http://github.com/deepseek-ai/DeepSeek-OCR-2.",
            "upvotes": 21,
            "discussionId": "697acf37df3e800774f13c44",
            "githubRepo": "https://github.com/deepseek-ai/DeepSeek-OCR-2",
            "githubRepoAddedBy": "user",
            "ai_summary": "DeepSeek-OCR 2 introduces DeepEncoder V2 that dynamically reorders visual tokens based on semantic content, enabling more human-like causal reasoning in 2D image understanding through cascaded 1D causal structures.",
            "ai_keywords": [
                "encoder-DeepEncoder V2",
                "visual tokens",
                "vision-language models",
                "raster-scan order",
                "positional encoding",
                "causal reasoning",
                "2D image understanding",
                "cascaded 1D causal reasoning"
            ],
            "githubStars": 1491,
            "organization": {
                "_id": "652faff917096ceb6bf53f3f",
                "name": "deepseek-ai",
                "fullname": "DeepSeek",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6538815d1bdb3c40db94fbfa/xMBly9PUMphrFVMxLX4kq.png"
            }
        },
        "translation_title": "DeepSeek-OCR 2: 시각적 인과 흐름",
        "purpose": "시각적 토큰을 이미지 의미에 따라 동적으로 재배열할 수 있는 새로운 인코더의 가능성을 조사",
        "method": [
            "기존의 비전-언어 모델(VLMs)은 고정된 위치 인코딩으로 비주얼 토큰을 단단한 스캔 순서로 처리하는 문제를 해결하려고 설계함(Conventional vision-language models (VLMs) invariably process visual tokens in a rigid raster-scan order with fixed positional encoding when fed into LLMs.)",
            "DeepEncoder V2는 인과적 추론 기능을 부여하여 LLM 기반 콘텐츠 해석 전에 비주얼 토큰을 지능적으로 재배열할 수 있도록 설계됨(DeepEncoder V2 is designed to endow the encoder with causal reasoning capabilities, enabling it to intelligently reorder visual tokens prior to LLM-based content interpretation.)",
            "2D 이미지 이해를 위한 새로운 패러다임을 탐색하며 1D 인과적 추론 구조를 2개 연결하는 방식을 제안함(This work explores a novel paradigm: whether 2D image understanding can be effectively achieved through two-cascaded 1D causal reasoning structures.)"
        ],
        "conclusion": "DeepEncoder V2의 설계를 통해 진정한 2D 추론을 달성할 수 있는 새로운 아키텍처 접근 방식을 제시함.",
        "keywords": [
            "Computer Vision",
            "Image Understanding",
            "Robotics"
        ]
    },
    {
        "paper": {
            "id": "2601.20209",
            "authors": [
                {
                    "_id": "697acf8ddf3e800774f13c46",
                    "user": {
                        "_id": "6747de57f8cab58c22ec94a2",
                        "avatarUrl": "/avatars/5bae0341862fac24564781c0fa32aac5.svg",
                        "isPro": false,
                        "fullname": "Jinyang Wu",
                        "user": "Jinyang23",
                        "type": "user"
                    },
                    "name": "Jinyang Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-29T09:16:13.804Z",
                    "hidden": false
                },
                {
                    "_id": "697acf8ddf3e800774f13c47",
                    "name": "Shuo Yang",
                    "hidden": false
                },
                {
                    "_id": "697acf8ddf3e800774f13c48",
                    "name": "Changpeng Yang",
                    "hidden": false
                },
                {
                    "_id": "697acf8ddf3e800774f13c49",
                    "name": "Yuhao Shen",
                    "hidden": false
                },
                {
                    "_id": "697acf8ddf3e800774f13c4a",
                    "name": "Shuai Zhang",
                    "hidden": false
                },
                {
                    "_id": "697acf8ddf3e800774f13c4b",
                    "name": "Zhengqi Wen",
                    "hidden": false
                },
                {
                    "_id": "697acf8ddf3e800774f13c4c",
                    "name": "Jianhua Tao",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-28T03:15:34.000Z",
            "submittedOnDailyAt": "2026-01-29T00:45:22.548Z",
            "title": "Spark: Strategic Policy-Aware Exploration via Dynamic Branching for Long-Horizon Agentic Learning",
            "submittedOnDailyBy": {
                "_id": "6747de57f8cab58c22ec94a2",
                "avatarUrl": "/avatars/5bae0341862fac24564781c0fa32aac5.svg",
                "isPro": false,
                "fullname": "Jinyang Wu",
                "user": "Jinyang23",
                "type": "user"
            },
            "summary": "Reinforcement learning has empowered large language models to act as intelligent agents, yet training them for long-horizon tasks remains challenging due to the scarcity of high-quality trajectories, especially under limited resources. Existing methods typically scale up rollout sizes and indiscriminately allocate computational resources among intermediate steps. Such attempts inherently waste substantial computation budget on trivial steps while failing to guarantee sample quality. To address this, we propose Spark (Strategic Policy-Aware exploRation via Key-state dynamic branching), a novel framework that selectively branches at critical decision states for resource-efficient exploration. Our key insight is to activate adaptive branching exploration at critical decision points to probe promising trajectories, thereby achieving precise resource allocation that prioritizes sampling quality over blind coverage. This design leverages the agent's intrinsic decision-making signals to reduce dependence on human priors, enabling the agent to autonomously expand exploration and achieve stronger generalization. Experiments across diverse tasks (e.g., embodied planning), demonstrate that Spark achieves superior success rates with significantly fewer training samples, exhibiting robust generalization even in unseen scenarios.",
            "upvotes": 11,
            "discussionId": "697acf8edf3e800774f13c4d",
            "ai_summary": "Spark is a reinforcement learning framework that strategically allocates computational resources by branching at critical decision states, improving sample efficiency and generalization for long-horizon tasks.",
            "ai_keywords": [
                "reinforcement learning",
                "large language models",
                "long-horizon tasks",
                "trajectory scarcity",
                "rollout size",
                "computational resource allocation",
                "adaptive branching exploration",
                "decision-making signals",
                "sample efficiency",
                "generalization"
            ]
        },
        "translation_title": "Spark: 동적 브랜칭을 통한 전략적 정책 인식 탐색으로 긴 수명 에이전트 학습 향상",
        "purpose": "제한된 자원으로 긴 수명 작업에서 고품질의 경로를 발견하기 위한 효율적인 탐색 방법 연구",
        "method": [
            "중요한 결정 상태에서 선택적으로 브랜칭하는 Spark라는 새로운 프레임워크를 제안함(To address this, we propose Spark (Strategic Policy-Aware exploRation via Key-state dynamic branching), a novel framework that selectively branches at critical decision states for resource-efficient exploration).",
            "전략적 브랜칭 탐색을 통해 중요한 결정 포인트에서 유망한 경로를 탐색함(Our key insight is to activate adaptive branching exploration at critical decision points to probe promising trajectories).",
            "에이전트의 내재적 결정 신호를 활용해 탐색을 자율적으로 확장하는 방법론을 적용함(This design leverages the agent's intrinsic decision-making signals to reduce dependence on human priors)."
        ],
        "conclusion": "Spark는 긴 수명 작업에서 고품질 샘플링을 우선시하며, 적은 훈련 샘플로 더 높은 성공률을 달성하여 강력한 일반화를 보여줌.",
        "keywords": [
            "Reinforcement Learning",
            "Long-Horizon Learning",
            "Generalization"
        ]
    }
]