[
    {
        "paper": {
            "id": "2507.03724",
            "authors": [
                {
                    "_id": "686c7266364e2ad167eb5319",
                    "name": "Zhiyu Li",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb531a",
                    "name": "Shichao Song",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb531b",
                    "user": {
                        "_id": "6541e9d5f49db03dc524225b",
                        "avatarUrl": "/avatars/d69a1119a9f279ea97dcbdf407e968d1.svg",
                        "isPro": false,
                        "fullname": "Xichenyang",
                        "user": "xisungod",
                        "type": "user"
                    },
                    "name": "Chenyang Xi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:47:42.310Z",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb531c",
                    "user": {
                        "_id": "669e0b93c7cb0568dac6e92e",
                        "avatarUrl": "/avatars/a39ea77d7391f164af8a80f94f85f2ca.svg",
                        "isPro": false,
                        "fullname": "hanyu Wang",
                        "user": "UglyToilet",
                        "type": "user"
                    },
                    "name": "Hanyu Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:47:20.957Z",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb531d",
                    "name": "Chen Tang",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb531e",
                    "user": {
                        "_id": "66daea8776dbaaa372eabec5",
                        "avatarUrl": "/avatars/1e5fbe4ff06bb6121c7029253b76b79f.svg",
                        "isPro": false,
                        "fullname": "siminniu",
                        "user": "siminniu",
                        "type": "user"
                    },
                    "name": "Simin Niu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:47:30.117Z",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb531f",
                    "name": "Ding Chen",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5320",
                    "name": "Jiawei Yang",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5321",
                    "name": "Chunyu Li",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5322",
                    "user": {
                        "_id": "6455ff584095c967f9a847bb",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6455ff584095c967f9a847bb/A5wjtWsudC73fLVmgASBr.jpeg",
                        "isPro": false,
                        "fullname": "Qingchen Yu",
                        "user": "Duguce",
                        "type": "user"
                    },
                    "name": "Qingchen Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:48:13.981Z",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5323",
                    "name": "Jihao Zhao",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5324",
                    "user": {
                        "_id": "662dd19f9e6d371ab71b91ce",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/662dd19f9e6d371ab71b91ce/mZBPw_Zs8ZlEFGlbekAoH.jpeg",
                        "isPro": false,
                        "fullname": "Yezhaohui Wang",
                        "user": "HaruTeru",
                        "type": "user"
                    },
                    "name": "Yezhaohui Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:48:25.329Z",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5325",
                    "name": "Peng Liu",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5326",
                    "user": {
                        "_id": "685daf7286be5119ab73fa86",
                        "avatarUrl": "/avatars/2d3af6b09545b8cf628f5b84023596f7.svg",
                        "isPro": false,
                        "fullname": "Zehao Lin",
                        "user": "Error404Bugmaker",
                        "type": "user"
                    },
                    "name": "Zehao Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:48:32.962Z",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5327",
                    "name": "Pengyuan Wang",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5328",
                    "name": "Jiahao Huo",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5329",
                    "name": "Tianyi Chen",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb532a",
                    "name": "Kai Chen",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb532b",
                    "name": "Kehang Li",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb532c",
                    "name": "Zhen Tao",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb532d",
                    "name": "Junpeng Ren",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb532e",
                    "name": "Huayi Lai",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb532f",
                    "name": "Hao Wu",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5330",
                    "name": "Bo Tang",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5331",
                    "name": "Zhenren Wang",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5332",
                    "user": {
                        "_id": "6462eab02538819c72a0b2cc",
                        "avatarUrl": "/avatars/b4ece21ce35da7506db9d8bef4abcf68.svg",
                        "isPro": false,
                        "fullname": "Zhaoxin Fan",
                        "user": "Jason007x",
                        "type": "user"
                    },
                    "name": "Zhaoxin Fan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:48:50.042Z",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5333",
                    "name": "Ningyu Zhang",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5334",
                    "name": "Linfeng Zhang",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5335",
                    "name": "Junchi Yan",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5336",
                    "name": "Mingchuan Yang",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5337",
                    "name": "Tong Xu",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5338",
                    "name": "Wei Xu",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb5339",
                    "name": "Huajun Chen",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb533a",
                    "name": "Haofeng Wang",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb533b",
                    "name": "Hongkang Yang",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb533c",
                    "user": {
                        "_id": "686c965f418acea658859af4",
                        "avatarUrl": "/avatars/4f453abeb7e82a3042cbec751b5cdb63.svg",
                        "isPro": false,
                        "fullname": "Wentao Zhang",
                        "user": "Wentao-PKU",
                        "type": "user"
                    },
                    "name": "Wentao Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-07-08T08:06:32.391Z",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb533d",
                    "name": "Zhi-Qin John Xu",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb533e",
                    "name": "Siheng Chen",
                    "hidden": false
                },
                {
                    "_id": "686c7266364e2ad167eb533f",
                    "name": "Feiyu Xiong",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/669e0b93c7cb0568dac6e92e/twRhDA4ThpQMfInSFdYDA.gif",
                "https://cdn-uploads.huggingface.co/production/uploads/669e0b93c7cb0568dac6e92e/9xHrSG0a8X2CYHxvfMFSH.gif",
                "https://cdn-uploads.huggingface.co/production/uploads/669e0b93c7cb0568dac6e92e/aaUeE4u2RhCnFYNKCqvyn.gif"
            ],
            "publishedAt": "2025-07-04T17:21:46.000Z",
            "submittedOnDailyAt": "2025-07-08T01:46:43.501Z",
            "title": "MemOS: A Memory OS for AI System",
            "submittedOnDailyBy": {
                "_id": "669e0b93c7cb0568dac6e92e",
                "avatarUrl": "/avatars/a39ea77d7391f164af8a80f94f85f2ca.svg",
                "isPro": false,
                "fullname": "hanyu Wang",
                "user": "UglyToilet",
                "type": "user"
            },
            "summary": "Large Language Models (LLMs) have become an essential infrastructure for\nArtificial General Intelligence (AGI), yet their lack of well-defined memory\nmanagement systems hinders the development of long-context reasoning, continual\npersonalization, and knowledge consistency.Existing models mainly rely on\nstatic parameters and short-lived contextual states, limiting their ability to\ntrack user preferences or update knowledge over extended periods.While\nRetrieval-Augmented Generation (RAG) introduces external knowledge in plain\ntext, it remains a stateless workaround without lifecycle control or\nintegration with persistent representations.Recent work has modeled the\ntraining and inference cost of LLMs from a memory hierarchy perspective,\nshowing that introducing an explicit memory layer between parameter memory and\nexternal retrieval can substantially reduce these costs by externalizing\nspecific knowledge. Beyond computational efficiency, LLMs face broader\nchallenges arising from how information is distributed over time and context,\nrequiring systems capable of managing heterogeneous knowledge spanning\ndifferent temporal scales and sources. To address this challenge, we propose\nMemOS, a memory operating system that treats memory as a manageable system\nresource. It unifies the representation, scheduling, and evolution of\nplaintext, activation-based, and parameter-level memories, enabling\ncost-efficient storage and retrieval. As the basic unit, a MemCube encapsulates\nboth memory content and metadata such as provenance and versioning. MemCubes\ncan be composed, migrated, and fused over time, enabling flexible transitions\nbetween memory types and bridging retrieval with parameter-based learning.\nMemOS establishes a memory-centric system framework that brings\ncontrollability, plasticity, and evolvability to LLMs, laying the foundation\nfor continual learning and personalized modeling.",
            "upvotes": 72,
            "discussionId": "686c7266364e2ad167eb5340",
            "projectPage": "https://memos.openmem.net/",
            "githubRepo": "https://github.com/MemTensor/MemOS",
            "ai_summary": "MemOS is proposed as a memory operating system for Large Language Models to enhance memory management, enabling efficient storage and retrieval, and facilitating continual learning and personalized modeling.",
            "ai_keywords": [
                "LLMs",
                "Artificial General Intelligence",
                "AGI",
                "Retrieval-Augmented Generation",
                "RAG",
                "MemOS",
                "memory operating system",
                "MemCube",
                "activation-based memory"
            ],
            "githubStars": 570
        },
        "translation_title": "MemOS: AI 시스템을 위한 메모리 운영 체제",
        "purpose": "AI 시스템에서 메모리를 관리할 수 있는 체계적인 운영 체제를 개발하여 장기적인 맥락 추론과 개인화, 지식의 일관성을 개선하기 위함",
        "method": [
            "MemOS라는 메모리 운영 체제를 제안하여 메모리를 관리 가능한 시스템 자원으로 취급함(To address this challenge, we propose MemOS, a memory operating system that treats memory as a manageable system resource.)",
            "MemOS는 다양한 유형의 메모리 representations을 통합하고 저장 및 검색을 비용 효율적으로 지원함(It unifies the representation, scheduling, and evolution of plaintext, activation-based, and parameter-level memories, enabling cost-efficient storage and retrieval.)",
            "MemOS에서 메모리의 기본 단위인 MemCube를 encapsulate하여 메모리 내용과 메타데이터를 관리함(as the basic unit, a MemCube encapsulates both memory content and metadata such as provenance and versioning.)"
        ],
        "conclusion": "MemOS는 LLMs에 대한 제어 가능성, 유연성, 발전 가능성을 제공하여 지속적인 학습과 개인화 모델링의 기초를 다짐.",
        "keywords": [
            "Large Language Models",
            "Memory Management",
            "Continual Learning"
        ]
    },
    {
        "paper": {
            "id": "2507.00994",
            "authors": [
                {
                    "_id": "6864e267d59a9eda59024bab",
                    "user": {
                        "_id": "65fa95405355a52c784633fc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65fa95405355a52c784633fc/rSfBUHPa7eSAsLd8DuOq4.png",
                        "isPro": false,
                        "fullname": "Hippolyte Gisserot-Boukhlef",
                        "user": "hgissbkh",
                        "type": "user"
                    },
                    "name": "Hippolyte Gisserot-Boukhlef",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-07-05T07:53:51.109Z",
                    "hidden": false
                },
                {
                    "_id": "6864e267d59a9eda59024bac",
                    "user": {
                        "_id": "62be186a5f59ff2320e6e32b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62be186a5f59ff2320e6e32b/W_emoC2uItM-MJZyCfIKI.png",
                        "isPro": false,
                        "fullname": "Nicolas-BZRD",
                        "user": "Nicolas-BZRD",
                        "type": "user"
                    },
                    "name": "Nicolas Boizard",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-07-02T12:22:12.240Z",
                    "hidden": false
                },
                {
                    "_id": "6864e267d59a9eda59024bad",
                    "user": {
                        "_id": "60f2e021adf471cbdf8bb660",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1654090481550-60f2e021adf471cbdf8bb660.jpeg",
                        "isPro": false,
                        "fullname": "Manuel Faysse",
                        "user": "manu",
                        "type": "user"
                    },
                    "name": "Manuel Faysse",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:52:55.139Z",
                    "hidden": false
                },
                {
                    "_id": "6864e267d59a9eda59024bae",
                    "name": "Duarte M. Alves",
                    "hidden": false
                },
                {
                    "_id": "6864e267d59a9eda59024baf",
                    "user": {
                        "_id": "66f2d6a684a241caac8e16dc",
                        "avatarUrl": "/avatars/81acb87c2b07bea938251b40a2139911.svg",
                        "isPro": false,
                        "fullname": "Emmanuel Malherbe",
                        "user": "emmanuelmalherbe",
                        "type": "user"
                    },
                    "name": "Emmanuel Malherbe",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:53:10.878Z",
                    "hidden": false
                },
                {
                    "_id": "6864e267d59a9eda59024bb0",
                    "name": "André F. T. Martins",
                    "hidden": false
                },
                {
                    "_id": "6864e267d59a9eda59024bb1",
                    "user": {
                        "_id": "61efea03a57920a251ec19b8",
                        "avatarUrl": "/avatars/f47c8e3cb17a2bf7d43f2c152bb86885.svg",
                        "isPro": false,
                        "fullname": "Celine Hudelot",
                        "user": "CelineH",
                        "type": "user"
                    },
                    "name": "Céline Hudelot",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:53:24.532Z",
                    "hidden": false
                },
                {
                    "_id": "6864e267d59a9eda59024bb2",
                    "user": {
                        "_id": "644a900e3a619fe72b14af0f",
                        "avatarUrl": "/avatars/e2d5dac3d92757ed48e37e126a3464a3.svg",
                        "isPro": false,
                        "fullname": "Colombo",
                        "user": "PierreColombo",
                        "type": "user"
                    },
                    "name": "Pierre Colombo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:53:30.831Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-07-01T17:45:48.000Z",
            "submittedOnDailyAt": "2025-07-08T07:51:12.578Z",
            "title": "Should We Still Pretrain Encoders with Masked Language Modeling?",
            "submittedOnDailyBy": {
                "_id": "62be186a5f59ff2320e6e32b",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62be186a5f59ff2320e6e32b/W_emoC2uItM-MJZyCfIKI.png",
                "isPro": false,
                "fullname": "Nicolas-BZRD",
                "user": "Nicolas-BZRD",
                "type": "user"
            },
            "summary": "Learning high-quality text representations is fundamental to a wide range of\nNLP tasks. While encoder pretraining has traditionally relied on Masked\nLanguage Modeling (MLM), recent evidence suggests that decoder models\npretrained with Causal Language Modeling (CLM) can be effectively repurposed as\nencoders, often surpassing traditional encoders on text representation\nbenchmarks. However, it remains unclear whether these gains reflect an inherent\nadvantage of the CLM objective or arise from confounding factors such as model\nand data scale. In this paper, we address this question through a series of\nlarge-scale, carefully controlled pretraining ablations, training a total of 30\nmodels ranging from 210 million to 1 billion parameters, and conducting over\n15,000 fine-tuning and evaluation runs. We find that while training with MLM\ngenerally yields better performance across text representation tasks,\nCLM-trained models are more data-efficient and demonstrate improved fine-tuning\nstability. Building on these findings, we experimentally show that a biphasic\ntraining strategy that sequentially applies CLM and then MLM, achieves optimal\nperformance under a fixed computational training budget. Moreover, we\ndemonstrate that this strategy becomes more appealing when initializing from\nreadily available pretrained CLM models (from the existing LLM ecosystem),\nreducing the computational burden needed to train best-in-class encoder models.\nWe release all project artifacts at https://hf.co/MLMvsCLM to foster further\nresearch.",
            "upvotes": 49,
            "discussionId": "6864e267d59a9eda59024bb3",
            "projectPage": "https://huggingface.co/MLMvsCLM",
            "githubRepo": "https://github.com/Nicolas-BZRD/EuroBERT",
            "githubStars": 60
        },
        "translation_title": "여전히 Masked Language Modeling으로 인코더를 사전 학습해야 할까?",
        "purpose": "기존의 Masked Language Modeling(MLM) 대신 Causal Language Modeling(CLM)으로 사전 학습된 디코더 모델이 인코더로 효과적으로 재사용될 수 있는지 연구하여, NLP 작업에서의 성능 향상을 확인하는 것.",
        "method": [
            "30개의 모델을 대상으로 대규모 사전 학습 변형 실험을 진행함(We address this question through a series of large-scale, carefully controlled pretraining ablations, training a total of 30 models ranging from 210 million to 1 billion parameters.)",
            "MLM이 일반적으로 텍스트 표현 작업에서 더 나은 성능을 보이는 반면, CLM 모델이 데이터 효율성과 파인튜닝의 안정성을 향상시킴을 발견함(We find that while training with MLM generally yields better performance across text representation tasks, CLM-trained models are more data-efficient and demonstrate improved fine-tuning stability.)",
            "CLM과 MLM을 순차적으로 적용하는 이중 단계 훈련 전략이 고정된 계산 예산 하에서 최적의 성능을 달성함을 실험적으로 보여줌(Building on these findings, we experimentally show that a biphasic training strategy that sequentially applies CLM and then MLM achieves optimal performance under a fixed computational training budget.)"
        ],
        "conclusion": "이중 단계 훈련 전략은 기존의 CLM 모델을 초기화하여 최적의 성능을 이루는 데 더 매력적이며, 최상급 인코더 모델을 훈련하는 데 필요한 계산 부담을 줄여줌.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2507.05163",
            "authors": [
                {
                    "_id": "686c928b364e2ad167eb53f1",
                    "user": {
                        "_id": "65bf190cf629068c7f73ced0",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65bf190cf629068c7f73ced0/4EcW7AS7HMQITtiUcJM2-.jpeg",
                        "isPro": false,
                        "fullname": "Yutian Chen",
                        "user": "YutianChen",
                        "type": "user"
                    },
                    "name": "Yutian Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:53:58.158Z",
                    "hidden": false
                },
                {
                    "_id": "686c928b364e2ad167eb53f2",
                    "name": "Shi Guo",
                    "hidden": false
                },
                {
                    "_id": "686c928b364e2ad167eb53f3",
                    "name": "Tianshuo Yang",
                    "hidden": false
                },
                {
                    "_id": "686c928b364e2ad167eb53f4",
                    "user": {
                        "_id": "64190a6c0956be7233a5f317",
                        "avatarUrl": "/avatars/8590515089bc31a168bc2da2c7516dfb.svg",
                        "isPro": false,
                        "fullname": "Lihe Ding",
                        "user": "Lihe",
                        "type": "user"
                    },
                    "name": "Lihe Ding",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:54:46.672Z",
                    "hidden": false
                },
                {
                    "_id": "686c928b364e2ad167eb53f5",
                    "user": {
                        "_id": "683277563a242c5e2d76a2ef",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/kRcqg3Qwh2MYu1ePLulnp.png",
                        "isPro": false,
                        "fullname": "Xiuyuan Yu",
                        "user": "edward1145",
                        "type": "user"
                    },
                    "name": "Xiuyuan Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:54:12.085Z",
                    "hidden": false
                },
                {
                    "_id": "686c928b364e2ad167eb53f6",
                    "user": {
                        "_id": "647e8118770c299e56fc2bc8",
                        "avatarUrl": "/avatars/adf80f3473dda42450148789ae5c208f.svg",
                        "isPro": false,
                        "fullname": "Jinwei Gu",
                        "user": "jwgu",
                        "type": "user"
                    },
                    "name": "Jinwei Gu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:54:28.245Z",
                    "hidden": false
                },
                {
                    "_id": "686c928b364e2ad167eb53f7",
                    "user": {
                        "_id": "67631f57abfbd60470d4b3c3",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/5VrG0IZjYrDLiatOr4y06.png",
                        "isPro": false,
                        "fullname": "Tianfan Xue",
                        "user": "littlemouse9",
                        "type": "user"
                    },
                    "name": "Tianfan Xue",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:54:19.731Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-07-07T16:18:35.000Z",
            "submittedOnDailyAt": "2025-07-08T02:14:44.087Z",
            "title": "4DSloMo: 4D Reconstruction for High Speed Scene with Asynchronous\n  Capture",
            "submittedOnDailyBy": {
                "_id": "64970d3d9c3b29dca8633f87",
                "avatarUrl": "/avatars/11e3c9c66d28490d6d09925f9aa47cd1.svg",
                "isPro": false,
                "fullname": "JunhaoZhuang",
                "user": "JunhaoZhuang",
                "type": "user"
            },
            "summary": "Reconstructing fast-dynamic scenes from multi-view videos is crucial for\nhigh-speed motion analysis and realistic 4D reconstruction. However, the\nmajority of 4D capture systems are limited to frame rates below 30 FPS (frames\nper second), and a direct 4D reconstruction of high-speed motion from low FPS\ninput may lead to undesirable results. In this work, we propose a high-speed 4D\ncapturing system only using low FPS cameras, through novel capturing and\nprocessing modules. On the capturing side, we propose an asynchronous capture\nscheme that increases the effective frame rate by staggering the start times of\ncameras. By grouping cameras and leveraging a base frame rate of 25 FPS, our\nmethod achieves an equivalent frame rate of 100-200 FPS without requiring\nspecialized high-speed cameras. On processing side, we also propose a novel\ngenerative model to fix artifacts caused by 4D sparse-view reconstruction, as\nasynchrony reduces the number of viewpoints at each timestamp. Specifically, we\npropose to train a video-diffusion-based artifact-fix model for sparse 4D\nreconstruction, which refines missing details, maintains temporal consistency,\nand improves overall reconstruction quality. Experimental results demonstrate\nthat our method significantly enhances high-speed 4D reconstruction compared to\nsynchronous capture.",
            "upvotes": 31,
            "discussionId": "686c928b364e2ad167eb53f8",
            "ai_summary": "A high-speed 4D capturing system using low FPS cameras with asynchronous capture and video-diffusion-based artifact correction enhances reconstruction quality.",
            "ai_keywords": [
                "asynchronous capture",
                "video-diffusion-based artifact-fix model",
                "sparse 4D reconstruction",
                "temporal consistency"
            ]
        },
        "translation_title": "4DSloMo: 비동기 캡처를 통한 고속 장면을 위한 4D 재구성",
        "purpose": "고속 동작 분석 및 사실적인 4D 재구성을 위한 비동기 캡처 시스템 개발",
        "method": [
            "비동기 캡처 방식을 제안하여 카메라의 시작 시간을 조절함으로써 효과적인 프레임 속도를 증가시킴(we propose an asynchronous capture scheme that increases the effective frame rate by staggering the start times of cameras.)",
            "기본 프레임 속도가 25 FPS인 카메라를 그룹화하여 100-200 FPS에 해당하는 프레임 속도를 달성함(By grouping cameras and leveraging a base frame rate of 25 FPS, our method achieves an equivalent frame rate of 100-200 FPS without requiring specialized high-speed cameras.)",
            "4D 희소 뷰 재구성에서 발생하는 아티팩트를 수정하기 위해 비디오 확산 기반의 아티팩트 수정 모델을 학습함(we propose to train a video-diffusion-based artifact-fix model for sparse 4D reconstruction, which refines missing details, maintains temporal consistency, and improves overall reconstruction quality.)"
        ],
        "conclusion": "제안한 방법은 동기 캡처에 비해 고속 4D 재구성을 크게 향상시킴.",
        "keywords": [
            "Computer Vision",
            "Image Understanding",
            "Video Generation"
        ]
    },
    {
        "paper": {
            "id": "2507.04447",
            "authors": [
                {
                    "_id": "686cab67364e2ad167eb5464",
                    "user": {
                        "_id": "65f9533b136fb8ddbd14e1fa",
                        "avatarUrl": "/avatars/d88f75da0448093ccd1babba2a37d73f.svg",
                        "isPro": false,
                        "fullname": "Zhang",
                        "user": "WenyaoZhang",
                        "type": "user"
                    },
                    "name": "Wenyao Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:54:59.906Z",
                    "hidden": false
                },
                {
                    "_id": "686cab67364e2ad167eb5465",
                    "name": "Hongsi Liu",
                    "hidden": false
                },
                {
                    "_id": "686cab67364e2ad167eb5466",
                    "user": {
                        "_id": "63c3e8abc7d7f4c63a515a02",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63c3e8abc7d7f4c63a515a02/npMHnVP2hHLbvoUGe7C4O.jpeg",
                        "isPro": false,
                        "fullname": "Zekun Qi",
                        "user": "qizekun",
                        "type": "user"
                    },
                    "name": "Zekun Qi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-07-08T08:05:57.749Z",
                    "hidden": false
                },
                {
                    "_id": "686cab67364e2ad167eb5467",
                    "user": {
                        "_id": "674d7c11c3df11ec9a1f3c17",
                        "avatarUrl": "/avatars/daa392c220dfc1ea791b9d48385df2f6.svg",
                        "isPro": false,
                        "fullname": "Yunnan Wang",
                        "user": "wangyunnan",
                        "type": "user"
                    },
                    "name": "Yunnan Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:55:17.010Z",
                    "hidden": false
                },
                {
                    "_id": "686cab67364e2ad167eb5468",
                    "name": "XinQiang Yu",
                    "hidden": false
                },
                {
                    "_id": "686cab67364e2ad167eb5469",
                    "user": {
                        "_id": "65658233d35fc55406e8b00d",
                        "avatarUrl": "/avatars/660eaa1923cd3e3478cec8197936a75c.svg",
                        "isPro": false,
                        "fullname": "Jiazhao Zhang",
                        "user": "Jzzhang",
                        "type": "user"
                    },
                    "name": "Jiazhao Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T13:55:28.159Z",
                    "hidden": false
                },
                {
                    "_id": "686cab67364e2ad167eb546a",
                    "user": {
                        "_id": "6201fc5d91d53938a6432fbf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6201fc5d91d53938a6432fbf/VLs8ZYaZrop4KBpZn53fH.jpeg",
                        "isPro": false,
                        "fullname": "Runpei Dong",
                        "user": "RunpeiDong",
                        "type": "user"
                    },
                    "name": "Runpei Dong",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-07-08T08:06:00.401Z",
                    "hidden": false
                },
                {
                    "_id": "686cab67364e2ad167eb546b",
                    "name": "Jiawei He",
                    "hidden": false
                },
                {
                    "_id": "686cab67364e2ad167eb546c",
                    "name": "He Wang",
                    "hidden": false
                },
                {
                    "_id": "686cab67364e2ad167eb546d",
                    "name": "Zhizheng Zhang",
                    "hidden": false
                },
                {
                    "_id": "686cab67364e2ad167eb546e",
                    "name": "Li Yi",
                    "hidden": false
                },
                {
                    "_id": "686cab67364e2ad167eb546f",
                    "name": "Wenjun Zeng",
                    "hidden": false
                },
                {
                    "_id": "686cab67364e2ad167eb5470",
                    "name": "Xin Jin",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/6201fc5d91d53938a6432fbf/Oe8hIH4_I_Pql9N72iHbn.mp4"
            ],
            "publishedAt": "2025-07-06T16:14:29.000Z",
            "submittedOnDailyAt": "2025-07-08T03:55:36.991Z",
            "title": "DreamVLA: A Vision-Language-Action Model Dreamed with Comprehensive\n  World Knowledge",
            "submittedOnDailyBy": {
                "_id": "6201fc5d91d53938a6432fbf",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6201fc5d91d53938a6432fbf/VLs8ZYaZrop4KBpZn53fH.jpeg",
                "isPro": false,
                "fullname": "Runpei Dong",
                "user": "RunpeiDong",
                "type": "user"
            },
            "summary": "Recent advances in vision-language-action (VLA) models have shown promise in\nintegrating image generation with action prediction to improve generalization\nand reasoning in robot manipulation. However, existing methods are limited to\nchallenging image-based forecasting, which suffers from redundant information\nand lacks comprehensive and critical world knowledge, including dynamic,\nspatial and semantic information. To address these limitations, we propose\nDreamVLA, a novel VLA framework that integrates comprehensive world knowledge\nforecasting to enable inverse dynamics modeling, thereby establishing a\nperception-prediction-action loop for manipulation tasks. Specifically,\nDreamVLA introduces a dynamic-region-guided world knowledge prediction,\nintegrated with the spatial and semantic cues, which provide compact yet\ncomprehensive representations for action planning. This design aligns with how\nhumans interact with the world by first forming abstract multimodal reasoning\nchains before acting. To mitigate interference among the dynamic, spatial and\nsemantic information during training, we adopt a block-wise structured\nattention mechanism that masks their mutual attention, preventing information\nleakage and keeping each representation clean and disentangled. Moreover, to\nmodel the conditional distribution over future actions, we employ a\ndiffusion-based transformer that disentangles action representations from\nshared latent features. Extensive experiments on both real-world and simulation\nenvironments demonstrate that DreamVLA achieves 76.7% success rate on real\nrobot tasks and 4.44 average length on the CALVIN ABC-D benchmarks.",
            "upvotes": 28,
            "discussionId": "686cab67364e2ad167eb5471",
            "projectPage": "https://zhangwenyao1.github.io/DreamVLA/",
            "githubRepo": "https://github.com/Zhangwenyao1/DreamVLA",
            "ai_summary": "DreamVLA improves robot manipulation through a VLA framework that incorporates world knowledge, dynamic-region guidance, and a diffusion-based transformer to ensure clear, disentangled representations for action planning.",
            "ai_keywords": [
                "vision-language-action",
                "dynamic-region-guided",
                "world knowledge prediction",
                "spatial and semantic cues",
                "block-wise structured attention",
                "diffusion-based transformer"
            ],
            "githubStars": 29
        },
        "translation_title": "DreamVLA: 포괄적인 세계 지식을 가진 비전-언어-행동 모델",
        "purpose": "로봇 조작에서의 일반화와 추론을 개선하기 위한 포괄적 세계 지식 예측을 통합한 VLA 모델 개발",
        "method": [
            "DreamVLA는 역 동역학 모델링을 가능하게 하는 포괄적 세계 지식 예측을 통합하는 새로운 VLA 프레임워크를 제안함(To address these limitations, we propose DreamVLA, a novel VLA framework that integrates comprehensive world knowledge forecasting to enable inverse dynamics modeling.)",
            "동적 영역 유도 세계 지식 예측을 도입하여 행동 계획을 위한 간결하고 포괄적인 표현을 제공함(Specifically, DreamVLA introduces a dynamic-region-guided world knowledge prediction, integrated with the spatial and semantic cues, which provide compact yet comprehensive representations for action planning.)",
            "훈련 중 동적, 공간 및 의미 정보 간의 간섭을 완화하기 위해 블록 구조 주의 메커니즘을 채택함(To mitigate interference among the dynamic, spatial and semantic information during training, we adopt a block-wise structured attention mechanism that masks their mutual attention.)"
        ],
        "conclusion": "DreamVLA는 실제 로봇 작업에서 76.7%의 성공률을 달성하고 CALVIN ABC-D 벤치마크에서 평균 4.44의 성능을 보임",
        "keywords": [
            "Vision-Language Models",
            "Robotics",
            "Image Generation"
        ]
    },
    {
        "paper": {
            "id": "2507.05197",
            "authors": [
                {
                    "_id": "686c7f78364e2ad167eb5354",
                    "name": "Shihan Dou",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5355",
                    "name": "Shichun Liu",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5356",
                    "user": {
                        "_id": "655c6b1abfb531437a54c0e6",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/V8Md2mMX83hrSowKk6qMS.jpeg",
                        "isPro": false,
                        "fullname": "Yuming Yang",
                        "user": "Umean",
                        "type": "user"
                    },
                    "name": "Yuming Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-07-08T08:06:28.979Z",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5357",
                    "user": {
                        "_id": "6234238485575ce6ff1f169a",
                        "avatarUrl": "/avatars/e5fff05f21cdea4e5aebc8ba426fac29.svg",
                        "isPro": false,
                        "fullname": "Yicheng Zou",
                        "user": "RowitZou",
                        "type": "user"
                    },
                    "name": "Yicheng Zou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T14:08:52.408Z",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5358",
                    "name": "Yunhua Zhou",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5359",
                    "name": "Shuhao Xing",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb535a",
                    "name": "Chenhao Huang",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb535b",
                    "name": "Qiming Ge",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb535c",
                    "name": "Demin Song",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb535d",
                    "name": "Haijun Lv",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb535e",
                    "name": "Songyang Gao",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb535f",
                    "name": "Chengqi Lv",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5360",
                    "name": "Enyu Zhou",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5361",
                    "name": "Honglin Guo",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5362",
                    "name": "Zhiheng Xi",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5363",
                    "name": "Wenwei Zhang",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5364",
                    "name": "Qipeng Guo",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5365",
                    "name": "Qi Zhang",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5366",
                    "name": "Xipeng Qiu",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5367",
                    "user": {
                        "_id": "67f9c4ee171948c38302ae0f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/Cqb3ijr_sZkpLhEEEEybK.png",
                        "isPro": false,
                        "fullname": "Xuanjing Huang",
                        "user": "xjhuang",
                        "type": "user"
                    },
                    "name": "Xuanjing Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-07-08T14:06:00.646Z",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5368",
                    "name": "Tao Gui",
                    "hidden": false
                },
                {
                    "_id": "686c7f78364e2ad167eb5369",
                    "name": "Kai Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-07-07T16:56:31.000Z",
            "submittedOnDailyAt": "2025-07-08T02:18:45.573Z",
            "title": "Pre-Trained Policy Discriminators are General Reward Models",
            "submittedOnDailyBy": {
                "_id": "6234238485575ce6ff1f169a",
                "avatarUrl": "/avatars/e5fff05f21cdea4e5aebc8ba426fac29.svg",
                "isPro": false,
                "fullname": "Yicheng Zou",
                "user": "RowitZou",
                "type": "user"
            },
            "summary": "We offer a novel perspective on reward modeling by formulating it as a policy\ndiscriminator, which quantifies the difference between two policies to generate\na reward signal, guiding the training policy towards a target policy with\ndesired behaviors. Based on this conceptual insight, we propose a scalable\npre-training method named Policy Discriminative Learning (POLAR), which trains\na reward model (RM) to discern identical policies and discriminate different\nones. Unlike traditional reward modeling methods relying on absolute\npreferences, POLAR captures the relative difference between one policy and an\narbitrary target policy, which is a scalable, high-level optimization objective\nsuitable for modeling generic ranking relationships. Leveraging the POLAR\npre-training paradigm, we present a series of RMs with parameter scales from\n1.8B to 7B. Empirical results show that POLAR substantially outperforms\ntraditional non-pre-trained methods, significantly enhancing RM performance.\nFor instance, POLAR-7B could improve preference accuracy from 54.8% to 81.0% on\nSTEM tasks and from 57.9% to 85.5% on creative writing tasks compared to SOTA\nbaselines. POLAR also shows robust generalization capabilities in RLHF using\nReinforcement Fine-tuning (RFT), providing reliable reward signals and markedly\nenhancing policy performance--improving LLaMa3.1-8B from an average of 47.36%\nto 56.33% and Qwen2.5-32B from 64.49% to 70.47% on 20 benchmarks. Moreover,\nscaling experiments reveal a clear power-law relationship between computation\nand performance, supported by linear correlation coefficients approaching 0.99.\nThe impressive performance, strong generalization, and scaling properties\nsuggest that POLAR is a promising direction for developing general and strong\nreward models.",
            "upvotes": 26,
            "discussionId": "686c7f78364e2ad167eb536a",
            "githubRepo": "https://github.com/InternLM/POLAR",
            "ai_summary": "A scalable reward modeling method, Policy Discriminative Learning (POLAR), enhances reward model performance and generalizes robustly in reinforcement learning through policy comparison.",
            "ai_keywords": [
                "policy discriminator",
                "reward model",
                "Policy Discriminative Learning",
                "POLAR",
                "Reinforcement Fine-tuning"
            ],
            "githubStars": 40
        },
        "translation_title": "사전 훈련된 정책 감별자는 일반 보상 모델이다",
        "purpose": "정책 감별기를 활용하여 보상 모델링의 새로운 접근 방식을 제안하여 정책 간의 차이를 정량화하고자 함.",
        "method": [
            "정책 감별기 형태로 보상 신호를 생성하는 방법을 제안함(Basing on this conceptual insight, we propose a scalable pre-training method named Policy Discriminative Learning (POLAR))",
            "POLAR을 통해 보상 모델(RM)을 훈련하여 동일한 정책을 구별하고 다른 정책을 감별함(we propose a scalable pre-training method named Policy Discriminative Learning (POLAR), which trains a reward model (RM) to discern identical policies and discriminate different ones.)",
            "정책 간의 상대적 차이를 수치화하여 높은 수준의 최적화를 달성함(POLAR captures the relative difference between one policy and an arbitrary target policy, which is a scalable, high-level optimization objective)."
        ],
        "conclusion": "POLAR 방법이 전통적인 비사전 훈련 방법보다 성능을 크게 향상시키며, 일반화 능력이 뛰어난 보상 모델 개발에 유망한 방향으로 작용함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Reinforcement Learning"
        ]
    }
]