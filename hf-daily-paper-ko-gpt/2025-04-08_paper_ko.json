[
    {
        "paper": {
            "id": "2504.05299",
            "authors": [
                {
                    "_id": "67f4cf5b504263bce1236d87",
                    "user": {
                        "_id": "65d66b494bbd0d92b641cdbb",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d66b494bbd0d92b641cdbb/6-7dm7B-JxcoS1QlCPdMN.jpeg",
                        "isPro": false,
                        "fullname": "Andres Marafioti",
                        "user": "andito",
                        "type": "user"
                    },
                    "name": "Andrés Marafioti",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-04-08T08:46:33.366Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d88",
                    "user": {
                        "_id": "648c9605565e3a44f3c9bb7b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/648c9605565e3a44f3c9bb7b/W5chvk17Zol6-2QSWkFVR.jpeg",
                        "isPro": true,
                        "fullname": "Orr Zohar",
                        "user": "orrzohar",
                        "type": "user"
                    },
                    "name": "Orr Zohar",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-04-08T09:11:26.498Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d89",
                    "user": {
                        "_id": "61ed0ff29539bc0a3bbc89f4",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61ed0ff29539bc0a3bbc89f4/iYWK7GParA7Ke5F6q132W.jpeg",
                        "isPro": false,
                        "fullname": "Miquel Farré",
                        "user": "mfarre",
                        "type": "user"
                    },
                    "name": "Miquel Farré",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-04-08T09:11:24.824Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d8a",
                    "user": {
                        "_id": "60315285d2c57896177ce764",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1613845120202-noauth.png",
                        "isPro": false,
                        "fullname": "Merve Noyan",
                        "user": "mervenoyan",
                        "type": "user"
                    },
                    "name": "Merve Noyan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T10:29:11.673Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d8b",
                    "user": {
                        "_id": "651e96991b97c9f33d26bde6",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651e96991b97c9f33d26bde6/-Bqs6qrmz0yCfwtB2e-6q.jpeg",
                        "isPro": false,
                        "fullname": "Elie Bakouch",
                        "user": "eliebak",
                        "type": "user"
                    },
                    "name": "Elie Bakouch",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T10:29:19.329Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d8c",
                    "user": {
                        "_id": "603d25b75f9d390ab190b777",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1617264212503-603d25b75f9d390ab190b777.jpeg",
                        "isPro": false,
                        "fullname": "Pedro Cuenca",
                        "user": "pcuenq",
                        "type": "user"
                    },
                    "name": "Pedro Cuenca",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T10:29:25.903Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d8d",
                    "user": {
                        "_id": "66ba71a4447411b9c0e19d71",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/4f93ZrYdaKfK3F53IB51x.jpeg",
                        "isPro": false,
                        "fullname": "Cyril",
                        "user": "cyrilzakka",
                        "type": "user"
                    },
                    "name": "Cyril Zakka",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T10:29:33.323Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d8e",
                    "user": {
                        "_id": "61c141342aac764ce1654e43",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg",
                        "isPro": false,
                        "fullname": "Loubna Ben Allal",
                        "user": "loubnabnl",
                        "type": "user"
                    },
                    "name": "Loubna Ben Allal",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-04-08T09:11:22.957Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d8f",
                    "user": {
                        "_id": "602e6dee60e3dd96631c906e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1613655355830-noauth.png",
                        "isPro": false,
                        "fullname": "Anton Lozhkov",
                        "user": "anton-l",
                        "type": "user"
                    },
                    "name": "Anton Lozhkov",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T10:29:39.905Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d90",
                    "user": {
                        "_id": "5ff8c9f4b2035d9a81a859f7",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1652134289581-5ff8c9f4b2035d9a81a859f7.jpeg",
                        "isPro": false,
                        "fullname": "Nouamane Tazi",
                        "user": "nouamanetazi",
                        "type": "user"
                    },
                    "name": "Nouamane Tazi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T10:29:46.326Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d91",
                    "user": {
                        "_id": "61b85ce86eb1f2c5e6233736",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655385361868-61b85ce86eb1f2c5e6233736.jpeg",
                        "isPro": true,
                        "fullname": "Vaibhav Srivastav",
                        "user": "reach-vb",
                        "type": "user"
                    },
                    "name": "Vaibhav Srivastav",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-04-08T10:28:41.404Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d92",
                    "user": {
                        "_id": "61b253b7ac5ecaae3d1efe0c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61b253b7ac5ecaae3d1efe0c/hwiQ0uvz3t-L5a-NtBIO6.png",
                        "isPro": false,
                        "fullname": "Joshua",
                        "user": "Xenova",
                        "type": "user"
                    },
                    "name": "Joshua Lochner",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-04-08T10:28:45.098Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d93",
                    "user": {
                        "_id": "641cc77c92cd25302998b740",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/641cc77c92cd25302998b740/5A81W5s3ecLaLXFir52Rw.jpeg",
                        "isPro": false,
                        "fullname": "Hugo Larcher",
                        "user": "hlarcher",
                        "type": "user"
                    },
                    "name": "Hugo Larcher",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T10:29:52.171Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d94",
                    "user": {
                        "_id": "664d7d1e4f54c9372970e121",
                        "avatarUrl": "/avatars/695a209d6951a4623eceedcd2eed3a68.svg",
                        "isPro": false,
                        "fullname": "Mathieu Morlon",
                        "user": "glutamatt",
                        "type": "user"
                    },
                    "name": "Mathieu Morlon",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T10:29:57.811Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d95",
                    "user": {
                        "_id": "5f0c746619cb630495b814fd",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1594651707950-noauth.jpeg",
                        "isPro": true,
                        "fullname": "Lewis Tunstall",
                        "user": "lewtun",
                        "type": "user"
                    },
                    "name": "Lewis Tunstall",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T10:30:03.679Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d96",
                    "user": {
                        "_id": "5e48005437cb5b49818287a5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5e48005437cb5b49818287a5/4uCXGGui-9QifAT4qelxU.png",
                        "isPro": false,
                        "fullname": "Leandro von Werra",
                        "user": "lvwerra",
                        "type": "user"
                    },
                    "name": "Leandro von Werra",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-04-08T10:28:43.360Z",
                    "hidden": false
                },
                {
                    "_id": "67f4cf5b504263bce1236d97",
                    "user": {
                        "_id": "5df7e9e5da6d0311fd3d53f9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1583857746553-5df7e9e5da6d0311fd3d53f9.jpeg",
                        "isPro": true,
                        "fullname": "Thomas Wolf",
                        "user": "thomwolf",
                        "type": "user"
                    },
                    "name": "Thomas Wolf",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T10:30:10.389Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-04-07T17:58:57.000Z",
            "submittedOnDailyAt": "2025-04-08T06:10:52.675Z",
            "title": "SmolVLM: Redefining small and efficient multimodal models",
            "submittedOnDailyBy": {
                "_id": "65d66b494bbd0d92b641cdbb",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d66b494bbd0d92b641cdbb/6-7dm7B-JxcoS1QlCPdMN.jpeg",
                "isPro": false,
                "fullname": "Andres Marafioti",
                "user": "andito",
                "type": "user"
            },
            "summary": "Large Vision-Language Models (VLMs) deliver exceptional performance but\nrequire significant computational resources, limiting their deployment on\nmobile and edge devices. Smaller VLMs typically mirror design choices of larger\nmodels, such as extensive image tokenization, leading to inefficient GPU memory\nusage and constrained practicality for on-device applications.\n  We introduce SmolVLM, a series of compact multimodal models specifically\nengineered for resource-efficient inference. We systematically explore\narchitectural configurations, tokenization strategies, and data curation\noptimized for low computational overhead. Through this, we identify key design\nchoices that yield substantial performance gains on image and video tasks with\nminimal memory footprints.\n  Our smallest model, SmolVLM-256M, uses less than 1GB GPU memory during\ninference and outperforms the 300-times larger Idefics-80B model, despite an\n18-month development gap. Our largest model, at 2.2B parameters, rivals\nstate-of-the-art VLMs consuming twice the GPU memory. SmolVLM models extend\nbeyond static images, demonstrating robust video comprehension capabilities.\n  Our results emphasize that strategic architectural optimizations, aggressive\nyet efficient tokenization, and carefully curated training data significantly\nenhance multimodal performance, facilitating practical, energy-efficient\ndeployments at significantly smaller scales.",
            "upvotes": 48,
            "discussionId": "67f4cf5d504263bce1236dda",
            "projectPage": "https://huggingface.co/collections/HuggingFaceTB/smolvlm2-smallest-video-lm-ever-67ab6b5e84bf8aaa60cb17c7",
            "githubRepo": "https://github.com/huggingface/smollm"
        },
        "translation_title": "SmolVLM: 작은 규모의 효율적인 멀티모달 모델 재정의",
        "purpose": "모바일 및 엣지 디바이스에서 활용 가능한 자원 효율적인 멀티모달 모델 개발",
        "method": [
            "SmolVLM이라는 일련의 컴팩트한 멀티모달 모델을 도입함(We introduce SmolVLM, a series of compact multimodal models specifically engineered for resource-efficient inference.)",
            "저전력 컴퓨팅을 위한 아키텍처 구성, 토큰화 전략, 데이터 선별을 체계적으로 탐색함(We systematically explore architectural configurations, tokenization strategies, and data curation optimized for low computational overhead.)",
            "가장 작은 모델이 GPU 메모리 사용을 1GB 이하로 유지하며 300배 더 큰 모델보다 성능이 우수함(Our smallest model, SmolVLM-256M, uses less than 1GB GPU memory during inference and outperforms the 300-times larger Idefics-80B model.)"
        ],
        "conclusion": "전략적 아키텍처 최적화와 효율적인 토큰화, 세심하게 선별된 훈련 데이터가 멀티모달 성능을 대폭 향상시켜, 더 작은 규모에서 실용적이고 에너지 효율적인 배포를 가능하게 함.",
        "keywords": [
            "Multimodal Learning",
            "Image Understanding",
            "Video Understanding"
        ]
    },
    {
        "paper": {
            "id": "2504.05298",
            "authors": [
                {
                    "_id": "67f4a0ccfefcc542f83f84e7",
                    "user": {
                        "_id": "646ebf2298e8f749fc60ce38",
                        "avatarUrl": "/avatars/5a76c9343451c24e9697d3165cdc0af6.svg",
                        "isPro": false,
                        "fullname": "Karan Dalal",
                        "user": "karansdalal",
                        "type": "user"
                    },
                    "name": "Karan Dalal",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T09:09:24.283Z",
                    "hidden": false
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84e8",
                    "user": {
                        "_id": "66b01b126038fe024ae979d3",
                        "avatarUrl": "/avatars/75b561be803fa28cb78c6cff9eb5ac54.svg",
                        "isPro": false,
                        "fullname": "Daniel Koceja",
                        "user": "koceja",
                        "type": "user"
                    },
                    "name": "Daniel Koceja",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T09:09:31.602Z",
                    "hidden": false
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84e9",
                    "user": {
                        "_id": "638835fede1fa6adc5485a05",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669871090087-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Gashon Hussein",
                        "user": "GashonHussein",
                        "type": "user"
                    },
                    "name": "Gashon Hussein",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T09:09:39.483Z",
                    "hidden": false
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84ea",
                    "name": "Jiarui Xu",
                    "hidden": false
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84eb",
                    "user": {
                        "_id": "638fe91639f7e2a7f9d2a8c6",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/638fe91639f7e2a7f9d2a8c6/hB7DMVODcdAEUdQnXxWA8.jpeg",
                        "isPro": false,
                        "fullname": "Yue Zhao",
                        "user": "zhaoyue-zephyrus",
                        "type": "user"
                    },
                    "name": "Yue Zhao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-04-08T06:51:29.995Z",
                    "hidden": false
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84ec",
                    "name": "Youjin Song",
                    "hidden": false
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84ed",
                    "name": "Shihao Han",
                    "hidden": false
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84ee",
                    "name": "Ka Chun Cheung",
                    "hidden": false
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84ef",
                    "name": "Jan Kautz",
                    "hidden": false
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84f0",
                    "user": {
                        "_id": "677c45511fbb93b90f1c6f3d",
                        "avatarUrl": "/avatars/3a78fdd8d1debc8d267e80e4b7a6bf77.svg",
                        "isPro": false,
                        "fullname": "Carlos Guestrin",
                        "user": "guestrin",
                        "type": "user"
                    },
                    "name": "Carlos Guestrin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T09:10:26.609Z",
                    "hidden": false
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84f1",
                    "user": {
                        "_id": "67ecbb7eb57a7b083182ea3f",
                        "avatarUrl": "/avatars/8fb800e0729771e61ff0d2f9a05eb5b9.svg",
                        "isPro": false,
                        "fullname": "Tatsunori Hashimoto",
                        "user": "hashtag56",
                        "type": "user"
                    },
                    "name": "Tatsunori Hashimoto",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T09:10:20.291Z",
                    "hidden": true
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84f2",
                    "user": {
                        "_id": "64931e7e2da595588288f161",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64931e7e2da595588288f161/4jOhJOFsU7RVFMgGk5kO7.jpeg",
                        "isPro": false,
                        "fullname": "Sanmi Koyejo",
                        "user": "sanmikoyejo",
                        "type": "user"
                    },
                    "name": "Sanmi Koyejo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T09:10:14.122Z",
                    "hidden": false
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84f3",
                    "user": {
                        "_id": "64d42729f63b01b7f676b176",
                        "avatarUrl": "/avatars/52e54bdd6a1fb6c774a40cd70f3d7925.svg",
                        "isPro": false,
                        "fullname": "Yejin Choi",
                        "user": "yejinchoinka",
                        "type": "user"
                    },
                    "name": "Yejin Choi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T09:10:07.480Z",
                    "hidden": false
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84f4",
                    "name": "Yu Sun",
                    "hidden": false
                },
                {
                    "_id": "67f4a0ccfefcc542f83f84f5",
                    "name": "Xiaolong Wang",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/638fe91639f7e2a7f9d2a8c6/cTDthYKFDTs8NDfvfVKJI.mp4"
            ],
            "publishedAt": "2025-04-07T17:56:31.000Z",
            "submittedOnDailyAt": "2025-04-08T02:38:37.647Z",
            "title": "One-Minute Video Generation with Test-Time Training",
            "submittedOnDailyBy": {
                "_id": "638fe91639f7e2a7f9d2a8c6",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/638fe91639f7e2a7f9d2a8c6/hB7DMVODcdAEUdQnXxWA8.jpeg",
                "isPro": false,
                "fullname": "Yue Zhao",
                "user": "zhaoyue-zephyrus",
                "type": "user"
            },
            "summary": "Transformers today still struggle to generate one-minute videos because\nself-attention layers are inefficient for long context. Alternatives such as\nMamba layers struggle with complex multi-scene stories because their hidden\nstates are less expressive. We experiment with Test-Time Training (TTT) layers,\nwhose hidden states themselves can be neural networks, therefore more\nexpressive. Adding TTT layers into a pre-trained Transformer enables it to\ngenerate one-minute videos from text storyboards. For proof of concept, we\ncurate a dataset based on Tom and Jerry cartoons. Compared to baselines such as\nMamba~2, Gated DeltaNet, and sliding-window attention layers, TTT layers\ngenerate much more coherent videos that tell complex stories, leading by 34 Elo\npoints in a human evaluation of 100 videos per method. Although promising,\nresults still contain artifacts, likely due to the limited capability of the\npre-trained 5B model. The efficiency of our implementation can also be\nimproved. We have only experimented with one-minute videos due to resource\nconstraints, but the approach can be extended to longer videos and more complex\nstories. Sample videos, code and annotations are available at:\nhttps://test-time-training.github.io/video-dit",
            "upvotes": 47,
            "discussionId": "67f4a0cefefcc542f83f8592",
            "projectPage": "https://test-time-training.github.io/video-dit/",
            "githubRepo": "https://github.com/test-time-training/ttt-video-dit"
        },
        "translation_title": "테스트 시간 학습을 통한 1분 비디오 생성",
        "purpose": "긴 맥락에서 비디오 생성의 효율성을 높이기 위한 새로운 방법 연구",
        "method": [
            "Test-Time Training(TTT) 레이어를 통해 비디오 생성의 숨겨진 상태를 신경망으로 만들고 표현력을 높임(We experiment with Test-Time Training (TTT) layers, whose hidden states themselves can be neural networks, therefore more expressive.)",
            "미리 학습된 Transformer에 TTT 레이어를 추가하여 텍스트 스토리보드에서 1분 비디오를 생성하도록 함(Adding TTT layers into a pre-trained Transformer enables it to generate one-minute videos from text storyboards.)",
            "Tom and Jerry 만화 기반 데이터셋을 수집하여 개념 증명 작업을 수행함(For proof of concept, we curate a dataset based on Tom and Jerry cartoons.)"
        ],
        "conclusion": "TTT 레이어를 사용한 결과, 복잡한 이야기를 더 일관되게 전달하는 비디오를 생성할 수 있었으며, 기존의 방법들보다 34 Elo 포인트 더 높은 평가를 받음.",
        "keywords": [
            "Video Generation",
            "Natural Language Processing",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2504.05305",
            "authors": [
                {
                    "_id": "67f495437e1624ebbaf2d90e",
                    "user": {
                        "_id": "64842d1edc475c315e41123a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64842d1edc475c315e41123a/Yqam_dy0MnQm4Rn1_1_4N.jpeg",
                        "isPro": false,
                        "fullname": "Sangbeom Lim",
                        "user": "SammyLim",
                        "type": "user"
                    },
                    "name": "Sangbeom Lim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-04-08T06:51:37.341Z",
                    "hidden": false
                },
                {
                    "_id": "67f495437e1624ebbaf2d90f",
                    "user": {
                        "_id": "64c2c45ae818eec6128fdda3",
                        "avatarUrl": "/avatars/d4399e25e6399345e263c7902789047e.svg",
                        "isPro": false,
                        "fullname": "Jun-Wan KIM",
                        "user": "junwann",
                        "type": "user"
                    },
                    "name": "Junwan Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-04-08T06:51:34.302Z",
                    "hidden": false
                },
                {
                    "_id": "67f495437e1624ebbaf2d910",
                    "name": "Heeji Yoon",
                    "hidden": false
                },
                {
                    "_id": "67f495437e1624ebbaf2d911",
                    "user": {
                        "_id": "65d02dc017e2b305e0d7bf4f",
                        "avatarUrl": "/avatars/2a50fd0541e7b0e200c577a661956696.svg",
                        "isPro": false,
                        "fullname": "Jaewoo Jung",
                        "user": "crepejung00",
                        "type": "user"
                    },
                    "name": "Jaewoo Jung",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-04-08T06:51:32.321Z",
                    "hidden": false
                },
                {
                    "_id": "67f495437e1624ebbaf2d912",
                    "user": {
                        "_id": "65cf717450818a335a1d3021",
                        "avatarUrl": "/avatars/382a0e0f40f661cda1b2531e3e6ea2ee.svg",
                        "isPro": false,
                        "fullname": "Seungryong Kim",
                        "user": "seungryong",
                        "type": "user"
                    },
                    "name": "Seungryong Kim",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T09:13:34.541Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-04-07T17:59:44.000Z",
            "submittedOnDailyAt": "2025-04-08T01:57:21.829Z",
            "title": "URECA: Unique Region Caption Anything",
            "submittedOnDailyBy": {
                "_id": "64842d1edc475c315e41123a",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64842d1edc475c315e41123a/Yqam_dy0MnQm4Rn1_1_4N.jpeg",
                "isPro": false,
                "fullname": "Sangbeom Lim",
                "user": "SammyLim",
                "type": "user"
            },
            "summary": "Region-level captioning aims to generate natural language descriptions for\nspecific image regions while highlighting their distinguishing features.\nHowever, existing methods struggle to produce unique captions across\nmulti-granularity, limiting their real-world applicability. To address the need\nfor detailed region-level understanding, we introduce URECA dataset, a\nlarge-scale dataset tailored for multi-granularity region captioning. Unlike\nprior datasets that focus primarily on salient objects, URECA dataset ensures a\nunique and consistent mapping between regions and captions by incorporating a\ndiverse set of objects, parts, and background elements. Central to this is a\nstage-wise data curation pipeline, where each stage incrementally refines\nregion selection and caption generation. By leveraging Multimodal Large\nLanguage Models (MLLMs) at each stage, our pipeline produces distinctive and\ncontextually grounded captions with improved accuracy and semantic diversity.\nBuilding upon this dataset, we present URECA, a novel captioning model designed\nto effectively encode multi-granularity regions. URECA maintains essential\nspatial properties such as position and shape through simple yet impactful\nmodifications to existing MLLMs, enabling fine-grained and semantically rich\nregion descriptions. Our approach introduces dynamic mask modeling and a\nhigh-resolution mask encoder to enhance caption uniqueness. Experiments show\nthat URECA achieves state-of-the-art performance on URECA dataset and\ngeneralizes well to existing region-level captioning benchmarks.",
            "upvotes": 26,
            "discussionId": "67f495477e1624ebbaf2da2f",
            "projectPage": "https://cvlab-kaist.github.io/URECA/",
            "githubRepo": "https://github.com/cvlab-kaist/URECA"
        },
        "translation_title": "URECA: 독특한 지역 캡션 생성",
        "purpose": "다양한 기밀성과 세부 지역 이해를 위해 고유한 캡션 생성을 지원하는 데이터셋 구축",
        "method": [
            "URECA 데이터셋을 통해 다양한 객체, 부분 및 배경 요소를 포함하여 지역과 캡션 간의 고유하고 일관된 매핑을 보장함(URECA dataset ensures a unique and consistent mapping between regions and captions by incorporating a diverse set of objects, parts, and background elements.)",
            "단계별 데이터 큐레이션 파이프라인을 활용하여 지역 선택과 캡션 생성을 점진적으로 개선함(Central to this is a stage-wise data curation pipeline, where each stage incrementally refines region selection and caption generation.)",
            "다양한 MLLMs를 활용하여 문맥에 맞는 캡션을 생성하며 정확성과 의미적 다양성을 향상시킴(By leveraging Multimodal Large Language Models (MLLMs) at each stage, our pipeline produces distinctive and contextually grounded captions with improved accuracy and semantic diversity.)"
        ],
        "conclusion": "URECA는 URECA 데이터셋에서 최첨단 성능을 달성하며, 기존의 지역 캡션 평가 지표에서도 잘 일반화됨.",
        "keywords": [
            "Multimodal Learning",
            "Natural Language Processing",
            "Image Understanding"
        ]
    },
    {
        "paper": {
            "id": "2504.04718",
            "authors": [
                {
                    "_id": "67f48eff463c4d1c4ae5284b",
                    "user": {
                        "_id": "64b74920fe6a108d03fed767",
                        "avatarUrl": "/avatars/a2c05b809c36fa5fab8e1a43b3e67051.svg",
                        "isPro": false,
                        "fullname": "Minki Kang",
                        "user": "Nardien",
                        "type": "user"
                    },
                    "name": "Minki Kang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T09:12:42.979Z",
                    "hidden": false
                },
                {
                    "_id": "67f48eff463c4d1c4ae5284c",
                    "name": "Jongwon Jeong",
                    "hidden": false
                },
                {
                    "_id": "67f48eff463c4d1c4ae5284d",
                    "name": "Jaewoong Cho",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-04-07T04:01:17.000Z",
            "submittedOnDailyAt": "2025-04-08T06:04:55.039Z",
            "title": "T1: Tool-integrated Self-verification for Test-time Compute Scaling in\n  Small Language Models",
            "submittedOnDailyBy": {
                "_id": "64b74920fe6a108d03fed767",
                "avatarUrl": "/avatars/a2c05b809c36fa5fab8e1a43b3e67051.svg",
                "isPro": false,
                "fullname": "Minki Kang",
                "user": "Nardien",
                "type": "user"
            },
            "summary": "Recent studies have demonstrated that test-time compute scaling effectively\nimproves the performance of small language models (sLMs). However, prior\nresearch has mainly examined test-time compute scaling with an additional\nlarger model as a verifier, leaving self-verification by sLMs underexplored. In\nthis work, we investigate whether sLMs can reliably self-verify their outputs\nunder test-time scaling. We find that even with knowledge distillation from\nlarger verifiers, sLMs struggle with verification tasks requiring memorization,\nsuch as numerical calculations and fact-checking. To address this limitation,\nwe propose Tool-integrated self-verification (T1), which delegates\nmemorization-heavy verification steps to external tools, such as a code\ninterpreter. Our theoretical analysis shows that tool integration reduces\nmemorization demands and improves test-time scaling performance. Experiments on\nthe MATH benchmark demonstrate that, with T1, a Llama-3.2 1B model under\ntest-time scaling outperforms the significantly larger Llama-3.1 8B model.\nMoreover, T1 generalizes effectively to both mathematical (MATH500) and\nmulti-domain knowledge-intensive tasks (MMLU-Pro). Our findings highlight the\npotential of tool integration to substantially improve the self-verification\nabilities of sLMs.",
            "upvotes": 25,
            "discussionId": "67f48f00463c4d1c4ae52882"
        },
        "translation_title": "T1: 소형 언어 모델의 테스트 시간 컴퓨팅 확장을 위한 도구 통합 자기 검증",
        "purpose": "소형 언어 모델(sLMs)의 자기 검증 능력을 개선하기 위한 도구 통합 방법 연구",
        "method": [
            "sLMs의 출력이 테스트 시간 확장 하에서 신뢰성 있게 자기 검증할 수 있는지 조사함(we investigate whether sLMs can reliably self-verify their outputs under test-time scaling.)",
            "기억력이 필요한 검증 단계는 외부 도구에 위임하는 Tool-integrated self-verification(T1) 방법을 제안함(to address this limitation, we propose Tool-integrated self-verification (T1), which delegates memorization-heavy verification steps to external tools, such as a code interpreter.)",
            "이론적 분석을 통해 도구 통합이 기억 요구를 줄이고 테스트 시간 성능을 향상시키는 것을 보여줌(our theoretical analysis shows that tool integration reduces memorization demands and improves test-time scaling performance.)"
        ],
        "conclusion": "T1을 통해 Llama-3.2 1B 모델이 테스트 시간 확장에서 Llama-3.1 8B 모델보다 뛰어난 성능을 보이며, 도구 통합은 sLMs의 자기 검증 능력을 크게 개선할 가능성을 보여줌.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2504.02828",
            "authors": [
                {
                    "_id": "67f01efe81f4f7a1b43f4930",
                    "user": {
                        "_id": "6279a4f6812ee439d9c72d3f",
                        "avatarUrl": "/avatars/a35a5674d1168d345d9fc5018485283e.svg",
                        "isPro": false,
                        "fullname": "Jinqi Luo",
                        "user": "peterljq",
                        "type": "user"
                    },
                    "name": "Jinqi Luo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-04-06T08:11:28.131Z",
                    "hidden": false
                },
                {
                    "_id": "67f01efe81f4f7a1b43f4931",
                    "name": "Tianjiao Ding",
                    "hidden": false
                },
                {
                    "_id": "67f01efe81f4f7a1b43f4932",
                    "user": {
                        "_id": "6627043551cedbbb0b352047",
                        "avatarUrl": "/avatars/8c4f80a24f8ba8761d33692c4ed28c29.svg",
                        "isPro": false,
                        "fullname": "Kwan Ho Ryan Chan",
                        "user": "ryanckh",
                        "type": "user"
                    },
                    "name": "Kwan Ho Ryan Chan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T09:13:58.769Z",
                    "hidden": false
                },
                {
                    "_id": "67f01efe81f4f7a1b43f4933",
                    "name": "Hancheng Min",
                    "hidden": false
                },
                {
                    "_id": "67f01efe81f4f7a1b43f4934",
                    "user": {
                        "_id": "6303ce25fc783bfc744216af",
                        "avatarUrl": "/avatars/09f5e87c1f56a1b7f6ef9c5037682285.svg",
                        "isPro": false,
                        "fullname": "Chris Callison-Burch",
                        "user": "CCB",
                        "type": "user"
                    },
                    "name": "Chris Callison-Burch",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-04-08T10:33:20.017Z",
                    "hidden": false
                },
                {
                    "_id": "67f01efe81f4f7a1b43f4935",
                    "name": "René Vidal",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-04-03T17:59:58.000Z",
            "submittedOnDailyAt": "2025-04-08T02:59:02.267Z",
            "title": "Concept Lancet: Image Editing with Compositional Representation\n  Transplant",
            "submittedOnDailyBy": {
                "_id": "6279a4f6812ee439d9c72d3f",
                "avatarUrl": "/avatars/a35a5674d1168d345d9fc5018485283e.svg",
                "isPro": false,
                "fullname": "Jinqi Luo",
                "user": "peterljq",
                "type": "user"
            },
            "summary": "Diffusion models are widely used for image editing tasks. Existing editing\nmethods often design a representation manipulation procedure by curating an\nedit direction in the text embedding or score space. However, such a procedure\nfaces a key challenge: overestimating the edit strength harms visual\nconsistency while underestimating it fails the editing task. Notably, each\nsource image may require a different editing strength, and it is costly to\nsearch for an appropriate strength via trial-and-error. To address this\nchallenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play\nframework for principled representation manipulation in diffusion-based image\nediting. At inference time, we decompose the source input in the latent (text\nembedding or diffusion score) space as a sparse linear combination of the\nrepresentations of the collected visual concepts. This allows us to accurately\nestimate the presence of concepts in each image, which informs the edit. Based\non the editing task (replace/add/remove), we perform a customized concept\ntransplant process to impose the corresponding editing direction. To\nsufficiently model the concept space, we curate a conceptual representation\ndataset, CoLan-150K, which contains diverse descriptions and scenarios of\nvisual terms and phrases for the latent dictionary. Experiments on multiple\ndiffusion-based image editing baselines show that methods equipped with CoLan\nachieve state-of-the-art performance in editing effectiveness and consistency\npreservation.",
            "upvotes": 14,
            "discussionId": "67f01eff81f4f7a1b43f4971",
            "projectPage": "https://peterljq.github.io/project/colan",
            "githubRepo": "https://github.com/peterljq/Concept-Lancet",
            "ai_keywords": [
                "diffusion models",
                "image editing",
                "text embedding",
                "score space",
                "latent space",
                "sparse linear combination",
                "visual concepts",
                "concept transplantation",
                "conceptual representation dataset",
                "CoLan-150K",
                "CoLan"
            ]
        },
        "translation_title": "Concept Lancet: 구성적 표현을 이용한 이미지 편집",
        "purpose": "Diffusion 기반 이미지 편집에서 적절한 편집 강도를 결정하기 위한 새로운 접근법 개발",
        "method": [
            "이미지를 편집할 때 편집 방향을 제대로 조정하기 위해 CoLan이라는 제로샷 프레임워크를 제안함(we propose Concept Lancet (CoLan), a zero-shot plug-and-play framework for principled representation manipulation in diffusion-based image editing.)",
            "소스 이미지를 사용할 수 있는 시각적 개념들의 표현으로 분해하여 각 이미지에서 개념의 존재를 정확히 추정함(This allows us to accurately estimate the presence of concepts in each image, which informs the edit.)",
            "CoLan-150K이라는 다양한 시각적 용어와 구문을 담은 개념 표현 데이터셋을 구축함(we curate a conceptual representation dataset, CoLan-150K, which contains diverse descriptions and scenarios of visual terms and phrases for the latent dictionary.)"
        ],
        "conclusion": "CoLan을 사용하는 방법이 편집의 효과성과 시각적 일관성을 유지하는 데 있어 최첨단 성능을 달성함.",
        "keywords": [
            "Image Editing",
            "Image Generation",
            "Computer Vision"
        ]
    }
]