[
    {
        "paper": {
            "id": "2505.02550",
            "authors": [
                {
                    "_id": "6819ef0b2ff435c58da4d860",
                    "user": {
                        "_id": "63ecbccac8827dd0f0f59579",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63ecbccac8827dd0f0f59579/kz-2F9Z0QKllifgZmr8tH.jpeg",
                        "isPro": false,
                        "fullname": "Chris Ociepa",
                        "user": "chrisociepa",
                        "type": "user"
                    },
                    "name": "Krzysztof Ociepa",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-12T09:03:56.213Z",
                    "hidden": false
                },
                {
                    "_id": "6819ef0b2ff435c58da4d861",
                    "name": "Łukasz Flis",
                    "hidden": false
                },
                {
                    "_id": "6819ef0b2ff435c58da4d862",
                    "user": {
                        "_id": "61786d0b038518aa2827c6b7",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61786d0b038518aa2827c6b7/d1UnfivoVreYebS5JM3P9.jpeg",
                        "isPro": false,
                        "fullname": "Remek Kinas",
                        "user": "Remek",
                        "type": "user"
                    },
                    "name": "Remigiusz Kinas",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-12T06:51:15.217Z",
                    "hidden": false
                },
                {
                    "_id": "6819ef0b2ff435c58da4d863",
                    "user": {
                        "_id": "5e47d3eb178ca95365287400",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
                        "isPro": true,
                        "fullname": "Krzysztof Wróbel",
                        "user": "djstrong",
                        "type": "user"
                    },
                    "name": "Krzysztof Wróbel",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-12T09:03:54.135Z",
                    "hidden": false
                },
                {
                    "_id": "6819ef0b2ff435c58da4d864",
                    "user": {
                        "_id": "636b9b006890dd5a450081a5",
                        "avatarUrl": "/avatars/2b4ba89894d952f95ecd1e9926580608.svg",
                        "isPro": false,
                        "fullname": "AG",
                        "user": "adgw",
                        "type": "user"
                    },
                    "name": "Adrian Gwoździej",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-12T12:56:24.966Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-05-05T10:39:51.000Z",
            "submittedOnDailyAt": "2025-05-12T07:26:20.895Z",
            "title": "Bielik v3 Small: Technical Report",
            "submittedOnDailyBy": {
                "_id": "5e47d3eb178ca95365287400",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
                "isPro": true,
                "fullname": "Krzysztof Wróbel",
                "user": "djstrong",
                "type": "user"
            },
            "summary": "We introduce Bielik v3, a series of parameter-efficient generative text\nmodels (1.5B and 4.5B) optimized for Polish language processing. These models\ndemonstrate that smaller, well-optimized architectures can achieve performance\ncomparable to much larger counterparts while requiring substantially fewer\ncomputational resources. Our approach incorporates several key innovations: a\ncustom Polish tokenizer (APT4) that significantly improves token efficiency,\nWeighted Instruction Cross-Entropy Loss to balance learning across instruction\ntypes, and Adaptive Learning Rate that dynamically adjusts based on training\nprogress. Trained on a meticulously curated corpus of 292 billion tokens\nspanning 303 million documents, these models excel across multiple benchmarks,\nincluding the Open PL LLM Leaderboard, Complex Polish Text Understanding\nBenchmark, Polish EQ-Bench, and Polish Medical Leaderboard. The 4.5B parameter\nmodel achieves results competitive with models 2-3 times its size, while the\n1.5B model delivers strong performance despite its extremely compact profile.\nThese advances establish new benchmarks for parameter-efficient language\nmodeling in less-represented languages, making high-quality Polish language AI\nmore accessible for resource-constrained applications.",
            "upvotes": 39,
            "discussionId": "6819ef0c2ff435c58da4d892",
            "projectPage": "https://bielik.ai/",
            "githubRepo": "https://github.com/speakleash",
            "ai_keywords": [
                "parameter-efficient",
                "generative text models",
                "token efficiency",
                "custom Polish tokenizer",
                "Weighted Instruction Cross-Entropy Loss",
                "Adaptive Learning Rate"
            ]
        },
        "translation_title": "Bielik v3 Small: 기술 보고서",
        "purpose": "파라미터 효율적인 Polish 언어 처리 생성 텍스트 모델 개발 및 성능 최적화를 목표로 함",
        "method": [
            "1.5B 및 4.5B 파라미터 모델을 소개하고, 컴퓨팅 자원을 크게 줄이면서도 유사한 성능을 유지하도록 최적화함(These models demonstrate that smaller, well-optimized architectures can achieve performance comparable to much larger counterparts while requiring substantially fewer computational resources.)",
            "Polish 언어에 맞는 토크나이저(APT4)를 사용해 토큰 효율성을 개선하고, 다양한 지시 유형의 학습을 균형 있게 조절하기 위해 Weighted Instruction Cross-Entropy Loss를 도입함(Our approach incorporates several key innovations: a custom Polish tokenizer (APT4) that significantly improves token efficiency, Weighted Instruction Cross-Entropy Loss to balance learning across instruction types.)",
            "훈련 데이터로 2920억 개 토큰과 3억 30백만 개 문서로 구성된 엄격하게 선택된 말뭉치를 사용하여 여러 벤치마크에서 뛰어난 성과를 냄(Trained on a meticulously curated corpus of 292 billion tokens spanning 303 million documents, these models excel across multiple benchmarks.)"
        ],
        "conclusion": "이 모델들은 자원 제약이 있는 애플리케이션에 고품질 Polish 언어 AI를 더 쉽게 접근할 수 있도록 하고, 파라미터 효율적인 언어 모델링의 새로운 기준을 세움.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2505.02410",
            "authors": [
                {
                    "_id": "6819f19e5c7ea9f74284d3a3",
                    "user": {
                        "_id": "63ecbccac8827dd0f0f59579",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63ecbccac8827dd0f0f59579/kz-2F9Z0QKllifgZmr8tH.jpeg",
                        "isPro": false,
                        "fullname": "Chris Ociepa",
                        "user": "chrisociepa",
                        "type": "user"
                    },
                    "name": "Krzysztof Ociepa",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-12T09:03:52.265Z",
                    "hidden": false
                },
                {
                    "_id": "6819f19e5c7ea9f74284d3a4",
                    "name": "Łukasz Flis",
                    "hidden": false
                },
                {
                    "_id": "6819f19e5c7ea9f74284d3a5",
                    "user": {
                        "_id": "5e47d3eb178ca95365287400",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
                        "isPro": true,
                        "fullname": "Krzysztof Wróbel",
                        "user": "djstrong",
                        "type": "user"
                    },
                    "name": "Krzysztof Wróbel",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-12T09:03:50.340Z",
                    "hidden": false
                },
                {
                    "_id": "6819f19e5c7ea9f74284d3a6",
                    "user": {
                        "_id": "636b9b006890dd5a450081a5",
                        "avatarUrl": "/avatars/2b4ba89894d952f95ecd1e9926580608.svg",
                        "isPro": false,
                        "fullname": "AG",
                        "user": "adgw",
                        "type": "user"
                    },
                    "name": "Adrian Gwoździej",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-12T12:56:22.907Z",
                    "hidden": false
                },
                {
                    "_id": "6819f19e5c7ea9f74284d3a7",
                    "user": {
                        "_id": "61786d0b038518aa2827c6b7",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61786d0b038518aa2827c6b7/d1UnfivoVreYebS5JM3P9.jpeg",
                        "isPro": false,
                        "fullname": "Remek Kinas",
                        "user": "Remek",
                        "type": "user"
                    },
                    "name": "Remigiusz Kinas",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-12T06:51:13.426Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-05-05T07:03:41.000Z",
            "submittedOnDailyAt": "2025-05-12T07:25:02.402Z",
            "title": "Bielik 11B v2 Technical Report",
            "submittedOnDailyBy": {
                "_id": "5e47d3eb178ca95365287400",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1633554153914-5e47d3eb178ca95365287400.png",
                "isPro": true,
                "fullname": "Krzysztof Wróbel",
                "user": "djstrong",
                "type": "user"
            },
            "summary": "We present Bielik 11B v2, a state-of-the-art language model optimized for\nPolish text processing. Built on the Mistral 7B v0.2 architecture and scaled to\n11B parameters using depth up-scaling, this model demonstrates exceptional\nperformance across Polish language benchmarks while maintaining strong\ncross-lingual capabilities. We introduce two key technical innovations:\nWeighted Instruction Cross-Entropy Loss, which optimizes learning across\ndiverse instruction types by assigning quality-based weights to training\nexamples, and Adaptive Learning Rate, which dynamically adjusts based on\ncontext length. Comprehensive evaluation across multiple benchmarks\ndemonstrates that Bielik 11B v2 outperforms many larger models, including those\nwith 2-6 times more parameters, and significantly surpasses other specialized\nPolish language models on tasks ranging from linguistic understanding to\ncomplex reasoning. The model's parameter efficiency and extensive quantization\noptions enable deployment across various hardware configurations, advancing\nPolish language AI capabilities and establishing new benchmarks for\nresource-efficient language modeling in less-represented languages.",
            "upvotes": 33,
            "discussionId": "6819f19e5c7ea9f74284d3cc",
            "projectPage": "https://bielik.ai/",
            "githubRepo": "https://github.com/speakleash",
            "ai_keywords": [
                "Weighted Instruction Cross-Entropy Loss",
                "Adaptive Learning Rate",
                "depth up-scaling",
                "parameter efficiency",
                "quantization"
            ]
        },
        "translation_title": "Bielik 11B v2 기술 보고서",
        "purpose": "폴란드어 텍스트 처리를 위한 최적화된 최신 언어 모델 개발",
        "method": [
            "Mistral 7B v0.2 아키텍처 기반으로 11B 파라미터로 확장함(Built on the Mistral 7B v0.2 architecture and scaled to 11B parameters using depth up-scaling.)",
            "다양한 지시 유형에 품질 기반 가중치를 부여하여 학습을 최적화하는 Weighted Instruction Cross-Entropy Loss 도입함(We introduce two key technical innovations: Weighted Instruction Cross-Entropy Loss, which optimizes learning across diverse instruction types by assigning quality-based weights to training examples.)",
            "맥락 길이에 따라 동적으로 조정되는 Adaptive Learning Rate를 도입함(Adaptive Learning Rate, which dynamically adjusts based on context length.)"
        ],
        "conclusion": "Bielik 11B v2는 많은 큰 모델들을 능가하며, 폴란드어 AI 능력을 향상시키고 자원이 부족한 언어 모델링에서 새로운 벤치마크를 설정함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Language Understanding"
        ]
    },
    {
        "paper": {
            "id": "2505.06111",
            "authors": [
                {
                    "_id": "68218b847202d193249511b6",
                    "user": {
                        "_id": "64ac1f169dcc5787461468a4",
                        "avatarUrl": "/avatars/c031a75989147009b7850df4eddfcb27.svg",
                        "isPro": false,
                        "fullname": "Qingwen Bu",
                        "user": "qwbu",
                        "type": "user"
                    },
                    "name": "Qingwen Bu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-12T13:14:55.391Z",
                    "hidden": false
                },
                {
                    "_id": "68218b847202d193249511b7",
                    "name": "Yanting Yang",
                    "hidden": false
                },
                {
                    "_id": "68218b847202d193249511b8",
                    "user": {
                        "_id": "66a3402e4c2093e582bdf511",
                        "avatarUrl": "/avatars/6f2e1f37b6a6cf9dc6df228482c0777a.svg",
                        "isPro": false,
                        "fullname": "Jisong Cai",
                        "user": "SereneC",
                        "type": "user"
                    },
                    "name": "Jisong Cai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-12T13:15:26.413Z",
                    "hidden": false
                },
                {
                    "_id": "68218b847202d193249511b9",
                    "user": {
                        "_id": "654a31c073416a223f3b5fca",
                        "avatarUrl": "/avatars/bab382c46787eaf7889ed241e12775ee.svg",
                        "isPro": false,
                        "fullname": "Shenyuan Gao",
                        "user": "Little-Podi",
                        "type": "user"
                    },
                    "name": "Shenyuan Gao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-12T13:15:33.171Z",
                    "hidden": false
                },
                {
                    "_id": "68218b847202d193249511ba",
                    "user": {
                        "_id": "646ec9b135f55eb49e405faa",
                        "avatarUrl": "/avatars/a17194be585d20e2a021e77a5a20e213.svg",
                        "isPro": false,
                        "fullname": "Guanghui Ren",
                        "user": "sundrops",
                        "type": "user"
                    },
                    "name": "Guanghui Ren",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-12T06:50:15.305Z",
                    "hidden": false
                },
                {
                    "_id": "68218b847202d193249511bb",
                    "user": {
                        "_id": "67739bfa64e8b7438ae68eb4",
                        "avatarUrl": "/avatars/15193bfbce487b2de4ce8c86bd18885a.svg",
                        "isPro": false,
                        "fullname": "Maoqing Yao",
                        "user": "AutobotZero",
                        "type": "user"
                    },
                    "name": "Maoqing Yao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-12T13:15:39.850Z",
                    "hidden": false
                },
                {
                    "_id": "68218b847202d193249511bc",
                    "user": {
                        "_id": "67cb7d55560c3dcbb1adeaa3",
                        "avatarUrl": "/avatars/0b616d3655b0b54a621c2608b2f14379.svg",
                        "isPro": false,
                        "fullname": "Ping Luo",
                        "user": "appleluo",
                        "type": "user"
                    },
                    "name": "Ping Luo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-12T13:15:47.622Z",
                    "hidden": false
                },
                {
                    "_id": "68218b847202d193249511bd",
                    "user": {
                        "_id": "6499b0184936457997180c90",
                        "avatarUrl": "/avatars/b8be7bfabf746639e30330f5f623f560.svg",
                        "isPro": false,
                        "fullname": "Hongyang Li",
                        "user": "compileme",
                        "type": "user"
                    },
                    "name": "Hongyang Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-12T13:16:21.369Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-05-09T15:11:13.000Z",
            "submittedOnDailyAt": "2025-05-12T04:30:20.087Z",
            "title": "UniVLA: Learning to Act Anywhere with Task-centric Latent Actions",
            "submittedOnDailyBy": {
                "_id": "64ac1f169dcc5787461468a4",
                "avatarUrl": "/avatars/c031a75989147009b7850df4eddfcb27.svg",
                "isPro": false,
                "fullname": "Qingwen Bu",
                "user": "qwbu",
                "type": "user"
            },
            "summary": "A generalist robot should perform effectively across various environments.\nHowever, most existing approaches heavily rely on scaling action-annotated data\nto enhance their capabilities. Consequently, they are often limited to single\nphysical specification and struggle to learn transferable knowledge across\ndifferent embodiments and environments. To confront these limitations, we\npropose UniVLA, a new framework for learning cross-embodiment\nvision-language-action (VLA) policies. Our key innovation is to derive\ntask-centric action representations from videos with a latent action model.\nThis enables us to exploit extensive data across a wide spectrum of embodiments\nand perspectives. To mitigate the effect of task-irrelevant dynamics, we\nincorporate language instructions and establish a latent action model within\nthe DINO feature space. Learned from internet-scale videos, the generalist\npolicy can be deployed to various robots through efficient latent action\ndecoding. We obtain state-of-the-art results across multiple manipulation and\nnavigation benchmarks, as well as real-robot deployments. UniVLA achieves\nsuperior performance over OpenVLA with less than 1/20 of pretraining compute\nand 1/10 of downstream data. Continuous performance improvements are observed\nas heterogeneous data, even including human videos, are incorporated into the\ntraining pipeline. The results underscore UniVLA's potential to facilitate\nscalable and efficient robot policy learning.",
            "upvotes": 14,
            "discussionId": "68218b857202d19324951214",
            "githubRepo": "https://github.com/OpenDriveLab/UniVLA",
            "ai_keywords": [
                "UniVLA",
                "vision-language-action (VLA) policies",
                "latent action model",
                "DINO feature space",
                "latent action decoding",
                "manipulation benchmarks",
                "navigation benchmarks",
                "real-robot deployments",
                "OpenVLA"
            ]
        },
        "translation_title": "UniVLA: 작업 중심의 잠재적 행동으로 어디서나 행동하는 법 배우기",
        "purpose": "여러 환경에서 효과적으로 작동하는 일반 로봇을 개발",
        "method": [
            "잠재적 행동 모델을 사용해 비디오에서 작업 중심의 행동 표현을 도출함 (our key innovation is to derive task-centric action representations from videos with a latent action model.)",
            "DINO feature 공간 내에서 언어 지침을 통합하여 작업과 무관한 동작의 영향을 완화함 (To mitigate the effect of task-irrelevant dynamics, we incorporate language instructions and establish a latent action model within the DINO feature space.)",
            "인터넷 규모의 비디오에서 학습한 일반적인 정책을 다양한 로봇에 배포할 수 있도록 효율적인 잠재 행동 디코딩을 사용함 (the generalist policy can be deployed to various robots through efficient latent action decoding.)"
        ],
        "conclusion": "UniVLA는 기존 방법보다 적은 자원으로 뛰어난 성능을 달성하며, 다양한 데이터가 훈련 파이프라인에 통합됨에 따라 지속적인 성능 향상을 보여줍니다.",
        "keywords": [
            "Robotics",
            "Multimodal Learning",
            "Vision-Language Models"
        ]
    },
    {
        "paper": {
            "id": "2505.05026",
            "authors": [
                {
                    "_id": "6821771ddf190eabf5f666d8",
                    "user": {
                        "_id": "655c44752205aab35222aca3",
                        "avatarUrl": "/avatars/57900539952382de0ce6892faf50b401.svg",
                        "isPro": false,
                        "fullname": "Jaehyun Jeon",
                        "user": "jeochris",
                        "type": "user"
                    },
                    "name": "Jaehyun Jeon",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-12T06:50:17.832Z",
                    "hidden": false
                },
                {
                    "_id": "6821771ddf190eabf5f666d9",
                    "user": {
                        "_id": "65c071e569429d85dc5e7e9c",
                        "avatarUrl": "/avatars/62a33b17db44e725da4df47ae3d8d554.svg",
                        "isPro": false,
                        "fullname": "Jang Han Yoon",
                        "user": "jeffrobot",
                        "type": "user"
                    },
                    "name": "Jang Han Yoon",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-12T13:16:34.355Z",
                    "hidden": false
                },
                {
                    "_id": "6821771ddf190eabf5f666da",
                    "name": "Min Soo Kim",
                    "hidden": false
                },
                {
                    "_id": "6821771ddf190eabf5f666db",
                    "user": {
                        "_id": "6548fceac8f267c7c40c85d9",
                        "avatarUrl": "/avatars/0c44a17f92519c8533c6de994aedb954.svg",
                        "isPro": false,
                        "fullname": "SUMIN SHIM",
                        "user": "use08174",
                        "type": "user"
                    },
                    "name": "Sumin Shim",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-12T13:16:50.404Z",
                    "hidden": false
                },
                {
                    "_id": "6821771ddf190eabf5f666dc",
                    "user": {
                        "_id": "64d42729f63b01b7f676b176",
                        "avatarUrl": "/avatars/52e54bdd6a1fb6c774a40cd70f3d7925.svg",
                        "isPro": false,
                        "fullname": "Yejin Choi",
                        "user": "yejinchoinka",
                        "type": "user"
                    },
                    "name": "Yejin Choi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-12T13:16:57.521Z",
                    "hidden": false
                },
                {
                    "_id": "6821771ddf190eabf5f666dd",
                    "name": "Hanbin Kim",
                    "hidden": false
                },
                {
                    "_id": "6821771ddf190eabf5f666de",
                    "name": "Youngjae Yu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-05-08T08:00:32.000Z",
            "submittedOnDailyAt": "2025-05-12T05:33:20.932Z",
            "title": "G-FOCUS: Towards a Robust Method for Assessing UI Design Persuasiveness",
            "submittedOnDailyBy": {
                "_id": "655c44752205aab35222aca3",
                "avatarUrl": "/avatars/57900539952382de0ce6892faf50b401.svg",
                "isPro": false,
                "fullname": "Jaehyun Jeon",
                "user": "jeochris",
                "type": "user"
            },
            "summary": "Evaluating user interface (UI) design effectiveness extends beyond aesthetics\nto influencing user behavior, a principle central to Design Persuasiveness. A/B\ntesting is the predominant method for determining which UI variations drive\nhigher user engagement, but it is costly and time-consuming. While recent\nVision-Language Models (VLMs) can process automated UI analysis, current\napproaches focus on isolated design attributes rather than comparative\npersuasiveness-the key factor in optimizing user interactions. To address this,\nwe introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design\nPersuasiveness Assessment task, featuring 300 real-world UI image pairs labeled\nwith A/B test results and expert rationales. Additionally, we propose G-FOCUS,\na novel inference-time reasoning strategy that enhances VLM-based\npersuasiveness assessment by reducing position bias and improving evaluation\naccuracy. Experimental results show that G-FOCUS surpasses existing inference\nstrategies in consistency and accuracy for pairwise UI evaluation. Through\npromoting VLM-driven evaluation of UI persuasiveness, our work offers an\napproach to complement A/B testing, propelling progress in scalable UI\npreference modeling and design optimization. Code and data will be released\npublicly.",
            "upvotes": 10,
            "discussionId": "68217722df190eabf5f66814",
            "ai_keywords": [
                "Vision-Language Models",
                "WiserUI-Bench",
                "Pairwise UI Design Persuasiveness Assessment",
                "G-FOCUS",
                "inference-time reasoning strategy",
                "position bias",
                "VLM-driven evaluation"
            ]
        },
        "translation_title": "G-FOCUS: UI 디자인 설득력 평가를 위한 강력한 방법에 대한 연구",
        "purpose": "UI 디자인의 설득력을 비교 평가하기 위한 효율적인 방법 개발",
        "method": [
            "반복되는 A/B 테스트의 한계를 극복하기 위해 WiserUI-Bench라는 벤치마크를 도입하여 300개의 실제 UI 이미지 쌍을 사용하여 설득력 평가를 수행함(we introduce WiserUI-Bench, a benchmark designed for Pairwise UI Design Persuasiveness Assessment task, featuring 300 real-world UI image pairs labeled with A/B test results and expert rationales.)",
            "G-FOCUS라는 새로운 추론 시간 전략을 제안하여 VLM 기반의 설득력 평가를 개선함(G-FOCUS, a novel inference-time reasoning strategy that enhances VLM-based persuasiveness assessment by reducing position bias and improving evaluation accuracy.)",
            "G-FOCUS의 실험 결과는 기존의 추론 전략보다 일관성과 정확성에서 뛰어난 성과를 나타냄(Experimental results show that G-FOCUS surpasses existing inference strategies in consistency and accuracy for pairwise UI evaluation.)"
        ],
        "conclusion": "G-FOCUS는 UI 설득력 평가를 향상시켜 A/B 테스트를 보완하는 데 기여하며, UI 선호 모델링과 디자인 최적화의 발전을 촉진할 수 있음.",
        "keywords": [
            "Vision-Language Models",
            "User Interface",
            "Design Optimization"
        ]
    },
    {
        "paper": {
            "id": "2505.02686",
            "authors": [
                {
                    "_id": "6821acfb2808328b91c0e365",
                    "user": {
                        "_id": "64cb02869e30a46f7b80b355",
                        "avatarUrl": "/avatars/81ce4ba78826b54f0e1b53eeaff87ee6.svg",
                        "isPro": false,
                        "fullname": "Xiaobao Wu",
                        "user": "bobxwu",
                        "type": "user"
                    },
                    "name": "Xiaobao Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-12T13:17:15.826Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-05-05T14:33:49.000Z",
            "submittedOnDailyAt": "2025-05-12T06:41:36.276Z",
            "title": "Sailing AI by the Stars: A Survey of Learning from Rewards in\n  Post-Training and Test-Time Scaling of Large Language Models",
            "submittedOnDailyBy": {
                "_id": "64cb02869e30a46f7b80b355",
                "avatarUrl": "/avatars/81ce4ba78826b54f0e1b53eeaff87ee6.svg",
                "isPro": false,
                "fullname": "Xiaobao Wu",
                "user": "bobxwu",
                "type": "user"
            },
            "summary": "Recent developments in Large Language Models (LLMs) have shifted from\npre-training scaling to post-training and test-time scaling. Across these\ndevelopments, a key unified paradigm has arisen: Learning from Rewards, where\nreward signals act as the guiding stars to steer LLM behavior. It has\nunderpinned a wide range of prevalent techniques, such as reinforcement\nlearning (in RLHF, DPO, and GRPO), reward-guided decoding, and post-hoc\ncorrection. Crucially, this paradigm enables the transition from passive\nlearning from static data to active learning from dynamic feedback. This endows\nLLMs with aligned preferences and deep reasoning capabilities. In this survey,\nwe present a comprehensive overview of the paradigm of learning from rewards.\nWe categorize and analyze the strategies under this paradigm across training,\ninference, and post-inference stages. We further discuss the benchmarks for\nreward models and the primary applications. Finally we highlight the challenges\nand future directions. We maintain a paper collection at\nhttps://github.com/bobxwu/learning-from-rewards-llm-papers.",
            "upvotes": 10,
            "discussionId": "6821acfd2808328b91c0e3e3",
            "githubRepo": "https://github.com/bobxwu/learning-from-rewards-llm-papers",
            "ai_keywords": [
                "reinforcement learning",
                "RLHF",
                "DPO",
                "GRPO",
                "reward-guided decoding",
                "post-hoc correction",
                "active learning",
                "reward models"
            ]
        },
        "translation_title": "별에서 배운 AI: 대형 언어 모델의 후속 훈련 및 테스트 타임 확장에서의 보상 학습 조사",
        "purpose": "대형 언어 모델의 학습 방식을 보상 신호를 이용해 개선하려는 목표",
        "method": [
            "보상 신호를 통해 LLM의 행동을 조정하는 Learning from Rewards라는 개념을 제안함(Recent developments in Large Language Models (LLMs) have shifted from pre-training scaling to post-training and test-time scaling. Across these developments, a key unified paradigm has arisen: Learning from Rewards, where reward signals act as the guiding stars to steer LLM behavior.)",
            "훈련, 추론 및 후속 추론 단계에서의 다양한 전략을 분류하고 분석함(We categorize and analyze the strategies under this paradigm across training, inference, and post-inference stages.)",
            "보상 모델의 벤치마크 및 주요 응용 분야를 논의함(We further discuss the benchmarks for reward models and the primary applications.)"
        ],
        "conclusion": "Learning from Rewards는 LLM을 능동적으로 학습 가능하게 하여 깊이 있는 추론 능력을 부여하며, 향후 연구 방향과 도전 과제를 제시함.",
        "keywords": [
            "Large Language Models",
            "Natural Language Processing",
            "Reinforcement Learning"
        ]
    }
]