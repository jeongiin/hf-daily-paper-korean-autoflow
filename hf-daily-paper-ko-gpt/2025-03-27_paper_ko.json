[
    {
        "paper": {
            "id": "2503.20215",
            "authors": [
                {
                    "_id": "67e4f2507e97884ba4205660",
                    "name": "Jin Xu",
                    "hidden": false
                },
                {
                    "_id": "67e4f2507e97884ba4205661",
                    "user": {
                        "_id": "661e577cbac5d981f883b743",
                        "avatarUrl": "/avatars/95e55e9707a6b55594c264081202d7f4.svg",
                        "isPro": false,
                        "fullname": "GuoZhifang",
                        "user": "ZhifangGuo",
                        "type": "user"
                    },
                    "name": "Zhifang Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:52:32.600Z",
                    "hidden": false
                },
                {
                    "_id": "67e4f2507e97884ba4205662",
                    "user": {
                        "_id": "6594f06ac04427eb38444bce",
                        "avatarUrl": "/avatars/b13fbf589b25eff038deb3fa12d95871.svg",
                        "isPro": false,
                        "fullname": "Jinzheng He",
                        "user": "jinzheng-he",
                        "type": "user"
                    },
                    "name": "Jinzheng He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:52:48.707Z",
                    "hidden": false
                },
                {
                    "_id": "67e4f2507e97884ba4205663",
                    "name": "Hangrui Hu",
                    "hidden": false
                },
                {
                    "_id": "67e4f2507e97884ba4205664",
                    "name": "Ting He",
                    "hidden": false
                },
                {
                    "_id": "67e4f2507e97884ba4205665",
                    "user": {
                        "_id": "63451cf0a05b51f7ded25505",
                        "avatarUrl": "/avatars/dec4bbee4a82b773fc58dfc2dce9dbeb.svg",
                        "isPro": false,
                        "fullname": "shuai bai",
                        "user": "bluelike",
                        "type": "user"
                    },
                    "name": "Shuai Bai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:53:02.818Z",
                    "hidden": false
                },
                {
                    "_id": "67e4f2507e97884ba4205666",
                    "user": {
                        "_id": "6461d675681b2e19b6acb5a5",
                        "avatarUrl": "/avatars/0d95d65d30f6672ec09dc92155324d7f.svg",
                        "isPro": false,
                        "fullname": "Keqin Chen",
                        "user": "chenkq",
                        "type": "user"
                    },
                    "name": "Keqin Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:53:19.770Z",
                    "hidden": false
                },
                {
                    "_id": "67e4f2507e97884ba4205667",
                    "user": {
                        "_id": "649a3ba9342f14148357c367",
                        "avatarUrl": "/avatars/81a769fa38b7384f382ff3cc10d6d624.svg",
                        "isPro": false,
                        "fullname": "Jialin Wang",
                        "user": "JialinWang",
                        "type": "user"
                    },
                    "name": "Jialin Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:53:26.467Z",
                    "hidden": false
                },
                {
                    "_id": "67e4f2507e97884ba4205668",
                    "name": "Yang Fan",
                    "hidden": false
                },
                {
                    "_id": "67e4f2507e97884ba4205669",
                    "user": {
                        "_id": "6712930f0fac3235c56edf5b",
                        "avatarUrl": "/avatars/cafe7cb56ce7c3b2572f5f2d0b89357a.svg",
                        "isPro": false,
                        "fullname": "kai dang",
                        "user": "1vk5i",
                        "type": "user"
                    },
                    "name": "Kai Dang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:53:33.105Z",
                    "hidden": false
                },
                {
                    "_id": "67e4f2507e97884ba420566a",
                    "name": "Bin Zhang",
                    "hidden": false
                },
                {
                    "_id": "67e4f2507e97884ba420566b",
                    "name": "Xiong Wang",
                    "hidden": false
                },
                {
                    "_id": "67e4f2507e97884ba420566c",
                    "user": {
                        "_id": "62c6a751a71b40cf26f359a8",
                        "avatarUrl": "/avatars/49abd2e71946035452c316d703baaac6.svg",
                        "isPro": false,
                        "fullname": "Yunfei Chu",
                        "user": "faychu",
                        "type": "user"
                    },
                    "name": "Yunfei Chu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:53:51.503Z",
                    "hidden": false
                },
                {
                    "_id": "67e4f2507e97884ba420566d",
                    "user": {
                        "_id": "620760a26e3b7210c2ff1943",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/620760a26e3b7210c2ff1943/VC-rKqimF6yxGESNVlPoR.jpeg",
                        "isPro": false,
                        "fullname": "Junyang Lin",
                        "user": "JustinLin610",
                        "type": "user"
                    },
                    "name": "Junyang Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:53:44.277Z",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/659e513ea9bc1f60189ac148/3pDelIehF3CWGPS0jrZvN.png"
            ],
            "publishedAt": "2025-03-26T04:17:55.000Z",
            "submittedOnDailyAt": "2025-03-27T05:14:09.555Z",
            "title": "Qwen2.5-Omni Technical Report",
            "submittedOnDailyBy": {
                "_id": "659e513ea9bc1f60189ac148",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/659e513ea9bc1f60189ac148/DBDDqjGTQ0SvjWyuYu7py.jpeg",
                "isPro": false,
                "fullname": "YuanjunLv",
                "user": "Bakerbunker",
                "type": "user"
            },
            "summary": "In this report, we present Qwen2.5-Omni, an end-to-end multimodal model\ndesigned to perceive diverse modalities, including text, images, audio, and\nvideo, while simultaneously generating text and natural speech responses in a\nstreaming manner. To enable the streaming of multimodal information inputs,\nboth audio and visual encoders utilize a block-wise processing approach. To\nsynchronize the timestamps of video inputs with audio, we organize the audio\nand video sequentially in an interleaved manner and propose a novel position\nembedding approach, named TMRoPE(Time-aligned Multimodal RoPE). To concurrently\ngenerate text and speech while avoiding interference between the two\nmodalities, we propose Thinker-Talker architecture. In this framework,\nThinker functions as a large language model tasked with text generation, while\nTalker is a dual-track autoregressive model that directly utilizes the hidden\nrepresentations from the Thinker to produce audio tokens as output. Both the\nThinker and Talker models are designed to be trained and inferred in an\nend-to-end manner. For decoding audio tokens in a streaming manner, we\nintroduce a sliding-window DiT that restricts the receptive field, aiming to\nreduce the initial package delay. Qwen2.5-Omni is comparable with the similarly\nsized Qwen2.5-VL and outperforms Qwen2-Audio. Furthermore, Qwen2.5-Omni\nachieves state-of-the-art performance on multimodal benchmarks like Omni-Bench.\nNotably, Qwen2.5-Omni's performance in end-to-end speech instruction following\nis comparable to its capabilities with text inputs, as evidenced by benchmarks\nsuch as MMLU and GSM8K. As for speech generation, Qwen2.5-Omni's streaming\nTalker outperforms most existing streaming and non-streaming alternatives in\nrobustness and naturalness.",
            "upvotes": 37,
            "discussionId": "67e4f2527e97884ba42056df",
            "projectPage": "https://qwenlm.github.io/blog/qwen2.5-omni/",
            "githubRepo": "https://github.com/QwenLM/Qwen2.5-Omni",
            "ai_keywords": [
                "multimodal model",
                "block-wise processing",
                "interleaved manner",
                "TMRoPE (Time-aligned Multimodal RoPE)",
                "position embedding",
                "Thinker-Talker architecture",
                "large language model",
                "dual-track autoregressive model",
                "end-to-end manner",
                "sliding-window DiT",
                "receptive field",
                "initial package delay",
                "Omni-Bench",
                "MMLU",
                "GSM8K",
                "end-to-end speech instruction following"
            ]
        },
        "translation_title": "Qwen2.5-Omni 기술 보고서",
        "purpose": "텍스트, 이미지, 오디오, 비디오 등 다양한 모달리티를 이해하고 생성하는 전처리 없이 끝까지 이어지는 멀티모달 모델 개발",
        "method": [
            "모든 입력 모달리티를 원활하게 스트리밍하기 위해 블록 방식 처리 접근법을 채택함(To enable the streaming of multimodal information inputs, both audio and visual encoders utilize a block-wise processing approach.)",
            "TMRoPE(Time-aligned Multimodal RoPE)라는 새로운 위치 임베딩 접근법을 제안하여 오디오와 비디오의 타임스탬프를 동기화함(To synchronize the timestamps of video inputs with audio, we propose a novel position embedding approach, named TMRoPE.)",
            "Thinker-Talker 아키텍처를 도입하여 텍스트와 음성을 동시에 생성할 때 두 모달리티 간의 간섭을 방지함(we propose Thinker-Talker architecture to concurrently generate text and speech while avoiding interference between the two modalities.)"
        ],
        "conclusion": "Qwen2.5-Omni는 멀티모달 벤치마크에서 최고 성능을 기록하며, 음성 생성에서 기존의 많은 방법보다 뛰어난 robustness와 자연스러움을 보여줌.",
        "keywords": [
            "Multimodal Learning",
            "Natural Language Processing",
            "Speech Generation"
        ]
    },
    {
        "paper": {
            "id": "2503.19757",
            "authors": [
                {
                    "_id": "67e3e1e20706b07bfb2713d6",
                    "user": {
                        "_id": "643fa1c318afbc4d1f3e5e59",
                        "avatarUrl": "/avatars/f8f35355902b4cda72e9c6d768322fae.svg",
                        "isPro": false,
                        "fullname": "Zhi Hou",
                        "user": "zhihou",
                        "type": "user"
                    },
                    "name": "Zhi Hou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:43:49.995Z",
                    "hidden": false
                },
                {
                    "_id": "67e3e1e20706b07bfb2713d7",
                    "user": {
                        "_id": "64c9e86a6a26cddbecd9bae2",
                        "avatarUrl": "/avatars/61a84989dbbc1898ebcba3236dbed039.svg",
                        "isPro": false,
                        "fullname": "Tianyi Zhang",
                        "user": "TianyiZhang0213",
                        "type": "user"
                    },
                    "name": "Tianyi Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:44:21.118Z",
                    "hidden": false
                },
                {
                    "_id": "67e3e1e20706b07bfb2713d8",
                    "name": "Yuwen Xiong",
                    "hidden": false
                },
                {
                    "_id": "67e3e1e20706b07bfb2713d9",
                    "user": {
                        "_id": "66ab30dfd456f0408b93f27b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66ab30dfd456f0408b93f27b/nps4Kni_eOExO5Z92RiiF.jpeg",
                        "isPro": false,
                        "fullname": "Haonan Duan",
                        "user": "robot-haonan",
                        "type": "user"
                    },
                    "name": "Haonan Duan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-27T09:04:53.498Z",
                    "hidden": false
                },
                {
                    "_id": "67e3e1e20706b07bfb2713da",
                    "user": {
                        "_id": "648a1e44fe11ebd7489c289c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/WwMcD9PK0gxIu2I0n0QyD.jpeg",
                        "isPro": false,
                        "fullname": "Hengjun Pu",
                        "user": "MIASANMIA",
                        "type": "user"
                    },
                    "name": "Hengjun Pu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:45:01.725Z",
                    "hidden": false
                },
                {
                    "_id": "67e3e1e20706b07bfb2713db",
                    "user": {
                        "_id": "66b9a5bb32be421cd8538cd6",
                        "avatarUrl": "/avatars/a1f7c0fe3ed4741017db713b4e6d47c8.svg",
                        "isPro": false,
                        "fullname": "Ronglei Tong",
                        "user": "TTTTTony",
                        "type": "user"
                    },
                    "name": "Ronglei Tong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:45:07.673Z",
                    "hidden": false
                },
                {
                    "_id": "67e3e1e20706b07bfb2713dc",
                    "user": {
                        "_id": "679165b9c7f527ef3619504e",
                        "avatarUrl": "/avatars/f3e6ce5fc3d05c8632d8b208f55c2987.svg",
                        "isPro": false,
                        "fullname": "Chengyang Zhao",
                        "user": "chengyzhao",
                        "type": "user"
                    },
                    "name": "Chengyang Zhao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:45:13.906Z",
                    "hidden": false
                },
                {
                    "_id": "67e3e1e20706b07bfb2713dd",
                    "user": {
                        "_id": "64ae2359179421d320b1694b",
                        "avatarUrl": "/avatars/c387a75191005bcaa473091de5383a10.svg",
                        "isPro": false,
                        "fullname": "Xizhou Zhu",
                        "user": "Einsiedler",
                        "type": "user"
                    },
                    "name": "Xizhou Zhu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:45:20.614Z",
                    "hidden": false
                },
                {
                    "_id": "67e3e1e20706b07bfb2713de",
                    "name": "Yu Qiao",
                    "hidden": false
                },
                {
                    "_id": "67e3e1e20706b07bfb2713df",
                    "user": {
                        "_id": "64686f7172d9180d4ac8b4e4",
                        "avatarUrl": "/avatars/db67dd6c4b2b41054ddcce5a18ade6f8.svg",
                        "isPro": false,
                        "fullname": "Jifeng Dai",
                        "user": "daijifeng",
                        "type": "user"
                    },
                    "name": "Jifeng Dai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:45:27.039Z",
                    "hidden": false
                },
                {
                    "_id": "67e3e1e20706b07bfb2713e0",
                    "user": {
                        "_id": "632dab84fdb35759ea6646a0",
                        "avatarUrl": "/avatars/857b0b4d115aa5ab2f143e60b0e4edc6.svg",
                        "isPro": false,
                        "fullname": "Yuntao Chen",
                        "user": "YuntaoChen",
                        "type": "user"
                    },
                    "name": "Yuntao Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:45:40.200Z",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/643fa1c318afbc4d1f3e5e59/T0twf6ibM7Htfq525gf3L.mp4"
            ],
            "publishedAt": "2025-03-25T15:19:56.000Z",
            "submittedOnDailyAt": "2025-03-27T01:27:55.746Z",
            "title": "Dita: Scaling Diffusion Transformer for Generalist\n  Vision-Language-Action Policy",
            "submittedOnDailyBy": {
                "_id": "643fa1c318afbc4d1f3e5e59",
                "avatarUrl": "/avatars/f8f35355902b4cda72e9c6d768322fae.svg",
                "isPro": false,
                "fullname": "Zhi Hou",
                "user": "zhihou",
                "type": "user"
            },
            "summary": "While recent vision-language-action models trained on diverse robot datasets\nexhibit promising generalization capabilities with limited in-domain data,\ntheir reliance on compact action heads to predict discretized or continuous\nactions constrains adaptability to heterogeneous action spaces. We present\nDita, a scalable framework that leverages Transformer architectures to directly\ndenoise continuous action sequences through a unified multimodal diffusion\nprocess. Departing from prior methods that condition denoising on fused\nembeddings via shallow networks, Dita employs in-context conditioning --\nenabling fine-grained alignment between denoised actions and raw visual tokens\nfrom historical observations. This design explicitly models action deltas and\nenvironmental nuances. By scaling the diffusion action denoiser alongside the\nTransformer's scalability, Dita effectively integrates cross-embodiment\ndatasets across diverse camera perspectives, observation scenes, tasks, and\naction spaces. Such synergy enhances robustness against various variances and\nfacilitates the successful execution of long-horizon tasks. Evaluations across\nextensive benchmarks demonstrate state-of-the-art or comparative performance in\nsimulation. Notably, Dita achieves robust real-world adaptation to\nenvironmental variances and complex long-horizon tasks through 10-shot\nfinetuning, using only third-person camera inputs. The architecture establishes\na versatile, lightweight and open-source baseline for generalist robot policy\nlearning. Project Page: https://robodita.github.io.",
            "upvotes": 37,
            "discussionId": "67e3e1e40706b07bfb2714cd",
            "projectPage": "https://robodita.github.io",
            "githubRepo": "https://github.com/RoboDita/Dita",
            "ai_keywords": [
                "Transformer architectures",
                "multimodal diffusion process",
                "in-context conditioning",
                "action deltas",
                "environmental nuances",
                "cross-embodiment datasets",
                "long-horizon tasks",
                "10-shot finetuning",
                "third-person camera inputs",
                "generalist robot policy learning"
            ]
        },
        "translation_title": "Dita: 일반화된 비전-언어-행동 정책을 위한 확장 가능한 Diffusion Transformer",
        "purpose": "디퍼시온 기반의 모델을 통해 연속적인 행동 시퀀스를 더 효과적으로 예측하고자 함",
        "method": [
            "Transformer 아키텍처를 활용하여 연속적인 행동 시퀀스를 직접적으로 제거하는 통합된 멀티모달 디퓨전 프로세스를 제공함.(we present Dita, a scalable framework that leverages Transformer architectures to directly denoise continuous action sequences through a unified multimodal diffusion process.)",
            "Dita는 과거 관찰에서의 원본 시각 토큰과 제거된 행동 사이의 정밀한 정렬을 가능하게 하는 인컨텍스트(인 상황) 조건화를 사용함.(Dita employs in-context conditioning -- enabling fine-grained alignment between denoised actions and raw visual tokens from historical observations.)",
            "디퓨전 액션 제거기를 Transformer의 확장성과 함께 스케일링하여 다양한 카메라 관점과 행동 공간을 통합함.(By scaling the diffusion action denoiser alongside the Transformer's scalability, Dita effectively integrates cross-embodiment datasets across diverse camera perspectives, observation scenes, tasks, and action spaces.)"
        ],
        "conclusion": "Dita는 다양한 환경 변동에 대해 강력한 적응력을 보여주고, 장기적인 작업 수행에 성공하며 로봇 정책 학습의 경량화된 오픈소스 기준을 확립함.",
        "keywords": [
            "Vision-Language Models",
            "Multimodal Learning",
            "Robotics"
        ]
    },
    {
        "paper": {
            "id": "2503.19990",
            "authors": [
                {
                    "_id": "67e4d3df7e97884ba4150ec0",
                    "user": {
                        "_id": "662516d72419feed62fb3a0a",
                        "avatarUrl": "/avatars/24c4157829e70a4e346aa984885aa5ad.svg",
                        "isPro": false,
                        "fullname": "Dian",
                        "user": "KexianTang",
                        "type": "user"
                    },
                    "name": "Kexian Tang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:46:12.696Z",
                    "hidden": false
                },
                {
                    "_id": "67e4d3df7e97884ba4150ec1",
                    "user": {
                        "_id": "64a6ae0e0437599198cf3a98",
                        "avatarUrl": "/avatars/6635432cc0589ba12dc170cad6986d6d.svg",
                        "isPro": false,
                        "fullname": "Junyao Gao",
                        "user": "favourisnotyou",
                        "type": "user"
                    },
                    "name": "Junyao Gao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-27T09:03:15.061Z",
                    "hidden": false
                },
                {
                    "_id": "67e4d3df7e97884ba4150ec2",
                    "user": {
                        "_id": "63d4b843df01ef426a0f79fb",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676365795587-63d4b843df01ef426a0f79fb.jpeg",
                        "isPro": false,
                        "fullname": "Yanhong Zeng",
                        "user": "zengyh1900",
                        "type": "user"
                    },
                    "name": "Yanhong Zeng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:46:24.775Z",
                    "hidden": false
                },
                {
                    "_id": "67e4d3df7e97884ba4150ec3",
                    "user": {
                        "_id": "63ee1379190ddd6214efd73a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676546883247-noauth.png",
                        "isPro": false,
                        "fullname": "HAODONG DUAN",
                        "user": "KennyUTC",
                        "type": "user"
                    },
                    "name": "Haodong Duan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-27T09:00:33.733Z",
                    "hidden": false
                },
                {
                    "_id": "67e4d3df7e97884ba4150ec4",
                    "name": "Yanan Sun",
                    "hidden": false
                },
                {
                    "_id": "67e4d3df7e97884ba4150ec5",
                    "user": {
                        "_id": "62fb2a9dc95d426ff8f74c8d",
                        "avatarUrl": "/avatars/25c1a68ee7b7d0cc7e9f56bde37f4914.svg",
                        "isPro": false,
                        "fullname": "Zhening Xing",
                        "user": "Leoxing",
                        "type": "user"
                    },
                    "name": "Zhening Xing",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-27T09:00:36.341Z",
                    "hidden": false
                },
                {
                    "_id": "67e4d3df7e97884ba4150ec6",
                    "user": {
                        "_id": "6385f8598b5acae8d24caf16",
                        "avatarUrl": "/avatars/9d261f95d24e882157b987b8827098be.svg",
                        "isPro": false,
                        "fullname": "liuwenran",
                        "user": "lwrshi1965",
                        "type": "user"
                    },
                    "name": "Wenran Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:46:45.866Z",
                    "hidden": false
                },
                {
                    "_id": "67e4d3df7e97884ba4150ec7",
                    "user": {
                        "_id": "6414230a0fcefcf72e5085dd",
                        "avatarUrl": "/avatars/3a38dc8c84b0f27af846184d1c19f6ef.svg",
                        "isPro": false,
                        "fullname": "Kaifeng Lyu",
                        "user": "vfleaking",
                        "type": "user"
                    },
                    "name": "Kaifeng Lyu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:46:52.341Z",
                    "hidden": false
                },
                {
                    "_id": "67e4d3df7e97884ba4150ec8",
                    "name": "Kai Chen",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/63ee1379190ddd6214efd73a/kjq_V0to2uTR2RSR3TyfV.png"
            ],
            "publishedAt": "2025-03-25T18:21:07.000Z",
            "submittedOnDailyAt": "2025-03-27T03:00:01.698Z",
            "title": "LEGO-Puzzles: How Good Are MLLMs at Multi-Step Spatial Reasoning?",
            "submittedOnDailyBy": {
                "_id": "63ee1379190ddd6214efd73a",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676546883247-noauth.png",
                "isPro": false,
                "fullname": "HAODONG DUAN",
                "user": "KennyUTC",
                "type": "user"
            },
            "summary": "Multi-step spatial reasoning entails understanding and reasoning about\nspatial relationships across multiple sequential steps, which is crucial for\ntackling complex real-world applications, such as robotic manipulation,\nautonomous navigation, and automated assembly. To assess how well current\nMultimodal Large Language Models (MLLMs) have acquired this fundamental\ncapability, we introduce LEGO-Puzzles, a scalable benchmark designed\nto evaluate both spatial understanding and sequential\nreasoning in MLLMs through LEGO-based tasks. LEGO-Puzzles consists of 1,100\ncarefully curated visual question-answering (VQA) samples spanning 11 distinct\ntasks, ranging from basic spatial understanding to complex multi-step\nreasoning. Based on LEGO-Puzzles, we conduct a comprehensive evaluation of\nstate-of-the-art MLLMs and uncover significant limitations in their spatial\nreasoning capabilities: even the most powerful MLLMs can answer only about half\nof the test cases, whereas human participants achieve over 90\\% accuracy. In\naddition to VQA tasks, we evaluate MLLMs' abilities to generate LEGO images\nfollowing assembly illustrations. Our experiments show that only\nGemini-2.0-Flash and GPT-4o exhibit a limited ability to follow these\ninstructions, while other MLLMs either replicate the input image or generate\ncompletely irrelevant outputs. Overall, LEGO-Puzzles exposes critical\ndeficiencies in existing MLLMs' spatial understanding and sequential reasoning\ncapabilities, and underscores the need for further advancements in multimodal\nspatial reasoning.",
            "upvotes": 24,
            "discussionId": "67e4d3e07e97884ba4150f2b",
            "ai_keywords": [
                "Multimodal Large Language Models (MLLMs)",
                "LEGO-Puzzles",
                "visual question-answering (VQA)",
                "spatial understanding",
                "sequential reasoning",
                "Gemini-2.0-Flash",
                "GPT-4o"
            ]
        },
        "translation_title": "LEGO-Puzzles: MLLMs의 다단계 공간 추론 능력은 얼마나 좋은가?",
        "purpose": "다단계 공간 추론 능력을 평가하여 로봇 조작, 자율 내비게이션 및 자동 조립과 같은 복잡한 현실 세계의 응용을 해결하기 위한 기초 능력 분석",
        "method": [
            "LEGO 기반 작업을 통해 MLLMs의 공간 이해와 순차적 추론을 평가하기 위해 LEGO-Puzzles라는 확장 가능한 벤치마크를 도입함(To assess how well current Multimodal Large Language Models (MLLMs) have acquired this fundamental capability, we introduce LEGO-Puzzles, a scalable benchmark designed to evaluate both spatial understanding and sequential reasoning in MLLMs through LEGO-based tasks.)",
            "1,100개의 시각적 질문-응답(VQA) 샘플로 구성된 LEGO-Puzzles를 설계함(LEGO-Puzzles consists of 1,100 carefully curated visual question-answering (VQA) samples spanning 11 distinct tasks.)",
            "MLLM의 성능 평가를 통해 공간 추론 능력에서 중요한 한계를 발견함(Based on LEGO-Puzzles, we conduct a comprehensive evaluation of state-of-the-art MLLMs and uncover significant limitations in their spatial reasoning capabilities.)"
        ],
        "conclusion": "LEGO-Puzzles는 기존 MLLMs의 공간 이해 및 순차적 추론 능력에 중대한 결 deficiencies를 노출하고, 다중 모달 공간 추론 분야의 추가 발전 필요성을 강조함.",
        "keywords": [
            "Multimodal Learning",
            "Image Generation",
            "Robotics"
        ]
    },
    {
        "paper": {
            "id": "2503.20314",
            "authors": [
                {
                    "_id": "67e4b65a080a33e3955b340c",
                    "name": "WanTeam",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b340e",
                    "user": {
                        "_id": "63f1f1727ddf724fbcbc9c7e",
                        "avatarUrl": "/avatars/9e0516d9b1036c23c78f313c79872f55.svg",
                        "isPro": false,
                        "fullname": "Ang Wang",
                        "user": "ang-annng",
                        "type": "user"
                    },
                    "name": "Ang Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:47:28.144Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b340f",
                    "user": {
                        "_id": "64755ff5a51711a3b59118af",
                        "avatarUrl": "/avatars/2e899088902db94e785107c3ec2abe85.svg",
                        "isPro": false,
                        "fullname": "Baole Ai",
                        "user": "baoleai",
                        "type": "user"
                    },
                    "name": "Baole Ai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:47:49.260Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3410",
                    "name": "Bin Wen",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3411",
                    "user": {
                        "_id": "6458970cab9a44f42f620a80",
                        "avatarUrl": "/avatars/f9779b0621c931f922440fec95342444.svg",
                        "isPro": false,
                        "fullname": "chaojie mao",
                        "user": "chaojiemao",
                        "type": "user"
                    },
                    "name": "Chaojie Mao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:48:02.730Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3412",
                    "user": {
                        "_id": "66592c72f4124d863fd55574",
                        "avatarUrl": "/avatars/98f0d5e6ba3728e8a1164aa5188a3298.svg",
                        "isPro": false,
                        "fullname": "Chenwei Xie",
                        "user": "chenweix7",
                        "type": "user"
                    },
                    "name": "Chen-Wei Xie",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:48:10.933Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3413",
                    "name": "Di Chen",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3414",
                    "name": "Feiwu Yu",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3415",
                    "user": {
                        "_id": "67a73767282aa06f7bcaeeb1",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/J28OVrPhD0xYulWMgICmW.png",
                        "isPro": false,
                        "fullname": "Haiming Zhao",
                        "user": "HermanZ",
                        "type": "user"
                    },
                    "name": "Haiming Zhao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:48:26.135Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3416",
                    "user": {
                        "_id": "651441e92c5da979038df5ee",
                        "avatarUrl": "/avatars/85cdafcccb522eced50dc9e4770b630a.svg",
                        "isPro": false,
                        "fullname": "Jianxiao Yang",
                        "user": "Jianxiao0203",
                        "type": "user"
                    },
                    "name": "Jianxiao Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:48:33.714Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3417",
                    "user": {
                        "_id": "6274b866f978441a764b30f6",
                        "avatarUrl": "/avatars/953b1ff82f63e371a7358a85d68304cd.svg",
                        "isPro": false,
                        "fullname": "jianyuan.zengjy",
                        "user": "filwsyl",
                        "type": "user"
                    },
                    "name": "Jianyuan Zeng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:48:40.108Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3418",
                    "name": "Jiayu Wang",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3419",
                    "user": {
                        "_id": "66f0e0262aee3cb7e981bbac",
                        "avatarUrl": "/avatars/f8f1e70469b5e047dc6e0e9dec6c5bc1.svg",
                        "isPro": false,
                        "fullname": "Jingfeng Zhang",
                        "user": "jingfengzhang",
                        "type": "user"
                    },
                    "name": "Jingfeng Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:48:58.316Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b341a",
                    "user": {
                        "_id": "602f88f5e8149a962412a667",
                        "avatarUrl": "/avatars/b78f0e583df8e5d5e3365934fe5f4900.svg",
                        "isPro": false,
                        "fullname": "Zhou",
                        "user": "Jingren",
                        "type": "user"
                    },
                    "name": "Jingren Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:49:09.146Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b341b",
                    "user": {
                        "_id": "627c93b2bec91eb1720b8bad",
                        "avatarUrl": "/avatars/89c31c71aa5027543ed5be0471fe1109.svg",
                        "isPro": false,
                        "fullname": "Jinkai Wang",
                        "user": "zwsjink",
                        "type": "user"
                    },
                    "name": "Jinkai Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:49:15.680Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b341c",
                    "user": {
                        "_id": "6465941d0e6c7618f615675b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6465941d0e6c7618f615675b/W4EHqlCucz_bojFLFEeV_.jpeg",
                        "isPro": false,
                        "fullname": "Jixuan Chen",
                        "user": "Mayome",
                        "type": "user"
                    },
                    "name": "Jixuan Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:49:25.437Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b341d",
                    "name": "Kai Zhu",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b341e",
                    "name": "Kang Zhao",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b341f",
                    "name": "Keyu Yan",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3420",
                    "name": "Lianghua Huang",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3421",
                    "user": {
                        "_id": "63b4ec15103617b0a5b3101e",
                        "avatarUrl": "/avatars/e6faad833b31ad5d892faccf621e7a34.svg",
                        "isPro": false,
                        "fullname": "Mengyang Feng",
                        "user": "archerfmy",
                        "type": "user"
                    },
                    "name": "Mengyang Feng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:50:01.919Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3422",
                    "user": {
                        "_id": "66eae63f533fd44f8a8ca60b",
                        "avatarUrl": "/avatars/38cecb4c80cc7a6e63028fcb572e3a22.svg",
                        "isPro": false,
                        "fullname": "Zhang Ningyi",
                        "user": "ZhangNy",
                        "type": "user"
                    },
                    "name": "Ningyi Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:50:13.628Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3423",
                    "name": "Pandeng Li",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3424",
                    "user": {
                        "_id": "64c5182771947b03ffee931c",
                        "avatarUrl": "/avatars/478f4e06ac1bced092dde0f11963a975.svg",
                        "isPro": false,
                        "fullname": "Wupingyu",
                        "user": "wpy1999",
                        "type": "user"
                    },
                    "name": "Pingyu Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:50:38.625Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3425",
                    "user": {
                        "_id": "642e3bcb958faf258a40e89c",
                        "avatarUrl": "/avatars/213501def37dc53032cee17e37fcc4c1.svg",
                        "isPro": false,
                        "fullname": "Ruihang Chu",
                        "user": "Ruihang",
                        "type": "user"
                    },
                    "name": "Ruihang Chu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:50:46.771Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3426",
                    "user": {
                        "_id": "6790e2b74932687e24024b4a",
                        "avatarUrl": "/avatars/951f55648490e1f520483a3e425621dd.svg",
                        "isPro": false,
                        "fullname": "Ruili",
                        "user": "RuiliFeng",
                        "type": "user"
                    },
                    "name": "Ruili Feng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:51:03.191Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3427",
                    "name": "Shiwei Zhang",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3428",
                    "user": {
                        "_id": "62bbf42ac9633b01802a6d45",
                        "avatarUrl": "/avatars/0fee1462d228f5e7f22d5c240900a3ad.svg",
                        "isPro": false,
                        "fullname": "Siyang Sun",
                        "user": "sunsiyang",
                        "type": "user"
                    },
                    "name": "Siyang Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:51:10.461Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3429",
                    "name": "Tao Fang",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b342a",
                    "name": "Tianxing Wang",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b342b",
                    "name": "Tianyi Gui",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b342c",
                    "name": "Tingyu Weng",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b342d",
                    "name": "Tong Shen",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b342e",
                    "name": "Wei Lin",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b342f",
                    "name": "Wei Wang",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3430",
                    "name": "Wei Wang",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3431",
                    "user": {
                        "_id": "623c6253389748c9f72ca287",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1654828369523-623c6253389748c9f72ca287.jpeg",
                        "isPro": false,
                        "fullname": "wenmeng zhou",
                        "user": "wenmengzhou",
                        "type": "user"
                    },
                    "name": "Wenmeng Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:51:38.310Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3432",
                    "user": {
                        "_id": "644240b1251730a7ee243ef3",
                        "avatarUrl": "/avatars/c4ca99739e2b6f3d3d0ca83ecc54766a.svg",
                        "isPro": false,
                        "fullname": "wente.wang",
                        "user": "shiftc",
                        "type": "user"
                    },
                    "name": "Wente Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:51:46.041Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3433",
                    "user": {
                        "_id": "64af91eb5c17fe25cfcbebc3",
                        "avatarUrl": "/avatars/ffc6e7b6a40300e05e66f544264dddbc.svg",
                        "isPro": false,
                        "fullname": "Wenting Shen",
                        "user": "SeventeenSSS",
                        "type": "user"
                    },
                    "name": "Wenting Shen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:51:53.298Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3434",
                    "name": "Wenyuan Yu",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3435",
                    "user": {
                        "_id": "642e19b26748dd4f8eea1321",
                        "avatarUrl": "/avatars/a534e61c21d2fb3c7a4c4d4dba98fafb.svg",
                        "isPro": false,
                        "fullname": "Xianzhong Shi",
                        "user": "itutor",
                        "type": "user"
                    },
                    "name": "Xianzhong Shi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:51:19.514Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3436",
                    "user": {
                        "_id": "65105ab08c4b535a97052fe8",
                        "avatarUrl": "/avatars/a97862045a26a74ca33d1a47b6a1f2b4.svg",
                        "isPro": false,
                        "fullname": "xiaominghuang",
                        "user": "xiaominghuang",
                        "type": "user"
                    },
                    "name": "Xiaoming Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:52:03.599Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3437",
                    "name": "Xin Xu",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3438",
                    "name": "Yan Kou",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3439",
                    "name": "Yangyu Lv",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b343a",
                    "name": "Yifei Li",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b343b",
                    "user": {
                        "_id": "67d39e61943a965360fbbc0c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/-JwILFmblPdd6Sv28c1J7.png",
                        "isPro": false,
                        "fullname": "yijing liu",
                        "user": "86diphda",
                        "type": "user"
                    },
                    "name": "Yijing Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:52:18.647Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b343c",
                    "name": "Yiming Wang",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b343d",
                    "name": "Yingya Zhang",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b343e",
                    "name": "Yitong Huang",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b343f",
                    "name": "Yong Li",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3440",
                    "name": "You Wu",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3441",
                    "name": "Yu Liu",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3442",
                    "name": "Yulin Pan",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3443",
                    "name": "Yun Zheng",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3444",
                    "name": "Yuntao Hong",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3445",
                    "name": "Yupeng Shi",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3446",
                    "name": "Yutong Feng",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3447",
                    "name": "Zeyinzi Jiang",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3448",
                    "name": "Zhen Han",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b3449",
                    "name": "Zhi-Fan Wu",
                    "hidden": false
                },
                {
                    "_id": "67e4b65a080a33e3955b344a",
                    "name": "Ziyu Liu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-26T08:25:43.000Z",
            "submittedOnDailyAt": "2025-03-27T00:52:37.426Z",
            "title": "Wan: Open and Advanced Large-Scale Video Generative Models",
            "submittedOnDailyBy": {
                "_id": "60f1abe7544c2adfd699860c",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
                "isPro": false,
                "fullname": "AK",
                "user": "akhaliq",
                "type": "user"
            },
            "summary": "This report presents Wan, a comprehensive and open suite of video foundation\nmodels designed to push the boundaries of video generation. Built upon the\nmainstream diffusion transformer paradigm, Wan achieves significant\nadvancements in generative capabilities through a series of innovations,\nincluding our novel VAE, scalable pre-training strategies, large-scale data\ncuration, and automated evaluation metrics. These contributions collectively\nenhance the model's performance and versatility. Specifically, Wan is\ncharacterized by four key features: Leading Performance: The 14B model of Wan,\ntrained on a vast dataset comprising billions of images and videos,\ndemonstrates the scaling laws of video generation with respect to both data and\nmodel size. It consistently outperforms the existing open-source models as well\nas state-of-the-art commercial solutions across multiple internal and external\nbenchmarks, demonstrating a clear and significant performance superiority.\nComprehensiveness: Wan offers two capable models, i.e., 1.3B and 14B\nparameters, for efficiency and effectiveness respectively. It also covers\nmultiple downstream applications, including image-to-video, instruction-guided\nvideo editing, and personal video generation, encompassing up to eight tasks.\nConsumer-Grade Efficiency: The 1.3B model demonstrates exceptional resource\nefficiency, requiring only 8.19 GB VRAM, making it compatible with a wide range\nof consumer-grade GPUs. Openness: We open-source the entire series of Wan,\nincluding source code and all models, with the goal of fostering the growth of\nthe video generation community. This openness seeks to significantly expand the\ncreative possibilities of video production in the industry and provide academia\nwith high-quality video foundation models. All the code and models are\navailable at https://github.com/Wan-Video/Wan2.1.",
            "upvotes": 23,
            "discussionId": "67e4b663080a33e3955b371a",
            "ai_keywords": [
                "diffusion transformer",
                "VAE",
                "large-scale data curation",
                "automated evaluation metrics",
                "scaling laws",
                "image-to-video",
                "instruction-guided video editing",
                "personal video generation"
            ]
        },
        "translation_title": "Wan: 개방형 고급 대규모 비디오 생성 모델",
        "purpose": "비디오 생성의 한계를 확장하기 위한 포괄적이고 개방된 비디오 기초 모델 수트 개발",
        "method": [
            "주류 diffusion transformer 패러다임을 기반으로 한 여러 혁신을 통해 생성 능력을 향상함( Built upon the mainstream diffusion transformer paradigm, Wan achieves significant advancements in generative capabilities through a series of innovations)",
            "대규모 데이터 큐레이션과 자동화된 평가 지표를 활용하여 모델 성능을 향상시킴(large-scale data curation, and automated evaluation metrics)",
            "14B 모델을 통해 수십억 개의 이미지와 비디오로 훈련되어 성능 우위를 입증함(The 14B model of Wan, trained on a vast dataset comprising billions of images and videos, demonstrates the scaling laws of video generation with respect to both data and model size)"
        ],
        "conclusion": "Wan은 비디오 생성의 성능을 크게 향상시키며, 비디오 생성 커뮤니티의 성장에 기여하기 위해 모든 모델과 소스 코드를 오픈소스화함.",
        "keywords": [
            "Video Generation",
            "Image-to-Video",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2503.20201",
            "authors": [
                {
                    "_id": "67e4b04c8c0347025bd0fe84",
                    "user": {
                        "_id": "6109bc89e84ad84682a69754",
                        "avatarUrl": "/avatars/067aac8784320d4e8e875379dc4cc209.svg",
                        "isPro": false,
                        "fullname": "Salaheddin Alzubi",
                        "user": "salzubi401",
                        "type": "user"
                    },
                    "name": "Salaheddin Alzubi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:54:03.915Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b04c8c0347025bd0fe85",
                    "user": {
                        "_id": "673f945e6cd62dbd4b02790d",
                        "avatarUrl": "/avatars/3742e4e6b88d4f8b78d5c5308f55773e.svg",
                        "isPro": false,
                        "fullname": "Creston Brooks",
                        "user": "cabxyz",
                        "type": "user"
                    },
                    "name": "Creston Brooks",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-03-27T01:56:28.853Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b04c8c0347025bd0fe86",
                    "user": {
                        "_id": "666619508a270cedd594e55e",
                        "avatarUrl": "/avatars/79bb2b09a663cae555140ec9379f05d9.svg",
                        "isPro": false,
                        "fullname": "Purva Chiniya",
                        "user": "pchiniya",
                        "type": "user"
                    },
                    "name": "Purva Chiniya",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:54:10.184Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b04c8c0347025bd0fe87",
                    "name": "Edoardo Contente",
                    "hidden": false
                },
                {
                    "_id": "67e4b04c8c0347025bd0fe88",
                    "name": "Chiara von Gerlach",
                    "hidden": false
                },
                {
                    "_id": "67e4b04c8c0347025bd0fe89",
                    "user": {
                        "_id": "62296d3f2df798b7e951e475",
                        "avatarUrl": "/avatars/661c23416c3d418e2996f9b9a024db82.svg",
                        "isPro": false,
                        "fullname": "Lucas Irwin",
                        "user": "ljirwin",
                        "type": "user"
                    },
                    "name": "Lucas Irwin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:54:26.927Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b04c8c0347025bd0fe8a",
                    "name": "Yihan Jiang",
                    "hidden": false
                },
                {
                    "_id": "67e4b04c8c0347025bd0fe8b",
                    "user": {
                        "_id": "67759bf644ceb61f96739324",
                        "avatarUrl": "/avatars/44cb431a9cbc73e060aff7d90435c42d.svg",
                        "isPro": false,
                        "fullname": "Arda Kaz",
                        "user": "speedyarda",
                        "type": "user"
                    },
                    "name": "Arda Kaz",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:54:57.570Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b04c8c0347025bd0fe8c",
                    "user": {
                        "_id": "64b98bcf842aa47891bc0f63",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/L-smrOCQ3MXtvnISJqmxJ.png",
                        "isPro": false,
                        "fullname": "Windsor Nguyen",
                        "user": "windsornguyen",
                        "type": "user"
                    },
                    "name": "Windsor Nguyen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:54:50.840Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b04c8c0347025bd0fe8d",
                    "user": {
                        "_id": "6756dffd88428044e2ddbdd9",
                        "avatarUrl": "/avatars/41dbb83c68b56546cdf8e34379faf6b3.svg",
                        "isPro": false,
                        "fullname": "Sewoong Oh",
                        "user": "sewoong79",
                        "type": "user"
                    },
                    "name": "Sewoong Oh",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:55:20.604Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b04c8c0347025bd0fe8e",
                    "user": {
                        "_id": "65f86cc77b704590d4a5439f",
                        "avatarUrl": "/avatars/1a828cf755839f058241fb19ca83341f.svg",
                        "isPro": false,
                        "fullname": "Himanshu Tyagi",
                        "user": "HimanshuTyagi",
                        "type": "user"
                    },
                    "name": "Himanshu Tyagi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-27T09:55:27.139Z",
                    "hidden": false
                },
                {
                    "_id": "67e4b04c8c0347025bd0fe8f",
                    "name": "Pramod Viswanath",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-26T03:51:32.000Z",
            "submittedOnDailyAt": "2025-03-27T00:26:59.804Z",
            "title": "Open Deep Search: Democratizing Search with Open-source Reasoning Agents",
            "submittedOnDailyBy": {
                "_id": "60f1abe7544c2adfd699860c",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
                "isPro": false,
                "fullname": "AK",
                "user": "akhaliq",
                "type": "user"
            },
            "summary": "We introduce Open Deep Search (ODS) to close the increasing gap between the\nproprietary search AI solutions, such as Perplexity's Sonar Reasoning Pro and\nOpenAI's GPT-4o Search Preview, and their open-source counterparts. The main\ninnovation introduced in ODS is to augment the reasoning capabilities of the\nlatest open-source LLMs with reasoning agents that can judiciously use web\nsearch tools to answer queries. Concretely, ODS consists of two components that\nwork with a base LLM chosen by the user: Open Search Tool and Open Reasoning\nAgent. Open Reasoning Agent interprets the given task and completes it by\norchestrating a sequence of actions that includes calling tools, one of which\nis the Open Search Tool. Open Search Tool is a novel web search tool that\noutperforms proprietary counterparts. Together with powerful open-source\nreasoning LLMs, such as DeepSeek-R1, ODS nearly matches and sometimes surpasses\nthe existing state-of-the-art baselines on two benchmarks: SimpleQA and FRAMES.\nFor example, on the FRAMES evaluation benchmark, ODS improves the best existing\nbaseline of the recently released GPT-4o Search Preview by 9.7% in accuracy.\nODS is a general framework for seamlessly augmenting any LLMs -- for example,\nDeepSeek-R1 that achieves 82.4% on SimpleQA and 30.1% on FRAMES -- with search\nand reasoning capabilities to achieve state-of-the-art performance: 88.3% on\nSimpleQA and 75.3% on FRAMES.",
            "upvotes": 19,
            "discussionId": "67e4b04c8c0347025bd0fed2",
            "ai_keywords": [
                "LLMs",
                "reasoning agents",
                "web search tools",
                "Open Search Tool",
                "Open Reasoning Agent",
                "DeepSeek-R1",
                "SimpleQA",
                "FRAMES",
                "GPT-4o Search Preview"
            ]
        },
        "translation_title": "Open Deep Search: 오픈소스 추론 에이전트로 검색 민주화하기",
        "purpose": "상용 검색 AI 솔루션과 오픈소스 솔루션 간의 격차를 해소하기 위한 연구",
        "method": [
            "Open Deep Search(ODS)를 통해 최신 오픈소스 LLM의 추론 능력을 증진하기 위해 웹 검색 도구를 사용할 수 있는 추론 에이전트를 도입함.(The main innovation introduced in ODS is to augment the reasoning capabilities of the latest open-source LLMs with reasoning agents that can judiciously use web search tools to answer queries.)",
            "사용자가 선택한 기본 LLM과 함께 작동하는 두 가지 구성 요소인 Open Search Tool과 Open Reasoning Agent로 구성됨.(Concretely, ODS consists of two components that work with a base LLM chosen by the user: Open Search Tool and Open Reasoning Agent.)",
            "Open Reasoning Agent는 주어진 작업을 해석하고 일련의 작업을 조율하여 완료함.(Open Reasoning Agent interprets the given task and completes it by orchestrating a sequence of actions that includes calling tools, one of which is the Open Search Tool.)"
        ],
        "conclusion": "ODS는 기존 상용 솔루션을 능가하는 성능을 보여주며, 오픈소스 LLM에 검색 및 추론 능력을 통합하여 최첨단 성능에 도달함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    }
]