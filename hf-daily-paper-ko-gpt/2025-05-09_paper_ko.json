[
    {
        "paper": {
            "id": "2505.04921",
            "authors": [
                {
                    "_id": "681dbb9988ca86d430f1d0d2",
                    "user": {
                        "_id": "62fdb01bc1588e1d4c6c1a7c",
                        "avatarUrl": "/avatars/bd03085995b1c34e0ac8a845cf2c4e83.svg",
                        "isPro": false,
                        "fullname": "Yunxin Li",
                        "user": "YunxinLi",
                        "type": "user"
                    },
                    "name": "Yunxin Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T09:05:42.761Z",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0d3",
                    "user": {
                        "_id": "64380ae1819f3ab20d17431b",
                        "avatarUrl": "/avatars/a36b073c1c783102ddb455204fd816bd.svg",
                        "isPro": false,
                        "fullname": "ZhenyuLiu",
                        "user": "foggyforest",
                        "type": "user"
                    },
                    "name": "Zhenyu Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-09T10:08:42.493Z",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0d4",
                    "user": {
                        "_id": "67ecc6a08647cfa1775a9fda",
                        "avatarUrl": "/avatars/bb15abd7a3d2c51380b0b1f819ef76e2.svg",
                        "isPro": false,
                        "fullname": "Zitao Li",
                        "user": "TerenceL-TL",
                        "type": "user"
                    },
                    "name": "Zitao Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-09T08:33:26.702Z",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0d5",
                    "user": {
                        "_id": "676fcc8b98612a870ddb848a",
                        "avatarUrl": "/avatars/7da1b77da1d18758b08d49436c5971c1.svg",
                        "isPro": false,
                        "fullname": "xuanyu",
                        "user": "xyidealist",
                        "type": "user"
                    },
                    "name": "Xuanyu Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-09T10:36:03.450Z",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0d6",
                    "user": {
                        "_id": "639c379cdb7c5f35004066cb",
                        "avatarUrl": "/avatars/3e435506ee85aa7d2d0ec2174a07462f.svg",
                        "isPro": false,
                        "fullname": "Zhenran Xu",
                        "user": "imryanxu",
                        "type": "user"
                    },
                    "name": "Zhenran Xu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-09T10:08:40.339Z",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0d7",
                    "user": {
                        "_id": "64d9da538767727dff1e8f19",
                        "avatarUrl": "/avatars/aaad38795007c6cbcb94c7eed1706e51.svg",
                        "isPro": false,
                        "fullname": "Yu",
                        "user": "Ghaser",
                        "type": "user"
                    },
                    "name": "Xinyu Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-09T13:54:43.127Z",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0d8",
                    "name": "Haoyuan Shi",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0d9",
                    "name": "Shenyuan Jiang",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0da",
                    "name": "Xintong Wang",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0db",
                    "name": "Jifang Wang",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0dc",
                    "name": "Shouzheng Huang",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0dd",
                    "name": "Xinping Zhao",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0de",
                    "name": "Borui Jiang",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0df",
                    "name": "Lanqing Hong",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0e0",
                    "name": "Longyue Wang",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0e1",
                    "name": "Zhuotao Tian",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0e2",
                    "name": "Baoxing Huai",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0e3",
                    "name": "Wenhan Luo",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0e4",
                    "name": "Weihua Luo",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0e5",
                    "name": "Zheng Zhang",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0e6",
                    "name": "Baotian Hu",
                    "hidden": false
                },
                {
                    "_id": "681dbb9988ca86d430f1d0e7",
                    "name": "Min Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-05-08T03:35:23.000Z",
            "submittedOnDailyAt": "2025-05-09T06:54:36.013Z",
            "title": "Perception, Reason, Think, and Plan: A Survey on Large Multimodal\n  Reasoning Models",
            "submittedOnDailyBy": {
                "_id": "64380ae1819f3ab20d17431b",
                "avatarUrl": "/avatars/a36b073c1c783102ddb455204fd816bd.svg",
                "isPro": false,
                "fullname": "ZhenyuLiu",
                "user": "foggyforest",
                "type": "user"
            },
            "summary": "Reasoning lies at the heart of intelligence, shaping the ability to make\ndecisions, draw conclusions, and generalize across domains. In artificial\nintelligence, as systems increasingly operate in open, uncertain, and\nmultimodal environments, reasoning becomes essential for enabling robust and\nadaptive behavior. Large Multimodal Reasoning Models (LMRMs) have emerged as a\npromising paradigm, integrating modalities such as text, images, audio, and\nvideo to support complex reasoning capabilities and aiming to achieve\ncomprehensive perception, precise understanding, and deep reasoning. As\nresearch advances, multimodal reasoning has rapidly evolved from modular,\nperception-driven pipelines to unified, language-centric frameworks that offer\nmore coherent cross-modal understanding. While instruction tuning and\nreinforcement learning have improved model reasoning, significant challenges\nremain in omni-modal generalization, reasoning depth, and agentic behavior. To\naddress these issues, we present a comprehensive and structured survey of\nmultimodal reasoning research, organized around a four-stage developmental\nroadmap that reflects the field's shifting design philosophies and emerging\ncapabilities. First, we review early efforts based on task-specific modules,\nwhere reasoning was implicitly embedded across stages of representation,\nalignment, and fusion. Next, we examine recent approaches that unify reasoning\ninto multimodal LLMs, with advances such as Multimodal Chain-of-Thought (MCoT)\nand multimodal reinforcement learning enabling richer and more structured\nreasoning chains. Finally, drawing on empirical insights from challenging\nbenchmarks and experimental cases of OpenAI O3 and O4-mini, we discuss the\nconceptual direction of native large multimodal reasoning models (N-LMRMs),\nwhich aim to support scalable, agentic, and adaptive reasoning and planning in\ncomplex, real-world environments.",
            "upvotes": 70,
            "discussionId": "681dbb9b88ca86d430f1d183",
            "projectPage": "https://github.com/HITsz-TMG/Awesome-Large-Multimodal-Reasoning-Models",
            "githubRepo": "https://github.com/HITsz-TMG/Awesome-Large-Multimodal-Reasoning-Models",
            "ai_keywords": [
                "Large Multimodal Reasoning Models (LMRMs)",
                "multimodal reasoning",
                "Cross-modal understanding",
                "task-specific modules",
                "representation",
                "alignment",
                "fusion",
                "Multimodal Chain-of-Thought (MCoT)",
                "multimodal reinforcement learning",
                "native large multimodal reasoning models (N-LMRMs)",
                "scalable",
                "agentic",
                "adaptive reasoning",
                "planning"
            ]
        },
        "translation_title": "지각, 추론, 사고 및 계획: 대규모 다중 모달 추론 모델에 대한 조사",
        "purpose": "대규모 다중 모달 추론 모델을 통해 복잡한 추론 능력을 지원하고 다양한 환경에서 적응 가능한 행동을 가능하게 하려는 목표",
        "method": [
            "다중 모달 데이터(텍스트, 이미지, 오디오, 비디오)를 통합하여 종합적인 지각과 정밀한 이해를 달성함(Integrating modalities such as text, images, audio, and video to support complex reasoning capabilities and aiming to achieve comprehensive perception, precise understanding, and deep reasoning.)",
            "초기 단계에서 작업 특화 모듈에 기반한 추론을 검토하고, 후속 단계에서 다중 모달 LLM으로의 통합을 탐구함(We review early efforts based on task-specific modules and examine recent approaches that unify reasoning into multimodal LLMs.)",
            "MCoT 및 다중 모달 강화 학습과 같은 최신 접근 방식을 통해 더 풍부하고 구조화된 추론 체인을 가능하게 함(Advances such as Multimodal Chain-of-Thought (MCoT) and multimodal reinforcement learning enabling richer and more structured reasoning chains.)"
        ],
        "conclusion": "대규모 다중 모달 추론 모델은 복잡한 실제 환경에서 확장 가능하고 적응 가능한 추론 및 계획을 지원할 수 있는 방향으로 발전하고 있음.",
        "keywords": [
            "Large Language Models",
            "Multimodal Learning",
            "Natural Language Processing"
        ]
    },
    {
        "paper": {
            "id": "2505.04620",
            "authors": [
                {
                    "_id": "681c6c1817fc8222eff39a1a",
                    "user": {
                        "_id": "647773a1168cb428e00e9a8f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647773a1168cb428e00e9a8f/NiRR3ScY6Plzjibfwy1hC.jpeg",
                        "isPro": false,
                        "fullname": "Hao Fei",
                        "user": "scofield7419",
                        "type": "user"
                    },
                    "name": "Hao Fei",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-08T09:58:07.591Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a1b",
                    "name": "Yuan Zhou",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a1c",
                    "user": {
                        "_id": "67bc247b593452cc18965cb1",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/EA3kTYaaff0Hr7-dGiOOj.png",
                        "isPro": false,
                        "fullname": "JUNCHENG LI",
                        "user": "JunchengLi",
                        "type": "user"
                    },
                    "name": "Juncheng Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:36:52.461Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a1d",
                    "user": {
                        "_id": "63958b4414513eaf9029ebf1",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/U1g5H071pWRswGAG9UTpo.png",
                        "isPro": false,
                        "fullname": "Xiangtai Li",
                        "user": "LXT",
                        "type": "user"
                    },
                    "name": "Xiangtai Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:36:59.117Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a1e",
                    "name": "Qingshan Xu",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a1f",
                    "name": "Bobo Li",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a20",
                    "user": {
                        "_id": "64c139d867eff857ea51caa8",
                        "avatarUrl": "/avatars/4b7b3f41c2e2cfa21dd43bbac6e081ae.svg",
                        "isPro": false,
                        "fullname": "Shengqiong Wu",
                        "user": "ChocoWu",
                        "type": "user"
                    },
                    "name": "Shengqiong Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-09T07:22:39.333Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a21",
                    "user": {
                        "_id": "64ff369d9abcc85a5519b33e",
                        "avatarUrl": "/avatars/4b99cdaf5f970d930b196eddf1e5e499.svg",
                        "isPro": false,
                        "fullname": "Yaoting Wang",
                        "user": "Gh0stAR",
                        "type": "user"
                    },
                    "name": "Yaoting Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:37:27.790Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a22",
                    "user": {
                        "_id": "67e906836c7216f5bf91f70c",
                        "avatarUrl": "/avatars/9c7f34d5b1d41ad7231d2733a399abb3.svg",
                        "isPro": false,
                        "fullname": "junbao.zhou",
                        "user": "junbaozhou",
                        "type": "user"
                    },
                    "name": "Junbao Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:37:34.046Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a23",
                    "user": {
                        "_id": "65a28e129acab19980226731",
                        "avatarUrl": "/avatars/abc3828f807efc4e03837b0eae063f98.svg",
                        "isPro": false,
                        "fullname": "Jiahao Meng",
                        "user": "marinero4972",
                        "type": "user"
                    },
                    "name": "Jiahao Meng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:37:40.200Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a24",
                    "user": {
                        "_id": "656724074f6ec72017754d33",
                        "avatarUrl": "/avatars/e61de248f6f53719b2375077340dd033.svg",
                        "isPro": false,
                        "fullname": "QingyuShi",
                        "user": "QingyuShi",
                        "type": "user"
                    },
                    "name": "Qingyu Shi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-09T07:22:34.088Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a25",
                    "name": "Zhiyuan Zhou",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a26",
                    "name": "Liangtao Shi",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a27",
                    "user": {
                        "_id": "648ef24dc92367eecac0f4bd",
                        "avatarUrl": "/avatars/38f1afd6b52efeee3aa41cc80225d788.svg",
                        "isPro": false,
                        "fullname": "Minghe Gao",
                        "user": "gmh5811",
                        "type": "user"
                    },
                    "name": "Minghe Gao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:38:16.554Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a28",
                    "user": {
                        "_id": "6241b95cfee9374a2598ecfe",
                        "avatarUrl": "/avatars/196669df1689a5872fc18b271e80fdc1.svg",
                        "isPro": false,
                        "fullname": "Zhang Daoan",
                        "user": "hazard",
                        "type": "user"
                    },
                    "name": "Daoan Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:38:28.567Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a29",
                    "name": "Zhiqi Ge",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a2a",
                    "user": {
                        "_id": "67ebcf69f5870fc1da715eda",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/TbfMOG2cKwPEh2xQdIqbr.png",
                        "isPro": false,
                        "fullname": "Weiming Wu",
                        "user": "wwm1415",
                        "type": "user"
                    },
                    "name": "Weiming Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-09T10:36:05.177Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a2b",
                    "name": "Siliang Tang",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a2c",
                    "name": "Kaihang Pan",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a2d",
                    "user": {
                        "_id": "662917afda1cae6cbb50cd00",
                        "avatarUrl": "/avatars/aa66de6cef6665c5d67071d82bac35c4.svg",
                        "isPro": false,
                        "fullname": "Yaobo Ye",
                        "user": "superyyb",
                        "type": "user"
                    },
                    "name": "Yaobo Ye",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:55:06.463Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a2e",
                    "user": {
                        "_id": "6391e41f2e73987364e6bcb2",
                        "avatarUrl": "/avatars/d09a9ee329bb8c3a9e2929d67d24e97d.svg",
                        "isPro": false,
                        "fullname": "Haobo Yuan",
                        "user": "HarborYuan",
                        "type": "user"
                    },
                    "name": "Haobo Yuan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:39:11.094Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a2f",
                    "name": "Tao Zhang",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a30",
                    "user": {
                        "_id": "6816d98fc075e49c1b15928e",
                        "avatarUrl": "/avatars/6b24d047fc25075bedb3e74f78981bc0.svg",
                        "isPro": false,
                        "fullname": "Tianjie Ju",
                        "user": "jometeorieNUS",
                        "type": "user"
                    },
                    "name": "Tianjie Ju",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:53:06.930Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a31",
                    "name": "Zixiang Meng",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a32",
                    "name": "Shilin Xu",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a33",
                    "name": "Liyu Jia",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a34",
                    "name": "Wentao Hu",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a35",
                    "user": {
                        "_id": "64ad1c0bad6218d51a07b54e",
                        "avatarUrl": "/avatars/0f84d9a51c6ca9bcef44de2d7c707d9b.svg",
                        "isPro": false,
                        "fullname": "LUO MENG",
                        "user": "Eureka-Leo",
                        "type": "user"
                    },
                    "name": "Meng Luo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-09T07:22:37.235Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a36",
                    "name": "Jiebo Luo",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a37",
                    "name": "Tat-Seng Chua",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a38",
                    "user": {
                        "_id": "67eaa070b9fa8908e151fd7d",
                        "avatarUrl": "/avatars/1fe2fd678d2e71099a83a9bcb9ab517e.svg",
                        "isPro": false,
                        "fullname": "shuicheng yan",
                        "user": "shuicheng",
                        "type": "user"
                    },
                    "name": "Shuicheng Yan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:52:30.205Z",
                    "hidden": false
                },
                {
                    "_id": "681c6c1817fc8222eff39a39",
                    "name": "Hanwang Zhang",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/647773a1168cb428e00e9a8f/TqzNcdmo0rwc-0JkEc0-i.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/647773a1168cb428e00e9a8f/HBVHtWBiagedRLXD-lWZc.png",
                "https://cdn-uploads.huggingface.co/production/uploads/647773a1168cb428e00e9a8f/X02B6xk6CZDywtG8tGliK.png",
                "https://cdn-uploads.huggingface.co/production/uploads/647773a1168cb428e00e9a8f/Xnc89DOmtr5j2hST5Um17.png",
                "https://cdn-uploads.huggingface.co/production/uploads/647773a1168cb428e00e9a8f/Awl6jj9MX38cMRkgXpxHp.png",
                "https://cdn-uploads.huggingface.co/production/uploads/647773a1168cb428e00e9a8f/HT_9Y1ponvvqUREjMTMBB.png",
                "https://cdn-uploads.huggingface.co/production/uploads/647773a1168cb428e00e9a8f/sG3FBiQCx3EONF25cEbED.png"
            ],
            "publishedAt": "2025-05-07T17:59:32.000Z",
            "submittedOnDailyAt": "2025-05-09T01:19:17.510Z",
            "title": "On Path to Multimodal Generalist: General-Level and General-Bench",
            "submittedOnDailyBy": {
                "_id": "647773a1168cb428e00e9a8f",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647773a1168cb428e00e9a8f/NiRR3ScY6Plzjibfwy1hC.jpeg",
                "isPro": false,
                "fullname": "Hao Fei",
                "user": "scofield7419",
                "type": "user"
            },
            "summary": "The Multimodal Large Language Model (MLLM) is currently experiencing rapid\ngrowth, driven by the advanced capabilities of LLMs. Unlike earlier\nspecialists, existing MLLMs are evolving towards a Multimodal Generalist\nparadigm. Initially limited to understanding multiple modalities, these models\nhave advanced to not only comprehend but also generate across modalities. Their\ncapabilities have expanded from coarse-grained to fine-grained multimodal\nunderstanding and from supporting limited modalities to arbitrary ones. While\nmany benchmarks exist to assess MLLMs, a critical question arises: Can we\nsimply assume that higher performance across tasks indicates a stronger MLLM\ncapability, bringing us closer to human-level AI? We argue that the answer is\nnot as straightforward as it seems. This project introduces General-Level, an\nevaluation framework that defines 5-scale levels of MLLM performance and\ngenerality, offering a methodology to compare MLLMs and gauge the progress of\nexisting systems towards more robust multimodal generalists and, ultimately,\ntowards AGI. At the core of the framework is the concept of Synergy, which\nmeasures whether models maintain consistent capabilities across comprehension\nand generation, and across multiple modalities. To support this evaluation, we\npresent General-Bench, which encompasses a broader spectrum of skills,\nmodalities, formats, and capabilities, including over 700 tasks and 325,800\ninstances. The evaluation results that involve over 100 existing\nstate-of-the-art MLLMs uncover the capability rankings of generalists,\nhighlighting the challenges in reaching genuine AI. We expect this project to\npave the way for future research on next-generation multimodal foundation\nmodels, providing a robust infrastructure to accelerate the realization of AGI.\nProject page: https://generalist.top/",
            "upvotes": 53,
            "discussionId": "681c6c1d17fc8222eff39b45",
            "projectPage": "https://generalist.top/",
            "githubRepo": "https://github.com/path2generalist/General-Level",
            "ai_keywords": [
                "Multimodal Large Language Model (MLLM)",
                "Multimodal Generalist",
                "multimodal understanding",
                "comprehension",
                "generation",
                "General-Level",
                "Synergy",
                "General-Bench",
                "AGI (Artificial General Intelligence)"
            ]
        },
        "translation_title": "멀티모달 범용 모델로의 길: General-Level과 General-Bench",
        "purpose": "멀티모달 대형 언어 모델의 성능과 일반성을 평가하기 위한 프레임워크 개발",
        "method": [
            "General-Level이라는 5단계 성과 기준을 정의하여 MLLM의 성능을 비교함(We argue that the answer is not as straightforward as it seems. This project introduces General-Level, an evaluation framework that defines 5-scale levels of MLLM performance and generality.)",
            "보다 다양한 기술, 양식, 능력을 포함하는 General-Bench를 제시함(To support this evaluation, we present General-Bench, which encompasses a broader spectrum of skills, modalities, formats, and capabilities.)",
            "700개 이상의 작업과 325,800개의 인스턴스를 포함한 평가 결과를 통해 기존 MLLM의 성능을 분석함(The evaluation results that involve over 100 existing state-of-the-art MLLMs uncover the capability rankings of generalists.)"
        ],
        "conclusion": "이 프로젝트는 다음 세대 멀티모달 기초 모델 연구의 길을 열어주고, AGI 실현을 가속화하기 위한 견고한 인프라를 제공할 것으로 기대됨.",
        "keywords": [
            "Multimodal Learning",
            "Large Language Models",
            "Natural Language Processing"
        ]
    },
    {
        "paper": {
            "id": "2505.05470",
            "authors": [
                {
                    "_id": "681d9829edf34a77aab565eb",
                    "user": {
                        "_id": "639be86b59473c6ae02ef9c4",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/639be86b59473c6ae02ef9c4/gw34RBCVZCOkcAA79xUr3.png",
                        "isPro": false,
                        "fullname": "Jie Liu",
                        "user": "jieliu",
                        "type": "user"
                    },
                    "name": "Jie Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-09T13:54:46.048Z",
                    "hidden": false
                },
                {
                    "_id": "681d9829edf34a77aab565ec",
                    "user": {
                        "_id": "6553316bf151de82f6a23e1d",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6553316bf151de82f6a23e1d/GTBkSj4Fa3OoyM6Muz_Sc.jpeg",
                        "isPro": false,
                        "fullname": "Gongye Liu",
                        "user": "liuhuohuo",
                        "type": "user"
                    },
                    "name": "Gongye Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:41:47.403Z",
                    "hidden": false
                },
                {
                    "_id": "681d9829edf34a77aab565ed",
                    "name": "Jiajun Liang",
                    "hidden": false
                },
                {
                    "_id": "681d9829edf34a77aab565ee",
                    "user": {
                        "_id": "64d71083a787c9bc7b9f1238",
                        "avatarUrl": "/avatars/d0b0546dec7fc5792921154bec41385a.svg",
                        "isPro": false,
                        "fullname": "Yangguang Li",
                        "user": "Lp256",
                        "type": "user"
                    },
                    "name": "Yangguang Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:43:44.697Z",
                    "hidden": false
                },
                {
                    "_id": "681d9829edf34a77aab565ef",
                    "user": {
                        "_id": "65377c30e48353201e6fdda0",
                        "avatarUrl": "/avatars/a8f803b6f2e598eaee9c52c0d2ddfc16.svg",
                        "isPro": false,
                        "fullname": "Jiaheng Liu",
                        "user": "CheeryLJH",
                        "type": "user"
                    },
                    "name": "Jiaheng Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:45:07.297Z",
                    "hidden": false
                },
                {
                    "_id": "681d9829edf34a77aab565f0",
                    "user": {
                        "_id": "60e272ca6c78a8c122b12127",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60e272ca6c78a8c122b12127/xldEGBzGrU-bX6IwAw0Ie.jpeg",
                        "isPro": false,
                        "fullname": "Xintao Wang",
                        "user": "Xintao",
                        "type": "user"
                    },
                    "name": "Xintao Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:42:27.977Z",
                    "hidden": false
                },
                {
                    "_id": "681d9829edf34a77aab565f1",
                    "name": "Pengfei Wan",
                    "hidden": false
                },
                {
                    "_id": "681d9829edf34a77aab565f2",
                    "user": {
                        "_id": "644c8324f02250233d0d67d9",
                        "avatarUrl": "/avatars/feb39d281457c1750f3eada3c060a23e.svg",
                        "isPro": false,
                        "fullname": "Di Zhang",
                        "user": "dizhang",
                        "type": "user"
                    },
                    "name": "Di Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:43:01.366Z",
                    "hidden": false
                },
                {
                    "_id": "681d9829edf34a77aab565f3",
                    "name": "Wanli Ouyang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-05-08T17:58:45.000Z",
            "submittedOnDailyAt": "2025-05-09T05:45:53.355Z",
            "title": "Flow-GRPO: Training Flow Matching Models via Online RL",
            "submittedOnDailyBy": {
                "_id": "64d71083a787c9bc7b9f1238",
                "avatarUrl": "/avatars/d0b0546dec7fc5792921154bec41385a.svg",
                "isPro": false,
                "fullname": "Yangguang Li",
                "user": "Lp256",
                "type": "user"
            },
            "summary": "We propose Flow-GRPO, the first method integrating online reinforcement\nlearning (RL) into flow matching models. Our approach uses two key strategies:\n(1) an ODE-to-SDE conversion that transforms a deterministic Ordinary\nDifferential Equation (ODE) into an equivalent Stochastic Differential Equation\n(SDE) that matches the original model's marginal distribution at all timesteps,\nenabling statistical sampling for RL exploration; and (2) a Denoising Reduction\nstrategy that reduces training denoising steps while retaining the original\ninference timestep number, significantly improving sampling efficiency without\nperformance degradation. Empirically, Flow-GRPO is effective across multiple\ntext-to-image tasks. For complex compositions, RL-tuned SD3.5 generates nearly\nperfect object counts, spatial relations, and fine-grained attributes, boosting\nGenEval accuracy from 63% to 95%. In visual text rendering, its accuracy\nimproves from 59% to 92%, significantly enhancing text generation.\nFlow-GRPO also achieves substantial gains in human preference alignment.\nNotably, little to no reward hacking occurred, meaning rewards did not increase\nat the cost of image quality or diversity, and both remained stable in our\nexperiments.",
            "upvotes": 32,
            "discussionId": "681d982aedf34a77aab56635",
            "githubRepo": "https://github.com/yifan123/flow_grpo",
            "ai_keywords": [
                "Flow-GRPO",
                "reinforcement learning (RL)",
                "flow matching models",
                "ODE-to-SDE conversion",
                "Ordinary Differential Equation (ODE)",
                "Stochastic Differential Equation (SDE)",
                "Denoising Reduction strategy",
                "GenEval accuracy",
                "text-to-image tasks",
                "SD3.5",
                "visual text rendering",
                "human preference alignment",
                "reward hacking"
            ]
        },
        "translation_title": "Flow-GRPO: 온라인 강화 학습을 통한 플로우 매칭 모델 학습",
        "purpose": "온라인 강화 학습을 통합하여 플로우 매칭 모델의 성능을 향상시키기 위한 방법 제안",
        "method": [
            "결정론적 미분 방정식(ODE)을 확률론적 미분 방정식(SDE)으로 변환하는 ODE-to-SDE 변환 전략 활용하여 모든 시점에서 분포를 맞춤(Our approach uses two key strategies: (1) an ODE-to-SDE conversion that transforms a deterministic Ordinary Differential Equation (ODE) into an equivalent Stochastic Differential Equation (SDE) that matches the original model's marginal distribution at all timesteps.)",
            "Denoising Reduction 전략을 적용하여 훈련 중 노이즈 제거 단계 감소 및 샘플링 효율성 향상(Denoising Reduction strategy that reduces training denoising steps while retaining the original inference timestep number, significantly improving sampling efficiency without performance degradation.)",
            "Flow-GRPO를 사용하여 여러 텍스트-이미지 작업에서 효과적인 결과 달성(Empirically, Flow-GRPO is effective across multiple text-to-image tasks.)"
        ],
        "conclusion": "Flow-GRPO는 인간 선호 정렬에서 상당한 향상과 함께 GenEval 정확도를 높이며, 이미지 품질이나 다양성을 해치지 않고 훈련하는 것이 가능함.",
        "keywords": [
            "Reinforcement Learning",
            "Image Generation",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2505.02847",
            "authors": [
                {
                    "_id": "681d7031e9969eecfcb4eb81",
                    "name": "Bang Zhang",
                    "hidden": false
                },
                {
                    "_id": "681d7031e9969eecfcb4eb82",
                    "user": {
                        "_id": "648294b2eb4befee378951c1",
                        "avatarUrl": "/avatars/da5d8bf9d8662cc2ffa2c0de49bd66a3.svg",
                        "isPro": false,
                        "fullname": "Ruotian Ma",
                        "user": "vvibt",
                        "type": "user"
                    },
                    "name": "Ruotian Ma",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-09T07:21:30.886Z",
                    "hidden": false
                },
                {
                    "_id": "681d7031e9969eecfcb4eb83",
                    "name": "Qingxuan Jiang",
                    "hidden": false
                },
                {
                    "_id": "681d7031e9969eecfcb4eb84",
                    "name": "Peisong Wang",
                    "hidden": false
                },
                {
                    "_id": "681d7031e9969eecfcb4eb85",
                    "name": "Jiaqi Chen",
                    "hidden": false
                },
                {
                    "_id": "681d7031e9969eecfcb4eb86",
                    "name": "Zheng Xie",
                    "hidden": false
                },
                {
                    "_id": "681d7031e9969eecfcb4eb87",
                    "name": "Xingyu Chen",
                    "hidden": false
                },
                {
                    "_id": "681d7031e9969eecfcb4eb88",
                    "name": "Yue Wang",
                    "hidden": false
                },
                {
                    "_id": "681d7031e9969eecfcb4eb89",
                    "name": "Fanghua Ye",
                    "hidden": false
                },
                {
                    "_id": "681d7031e9969eecfcb4eb8a",
                    "name": "Jian Li",
                    "hidden": false
                },
                {
                    "_id": "681d7031e9969eecfcb4eb8b",
                    "name": "Yifan Yang",
                    "hidden": false
                },
                {
                    "_id": "681d7031e9969eecfcb4eb8c",
                    "user": {
                        "_id": "67485743561b1e6f9579389f",
                        "avatarUrl": "/avatars/8a4cc63bd7be388010bc329bb74582a1.svg",
                        "isPro": false,
                        "fullname": "Zhaopeng Tu",
                        "user": "zptu",
                        "type": "user"
                    },
                    "name": "Zhaopeng Tu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-09T07:21:28.468Z",
                    "hidden": false
                },
                {
                    "_id": "681d7031e9969eecfcb4eb8d",
                    "name": "Xiaolong Li",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-05-01T19:06:10.000Z",
            "submittedOnDailyAt": "2025-05-09T01:37:10.548Z",
            "title": "Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in\n  Large Language Models",
            "submittedOnDailyBy": {
                "_id": "648294b2eb4befee378951c1",
                "avatarUrl": "/avatars/da5d8bf9d8662cc2ffa2c0de49bd66a3.svg",
                "isPro": false,
                "fullname": "Ruotian Ma",
                "user": "vvibt",
                "type": "user"
            },
            "summary": "Assessing how well a large language model (LLM) understands human, rather\nthan merely text, remains an open challenge. To bridge the gap, we introduce\nSentient Agent as a Judge (SAGE), an automated evaluation framework that\nmeasures an LLM's higher-order social cognition. SAGE instantiates a Sentient\nAgent that simulates human-like emotional changes and inner thoughts during\ninteraction, providing a more realistic evaluation of the tested model in\nmulti-turn conversations. At every turn, the agent reasons about (i) how its\nemotion changes, (ii) how it feels, and (iii) how it should reply, yielding a\nnumerical emotion trajectory and interpretable inner thoughts. Experiments on\n100 supportive-dialogue scenarios show that the final Sentient emotion score\ncorrelates strongly with Barrett-Lennard Relationship Inventory (BLRI) ratings\nand utterance-level empathy metrics, validating psychological fidelity. We also\nbuild a public Sentient Leaderboard covering 18 commercial and open-source\nmodels that uncovers substantial gaps (up to 4x) between frontier systems\n(GPT-4o-Latest, Gemini2.5-Pro) and earlier baselines, gaps not reflected in\nconventional leaderboards (e.g., Arena). SAGE thus provides a principled,\nscalable and interpretable tool for tracking progress toward genuinely\nempathetic and socially adept language agents.",
            "upvotes": 16,
            "discussionId": "681d7033e9969eecfcb4ec2d",
            "githubRepo": "https://github.com/Tencent/digitalhuman/tree/main/SAGE",
            "ai_keywords": [
                "Sentient Agent as a Judge (SAGE)",
                "higher-order social cognition",
                "emotional changes",
                "inner thoughts",
                "multi-turn conversations",
                "numerical emotion trajectory",
                "Barrett-Lennard Relationship Inventory (BLRI)",
                "utterance-level empathy metrics",
                "psychological fidelity",
                "Sentient Leaderboard",
                "empathetic",
                "socially adept language agents"
            ]
        },
        "translation_title": "판단자로서의 감정적 에이전트: 대형 언어 모델의 고차원 사회 인지 평가",
        "purpose": "대형 언어 모델이 인간의 감정 이해 능력을 평가하고 이를 개선하기 위한 자동화된 평가 프레임워크 구축",
        "method": [
            "Sentient Agent as a Judge (SAGE)라는 자동 평가 프레임워크를 도입하여 고차원 사회 인지를 측정함(To bridge the gap, we introduce Sentient Agent as a Judge (SAGE), an automated evaluation framework that measures an LLM's higher-order social cognition.)",
            "SAGE는 감정 변화와 내적 사고를 시뮬레이션하는 에이전트를 구현하여 다회 대화에서 더 현실적인 평가를 제공함(SAGE instantiates a Sentient Agent that simulates human-like emotional changes and inner thoughts during interaction, providing a more realistic evaluation of the tested model in multi-turn conversations.)",
            "100개의 지원 대화 시나리오 실험을 통해 Sentient 감정 점수가 심리적 신뢰성을 검증함(Experiments on 100 supportive-dialogue scenarios show that the final Sentient emotion score correlates strongly with Barrett-Lennard Relationship Inventory (BLRI) ratings and utterance-level empathy metrics.)"
        ],
        "conclusion": "SAGE는 공감적이고 사회적으로 능숙한 언어 에이전트를 추적하기 위한 원칙적이고 확장 가능하며 해석 가능한 도구를 제공함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2505.05315",
            "authors": [
                {
                    "_id": "681d7ccb572e742b3f42d1f3",
                    "user": {
                        "_id": "6602869253a0518b2a98cafd",
                        "avatarUrl": "/avatars/c14b5953a716f42c83ad28147f8308ae.svg",
                        "isPro": false,
                        "fullname": "Yuhui Xu",
                        "user": "yuhuixu",
                        "type": "user"
                    },
                    "name": "Yuhui Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:56:04.644Z",
                    "hidden": false
                },
                {
                    "_id": "681d7ccb572e742b3f42d1f4",
                    "user": {
                        "_id": "63a3ff69f91ad3ea5703841d",
                        "avatarUrl": "/avatars/69227c4bce01d33747c1377b6f9672db.svg",
                        "isPro": false,
                        "fullname": "Hanze Dong",
                        "user": "hendrydong",
                        "type": "user"
                    },
                    "name": "Hanze Dong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:56:10.829Z",
                    "hidden": false
                },
                {
                    "_id": "681d7ccb572e742b3f42d1f5",
                    "name": "Lei Wang",
                    "hidden": false
                },
                {
                    "_id": "681d7ccb572e742b3f42d1f6",
                    "user": {
                        "_id": "65f84fd980481173afd91233",
                        "avatarUrl": "/avatars/6ac7bd6beba24d1476c5179b88c9e3fa.svg",
                        "isPro": false,
                        "fullname": "Doyen",
                        "user": "doyensahoo",
                        "type": "user"
                    },
                    "name": "Doyen Sahoo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:56:18.676Z",
                    "hidden": false
                },
                {
                    "_id": "681d7ccb572e742b3f42d1f7",
                    "user": {
                        "_id": "61f9d3b54ac99e8a1bae85f4",
                        "avatarUrl": "/avatars/ac47d13204dd22452e4bc46e280842d5.svg",
                        "isPro": false,
                        "fullname": "JunnanLi",
                        "user": "JunnanLi",
                        "type": "user"
                    },
                    "name": "Junnan Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:56:32.272Z",
                    "hidden": false
                },
                {
                    "_id": "681d7ccb572e742b3f42d1f8",
                    "user": {
                        "_id": "649dbcc4e0fff1ed099dc80a",
                        "avatarUrl": "/avatars/c87c273ca628dbcddccbf1ee19b2ce33.svg",
                        "isPro": false,
                        "fullname": "Caiming Xiong",
                        "user": "cxiong",
                        "type": "user"
                    },
                    "name": "Caiming Xiong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-05-09T08:56:38.430Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-05-08T15:01:06.000Z",
            "submittedOnDailyAt": "2025-05-09T02:31:21.542Z",
            "title": "Scalable Chain of Thoughts via Elastic Reasoning",
            "submittedOnDailyBy": {
                "_id": "6602869253a0518b2a98cafd",
                "avatarUrl": "/avatars/c14b5953a716f42c83ad28147f8308ae.svg",
                "isPro": false,
                "fullname": "Yuhui Xu",
                "user": "yuhuixu",
                "type": "user"
            },
            "summary": "Large reasoning models (LRMs) have achieved remarkable progress on complex\ntasks by generating extended chains of thought (CoT). However, their\nuncontrolled output lengths pose significant challenges for real-world\ndeployment, where inference-time budgets on tokens, latency, or compute are\nstrictly constrained. We propose Elastic Reasoning, a novel framework for\nscalable chain of thoughts that explicitly separates reasoning into two\nphases--thinking and solution--with independently allocated budgets. At test\ntime, Elastic Reasoning prioritize that completeness of solution segments,\nsignificantly improving reliability under tight resource constraints. To train\nmodels that are robust to truncated thinking, we introduce a lightweight\nbudget-constrained rollout strategy, integrated into GRPO, which teaches the\nmodel to reason adaptively when the thinking process is cut short and\ngeneralizes effectively to unseen budget constraints without additional\ntraining. Empirical results on mathematical (AIME, MATH500) and programming\n(LiveCodeBench, Codeforces) benchmarks demonstrate that Elastic Reasoning\nperforms robustly under strict budget constraints, while incurring\nsignificantly lower training cost than baseline methods. Remarkably, our\napproach also produces more concise and efficient reasoning even in\nunconstrained settings. Elastic Reasoning offers a principled and practical\nsolution to the pressing challenge of controllable reasoning at scale.",
            "upvotes": 15,
            "discussionId": "681d7ccc572e742b3f42d21a",
            "ai_keywords": [
                "Large reasoning models (LRMs)",
                "chain of thought (CoT)",
                "inference-time budgets",
                "tokens",
                "latency",
                "compute",
                "Elastic Reasoning",
                "scalable chain of thoughts",
                "thinking phase",
                "solution phase",
                "independently allocated budgets",
                "completeness of solution segments",
                "reliability",
                "resource constraints",
                "lightweight budget-constrained rollout strategy",
                "GRPO",
                "adaptive reasoning",
                "unseen budget constraints",
                "mathematical benchmarks (AIME, MATH500)",
                "programming benchmarks (LiveCodeBench, Codeforces)",
                "unconstrained settings",
                "principled solution"
            ]
        },
        "translation_title": "탄력적 추리를 통한 확장 가능한 사고의 연쇄",
        "purpose": "현실의 자원 제약 하에서도 신뢰성 있는 추론을 가능하게 하는 것을 목표로 함.",
        "method": [
            "사고를 두 단계(사고와 해결)로 나누고 각 단계에 독립적으로 할당된 예산을 사용하는 Elastic Reasoning 프레임워크를 제안함(We propose Elastic Reasoning, a novel framework for scalable chain of thoughts that explicitly separates reasoning into two phases--thinking and solution--with independently allocated budgets.)",
            "모델이 사고를 중단할 때도 적응적으로 추론할 수 있도록 경량 예산 제약 롤아웃 전략을 도입함(we introduce a lightweight budget-constrained rollout strategy, integrated into GRPO, which teaches the model to reason adaptively when the thinking process is cut short).",
            "결과로서, 문자열 수학(AIME, MATH500) 및 프로그래밍(LiveCodeBench, Codeforces) 벤치마크에서 강력한 성능을 보임(Empirical results on mathematical (AIME, MATH500) and programming (LiveCodeBench, Codeforces) benchmarks demonstrate that Elastic Reasoning performs robustly under strict budget constraints)."
        ],
        "conclusion": "Elastic Reasoning은 다양한 자원 제약 상황에서 신뢰성을 높이며, 기존 방법보다 훈련 비용이 현저히 낮고, 더 간결하고 효율적인 추론을 생성함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    }
]