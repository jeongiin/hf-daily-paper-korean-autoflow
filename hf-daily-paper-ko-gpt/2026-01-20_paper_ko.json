[
    {
        "paper": {
            "id": "2601.11077",
            "authors": [
                {
                    "_id": "696da04e3f1837bfb89709c2",
                    "user": {
                        "_id": "66206a2136201a18e5329631",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66206a2136201a18e5329631/9aJiGOKshh1tZ171zDw_D.png",
                        "isPro": false,
                        "fullname": "yangjie",
                        "user": "red-fox-yj",
                        "type": "user"
                    },
                    "name": "Jie Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-20T09:41:07.348Z",
                    "hidden": false
                },
                {
                    "_id": "696da04e3f1837bfb89709c3",
                    "user": {
                        "_id": "638ef0b0c67af472d31674a6",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/638ef0b0c67af472d31674a6/zXQjC3DdY3jpVkATkpms6.png",
                        "isPro": false,
                        "fullname": "Honglin Guo",
                        "user": "KYLN24",
                        "type": "user"
                    },
                    "name": "Honglin Guo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-20T09:41:05.334Z",
                    "hidden": false
                },
                {
                    "_id": "696da04e3f1837bfb89709c4",
                    "name": "Li Ji",
                    "hidden": false
                },
                {
                    "_id": "696da04e3f1837bfb89709c5",
                    "user": {
                        "_id": "683c6a19a4b3e38a3e23d50a",
                        "avatarUrl": "/avatars/ae9f212acaa9d1a65b4a5d86c5f7a355.svg",
                        "isPro": false,
                        "fullname": "Jiazheng Zhou",
                        "user": "HaZ-K",
                        "type": "user"
                    },
                    "name": "Jiazheng Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-20T09:42:49.533Z",
                    "hidden": false
                },
                {
                    "_id": "696da04e3f1837bfb89709c6",
                    "name": "Rui Zheng",
                    "hidden": false
                },
                {
                    "_id": "696da04e3f1837bfb89709c7",
                    "name": "Zhikai Lei",
                    "hidden": false
                },
                {
                    "_id": "696da04e3f1837bfb89709c8",
                    "user": {
                        "_id": "6334f2f1259c518276efa730",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6334f2f1259c518276efa730/z_SH_OBkDyj4RCN9mqsKS.jpeg",
                        "isPro": false,
                        "fullname": "Shuo Zhang",
                        "user": "Meteonis",
                        "type": "user"
                    },
                    "name": "Shuo Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-20T14:48:19.478Z",
                    "hidden": false
                },
                {
                    "_id": "696da04e3f1837bfb89709c9",
                    "user": {
                        "_id": "653a6e5cae155b92bae77b74",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/653a6e5cae155b92bae77b74/TA5FWKAUsB249ux4MzD_R.jpeg",
                        "isPro": false,
                        "fullname": "Zhiheng Xi",
                        "user": "WooooDyy",
                        "type": "user"
                    },
                    "name": "Zhiheng Xi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-20T09:43:14.561Z",
                    "hidden": false
                },
                {
                    "_id": "696da04e3f1837bfb89709ca",
                    "user": {
                        "_id": "65435cad429b80b14922ab8d",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/N8oWq4ZZn3dRxmXi18FrA.jpeg",
                        "isPro": false,
                        "fullname": "Shichun Liu",
                        "user": "Liusc2020",
                        "type": "user"
                    },
                    "name": "Shichun Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-20T09:43:20.286Z",
                    "hidden": false
                },
                {
                    "_id": "696da04e3f1837bfb89709cb",
                    "name": "Yuxin Wang",
                    "hidden": false
                },
                {
                    "_id": "696da04e3f1837bfb89709cc",
                    "name": "Bo Wang",
                    "hidden": false
                },
                {
                    "_id": "696da04e3f1837bfb89709cd",
                    "user": {
                        "_id": "64b7495a75b23e68c538f4c0",
                        "avatarUrl": "/avatars/ce06f3b89f9e09dcbe748b208eec1e9d.svg",
                        "isPro": false,
                        "fullname": "Yining Zheng",
                        "user": "WillQvQ",
                        "type": "user"
                    },
                    "name": "Yining Zheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-20T09:43:29.765Z",
                    "hidden": false
                },
                {
                    "_id": "696da04e3f1837bfb89709ce",
                    "name": "Tao Gui",
                    "hidden": false
                },
                {
                    "_id": "696da04e3f1837bfb89709cf",
                    "user": {
                        "_id": "61457b8deff2c9fdb4de4988",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1632381702899-61457b8deff2c9fdb4de4988.jpeg",
                        "isPro": false,
                        "fullname": "Xipeng Qiu",
                        "user": "xpqiu",
                        "type": "user"
                    },
                    "name": "Xipeng Qiu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-20T09:43:35.123Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-16T08:23:52.000Z",
            "submittedOnDailyAt": "2026-01-20T00:57:45.521Z",
            "title": "ABC-Bench: Benchmarking Agentic Backend Coding in Real-World Development",
            "submittedOnDailyBy": {
                "_id": "66206a2136201a18e5329631",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66206a2136201a18e5329631/9aJiGOKshh1tZ171zDw_D.png",
                "isPro": false,
                "fullname": "yangjie",
                "user": "red-fox-yj",
                "type": "user"
            },
            "summary": "The evolution of Large Language Models (LLMs) into autonomous agents has expanded the scope of AI coding from localized code generation to complex, repository-level, and execution-driven problem solving. However, current benchmarks predominantly evaluate code logic in static contexts, neglecting the dynamic, full-process requirements of real-world engineering, particularly in backend development which demands rigorous environment configuration and service deployment. To address this gap, we introduce ABC-Bench, a benchmark explicitly designed to evaluate agentic backend coding within a realistic, executable workflow. Using a scalable automated pipeline, we curated 224 practical tasks spanning 8 languages and 19 frameworks from open-source repositories. Distinct from previous evaluations, ABC-Bench require the agents to manage the entire development lifecycle from repository exploration to instantiating containerized services and pass the external end-to-end API tests. Our extensive evaluation reveals that even state-of-the-art models struggle to deliver reliable performance on these holistic tasks, highlighting a substantial disparity between current model capabilities and the demands of practical backend engineering. Our code is available at https://github.com/OpenMOSS/ABC-Bench.",
            "upvotes": 45,
            "discussionId": "696da04e3f1837bfb89709d0",
            "projectPage": "https://dawning-road.github.io/blog/abc-bench",
            "githubRepo": "https://github.com/OpenMOSS/ABC-Bench",
            "githubRepoAddedBy": "user",
            "ai_summary": "ABC-Bench evaluates LLM agents on realistic backend coding tasks requiring full development lifecycle management from repository exploration to containerized service deployment and API testing.",
            "ai_keywords": [
                "Large Language Models",
                "agentic backend coding",
                "executable workflow",
                "development lifecycle",
                "containerized services",
                "end-to-end API tests"
            ],
            "githubStars": 6,
            "organization": {
                "_id": "613b0dee83ec35d460684607",
                "name": "OpenMOSS-Team",
                "fullname": "OpenMOSS",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61457b8deff2c9fdb4de4988/N5b9663zQ4uq5_OTNlnmw.png"
            }
        },
        "translation_title": "ABC-Bench: 실제 개발에서 에이전틱 백엔드 코딩 평가하기",
        "purpose": "실제 엔지니어링의 동적 요구를 충족하기 위한 에이전틱 백엔드 코딩 평가 기준 수립",
        "method": [
            "실행 가능한 워크플로우 내에서 에이전틱 백엔드 코딩을 평가하기 위해 ABC-Bench를 소개함(To address this gap, we introduce ABC-Bench, a benchmark explicitly designed to evaluate agentic backend coding within a realistic, executable workflow.)",
            "자동화된 파이프라인을 이용해 8개 언어와 19개 프레임워크의 실용적인 224개 작업을 수집함(Using a scalable automated pipeline, we curated 224 practical tasks spanning 8 languages and 19 frameworks from open-source repositories.)",
            "ABC-Bench는 에이전트들이 저장소 탐색에서 컨테이너화된 서비스 생성 및 외부 API 테스트까지 전체 개발 생애 주기를 관리하도록 요구함(ABC-Bench requires the agents to manage the entire development lifecycle from repository exploration to instantiating containerized services and pass the external end-to-end API tests.)"
        ],
        "conclusion": "최신 모델조차도 이러한 포괄적인 작업에서 신뢰할 수 있는 성능을 발휘하는 데 어려움을 겪어, 현재 모델 능력과 실제 백엔드 엔지니어링 요구 간의 큰 격차를 드러냄.",
        "keywords": [
            "Large Language Models",
            "Robotics",
            "Natural Language Processing"
        ]
    },
    {
        "paper": {
            "id": "2601.08808",
            "authors": [
                {
                    "_id": "69670fa1c5e371f6b235d137",
                    "name": "Yao Tang",
                    "hidden": false
                },
                {
                    "_id": "69670fa1c5e371f6b235d138",
                    "user": {
                        "_id": "5df85abada6d0311fd3d5408",
                        "avatarUrl": "/avatars/2331cf703c1b5d3a62e2050b1a6eb108.svg",
                        "isPro": false,
                        "fullname": "Li Dong",
                        "user": "unilm",
                        "type": "user"
                    },
                    "name": "Li Dong",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-20T09:41:21.254Z",
                    "hidden": false
                },
                {
                    "_id": "69670fa1c5e371f6b235d139",
                    "name": "Yaru Hao",
                    "hidden": false
                },
                {
                    "_id": "69670fa1c5e371f6b235d13a",
                    "name": "Qingxiu Dong",
                    "hidden": false
                },
                {
                    "_id": "69670fa1c5e371f6b235d13b",
                    "user": {
                        "_id": "6368c512fbfe97c16a40baba",
                        "avatarUrl": "/avatars/1c23bc7c0b6d9225699ce27647623d7a.svg",
                        "isPro": false,
                        "fullname": "Furu Wei",
                        "user": "thegenerality",
                        "type": "user"
                    },
                    "name": "Furu Wei",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-20T09:42:02.698Z",
                    "hidden": false
                },
                {
                    "_id": "69670fa1c5e371f6b235d13c",
                    "user": {
                        "_id": "646360fed2044cd1d7c72061",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/1wHh3PyoFS_6IHRYMxXih.jpeg",
                        "isPro": false,
                        "fullname": "Jiatao.Guo",
                        "user": "Findpsyche",
                        "type": "user"
                    },
                    "name": "Jiatao Gu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-20T09:41:55.894Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-13T18:48:00.000Z",
            "submittedOnDailyAt": "2026-01-20T00:45:12.349Z",
            "title": "Multiplex Thinking: Reasoning via Token-wise Branch-and-Merge",
            "submittedOnDailyBy": {
                "_id": "5df85abada6d0311fd3d5408",
                "avatarUrl": "/avatars/2331cf703c1b5d3a62e2050b1a6eb108.svg",
                "isPro": false,
                "fullname": "Li Dong",
                "user": "unilm",
                "type": "user"
            },
            "summary": "Large language models often solve complex reasoning tasks more effectively with Chain-of-Thought (CoT), but at the cost of long, low-bandwidth token sequences. Humans, by contrast, often reason softly by maintaining a distribution over plausible next steps. Motivated by this, we propose Multiplex Thinking, a stochastic soft reasoning mechanism that, at each thinking step, samples K candidate tokens and aggregates their embeddings into a single continuous multiplex token. This preserves the vocabulary embedding prior and the sampling dynamics of standard discrete generation, while inducing a tractable probability distribution over multiplex rollouts. Consequently, multiplex trajectories can be directly optimized with on-policy reinforcement learning (RL). Importantly, Multiplex Thinking is self-adaptive: when the model is confident, the multiplex token is nearly discrete and behaves like standard CoT; when it is uncertain, it compactly represents multiple plausible next steps without increasing sequence length. Across challenging math reasoning benchmarks, Multiplex Thinking consistently outperforms strong discrete CoT and RL baselines from Pass@1 through Pass@1024, while producing shorter sequences. The code and checkpoints are available at https://github.com/GMLR-Penn/Multiplex-Thinking.",
            "upvotes": 21,
            "discussionId": "69670fa2c5e371f6b235d13d",
            "projectPage": "https://gmlr-penn.github.io/Multiplex-Thinking/",
            "githubRepo": "https://github.com/GMLR-Penn/Multiplex-Thinking",
            "githubRepoAddedBy": "user",
            "ai_summary": "Multiplex Thinking introduces a stochastic soft reasoning mechanism that samples multiple candidate tokens at each step to optimize reasoning trajectories with reinforcement learning while maintaining shorter sequences than traditional chain-of-thought methods.",
            "ai_keywords": [
                "Chain-of-Thought",
                "stochastic soft reasoning",
                "multiplex token",
                "continuous multiplex token",
                "on-policy reinforcement learning",
                "Pass@1",
                "Pass@1024",
                "reasoning trajectories"
            ],
            "githubStars": 46,
            "organization": {
                "_id": "68151d0f51add3813f3f7d1b",
                "name": "MicrosoftResearch",
                "fullname": "Microsoft Research",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6529a4f2f1205983224fa513/PeuVr7jSuJflmDBBGxoDX.png"
            }
        },
        "translation_title": "Multiplex Thinking: 토큰 단위의 브랜치 및 병합을 통한 추론",
        "purpose": "복잡한 추론 작업을 더 효율적으로 수행하기 위한 새로운 사고 메커니즘 연구",
        "method": [
            "K 후보 토큰을 샘플링하고 이를 하나의 연속적인 멀티플렉스 토큰으로 집계하는 확률적 사고 메커니즘을 제안함(Motivated by this, we propose Multiplex Thinking, a stochastic soft reasoning mechanism that, at each thinking step, samples K candidate tokens and aggregates their embeddings into a single continuous multiplex token.)",
            "표준 이산 생성의 샘플링 동적을 유지하면서 멀티플렉스 롤아웃에 대한 접근 가능한 확률 분포를 유도함(This preserves the vocabulary embedding prior and the sampling dynamics of standard discrete generation, while inducing a tractable probability distribution over multiplex rollouts.)",
            "On-policy reinforcement learning(RL)으로 멀티플렉스 경로를 직접 최적화함(Consequently, multiplex trajectories can be directly optimized with on-policy reinforcement learning (RL).)"
        ],
        "conclusion": "멀티플렉스 사고는 복잡한 수학적 추론 벤치마크에서 강력한 성능을 발휘하며, 표준 Chain-of-Thought보다 짧은 시퀀스를 생성함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2601.10880",
            "authors": [
                {
                    "_id": "696ee0455750539a88acc784",
                    "user": {
                        "_id": "668ca2bad10c3be5d3514449",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/668ca2bad10c3be5d3514449/LqgRQzwqI3tg0M4G6vKec.jpeg",
                        "isPro": false,
                        "fullname": "ChongCongJiang",
                        "user": "ChongCong",
                        "type": "user"
                    },
                    "name": "Chongcong Jiang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-20T09:39:15.230Z",
                    "hidden": false
                },
                {
                    "_id": "696ee0455750539a88acc785",
                    "name": "Tianxingjian Ding",
                    "hidden": false
                },
                {
                    "_id": "696ee0455750539a88acc786",
                    "name": "Chuhan Song",
                    "hidden": false
                },
                {
                    "_id": "696ee0455750539a88acc787",
                    "name": "Jiachen Tu",
                    "hidden": false
                },
                {
                    "_id": "696ee0455750539a88acc788",
                    "name": "Ziyang Yan",
                    "hidden": false
                },
                {
                    "_id": "696ee0455750539a88acc789",
                    "name": "Yihua Shao",
                    "hidden": false
                },
                {
                    "_id": "696ee0455750539a88acc78a",
                    "name": "Zhenyi Wang",
                    "hidden": false
                },
                {
                    "_id": "696ee0455750539a88acc78b",
                    "name": "Yuzhang Shang",
                    "hidden": false
                },
                {
                    "_id": "696ee0455750539a88acc78c",
                    "name": "Tianyu Han",
                    "hidden": false
                },
                {
                    "_id": "696ee0455750539a88acc78d",
                    "name": "Yu Tian",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-15T22:18:14.000Z",
            "submittedOnDailyAt": "2026-01-20T08:02:06.827Z",
            "title": "Medical SAM3: A Foundation Model for Universal Prompt-Driven Medical Image Segmentation",
            "submittedOnDailyBy": {
                "_id": "668ca2bad10c3be5d3514449",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/668ca2bad10c3be5d3514449/LqgRQzwqI3tg0M4G6vKec.jpeg",
                "isPro": false,
                "fullname": "ChongCongJiang",
                "user": "ChongCong",
                "type": "user"
            },
            "summary": "Promptable segmentation foundation models such as SAM3 have demonstrated strong generalization capabilities through interactive and concept-based prompting. However, their direct applicability to medical image segmentation remains limited by severe domain shifts, the absence of privileged spatial prompts, and the need to reason over complex anatomical and volumetric structures. Here we present Medical SAM3, a foundation model for universal prompt-driven medical image segmentation, obtained by fully fine-tuning SAM3 on large-scale, heterogeneous 2D and 3D medical imaging datasets with paired segmentation masks and text prompts. Through a systematic analysis of vanilla SAM3, we observe that its performance degrades substantially on medical data, with its apparent competitiveness largely relying on strong geometric priors such as ground-truth-derived bounding boxes. These findings motivate full model adaptation beyond prompt engineering alone. By fine-tuning SAM3's model parameters on 33 datasets spanning 10 medical imaging modalities, Medical SAM3 acquires robust domain-specific representations while preserving prompt-driven flexibility. Extensive experiments across organs, imaging modalities, and dimensionalities demonstrate consistent and significant performance gains, particularly in challenging scenarios characterized by semantic ambiguity, complex morphology, and long-range 3D context. Our results establish Medical SAM3 as a universal, text-guided segmentation foundation model for medical imaging and highlight the importance of holistic model adaptation for achieving robust prompt-driven segmentation under severe domain shift. Code and model will be made available at https://github.com/AIM-Research-Lab/Medical-SAM3.",
            "upvotes": 5,
            "discussionId": "696ee0455750539a88acc78e",
            "projectPage": "https://chongcongjiang.github.io/MedicalSAM3/",
            "githubRepo": "https://github.com/AIM-Research-Lab/Medical-SAM3.git",
            "githubRepoAddedBy": "user",
            "ai_summary": "Medical SAM3 adapts the SAM3 foundation model through comprehensive fine-tuning on diverse medical imaging datasets to achieve robust prompt-driven segmentation across various modalities and anatomical structures.",
            "ai_keywords": [
                "foundation model",
                "prompt-driven segmentation",
                "medical image segmentation",
                "SAM3",
                "fine-tuning",
                "medical imaging modalities",
                "anatomical structures",
                "domain shift",
                "text prompts",
                "segmentation masks",
                "geometric priors",
                "universal segmentation"
            ],
            "githubStars": 8
        },
        "translation_title": "Medical SAM3: 보편적인 프롬프트 기반의 의료 이미지 분할을 위한 기초 모델",
        "purpose": "의료 이미지 분할에서 강력한 일반화 능력을 가진 프롬프트 기반 모델의 적용 가능성을 높이기 위해 모델을 개발하고자 함",
        "method": [
            "SAM3 모델을 33개의 의료 이미지 데이터셋에 대해 전체 미세 조정하여 적용함.(By fine-tuning SAM3's model parameters on 33 datasets spanning 10 medical imaging modalities, Medical SAM3 acquires robust domain-specific representations while preserving prompt-driven flexibility.)",
            "2D 및 3D 의료 이미징 데이터셋에서 쌍으로 된 분할 마스크와 텍스트 프롬프트를 사용하여 대규모로 훈련함.(obtained by fully fine-tuning SAM3 on large-scale, heterogeneous 2D and 3D medical imaging datasets with paired segmentation masks and text prompts.)",
            "의료 데이터에서의 성능 저하를 관찰하고, 기하학적 우선 사항에 의존하지 않도록 설계되어 있음.(we observe that its performance degrades substantially on medical data, with its apparent competitiveness largely relying on strong geometric priors such as ground-truth-derived bounding boxes.)"
        ],
        "conclusion": "Medical SAM3는 의료 이미지 분할을 위한 보편적이고 텍스트 기반의 분할 모델로 자리 잡았으며, 심각한 도메인 변화에 대응하기 위한 전반적인 모델 조정의 중요성을 강조함.",
        "keywords": [
            "Image Segmentation",
            "3D Vision",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2601.11096",
            "authors": [
                {
                    "_id": "696da7ca3f1837bfb89709f6",
                    "name": "Shuai Tan",
                    "hidden": false
                },
                {
                    "_id": "696da7ca3f1837bfb89709f7",
                    "name": "Biao Gong",
                    "hidden": false
                },
                {
                    "_id": "696da7ca3f1837bfb89709f8",
                    "user": {
                        "_id": "6442060e8bf0d7756e010e86",
                        "avatarUrl": "/avatars/47d53530631e2dffa5d8c9961278718f.svg",
                        "isPro": false,
                        "fullname": "Ke Ma",
                        "user": "kema",
                        "type": "user"
                    },
                    "name": "Ke Ma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-20T09:44:22.904Z",
                    "hidden": false
                },
                {
                    "_id": "696da7ca3f1837bfb89709f9",
                    "user": {
                        "_id": "64a54e468cfaa458bd6844bf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64a54e468cfaa458bd6844bf/5Gmf4tAr59GNl-2VaZDbu.png",
                        "isPro": false,
                        "fullname": "Yutong Feng",
                        "user": "fengyutong",
                        "type": "user"
                    },
                    "name": "Yutong Feng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-20T09:44:15.812Z",
                    "hidden": false
                },
                {
                    "_id": "696da7ca3f1837bfb89709fa",
                    "user": {
                        "_id": "62a42f22c683d02f5b63320c",
                        "avatarUrl": "/avatars/bc611abe9c4ef8d378123cb8ac9fdbf2.svg",
                        "isPro": true,
                        "fullname": "Qiyuan Zhang",
                        "user": "DonJoey",
                        "type": "user"
                    },
                    "name": "Qiyuan Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-20T09:44:09.177Z",
                    "hidden": false
                },
                {
                    "_id": "696da7ca3f1837bfb89709fb",
                    "name": "Yan Wang",
                    "hidden": false
                },
                {
                    "_id": "696da7ca3f1837bfb89709fc",
                    "user": {
                        "_id": "6969f153bb68e272ac6e2676",
                        "avatarUrl": "/avatars/06d79a105c8d36c86f3e024ab41a9998.svg",
                        "isPro": false,
                        "fullname": "Yujun Shen",
                        "user": "shen12313",
                        "type": "user"
                    },
                    "name": "Yujun Shen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-20T09:43:55.399Z",
                    "hidden": false
                },
                {
                    "_id": "696da7ca3f1837bfb89709fd",
                    "user": {
                        "_id": "690090cca41c454e4786c0e5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/690090cca41c454e4786c0e5/ykyy4gV7EV_xfv4glxC1m.png",
                        "isPro": false,
                        "fullname": "Hengshuang Zhao",
                        "user": "Hengshuang",
                        "type": "user"
                    },
                    "name": "Hengshuang Zhao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-20T09:43:49.910Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-16T08:53:09.000Z",
            "submittedOnDailyAt": "2026-01-20T00:50:22.808Z",
            "title": "CoDance: An Unbind-Rebind Paradigm for Robust Multi-Subject Animation",
            "submittedOnDailyBy": {
                "_id": "644fcbea4f7316588267dc80",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/644fcbea4f7316588267dc80/w8-2Gkaw9BN9VzppNXrTP.jpeg",
                "isPro": false,
                "fullname": "Biao Gong",
                "user": "BiaoGong",
                "type": "user"
            },
            "summary": "Character image animation is gaining significant importance across various domains, driven by the demand for robust and flexible multi-subject rendering. While existing methods excel in single-person animation, they struggle to handle arbitrary subject counts, diverse character types, and spatial misalignment between the reference image and the driving poses. We attribute these limitations to an overly rigid spatial binding that forces strict pixel-wise alignment between the pose and reference, and an inability to consistently rebind motion to intended subjects. To address these challenges, we propose CoDance, a novel Unbind-Rebind framework that enables the animation of arbitrary subject counts, types, and spatial configurations conditioned on a single, potentially misaligned pose sequence. Specifically, the Unbind module employs a novel pose shift encoder to break the rigid spatial binding between the pose and the reference by introducing stochastic perturbations to both poses and their latent features, thereby compelling the model to learn a location-agnostic motion representation. To ensure precise control and subject association, we then devise a Rebind module, leveraging semantic guidance from text prompts and spatial guidance from subject masks to direct the learned motion to intended characters. Furthermore, to facilitate comprehensive evaluation, we introduce a new multi-subject CoDanceBench. Extensive experiments on CoDanceBench and existing datasets show that CoDance achieves SOTA performance, exhibiting remarkable generalization across diverse subjects and spatial layouts. The code and weights will be open-sourced.",
            "upvotes": 4,
            "discussionId": "696da7ca3f1837bfb89709fe",
            "projectPage": "https://lucaria-academy.github.io/CoDance/",
            "ai_summary": "CoDance introduces an Unbind-Rebind framework for animating multiple subjects with flexible spatial configurations, using pose shift encoding and semantic/textual guidance for motion reassignment.",
            "ai_keywords": [
                "Unbind-Rebind framework",
                "pose shift encoder",
                "stochastic perturbations",
                "location-agnostic motion representation",
                "semantic guidance",
                "spatial guidance",
                "subject masks",
                "CoDanceBench"
            ]
        },
        "translation_title": "CoDance: 강한 다중 주제 애니메이션을 위한 Unbind-Rebind 패러다임",
        "purpose": "다양한 주제를 유연하고 강하게 애니메이션화하기 위한 새로운 방법론 개발",
        "method": [
            "Unbind-Rebind 프레임워크를 통해 임의의 주제 수와 타입, 공간 구성을 처리할 수 있도록 함(To address these challenges, we propose CoDance, a novel Unbind-Rebind framework that enables the animation of arbitrary subject counts, types, and spatial configurations.)",
            "Unbind 모듈에서 새로운 pose shift encoder를 활용해 강한 공간 결합을 깨고, 모델이 위치에 구애받지 않는 동작 표현을 학습하도록 유도함(Specifically, the Unbind module employs a novel pose shift encoder to break the rigid spatial binding between the pose and the reference by introducing stochastic perturbations to both poses and their latent features.)",
            "Rebind 모듈을 통해 텍스트 프롬프트와 주제 마스크의 공간적 안내를 활용하여 학습된 동작을 특정 캐릭터에 맞춰 조정함(we then devise a Rebind module, leveraging semantic guidance from text prompts and spatial guidance from subject masks to direct the learned motion to intended characters.)"
        ],
        "conclusion": "CoDance는 다양한 주제와 공간 배열에 대해 우수한 일반화 성능을 보이며 최신 기술 기준(SOTA) 성능을 달성함.",
        "keywords": [
            "Computer Vision",
            "Image Generation",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2601.10387",
            "authors": [
                {
                    "_id": "696e966d5750539a88acc746",
                    "name": "Christina Lu",
                    "hidden": false
                },
                {
                    "_id": "696e966d5750539a88acc747",
                    "name": "Jack Gallagher",
                    "hidden": false
                },
                {
                    "_id": "696e966d5750539a88acc748",
                    "name": "Jonathan Michala",
                    "hidden": false
                },
                {
                    "_id": "696e966d5750539a88acc749",
                    "name": "Kyle Fish",
                    "hidden": false
                },
                {
                    "_id": "696e966d5750539a88acc74a",
                    "name": "Jack Lindsey",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-15T13:40:06.000Z",
            "submittedOnDailyAt": "2026-01-20T01:07:25.144Z",
            "title": "The Assistant Axis: Situating and Stabilizing the Default Persona of Language Models",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Large language models can represent a variety of personas but typically default to a helpful Assistant identity cultivated during post-training. We investigate the structure of the space of model personas by extracting activation directions corresponding to diverse character archetypes. Across several different models, we find that the leading component of this persona space is an \"Assistant Axis,\" which captures the extent to which a model is operating in its default Assistant mode. Steering towards the Assistant direction reinforces helpful and harmless behavior; steering away increases the model's tendency to identify as other entities. Moreover, steering away with more extreme values often induces a mystical, theatrical speaking style. We find this axis is also present in pre-trained models, where it primarily promotes helpful human archetypes like consultants and coaches and inhibits spiritual ones. Measuring deviations along the Assistant Axis predicts \"persona drift,\" a phenomenon where models slip into exhibiting harmful or bizarre behaviors that are uncharacteristic of their typical persona. We find that persona drift is often driven by conversations demanding meta-reflection on the model's processes or featuring emotionally vulnerable users. We show that restricting activations to a fixed region along the Assistant Axis can stabilize model behavior in these scenarios -- and also in the face of adversarial persona-based jailbreaks. Our results suggest that post-training steers models toward a particular region of persona space but only loosely tethers them to it, motivating work on training and steering strategies that more deeply anchor models to a coherent persona.",
            "upvotes": 4,
            "discussionId": "696e966e5750539a88acc74b",
            "ai_summary": "Research reveals that large language models operate within a persona space where an \"Assistant Axis\" controls helpfulness and behavioral stability, with steering techniques able to influence model responses and prevent harmful behavior drift.",
            "ai_keywords": [
                "persona space",
                "activation directions",
                "Assistant Axis",
                "persona drift",
                "meta-reflection",
                "adversarial persona-based jailbreaks"
            ]
        },
        "translation_title": "어시스턴트 축: 언어 모델의 기본 인격 위치 선정 및 안정화",
        "purpose": "언어 모델이 어시스턴트 인격으로 안정적으로 작동하도록 하는 방법 탐구",
        "method": [
            "모델의 다양한 캐릭터 원형에 대한 활성화 방향을 추출하여 인격 공간 구조를 조사함(We investigate the structure of the space of model personas by extracting activation directions corresponding to diverse character archetypes.)",
            "각 모델에서 어시스턴트 축이 기본 어시스턴트 모드에서의 모델 작동 정도를 포착하고 있음을 발견함(we find that the leading component of this persona space is an 'Assistant Axis,' which captures the extent to which a model is operating in its default Assistant mode.)",
            "어시스턴트 축을 따라 제한된 활성화를 통해 모델의 행동을 안정화함(We show that restricting activations to a fixed region along the Assistant Axis can stabilize model behavior in these scenarios.)"
        ],
        "conclusion": "어시스턴트 축은 언어 모델의 일관된 인격을 유지하는 데 중요한 역할을 하며, 개선된 훈련 및 조정 전략이 필요함을 제안함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    }
]