[
    {
        "paper": {
            "id": "2512.16969",
            "authors": [
                {
                    "_id": "6948b09934f46eaf46cbb214",
                    "user": {
                        "_id": "65f3f43fc9940817ca9a427b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65f3f43fc9940817ca9a427b/02NN3XjSsbgWDhjrJWtVL.jpeg",
                        "isPro": false,
                        "fullname": "Wanghan Xu",
                        "user": "CoCoOne",
                        "type": "user"
                    },
                    "name": "Wanghan Xu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-22T10:58:47.069Z",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb215",
                    "name": "Yuhao Zhou",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb216",
                    "name": "Yifan Zhou",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb217",
                    "name": "Qinglong Cao",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb218",
                    "name": "Shuo Li",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb219",
                    "name": "Jia Bu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb21a",
                    "user": {
                        "_id": "61e6dd8a82b19b93e1a51fa6",
                        "avatarUrl": "/avatars/babbee52793a35dd5754d000946dd1ee.svg",
                        "isPro": false,
                        "fullname": "Kelvin Liu",
                        "user": "BoKelvin",
                        "type": "user"
                    },
                    "name": "Bo Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-22T10:58:41.476Z",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb21b",
                    "name": "Yixin Chen",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb21c",
                    "name": "Xuming He",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb21d",
                    "name": "Xiangyu Zhao",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb21e",
                    "name": "Xiang Zhuang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb21f",
                    "name": "Fengxiang Wang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb220",
                    "name": "Zhiwang Zhou",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb221",
                    "name": "Qiantai Feng",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb222",
                    "name": "Wenxuan Huang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb223",
                    "user": {
                        "_id": "6539bc7756c9b35961021fa8",
                        "avatarUrl": "/avatars/b0140589c0a435c903c93d93a1a6ee8b.svg",
                        "isPro": false,
                        "fullname": "Jiaqi Wei",
                        "user": "VitaCoco",
                        "type": "user"
                    },
                    "name": "Jiaqi Wei",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-22T10:58:43.408Z",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb224",
                    "name": "Hao Wu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb225",
                    "name": "Yuejin Yang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb226",
                    "name": "Guangshuai Wang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb227",
                    "name": "Sheng Xu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb228",
                    "name": "Ziyan Huang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb229",
                    "name": "Xinyao Liu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb22a",
                    "name": "Jiyao Liu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb22b",
                    "name": "Cheng Tang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb22c",
                    "name": "Wei Li",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb22d",
                    "name": "Ying Chen",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb22e",
                    "name": "Junzhi Ning",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb22f",
                    "name": "Pengfei Jiang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb230",
                    "name": "Chenglong Ma",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb231",
                    "name": "Ye Du",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb232",
                    "name": "Changkai Ji",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb233",
                    "name": "Huihui Xu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb234",
                    "name": "Ming Hu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb235",
                    "name": "Jiangbin Zheng",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb236",
                    "name": "Xin Chen",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb237",
                    "name": "Yucheng Wu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb238",
                    "name": "Feifei Jiang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb239",
                    "name": "Xi Chen",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb23a",
                    "name": "Xiangru Tang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb23b",
                    "name": "Yuchen Fu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb23c",
                    "name": "Yingzhou Lu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb23d",
                    "name": "Yuanyuan Zhang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb23e",
                    "name": "Lihao Sun",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb23f",
                    "name": "Chengbo Li",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb240",
                    "name": "Jinzhe Ma",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb241",
                    "name": "Wanhao Liu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb242",
                    "name": "Yating Liu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb243",
                    "name": "Kuo-Cheng Wu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb244",
                    "name": "Shengdu Chai",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb245",
                    "name": "Yizhou Wang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb246",
                    "name": "Ouwen Zhangjin",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb247",
                    "name": "Chen Tang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb248",
                    "name": "Shufei Zhang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb249",
                    "name": "Wenbo Cao",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb24a",
                    "name": "Junjie Ren",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb24b",
                    "name": "Taoyong Cui",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb24c",
                    "name": "Zhouheng Yao",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb24d",
                    "name": "Juntao Deng",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb24e",
                    "name": "Yijie Sun",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb24f",
                    "name": "Feng Liu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb250",
                    "name": "Wangxu Wei",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb251",
                    "name": "Jingyi Xu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb252",
                    "name": "Zhangrui Li",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb253",
                    "name": "Junchao Gong",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb254",
                    "name": "Zijie Guo",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb255",
                    "name": "Zhiyu Yao",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb256",
                    "name": "Zaoyu Chen",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb257",
                    "name": "Tianhao Peng",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb258",
                    "user": {
                        "_id": "68ad9cb3bcaa8d84217a8bdf",
                        "avatarUrl": "/avatars/dbb3199cf5bfc2acdbd38069c823c027.svg",
                        "isPro": false,
                        "fullname": "Fangchen Yu",
                        "user": "SciYu",
                        "type": "user"
                    },
                    "name": "Fangchen Yu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-22T10:58:45.323Z",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb259",
                    "name": "Bo Zhang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb25a",
                    "name": "Dongzhan Zhou",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb25b",
                    "name": "Shixiang Tang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb25c",
                    "name": "Jiaheng Liu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb25d",
                    "name": "Fenghua Ling",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb25e",
                    "name": "Yan Lu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb25f",
                    "name": "Yuchen Ren",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb260",
                    "name": "Ben Fei",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb261",
                    "name": "Zhen Zhao",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb262",
                    "name": "Xinyu Gu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb263",
                    "name": "Rui Su",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb264",
                    "name": "Xiao-Ming Wu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb265",
                    "name": "Weikang Si",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb266",
                    "name": "Yang Liu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb267",
                    "name": "Hao Chen",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb268",
                    "name": "Xiangchao Yan",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb269",
                    "name": "Xue Yang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb26a",
                    "name": "Junchi Yan",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb26b",
                    "name": "Jiamin Wu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb26c",
                    "name": "Qihao Zheng",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb26d",
                    "name": "Chenhui Li",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb26e",
                    "name": "Zhiqiang Gao",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb26f",
                    "name": "Hao Kong",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb270",
                    "name": "Junjun He",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb271",
                    "name": "Mao Su",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb272",
                    "name": "Tianfan Fu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb273",
                    "name": "Peng Ye",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb274",
                    "name": "Chunfeng Song",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb275",
                    "name": "Nanqing Dong",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb276",
                    "name": "Yuqiang Li",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb277",
                    "name": "Huazhu Fu",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb278",
                    "name": "Siqi Sun",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb279",
                    "name": "Lijing Cheng",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb27a",
                    "name": "Jintai Lin",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb27b",
                    "name": "Wanli Ouyang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb27c",
                    "name": "Bowen Zhou",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb27d",
                    "name": "Wenlong Zhang",
                    "hidden": false
                },
                {
                    "_id": "6948b09934f46eaf46cbb27e",
                    "name": "Lei Bai",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-18T12:44:36.000Z",
            "submittedOnDailyAt": "2025-12-22T00:14:52.424Z",
            "title": "Probing Scientific General Intelligence of LLMs with Scientist-Aligned Workflows",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Despite advances in scientific AI, a coherent framework for Scientific General Intelligence (SGI)-the ability to autonomously conceive, investigate, and reason across scientific domains-remains lacking. We present an operational SGI definition grounded in the Practical Inquiry Model (PIM: Deliberation, Conception, Action, Perception) and operationalize it via four scientist-aligned tasks: deep research, idea generation, dry/wet experiments, and experimental reasoning. SGI-Bench comprises over 1,000 expert-curated, cross-disciplinary samples inspired by Science's 125 Big Questions, enabling systematic evaluation of state-of-the-art LLMs. Results reveal gaps: low exact match (10--20%) in deep research despite step-level alignment; ideas lacking feasibility and detail; high code executability but low execution result accuracy in dry experiments; low sequence fidelity in wet protocols; and persistent multimodal comparative-reasoning challenges. We further introduce Test-Time Reinforcement Learning (TTRL), which optimizes retrieval-augmented novelty rewards at inference, enhancing hypothesis novelty without reference answer. Together, our PIM-grounded definition, workflow-centric benchmark, and empirical insights establish a foundation for AI systems that genuinely participate in scientific discovery.",
            "upvotes": 75,
            "discussionId": "6948b09934f46eaf46cbb27f",
            "projectPage": "https://internscience.github.io/SGI-Page/",
            "githubRepo": "https://github.com/InternScience/SGI-Bench",
            "githubRepoAddedBy": "user",
            "ai_summary": "A framework for Scientific General Intelligence (SGI) is presented, evaluated using SGI-Bench, and improved with Test-Time Reinforcement Learning, highlighting gaps in existing models' scientific capabilities.",
            "ai_keywords": [
                "Scientific General Intelligence",
                "SGI",
                "Practical Inquiry Model",
                "PIM",
                "deep research",
                "idea generation",
                "dry experiments",
                "wet experiments",
                "experimental reasoning",
                "SGI-Bench",
                "Big Questions",
                "Low exact match",
                "feasibility",
                "detail",
                "code executability",
                "execution result accuracy",
                "sequence fidelity",
                "multimodal comparative-reasoning",
                "Test-Time Reinforcement Learning",
                "TTRL",
                "retrieval-augmented novelty rewards",
                "hypothesis novelty"
            ],
            "githubStars": 50
        },
        "translation_title": "과학자 정렬 워크플로우를 통한 LLM의 과학적 일반 지능 탐색",
        "purpose": "과학적 일반 지능(SGI)을 평가하고 개선하기 위한 체계적인 기준 및 작업 흐름을 개발하는 것",
        "method": [
            "Practical Inquiry Model(PIM)에 기반한 SGI의 운영적 정의를 포함하여, 심층 연구, 아이디어 생성, 건식/습식 실험, 실험적 추론의 네 가지 작업으로 이를 구체화함(We present an operational SGI definition grounded in the Practical Inquiry Model (PIM: Deliberation, Conception, Action, Perception) and operationalize it via four scientist-aligned tasks: deep research, idea generation, dry/wet experiments, and experimental reasoning.)",
            "1,000개 이상의 전문가 제작 샘플로 구성된 SGI-Bench를 통해 최신 LLM을 체계적으로 평가함(SGI-Bench comprises over 1,000 expert-curated, cross-disciplinary samples inspired by Science's 125 Big Questions, enabling systematic evaluation of state-of-the-art LLMs.)",
            "TTRL(Test-Time Reinforcement Learning)을 도입하여 추론 시 새로운 아이디어의 신선함을 강화함(We further introduce Test-Time Reinforcement Learning (TTRL), which optimizes retrieval-augmented novelty rewards at inference, enhancing hypothesis novelty without reference answer.)"
        ],
        "conclusion": "PIM에 기반한 정의, 워크플로우 중심의 벤치마크, 경험적 통찰을 통해 AI 시스템이 과학적 발견에 실제로 참여하는 기반을 마련함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2512.17901",
            "authors": [
                {
                    "_id": "6948af7534f46eaf46cbb1da",
                    "user": {
                        "_id": "6719bfd07c6e6c83a388aeae",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6719bfd07c6e6c83a388aeae/jHxryk04dzHo23TX5F5sz.png",
                        "isPro": false,
                        "fullname": "Junyu Zhang",
                        "user": "jyzhang1208",
                        "type": "user"
                    },
                    "name": "Junyu Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-22T10:58:53.009Z",
                    "hidden": false
                },
                {
                    "_id": "6948af7534f46eaf46cbb1db",
                    "name": "Yifan Sun",
                    "hidden": false
                },
                {
                    "_id": "6948af7534f46eaf46cbb1dc",
                    "name": "Tianang Leng",
                    "hidden": false
                },
                {
                    "_id": "6948af7534f46eaf46cbb1dd",
                    "name": "Jingyan Shen",
                    "hidden": false
                },
                {
                    "_id": "6948af7534f46eaf46cbb1de",
                    "name": "Liu Ziyin",
                    "hidden": false
                },
                {
                    "_id": "6948af7534f46eaf46cbb1df",
                    "name": "Paul Pu Liang",
                    "hidden": false
                },
                {
                    "_id": "6948af7534f46eaf46cbb1e0",
                    "name": "Huan Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-19T18:59:11.000Z",
            "submittedOnDailyAt": "2025-12-22T00:10:07.525Z",
            "title": "When Reasoning Meets Its Laws",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Despite the superior performance of Large Reasoning Models (LRMs), their reasoning behaviors are often counterintuitive, leading to suboptimal reasoning capabilities. To theoretically formalize the desired reasoning behaviors, this paper presents the Laws of Reasoning (LoRe), a unified framework that characterizes intrinsic reasoning patterns in LRMs. We first propose compute law with the hypothesis that the reasoning compute should scale linearly with question complexity. Beyond compute, we extend LoRe with a supplementary accuracy law. Since the question complexity is difficult to quantify in practice, we examine these hypotheses by two properties of the laws, monotonicity and compositionality. We therefore introduce LoRe-Bench, a benchmark that systematically measures these two tractable properties for large reasoning models. Evaluation shows that most reasoning models exhibit reasonable monotonicity but lack compositionality. In response, we develop an effective finetuning approach that enforces compute-law compositionality. Extensive empirical studies demonstrate that better compliance with compute laws yields consistently improved reasoning performance on multiple benchmarks, and uncovers synergistic effects across properties and laws. Project page: https://lore-project.github.io/",
            "upvotes": 40,
            "discussionId": "6948af7534f46eaf46cbb1e1",
            "projectPage": "https://lore-project.github.io/",
            "githubRepo": "https://github.com/ASTRAL-Group/LoRe",
            "githubRepoAddedBy": "user",
            "ai_summary": "A framework called Laws of Reasoning (LoRe) is introduced to theoretically define desired reasoning behaviors in Large Reasoning Models, with a focus on compute and accuracy laws, and a benchmark (LoRe-Bench) to measure these properties.",
            "ai_keywords": [
                "Laws of Reasoning",
                "LoRe",
                "compute law",
                "accuracy law",
                "question complexity",
                "monotonicity",
                "compositionality",
                "LoRe-Bench",
                "finetuning approach",
                "compute-law compositionality"
            ],
            "githubStars": 11
        },
        "translation_title": "사고가 법칙을 만날 때",
        "purpose": "Large Reasoning Models의 비직관적인 추론 행동을 개선하고자 하는 목표",
        "method": [
            "Reasoning 행위를 수학적으로 공식화하기 위해 Laws of Reasoning (LoRe)를 제시함(we present the Laws of Reasoning (LoRe), a unified framework that characterizes intrinsic reasoning patterns in LRMs).",
            "질문의 복잡도와 비례하여 추론 컴퓨팅이 선형적으로 증가해야 한다는 hypothesize하여 compute law를 제안함(we first propose compute law with the hypothesis that the reasoning compute should scale linearly with question complexity).",
            "LoRe-Bench라는 기준점을 도입해 두 가지 속성인 단조성(Monotonicity)와 조합성(Compositionality)을 체계적으로 측정함(we therefore introduce LoRe-Bench, a benchmark that systematically measures these two tractable properties for large reasoning models).",
            "효과적인 fine-tuning 방법을 개발하여 compute-law 조합성을 강화함(in response, we develop an effective finetuning approach that enforces compute-law compositionality)."
        ],
        "conclusion": "compute laws를 더 잘 준수할수록 다양한 기준에서 추론 성능이 일관되게 개선된다는 것을 입증함.",
        "keywords": [
            "Large Language Models",
            "Natural Language Processing",
            "Multi-modal Learning"
        ]
    },
    {
        "paper": {
            "id": "2512.17260",
            "authors": [
                {
                    "_id": "6948afc434f46eaf46cbb1f1",
                    "name": "Jiangjie Chen",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1f2",
                    "name": "Wenxiang Chen",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1f3",
                    "name": "Jiacheng Du",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1f4",
                    "user": {
                        "_id": "637a06580a77f602dc4ac922",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/637a06580a77f602dc4ac922/qOJAhHOEE2N-HzRcZOu1L.jpeg",
                        "isPro": false,
                        "fullname": "Jinyi Hu",
                        "user": "JamesHujy",
                        "type": "user"
                    },
                    "name": "Jinyi Hu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-22T10:58:50.739Z",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1f5",
                    "name": "Zhicheng Jiang",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1f6",
                    "user": {
                        "_id": "5f729da2f1e7ef6e919a1c27",
                        "avatarUrl": "/avatars/bdf48f0d3290fab54d7e9636a3d14158.svg",
                        "isPro": false,
                        "fullname": "Zhanming (Allan) Jie",
                        "user": "allanjie",
                        "type": "user"
                    },
                    "name": "Allan Jie",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-22T10:58:49.005Z",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1f7",
                    "name": "Xiaoran Jin",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1f8",
                    "name": "Xing Jin",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1f9",
                    "name": "Chenggang Li",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1fa",
                    "name": "Wenlei Shi",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1fb",
                    "name": "Zhihong Wang",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1fc",
                    "name": "Mingxuan Wang",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1fd",
                    "name": "Chenrui Wei",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1fe",
                    "name": "Shufa Wei",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb1ff",
                    "name": "Huajian Xin",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb200",
                    "name": "Fan Yang",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb201",
                    "name": "Weihao Gao",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb202",
                    "name": "Zheng Yuan",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb203",
                    "name": "Tianyang Zhan",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb204",
                    "name": "Zeyu Zheng",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb205",
                    "name": "Tianxi Zhou",
                    "hidden": false
                },
                {
                    "_id": "6948afc434f46eaf46cbb206",
                    "name": "Thomas Hanwen Zhu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-19T06:19:55.000Z",
            "submittedOnDailyAt": "2025-12-22T00:11:16.085Z",
            "title": "Seed-Prover 1.5: Mastering Undergraduate-Level Theorem Proving via Learning from Experience",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Large language models have recently made significant progress to generate rigorous mathematical proofs. In contrast, utilizing LLMs for theorem proving in formal languages (such as Lean) remains challenging and computationally expensive, particularly when addressing problems at the undergraduate level and beyond. In this work, we present Seed-Prover 1.5, a formal theorem-proving model trained via large-scale agentic reinforcement learning, alongside an efficient test-time scaling (TTS) workflow. Through extensive interactions with Lean and other tools, the model continuously accumulates experience during the RL process, substantially enhancing the capability and efficiency of formal theorem proving. Furthermore, leveraging recent advancements in natural language proving, our TTS workflow efficiently bridges the gap between natural and formal languages. Compared to state-of-the-art methods, Seed-Prover 1.5 achieves superior performance with a smaller compute budget. It solves 88\\% of PutnamBench (undergraduate-level), 80\\% of Fate-H (graduate-level), and 33\\% of Fate-X (PhD-level) problems. Notably, using our system, we solved 11 out of 12 problems from Putnam 2025 within 9 hours. Our findings suggest that scaling learning from experience, driven by high-quality formal feedback, holds immense potential for the future of formal mathematical reasoning.",
            "upvotes": 36,
            "discussionId": "6948afc534f46eaf46cbb207",
            "ai_summary": "Seed-Prover 1.5, a formal theorem-proving model using large-scale agentic reinforcement learning and an efficient test-time scaling workflow, demonstrates superior performance in solving mathematical problems across various levels with reduced computational resources.",
            "ai_keywords": [
                "large language models",
                "theorem proving",
                "formal languages",
                "Lean",
                "reinforcement learning",
                "test-time scaling",
                "PutnamBench",
                "Fate-H",
                "Fate-X",
                "formal mathematical reasoning"
            ],
            "organization": {
                "_id": "67d1140985ea0644e2f14b99",
                "name": "ByteDance-Seed",
                "fullname": "ByteDance Seed",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6535c9e88bde2fae19b6fb25/flkDUqd_YEuFsjeNET3r-.png"
            }
        },
        "translation_title": "Seed-Prover 1.5: 경험 학습을 통한 학부 수준 정리 증명 능력 향상",
        "purpose": "학부 수준의 정리 증명을 위한 LLM의 효율적인 활용 및 성능 향상",
        "method": [
            "대규모 에이전트 강화 학습을 통해 훈련된 정리 증명 모델을 개발함(we present Seed-Prover 1.5, a formal theorem-proving model trained via large-scale agentic reinforcement learning.)",
            "Lean과 다른 도구와의 상호작용을 통해 경험을 지속적으로 축적하며 능력을 향상시킴(the model continuously accumulates experience during the RL process, substantially enhancing the capability and efficiency of formal theorem proving.)",
            "자연어 증명에서의 최신 기술을 활용하여 자연어와 형식 언어 간의 간극을 효과적으로 연결함(our TTS workflow efficiently bridges the gap between natural and formal languages.)"
        ],
        "conclusion": "Seed-Prover 1.5는 적은 컴퓨팅 자원으로도 뛰어난 성능을 보이며, 정리 증명에서 경험에서 학습하는 접근 방식이 큰 잠재력을 지닌다는 것을 보여줌.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Computer Vision"
        ]
    },
    {
        "paper": {
            "id": "2512.17012",
            "authors": [
                {
                    "_id": "6948aa3d34f46eaf46cbb1cb",
                    "name": "Chiao-An Yang",
                    "hidden": false
                },
                {
                    "_id": "6948aa3d34f46eaf46cbb1cc",
                    "name": "Ryo Hachiuma",
                    "hidden": false
                },
                {
                    "_id": "6948aa3d34f46eaf46cbb1cd",
                    "name": "Sifei Liu",
                    "hidden": false
                },
                {
                    "_id": "6948aa3d34f46eaf46cbb1ce",
                    "name": "Subhashree Radhakrishnan",
                    "hidden": false
                },
                {
                    "_id": "6948aa3d34f46eaf46cbb1cf",
                    "name": "Raymond A. Yeh",
                    "hidden": false
                },
                {
                    "_id": "6948aa3d34f46eaf46cbb1d0",
                    "name": "Yu-Chiang Frank Wang",
                    "hidden": false
                },
                {
                    "_id": "6948aa3d34f46eaf46cbb1d1",
                    "user": {
                        "_id": "64ae22dd1aee69ece065cdcd",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ae22dd1aee69ece065cdcd/JG7QaHIrr4i2k4uwR4pZK.png",
                        "isPro": false,
                        "fullname": "Min-Hung Chen",
                        "user": "cmhungsteve",
                        "type": "user"
                    },
                    "name": "Min-Hung Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-22T10:58:54.795Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-18T19:13:44.000Z",
            "submittedOnDailyAt": "2025-12-22T00:08:35.679Z",
            "title": "4D-RGPT: Toward Region-level 4D Understanding via Perceptual Distillation",
            "submittedOnDailyBy": {
                "_id": "64ae22dd1aee69ece065cdcd",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ae22dd1aee69ece065cdcd/JG7QaHIrr4i2k4uwR4pZK.png",
                "isPro": false,
                "fullname": "Min-Hung Chen",
                "user": "cmhungsteve",
                "type": "user"
            },
            "summary": "Despite advances in Multimodal LLMs (MLLMs), their ability to reason over 3D structures and temporal dynamics remains limited, constrained by weak 4D perception and temporal understanding. Existing 3D and 4D Video Question Answering (VQA) benchmarks also emphasize static scenes and lack region-level prompting. We tackle these issues by introducing: (a) 4D-RGPT, a specialized MLLM designed to capture 4D representations from video inputs with enhanced temporal perception; (b) Perceptual 4D Distillation (P4D), a training framework that transfers 4D representations from a frozen expert model into 4D-RGPT for comprehensive 4D perception; and (c) R4D-Bench, a benchmark for depth-aware dynamic scenes with region-level prompting, built via a hybrid automated and human-verified pipeline. Our 4D-RGPT achieves notable improvements on both existing 4D VQA benchmarks and the proposed R4D-Bench benchmark.",
            "upvotes": 26,
            "discussionId": "6948aa3d34f46eaf46cbb1d2",
            "projectPage": "https://ca-joe-yang.github.io/resource/projects/4D_RGPT",
            "ai_summary": "4D-RGPT, a specialized multimodal LLM, enhances 4D perception in video inputs through Perceptual 4D Distillation and is evaluated on R4D-Bench, a new benchmark for depth-aware dynamic scenes.",
            "ai_keywords": [
                "4D-RGPT",
                "Multimodal LLMs",
                "4D Video Question Answering",
                "4D representations",
                "Perceptual 4D Distillation",
                "R4D-Bench",
                "depth-aware",
                "dynamic scenes",
                "region-level prompting"
            ],
            "organization": {
                "_id": "60262b67268c201cdc8b7d43",
                "name": "nvidia",
                "fullname": "NVIDIA",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1613114437487-60262a8e0703121c822a80b6.png"
            }
        },
        "translation_title": "4D-RGPT: 지역 수준의 4D 이해를 위한 지각적 증류",
        "purpose": "3D 구조와 시간적 동역학에 대한 이해를 개선하고자 하는 목표.",
        "method": [
            "4D 비디오 입력에서 4D 표현을 캡처할 수 있도록 설계된 MLLM 모델인 4D-RGPT를 도입함(We tackle these issues by introducing: (a) 4D-RGPT, a specialized MLLM designed to capture 4D representations from video inputs with enhanced temporal perception;)",
            "P4D라는 훈련 프레임워크를 통해 4D 표현을 전문가 모델에서 4D-RGPT에 전이함( (b) Perceptual 4D Distillation (P4D), a training framework that transfers 4D representations from a frozen expert model into 4D-RGPT for comprehensive 4D perception;)",
            "지역 수준의 프롬프트가 있는 깊이 인식 동적 장면을 위한 새로운 벤치마크인 R4D-Bench를 생성함((c) R4D-Bench, a benchmark for depth-aware dynamic scenes with region-level prompting, built via a hybrid automated and human-verified pipeline.)"
        ],
        "conclusion": "4D-RGPT는 기존 4D VQA 벤치마크와 제안된 R4D-Bench 벤치마크 모두에서 눈에 띄는 개선을 달성함.",
        "keywords": [
            "Multimodal Learning",
            "3D Vision",
            "Video Understanding"
        ]
    }
]