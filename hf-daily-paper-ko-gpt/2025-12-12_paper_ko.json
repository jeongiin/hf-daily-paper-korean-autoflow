[
    {
        "paper": {
            "id": "2512.10430",
            "authors": [
                {
                    "_id": "693bba8d9874a2a5e4ffb3ab",
                    "user": {
                        "_id": "64f4c8739ee58d48e8507e0e",
                        "avatarUrl": "/avatars/4be540dfb4a949f37cba2d3c3729fbde.svg",
                        "isPro": false,
                        "fullname": "Dmitrii Stoianov",
                        "user": "heylimon",
                        "type": "user"
                    },
                    "name": "Dmitrii Stoianov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:40.198Z",
                    "hidden": false
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3ac",
                    "user": {
                        "_id": "64fb054ebb362cbf2fe53159",
                        "avatarUrl": "/avatars/936c37a77d46d0ea579d2f8a9aea9284.svg",
                        "isPro": false,
                        "fullname": "Danil Taranets",
                        "user": "taranetsdan",
                        "type": "user"
                    },
                    "name": "Danil Taranets",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:29.281Z",
                    "hidden": false
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3ad",
                    "user": {
                        "_id": "6612fe63da0c53de48c7ce3b",
                        "avatarUrl": "/avatars/207c80b5da078239371a31b17f63ccfd.svg",
                        "isPro": false,
                        "fullname": "Olga Tsymboi",
                        "user": "oltsy",
                        "type": "user"
                    },
                    "name": "Olga Tsymboi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:38.180Z",
                    "hidden": false
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3ae",
                    "user": {
                        "_id": "6780dcd6acf8d824c03864da",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/6PeN6OXbSq0M-L4OxFTrn.png",
                        "isPro": false,
                        "fullname": "Ramil Latypov",
                        "user": "kylecr4ne",
                        "type": "user"
                    },
                    "name": "Ramil Latypov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:23.437Z",
                    "hidden": false
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3af",
                    "user": {
                        "_id": "6513f03e86d74f32ed65e3b8",
                        "avatarUrl": "/avatars/c327966623f775a2d1f3d984ca162ef6.svg",
                        "isPro": false,
                        "fullname": "Almaz Dautov",
                        "user": "the-hir0",
                        "type": "user"
                    },
                    "name": "Almaz Dautov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:30.990Z",
                    "hidden": false
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3b0",
                    "user": {
                        "_id": "621a8daf325b927e60fcef08",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/621a8daf325b927e60fcef08/bM8W-of2u0yvL8FHeY2ra.jpeg",
                        "isPro": false,
                        "fullname": "Vladislav Kruglikov",
                        "user": "vladislavkruglikov",
                        "type": "user"
                    },
                    "name": "Vladislav Kruglikov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:21.170Z",
                    "hidden": false
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3b1",
                    "name": "Nikita Surkov",
                    "hidden": false
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3b2",
                    "user": {
                        "_id": "63188c428d698d8c1642a0d8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63188c428d698d8c1642a0d8/MlcBnU7CmnKdRF053JcY4.jpeg",
                        "isPro": false,
                        "fullname": "German Abramov",
                        "user": "germanjke",
                        "type": "user"
                    },
                    "name": "German Abramov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T12:59:28.579Z",
                    "hidden": false
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3b3",
                    "name": "Pavel Gein",
                    "hidden": false
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3b4",
                    "user": {
                        "_id": "636a9a07e3ad78bc68b1a5a2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1668020490988-636a9a07e3ad78bc68b1a5a2.jpeg",
                        "isPro": false,
                        "fullname": "Dmitry Abulkhanov",
                        "user": "mponty",
                        "type": "user"
                    },
                    "name": "Dmitry Abulkhanov",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-12-12T13:02:42.107Z",
                    "hidden": true
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3b5",
                    "user": {
                        "_id": "658bc20cfdf2279d4721f218",
                        "avatarUrl": "/avatars/5f1cb94373fbbbcfed9b848c5ebdd1ad.svg",
                        "isPro": false,
                        "fullname": "Mikhail Gashkov",
                        "user": "MikeGashkov",
                        "type": "user"
                    },
                    "name": "Mikhail Gashkov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:32.809Z",
                    "hidden": false
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3b6",
                    "name": "Viktor Zelenkovskiy",
                    "hidden": false
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3b7",
                    "user": {
                        "_id": "644f64bc17b6189cda54cae8",
                        "avatarUrl": "/avatars/f684a65b35a9be06cbb16fb8f44a4782.svg",
                        "isPro": false,
                        "fullname": "Artem Batalov",
                        "user": "batalovme",
                        "type": "user"
                    },
                    "name": "Artem Batalov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:27.497Z",
                    "hidden": false
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3b8",
                    "user": {
                        "_id": "62609d224e6e4b84475eb8d9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62609d224e6e4b84475eb8d9/PKQvuLm40PGg91VKRVSIb.jpeg",
                        "isPro": false,
                        "fullname": "Alex Medvedev",
                        "user": "kenkaneki",
                        "type": "user"
                    },
                    "name": "Aleksandr Medvedev",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:36.035Z",
                    "hidden": false
                },
                {
                    "_id": "693bba8d9874a2a5e4ffb3b9",
                    "user": {
                        "_id": "63f26358be95ed4c9a9b0583",
                        "avatarUrl": "/avatars/133f2d28c5e5139d61048dfef5e9f4ff.svg",
                        "isPro": false,
                        "fullname": "Anatoly Potapov",
                        "user": "AnatoliiPotapov",
                        "type": "user"
                    },
                    "name": "Anatolii Potapov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:25.666Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-11T08:40:10.000Z",
            "submittedOnDailyAt": "2025-12-12T08:33:32.798Z",
            "title": "T-pro 2.0: An Efficient Russian Hybrid-Reasoning Model and Playground",
            "submittedOnDailyBy": {
                "_id": "6612fe63da0c53de48c7ce3b",
                "avatarUrl": "/avatars/207c80b5da078239371a31b17f63ccfd.svg",
                "isPro": false,
                "fullname": "Olga Tsymboi",
                "user": "oltsy",
                "type": "user"
            },
            "summary": "We introduce T-pro 2.0, an open-weight Russian LLM for hybrid reasoning and efficient inference. The model supports direct answering and reasoning-trace generation, using a Cyrillic-dense tokenizer and an adapted EAGLE speculative-decoding pipeline to reduce latency. To enable reproducible and extensible research, we release the model weights, the T-Wix 500k instruction corpus, the T-Math reasoning benchmark, and the EAGLE weights on Hugging Face. These resources allow users to study Russian-language reasoning and to extend or adapt both the model and the inference pipeline. A public web demo exposes reasoning and non-reasoning modes and illustrates the speedups achieved by our inference stack across domains. T-pro 2.0 thus serves as an accessible open system for building and evaluating efficient, practical Russian LLM applications.",
            "upvotes": 56,
            "discussionId": "693bba8e9874a2a5e4ffb3ba",
            "ai_summary": "T-pro 2.0 is an open-weight Russian LLM for hybrid reasoning and efficient inference, using a Cyrillic-dense tokenizer and EAGLE speculative-decoding pipeline.",
            "ai_keywords": [
                "Cyrillic-dense tokenizer",
                "EAGLE speculative-decoding pipeline",
                "hybrid reasoning",
                "efficient inference",
                "reasoning-trace generation"
            ],
            "organization": {
                "_id": "675861e944dbb69c2673c71c",
                "name": "t-tech",
                "fullname": "T-Tech",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/674ea07d320a043daeb2d98b/IwSCMolFY4Otk7sFXzWhi.jpeg"
            }
        },
        "translation_title": "T-pro 2.0: 효율적인 러시아어 하이브리드 추론 모델과 플랫폼",
        "purpose": "효율적 추론 및 하이브리드 추론을 위한 공개 러시아어 LLM 개발",
        "method": [
            "Cyrillic에 최적화된 토크나이저와 EAGLE의 재정의 파이프라인을 사용하여 지연 시간을 줄임(Using a Cyrillic-dense tokenizer and an adapted EAGLE speculative-decoding pipeline to reduce latency.)",
            "모델 가중치, T-Wix 500k 지침 데이터셋, T-Math 추론 벤치마크, EAGLE 가중치를 Hugging Face에 공개하여 재현 가능한 연구 지원(We release the model weights, the T-Wix 500k instruction corpus, the T-Math reasoning benchmark, and the EAGLE weights on Hugging Face.)",
            "공공 웹 데모를 통해 추론 및 비추론 모드를 보여주고 다양한 분야에서의 속도 개선을 설명함(A public web demo exposes reasoning and non-reasoning modes and illustrates the speedups achieved by our inference stack across domains.)"
        ],
        "conclusion": "T-pro 2.0은 효율적이고 실용적인 러시아어 LLM 응용 프로그램의 구축 및 평가를 위한 접근 가능한 시스템으로 작용함.",
        "keywords": [
            "Large Language Models",
            "Natural Language Processing",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2512.10739",
            "authors": [
                {
                    "_id": "693b91d89874a2a5e4ffb329",
                    "name": "Songyang Gao",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb32a",
                    "user": {
                        "_id": "6601196cc91ba4c08ad6e270",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6601196cc91ba4c08ad6e270/venywO3WPi2fNi5WUJTH0.jpeg",
                        "isPro": false,
                        "fullname": "Yuzhe Gu",
                        "user": "vanilla1116",
                        "type": "user"
                    },
                    "name": "Yuzhe Gu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:56.632Z",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb32b",
                    "name": "Zijian Wu",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb32c",
                    "name": "Lingkai Kong",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb32d",
                    "user": {
                        "_id": "64e8505321540e1da3226b54",
                        "avatarUrl": "/avatars/18958b8406d1ce492b54c1c839f18c54.svg",
                        "isPro": false,
                        "fullname": "Wenwei Zhang",
                        "user": "ZwwWayne",
                        "type": "user"
                    },
                    "name": "Wenwei Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-12-12T13:03:21.987Z",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb32e",
                    "name": "Zhongrui Cai",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb32f",
                    "name": "Fan Zheng",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb330",
                    "user": {
                        "_id": "670f8df2005a358fdc6c2fb6",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/qw2yocepl2vhC5T2ae49b.png",
                        "isPro": false,
                        "fullname": "tianyou",
                        "user": "matianyou",
                        "type": "user"
                    },
                    "name": "Tianyou Ma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-12-12T13:03:57.205Z",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb331",
                    "user": {
                        "_id": "687f853bb39262ba84f3eeff",
                        "avatarUrl": "/avatars/cdfc44fde8237f08f10192553fe5a075.svg",
                        "isPro": false,
                        "fullname": "Junhao Shen",
                        "user": "shenjunhao",
                        "type": "user"
                    },
                    "name": "Junhao Shen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:15:00.496Z",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb332",
                    "name": "Haiteng Zhao",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb333",
                    "user": {
                        "_id": "6454b1073aaeff9f3d330ef6",
                        "avatarUrl": "/avatars/331fcbbf18a72b0dc8419ca3a77299bb.svg",
                        "isPro": false,
                        "fullname": "Duanyang Zhang",
                        "user": "KKKDaniel",
                        "type": "user"
                    },
                    "name": "Duanyang Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-12-12T13:04:12.911Z",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb334",
                    "name": "Huilun Zhang",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb335",
                    "user": {
                        "_id": "63fd691794cc8f815d50c112",
                        "avatarUrl": "/avatars/87305d1cbfcc717e910ccdfaf0568f80.svg",
                        "isPro": false,
                        "fullname": "liu",
                        "user": "Harold-lkk",
                        "type": "user"
                    },
                    "name": "Kuikun Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:58.650Z",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb336",
                    "name": "Chengqi Lyu",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb337",
                    "name": "Yanhui Duan",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb338",
                    "name": "Chiyu Chen",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb339",
                    "name": "Ningsheng Ma",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb33a",
                    "name": "Jianfei Gao",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb33b",
                    "name": "Han Lyu",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb33c",
                    "user": {
                        "_id": "636317ed80c1a705a6eff396",
                        "avatarUrl": "/avatars/3db090e101b916d9256d0d3e043db71d.svg",
                        "isPro": false,
                        "fullname": "Dahua Lin",
                        "user": "lindahua",
                        "type": "user"
                    },
                    "name": "Dahua Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-12-12T13:04:20.346Z",
                    "hidden": false
                },
                {
                    "_id": "693b91d89874a2a5e4ffb33d",
                    "name": "Kai Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-11T15:26:28.000Z",
            "submittedOnDailyAt": "2025-12-12T01:27:55.307Z",
            "title": "Long-horizon Reasoning Agent for Olympiad-Level Mathematical Problem Solving",
            "submittedOnDailyBy": {
                "_id": "6601196cc91ba4c08ad6e270",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6601196cc91ba4c08ad6e270/venywO3WPi2fNi5WUJTH0.jpeg",
                "isPro": false,
                "fullname": "Yuzhe Gu",
                "user": "vanilla1116",
                "type": "user"
            },
            "summary": "Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the Outcome-based Process Verifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out \\thisbench, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2\\% to 73.3\\% on AIME2025 as the compute budget scales.",
            "upvotes": 37,
            "discussionId": "693b91d99874a2a5e4ffb33e",
            "ai_summary": "OPV, an iterative active learning framework with Rejection Fine-Tuning, enhances verification of long reasoning chains in large language models, achieving state-of-the-art results and improving accuracy in collaborative tasks.",
            "ai_keywords": [
                "Reinforcement Learning with Verifiable Rewards (RLVR)",
                "outcome-based verifiers (OVs)",
                "process-based verifiers (PVs)",
                "long reasoning chains of thought (CoTs)",
                "iterative active learning",
                "Rejection Fine-Tuning (RFT)",
                "F1 score",
                "accuracy",
                "DeepSeek-R1-Distill-Qwen-32B",
                "AIME2025"
            ],
            "organization": {
                "_id": "6747ee5decec679eafb90450",
                "name": "ShanghaiAiLab",
                "fullname": "shanghai ailab "
            }
        },
        "translation_title": "올림피아드 수준 수학 문제 해결을 위한 장기 추론 에이전트",
        "purpose": "장기 추론 체인의 신뢰할 수 없는 중간 단계를 확인할 수 있는 검증 도구 개발",
        "method": [
            "Outcome-based Process Verifier (OPV)를 제안하여 장기 추론 체인의 결과를 검증하는 방식으로 정확하고 효율적인 검증 가능하게 함(To achieve both accurate and efficient verification, we propose the Outcome-based Process Verifier (OPV).)",
            "전문가 주석을 포함한 반복적 능동 학습 프레임워크를 채택하여 OPV의 검증 능력을 향상시킴(To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs.)",
            "Rejection Fine-Tuning (RFT)와 Reinforcement Learning with Verifiable Rewards (RLVR)를 통해 OPV를 점진적으로 훈련함(Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round.)"
        ],
        "conclusion": "OPV는 새로운 최첨단 성과를 달성하며, DeepSeek-R1-Distill-Qwen-32B 모델의 정확도를 55.2%에서 73.3%로 향상시키는 데 기여하였음.",
        "keywords": [
            "Large Language Models",
            "Reinforcement Learning",
            "Document Parsing"
        ]
    },
    {
        "paper": {
            "id": "2512.10949",
            "authors": [
                {
                    "_id": "693b895d9874a2a5e4ffb302",
                    "user": {
                        "_id": "6552f1ad5d55ccb20e9142a0",
                        "avatarUrl": "/avatars/0e3e80cba64b5ae0bc5638694ac33dbf.svg",
                        "isPro": false,
                        "fullname": "Ivan Tang",
                        "user": "IvanTang",
                        "type": "user"
                    },
                    "name": "Yiwen Tang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-12-12T13:04:55.504Z",
                    "hidden": false
                },
                {
                    "_id": "693b895d9874a2a5e4ffb303",
                    "user": {
                        "_id": "642a8302d651bae3c11b72b1",
                        "avatarUrl": "/avatars/4d2d422613e274d80482fed9a7d3f785.svg",
                        "isPro": false,
                        "fullname": "Zoey Guo",
                        "user": "Purple1288",
                        "type": "user"
                    },
                    "name": "Zoey Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-12-12T13:05:01.705Z",
                    "hidden": false
                },
                {
                    "_id": "693b895d9874a2a5e4ffb304",
                    "user": {
                        "_id": "6708920aeae29d1cd41a703b",
                        "avatarUrl": "/avatars/922427a86523b0aa810412fd2d75f88e.svg",
                        "isPro": false,
                        "fullname": "kaixin zhu",
                        "user": "czkk566",
                        "type": "user"
                    },
                    "name": "Kaixin Zhu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:16:10.275Z",
                    "hidden": false
                },
                {
                    "_id": "693b895d9874a2a5e4ffb305",
                    "name": "Ray Zhang",
                    "hidden": false
                },
                {
                    "_id": "693b895d9874a2a5e4ffb306",
                    "user": {
                        "_id": "6535045a910b844786a6642f",
                        "avatarUrl": "/avatars/37a94864a7a348151837b421ea6d77e3.svg",
                        "isPro": false,
                        "fullname": "Qizhi Chen",
                        "user": "Tavish9",
                        "type": "user"
                    },
                    "name": "Qizhi Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-12-12T13:05:11.060Z",
                    "hidden": false
                },
                {
                    "_id": "693b895d9874a2a5e4ffb307",
                    "user": {
                        "_id": "6349214f8146350b3a4c5cdf",
                        "avatarUrl": "/avatars/cfd24caac9a87efb528d0f4c375932bc.svg",
                        "isPro": false,
                        "fullname": "Dongzhi Jiang",
                        "user": "CaraJ",
                        "type": "user"
                    },
                    "name": "Dongzhi Jiang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-12-12T13:06:02.910Z",
                    "hidden": false
                },
                {
                    "_id": "693b895d9874a2a5e4ffb308",
                    "name": "Junli Liu",
                    "hidden": false
                },
                {
                    "_id": "693b895d9874a2a5e4ffb309",
                    "user": {
                        "_id": "6671214c92412fd4640714eb",
                        "avatarUrl": "/avatars/48fa84e7bc3bb92ad0192aa26b32de10.svg",
                        "isPro": false,
                        "fullname": "bohan zeng",
                        "user": "zbhpku",
                        "type": "user"
                    },
                    "name": "Bohan Zeng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:15:08.733Z",
                    "hidden": false
                },
                {
                    "_id": "693b895d9874a2a5e4ffb30a",
                    "user": {
                        "_id": "6662d2c9de4c4e1f04bd29c7",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/QnnO_KOyZjFd-iXuPnHqR.png",
                        "isPro": false,
                        "fullname": "HaomingSong",
                        "user": "HaomingSong",
                        "type": "user"
                    },
                    "name": "Haoming Song",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-12-12T13:05:30.062Z",
                    "hidden": false
                },
                {
                    "_id": "693b895d9874a2a5e4ffb30b",
                    "user": {
                        "_id": "64daecec888b7e9c400f59b5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64daecec888b7e9c400f59b5/f4pfOfWk6jYJX-Nf2-qHn.png",
                        "isPro": false,
                        "fullname": "Delin Qu",
                        "user": "delinqu",
                        "type": "user"
                    },
                    "name": "Delin Qu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:16:34.085Z",
                    "hidden": false
                },
                {
                    "_id": "693b895d9874a2a5e4ffb30c",
                    "name": "Tianyi Bai",
                    "hidden": false
                },
                {
                    "_id": "693b895d9874a2a5e4ffb30d",
                    "name": "Dan Xu",
                    "hidden": false
                },
                {
                    "_id": "693b895d9874a2a5e4ffb30e",
                    "name": "Wentao Zhang",
                    "hidden": false
                },
                {
                    "_id": "693b895d9874a2a5e4ffb30f",
                    "name": "Bin Zhao",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-11T18:59:52.000Z",
            "submittedOnDailyAt": "2025-12-12T00:49:43.850Z",
            "title": "Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation",
            "submittedOnDailyBy": {
                "_id": "6552f1ad5d55ccb20e9142a0",
                "avatarUrl": "/avatars/0e3e80cba64b5ae0bc5638694ac33dbf.svg",
                "isPro": false,
                "fullname": "Ivan Tang",
                "user": "IvanTang",
                "type": "user"
            },
            "summary": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.",
            "upvotes": 35,
            "discussionId": "693b895d9874a2a5e4ffb310",
            "githubRepo": "https://github.com/Ivan-Tang-3D/3DGen-R1",
            "githubRepoAddedBy": "user",
            "ai_summary": "This study investigates reinforcement learning for text-to-3D generation, focusing on reward designs, RL algorithms, benchmarking, and hierarchical optimization, introducing AR3D-R1 as the first RL-enhanced model for 3D generation.",
            "ai_keywords": [
                "reinforcement learning",
                "text-to-3D generation",
                "reward designs",
                "GRPO variants",
                "token-level optimization",
                "MME-3DR",
                "Hi-GRPO",
                "hierarchical 3D generation",
                "AR3D-R1"
            ],
            "githubStars": 37,
            "organization": {
                "_id": "6747ee5decec679eafb90450",
                "name": "ShanghaiAiLab",
                "fullname": "shanghai ailab "
            }
        },
        "translation_title": "텍스트에서 3D 생성으로의 RL 준비가 되었는가? 점진적인 조사",
        "purpose": "3D 생성에서 RL을 적용하기 위한 도전 과제를 해결하고 RL 기반 모델을 개발하기 위함",
        "method": [
            "여러 보상 차원과 모델 선택을 평가하여 인간 선호와의 정렬이 중요함을 보여줌(We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes.)",
            "GRPO 변형을 연구하여 토큰 수준 최적화의 효과를 강조하고, 학습 데이터와 반복의 크기를 조사함(We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations.)",
            "MME-3DR이라는 새로운 벤치마크를 도입하여 기존 벤치마크의 한계를 극복함(we introduce MME-3DR.)",
            "Hi-GRPO라는 고급 RL 패러다임을 제안하여 글로벌-로컬 3D 생성을 최적화함(we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles.)"
        ],
        "conclusion": "이 연구는 3D 생성에서 RL 기반 추론에 대한 인사이트를 제공하며, AR3D-R1이라는 첫 번째 RL 향상 텍스트-투-3D 모델을 개발함.",
        "keywords": [
            "Computer Vision",
            "Image Generation",
            "3D Vision"
        ]
    },
    {
        "paper": {
            "id": "2512.10756",
            "authors": [
                {
                    "_id": "693b91539874a2a5e4ffb318",
                    "name": "Zijian Wu",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb319",
                    "name": "Lingkai Kong",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb31a",
                    "name": "Wenwei Zhang",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb31b",
                    "name": "Songyang Gao",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb31c",
                    "user": {
                        "_id": "6601196cc91ba4c08ad6e270",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6601196cc91ba4c08ad6e270/venywO3WPi2fNi5WUJTH0.jpeg",
                        "isPro": false,
                        "fullname": "Yuzhe Gu",
                        "user": "vanilla1116",
                        "type": "user"
                    },
                    "name": "Yuzhe Gu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:15:02.946Z",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb31d",
                    "name": "Zhongrui Cai",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb31e",
                    "name": "Tianyou Ma",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb31f",
                    "name": "Yuhong Liu",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb320",
                    "name": "Zhi Wang",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb321",
                    "name": "Runyuan Ma",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb322",
                    "name": "Guangyu Wang",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb323",
                    "name": "Wei Li",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb324",
                    "name": "Conghui He",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb325",
                    "name": "Dahua Lin",
                    "hidden": false
                },
                {
                    "_id": "693b91539874a2a5e4ffb326",
                    "name": "Kai Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-11T15:47:38.000Z",
            "submittedOnDailyAt": "2025-12-12T01:23:10.732Z",
            "title": "OPV: Outcome-based Process Verifier for Efficient Long Chain-of-Thought Verification",
            "submittedOnDailyBy": {
                "_id": "6601196cc91ba4c08ad6e270",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6601196cc91ba4c08ad6e270/venywO3WPi2fNi5WUJTH0.jpeg",
                "isPro": false,
                "fullname": "Yuzhe Gu",
                "user": "vanilla1116",
                "type": "user"
            },
            "summary": "Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the Outcome-based Process Verifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out OPV-Bench, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2% to 73.3% on AIME2025 as the compute budget scales.",
            "upvotes": 30,
            "discussionId": "693b91539874a2a5e4ffb327",
            "ai_summary": "The Outcome-based Process Verifier (OPV) improves the verification of complex reasoning chains in large language models by combining outcome-based and process-based verification with iterative active learning and Rejection Fine-Tuning, achieving state-of-the-art performance on various benchmarks.",
            "ai_keywords": [
                "Reinforcement Learning with Verifiable Rewards (RLVR)",
                "verifiers",
                "outcome-based verifiers (OVs)",
                "process-based verifiers (PVs)",
                "CoTs",
                "iterative active learning",
                "Rejection Fine-Tuning (RFT)",
                "OPV-Bench",
                "AIME2025",
                "DeepSeek-R1-Distill-Qwen-32B"
            ],
            "organization": {
                "_id": "6747ee5decec679eafb90450",
                "name": "ShanghaiAiLab",
                "fullname": "shanghai ailab "
            }
        },
        "translation_title": "OPV: 효율적인 긴 연쇄 사고 검증을 위한 결과 기반 과정 검증기",
        "purpose": "긴 연쇄 사고의 중간 단계를 신뢰할 수 있도록 검증하기 위한 새로운 접근 방식 제안",
        "method": [
            "Outcome-based Process Verifier (OPV)를 제안하고 긴 연쇄 사고의 요약된 결과를 검증함(Therefore, we propose the Outcome-based Process Verifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation.)",
            "전문가 주석을 활용한 반복적 능동 학습 프레임워크를 도입하여 검증 능력을 점진적으로 향상시킴(To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs.)",
            "가장 불확실한 경우를 주석 처리하고 이를 통해 새로운 OPV를 훈련하는 과정 수행(Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round.)"
        ],
        "conclusion": "OPV는 기존 모델보다 우수한 성능을 발휘하며, 정책 모델과 협력할 때 지속적인 성능 향상을 달성함.",
        "keywords": [
            "Large Language Models",
            "Natural Language Processing",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2512.10534",
            "authors": [
                {
                    "_id": "693b94359874a2a5e4ffb340",
                    "name": "Haiteng Zhao",
                    "hidden": false
                },
                {
                    "_id": "693b94359874a2a5e4ffb341",
                    "user": {
                        "_id": "687f853bb39262ba84f3eeff",
                        "avatarUrl": "/avatars/cdfc44fde8237f08f10192553fe5a075.svg",
                        "isPro": false,
                        "fullname": "Junhao Shen",
                        "user": "shenjunhao",
                        "type": "user"
                    },
                    "name": "Junhao Shen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:51.355Z",
                    "hidden": false
                },
                {
                    "_id": "693b94359874a2a5e4ffb342",
                    "user": {
                        "_id": "64ccaa4687ec96aa4752e754",
                        "avatarUrl": "/avatars/d2dd2040a521de4f55c7335cb7771c75.svg",
                        "isPro": false,
                        "fullname": "Yiming Zhang",
                        "user": "ymzhang319",
                        "type": "user"
                    },
                    "name": "Yiming Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T12:59:27.118Z",
                    "hidden": false
                },
                {
                    "_id": "693b94359874a2a5e4ffb343",
                    "name": "Songyang Gao",
                    "hidden": false
                },
                {
                    "_id": "693b94359874a2a5e4ffb344",
                    "user": {
                        "_id": "63fd691794cc8f815d50c112",
                        "avatarUrl": "/avatars/87305d1cbfcc717e910ccdfaf0568f80.svg",
                        "isPro": false,
                        "fullname": "liu",
                        "user": "Harold-lkk",
                        "type": "user"
                    },
                    "name": "Kuikun Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-12-12T09:14:54.577Z",
                    "hidden": false
                },
                {
                    "_id": "693b94359874a2a5e4ffb345",
                    "name": "Tianyou Ma",
                    "hidden": false
                },
                {
                    "_id": "693b94359874a2a5e4ffb346",
                    "name": "Fan Zheng",
                    "hidden": false
                },
                {
                    "_id": "693b94359874a2a5e4ffb347",
                    "name": "Dahua Lin",
                    "hidden": false
                },
                {
                    "_id": "693b94359874a2a5e4ffb348",
                    "name": "Wenwei Zhang",
                    "hidden": false
                },
                {
                    "_id": "693b94359874a2a5e4ffb349",
                    "name": "Kai Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-11T11:05:04.000Z",
            "submittedOnDailyAt": "2025-12-12T03:29:52.050Z",
            "title": "Achieving Olympia-Level Geometry Large Language Model Agent via Complexity Boosting Reinforcement Learning",
            "submittedOnDailyBy": {
                "_id": "6601196cc91ba4c08ad6e270",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6601196cc91ba4c08ad6e270/venywO3WPi2fNi5WUJTH0.jpeg",
                "isPro": false,
                "fullname": "Yuzhe Gu",
                "user": "vanilla1116",
                "type": "user"
            },
            "summary": "Large language model (LLM) agents exhibit strong mathematical problem-solving abilities and can even solve International Mathematical Olympiad (IMO) level problems with the assistance of formal proof systems. However, due to weak heuristics for auxiliary constructions, AI for geometry problem solving remains dominated by expert models such as AlphaGeometry 2, which rely heavily on large-scale data synthesis and search for both training and evaluation. In this work, we make the first attempt to build a medalist-level LLM agent for geometry and present InternGeometry. InternGeometry overcomes the heuristic limitations in geometry by iteratively proposing propositions and auxiliary constructions, verifying them with a symbolic engine, and reflecting on the engine's feedback to guide subsequent proposals. A dynamic memory mechanism enables InternGeometry to conduct more than two hundred interactions with the symbolic engine per problem. To further accelerate learning, we introduce Complexity-Boosting Reinforcement Learning (CBRL), which gradually increases the complexity of synthesized problems across training stages. Built on InternThinker-32B, InternGeometry solves 44 of 50 IMO geometry problems (2000-2024), exceeding the average gold medalist score (40.9), using only 13K training examples, just 0.004% of the data used by AlphaGeometry 2, demonstrating the potential of LLM agents on expert-level geometry tasks. InternGeometry can also propose novel auxiliary constructions for IMO problems that do not appear in human solutions. We will release the model, data, and symbolic engine to support future research.",
            "upvotes": 24,
            "discussionId": "693b94359874a2a5e4ffb34a",
            "ai_summary": "InternGeometry, an LLM agent, surpasses human performance on IMO geometry problems using a heuristic-driven approach with iterative proposition verification and a dynamic memory mechanism, significantly outperforming AlphaGeometry 2 with limited training data.",
            "ai_keywords": [
                "LLM agents",
                "mathematical problem-solving",
                "International Mathematical Olympiad",
                "AI for geometry",
                "AlphaGeometry 2",
                "large-scale data synthesis",
                "search",
                "heuristic limitations",
                "propositions",
                "auxiliary constructions",
                "symbolic engine",
                "dynamic memory mechanism",
                "Complexity-Boosting Reinforcement Learning",
                "CBRL",
                "training examples",
                "InternThinker-32B",
                "expert-level geometry tasks"
            ],
            "organization": {
                "_id": "6747ee5decec679eafb90450",
                "name": "ShanghaiAiLab",
                "fullname": "shanghai ailab "
            }
        },
        "translation_title": "복잡성 향상 강화 학습을 통한 올림피아 수준의 기하학 대형 언어 모델 에이전트 달성",
        "purpose": "기하학 문제 해결에 있어 전문가 모델에 필적하는 성능을 가진 LLM 에이전트를 개발하기 위한 연구",
        "method": [
            "기하학의 한계점을 극복하기 위해 제안과 보조 구조를 반복적으로 제안하고, 이를 기호 엔진으로 검증함(InternGeometry overcomes the heuristic limitations in geometry by iteratively proposing propositions and auxiliary constructions, verifying them with a symbolic engine.)",
            "복잡성 향상 강화를 통해 훈련 단계에 따라 합성 문제의 복잡성을 점진적으로 증가시키는 방법을 도입함(We introduce Complexity-Boosting Reinforcement Learning (CBRL), which gradually increases the complexity of synthesized problems across training stages.)",
            "상징적 엔진과의 상호작용을 통해 각 문제에 대해 200회 이상의 상호작용을 수행 가능하게 하는 동적 기억 메커니즘을 활용함(A dynamic memory mechanism enables InternGeometry to conduct more than two hundred interactions with the symbolic engine per problem.)"
        ],
        "conclusion": "InternGeometry는 50개의 IMO 기하학 문제 중 44개를 해결하며, 전문가 수준의 기하학 과제를 수행할 수 있는 LLM 에이전트의 가능성을 입증함.",
        "keywords": [
            "Large Language Models",
            "Robotics",
            "Computer Vision"
        ]
    }
]