[
    {
        "paper": {
            "id": "2509.13312",
            "authors": [
                {
                    "_id": "68ca16756e0073c09bd1de0f",
                    "user": {
                        "_id": "64d31c55d8b712baf198602f",
                        "avatarUrl": "/avatars/fad7972744f879116a8dc8b406f8b91c.svg",
                        "isPro": false,
                        "fullname": "Zijian Li",
                        "user": "zli999",
                        "type": "user"
                    },
                    "name": "Zijian Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-17T12:56:59.945Z",
                    "hidden": false
                },
                {
                    "_id": "68ca16756e0073c09bd1de10",
                    "name": "Xin Guan",
                    "hidden": false
                },
                {
                    "_id": "68ca16756e0073c09bd1de11",
                    "name": "Bo Zhang",
                    "hidden": false
                },
                {
                    "_id": "68ca16756e0073c09bd1de12",
                    "name": "Shen Huang",
                    "hidden": false
                },
                {
                    "_id": "68ca16756e0073c09bd1de13",
                    "name": "Houquan Zhou",
                    "hidden": false
                },
                {
                    "_id": "68ca16756e0073c09bd1de14",
                    "name": "Shaopeng Lai",
                    "hidden": false
                },
                {
                    "_id": "68ca16756e0073c09bd1de15",
                    "name": "Ming Yan",
                    "hidden": false
                },
                {
                    "_id": "68ca16756e0073c09bd1de16",
                    "name": "Yong Jiang",
                    "hidden": false
                },
                {
                    "_id": "68ca16756e0073c09bd1de17",
                    "name": "Pengjun Xie",
                    "hidden": false
                },
                {
                    "_id": "68ca16756e0073c09bd1de18",
                    "name": "Fei Huang",
                    "hidden": false
                },
                {
                    "_id": "68ca16756e0073c09bd1de19",
                    "name": "Jun Zhang",
                    "hidden": false
                },
                {
                    "_id": "68ca16756e0073c09bd1de1a",
                    "name": "Jingren Zhou",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-16T17:57:21.000Z",
            "submittedOnDailyAt": "2025-09-17T00:31:34.945Z",
            "title": "WebWeaver: Structuring Web-Scale Evidence with Dynamic Outlines for\n  Open-Ended Deep Research",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "This paper tackles open-ended deep research (OEDR), a complex challenge where\nAI agents must synthesize vast web-scale information into insightful reports.\nCurrent approaches are plagued by dual-fold limitations: static research\npipelines that decouple planning from evidence acquisition and one-shot\ngeneration paradigms that easily suffer from long-context failure issues like\n\"loss in the middle\" and hallucinations. To address these challenges, we\nintroduce WebWeaver, a novel dual-agent framework that emulates the human\nresearch process. The planner operates in a dynamic cycle, iteratively\ninterleaving evidence acquisition with outline optimization to produce a\ncomprehensive, source-grounded outline linking to a memory bank of evidence.\nThe writer then executes a hierarchical retrieval and writing process,\ncomposing the report section by section. By performing targeted retrieval of\nonly the necessary evidence from the memory bank for each part, it effectively\nmitigates long-context issues. Our framework establishes a new state-of-the-art\nacross major OEDR benchmarks, including DeepResearch Bench, DeepConsult, and\nDeepResearchGym. These results validate our human-centric, iterative\nmethodology, demonstrating that adaptive planning and focused synthesis are\ncrucial for producing high-quality, reliable, and well-structured reports.",
            "upvotes": 73,
            "discussionId": "68ca16756e0073c09bd1de1b",
            "projectPage": "https://tongyi-agent.github.io/blog/",
            "githubRepo": "https://github.com/Alibaba-NLP/DeepResearch",
            "ai_summary": "WebWeaver, a dual-agent framework, addresses open-ended deep research challenges by integrating adaptive planning and focused synthesis to produce high-quality, reliable reports.",
            "ai_keywords": [
                "open-ended deep research",
                "AI agents",
                "static research pipelines",
                "one-shot generation",
                "long-context failure",
                "loss in the middle",
                "hallucinations",
                "dual-agent framework",
                "human research process",
                "planner",
                "evidence acquisition",
                "outline optimization",
                "memory bank",
                "writer",
                "hierarchical retrieval",
                "writing process",
                "DeepResearch Bench",
                "DeepConsult",
                "DeepResearchGym"
            ],
            "githubStars": 7308
        },
        "translation_title": "WebWeaver: 열린 심층 연구를 위한 동적 개요를 통한 웹 규모 증거 구조화",
        "purpose": "AI 에이전트가 방대한 웹 정보를 통합하여 통찰력 있는 보고서를 작성하도록 지원하기 위한 새로운 방법론 개발",
        "method": [
            "WebWeaver라는 이중 에이전트 프레임워크를 통해 연구 과정 모사(we introduce WebWeaver, a novel dual-agent framework that emulates the human research process.)",
            "계획 및 증거 수집을 동적으로 반복하며 포괄적이고 출처 기반의 개요 생성(Planned operates in a dynamic cycle, iteratively interleaving evidence acquisition with outline optimization to produce a comprehensive, source-grounded outline.)",
            "필요한 증거를 메모리 뱅크에서 직접 검색하여 보고서를 작성(performing targeted retrieval of only the necessary evidence from the memory bank for each part, it effectively mitigates long-context issues.)"
        ],
        "conclusion": "우리의 프레임워크는 주요 OEDR 벤치마크에서 새로운 최첨단 결과를 Establish하고, 적응형 계획과 집중적인 합성이 고품질의 신뢰할 수 있는 보고서를 작성하는 데 중요함을 입증함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Document Parsing"
        ]
    },
    {
        "paper": {
            "id": "2509.13310",
            "authors": [
                {
                    "_id": "68ca3cbe6e0073c09bd1df42",
                    "user": {
                        "_id": "677f945ea82c316db164a180",
                        "avatarUrl": "/avatars/50ec99d971564944de3b1d9c17d50cfd.svg",
                        "isPro": false,
                        "fullname": "Liangcai Su",
                        "user": "HKU-Liangcai",
                        "type": "user"
                    },
                    "name": "Liangcai Su",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-17T12:47:38.981Z",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df43",
                    "name": "Zhen Zhang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df44",
                    "name": "Guangyu Li",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df45",
                    "name": "Zhuo Chen",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df46",
                    "name": "Chenxi Wang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df47",
                    "name": "Maojia Song",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df48",
                    "name": "Xinyu Wang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df49",
                    "name": "Kuan Li",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df4a",
                    "user": {
                        "_id": "644a4fbc2166258fccc664bc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/8k3b44MbhQiWuo6i8BnYl.jpeg",
                        "isPro": false,
                        "fullname": "Jialong Wu",
                        "user": "callanwu",
                        "type": "user"
                    },
                    "name": "Jialong Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-17T12:47:36.751Z",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df4b",
                    "user": {
                        "_id": "65e6970d135c27ea806526fe",
                        "avatarUrl": "/avatars/4aced113d9cab055ae06f3945869a280.svg",
                        "isPro": false,
                        "fullname": "Xuanzhong Chen",
                        "user": "chenxz",
                        "type": "user"
                    },
                    "name": "Xuanzhong Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-17T12:47:41.195Z",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df4c",
                    "name": "Zile Qiao",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df4d",
                    "name": "Zhongwang Zhang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df4e",
                    "name": "Huifeng Yin",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df4f",
                    "name": "Shihao Cai",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df50",
                    "name": "Runnan Fang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df51",
                    "name": "Zhengwei Tao",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df52",
                    "name": "Wenbiao Yin",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df53",
                    "name": "Chenxiong Qian",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df54",
                    "name": "Yong Jiang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df55",
                    "name": "Pengjun Xie",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df56",
                    "name": "Fei Huang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cbe6e0073c09bd1df57",
                    "name": "Jingren Zhou",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-16T17:57:19.000Z",
            "submittedOnDailyAt": "2025-09-17T03:17:41.951Z",
            "title": "Scaling Agents via Continual Pre-training",
            "submittedOnDailyBy": {
                "_id": "644a4fbc2166258fccc664bc",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/8k3b44MbhQiWuo6i8BnYl.jpeg",
                "isPro": false,
                "fullname": "Jialong Wu",
                "user": "callanwu",
                "type": "user"
            },
            "summary": "Large language models (LLMs) have evolved into agentic systems capable of\nautonomous tool use and multi-step reasoning for complex problem-solving.\nHowever, post-training approaches building upon general-purpose foundation\nmodels consistently underperform in agentic tasks, particularly in open-source\nimplementations. We identify the root cause: the absence of robust agentic\nfoundation models forces models during post-training to simultaneously learn\ndiverse agentic behaviors while aligning them to expert demonstrations, thereby\ncreating fundamental optimization tensions. To this end, we are the first to\npropose incorporating Agentic Continual Pre-training (Agentic CPT) into the\ndeep research agents training pipeline to build powerful agentic foundational\nmodels. Based on this approach, we develop a deep research agent model named\nAgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks and achieve\nstate-of-the-art performance while retains strong tool-use ability, notably\n39.9% on BrowseComp-en, 43.3% on BrowseComp-zh, and 31.5% Pass@1 on HLE.",
            "upvotes": 58,
            "discussionId": "68ca3cbe6e0073c09bd1df58",
            "projectPage": "https://tongyi-agent.github.io/blog/",
            "githubRepo": "https://github.com/Alibaba-NLP/DeepResearch///",
            "ai_summary": "AgentFounder, a deep research agent model incorporating Agentic Continual Pre-training, achieves state-of-the-art performance in agentic tasks while maintaining strong tool-use ability.",
            "ai_keywords": [
                "Large language models",
                "agentic systems",
                "autonomous tool use",
                "multi-step reasoning",
                "post-training approaches",
                "general-purpose foundation models",
                "agentic foundation models",
                "Agentic Continual Pre-training",
                "deep research agents",
                "AgentFounder",
                "BrowseComp-en",
                "BrowseComp-zh",
                "HLE"
            ],
            "githubStars": 7308
        },
        "translation_title": "에이전트를 지속적으로 사전 훈련하여 확장하기",
        "purpose": "에이전틱 작업을 위한 강력한 기초 모델을 구축하기 위해 지속적인 사전 훈련을 적용",
        "method": [
            "일반용 기초 모델의 부재가 에이전틱 작업에서 성능 저하를 초래하였음을 확인함(The absence of robust agentic foundation models forces models during post-training to learn diverse agentic behaviors while aligning them to expert demonstrations.)",
            "에이전틱 지속적 사전 훈련(Agentic CPT)을 훈련 파이프라인에 통합하여 강력한 에이전틱 기초 모델을 제안함(To this end, we are the first to propose incorporating Agentic Continual Pre-training (Agentic CPT) into the deep research agents training pipeline.)",
            "AgentFounder라는 딥 리서치 에이전트 모델을 개발하고 10개의 벤치마크에서 평가함(Based on this approach, we develop a deep research agent model named AgentFounder. We evaluate our AgentFounder-30B on 10 benchmarks.)"
        ],
        "conclusion": "AgentFounder는 최첨단 성능을 달성하며 강력한 도구 사용 능력을 유지함.",
        "keywords": [
            "Large Language Models",
            "Multimodal Learning",
            "Robotics"
        ]
    },
    {
        "paper": {
            "id": "2509.13305",
            "authors": [
                {
                    "_id": "68ca3cd06e0073c09bd1df5a",
                    "name": "Kuan Li",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df5b",
                    "name": "Zhongwang Zhang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df5c",
                    "name": "Huifeng Yin",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df5d",
                    "name": "Rui Ye",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df5e",
                    "name": "Yida Zhao",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df5f",
                    "name": "Liwen Zhang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df60",
                    "name": "Litu Ou",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df61",
                    "name": "Dingchu Zhang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df62",
                    "user": {
                        "_id": "6622132f63598534f96ca29d",
                        "avatarUrl": "/avatars/34e61fc3101f8ebce1ef7041f761e108.svg",
                        "isPro": false,
                        "fullname": "Xixi Wu",
                        "user": "xxwu",
                        "type": "user"
                    },
                    "name": "Xixi Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-17T12:47:32.127Z",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df63",
                    "user": {
                        "_id": "644a4fbc2166258fccc664bc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/8k3b44MbhQiWuo6i8BnYl.jpeg",
                        "isPro": false,
                        "fullname": "Jialong Wu",
                        "user": "callanwu",
                        "type": "user"
                    },
                    "name": "Jialong Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-17T12:47:34.465Z",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df64",
                    "name": "Xinyu Wang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df65",
                    "name": "Zile Qiao",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df66",
                    "name": "Zhen Zhang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df67",
                    "name": "Yong Jiang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df68",
                    "name": "Pengjun Xie",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df69",
                    "name": "Fei Huang",
                    "hidden": false
                },
                {
                    "_id": "68ca3cd06e0073c09bd1df6a",
                    "name": "Jingren Zhou",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-16T17:57:03.000Z",
            "submittedOnDailyAt": "2025-09-17T03:16:18.695Z",
            "title": "WebSailor-V2: Bridging the Chasm to Proprietary Agents via Synthetic\n  Data and Scalable Reinforcement Learning",
            "submittedOnDailyBy": {
                "_id": "644a4fbc2166258fccc664bc",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/8k3b44MbhQiWuo6i8BnYl.jpeg",
                "isPro": false,
                "fullname": "Jialong Wu",
                "user": "callanwu",
                "type": "user"
            },
            "summary": "Transcending human cognitive limitations represents a critical frontier in\nLLM training. Proprietary agentic systems like DeepResearch have demonstrated\nsuperhuman capabilities on extremely complex information-seeking benchmarks\nsuch as BrowseComp, a feat previously unattainable. We posit that their success\nhinges on a sophisticated reasoning pattern absent in open-source models: the\nability to systematically reduce extreme uncertainty when navigating vast\ninformation landscapes. Based on this insight, we introduce WebSailor, a\ncomplete post-training methodology designed to instill this crucial capability.\nOur approach involves generating novel, high-uncertainty tasks through\nstructured sampling and information obfuscation, RFT cold start, and an\nefficient agentic RL training algorithm, Duplicating Sampling Policy\nOptimization (DUPO). With this integrated pipeline, WebSailor significantly\noutperforms all open-source agents in complex information-seeking tasks,\nmatching proprietary agents' performance and closing the capability gap.",
            "upvotes": 50,
            "discussionId": "68ca3cd06e0073c09bd1df6b",
            "projectPage": "https://tongyi-agent.github.io/blog/",
            "githubRepo": "https://github.com/Alibaba-NLP/DeepResearch/",
            "ai_summary": "WebSailor, a post-training methodology, enhances open-source models with systematic uncertainty reduction, matching proprietary agents' performance in complex information-seeking tasks.",
            "ai_keywords": [
                "LLM training",
                "DeepResearch",
                "BrowseComp",
                "reasoning pattern",
                "high-uncertainty tasks",
                "structured sampling",
                "information obfuscation",
                "RFT cold start",
                "agentic RL training",
                "Duplicating Sampling Policy Optimization",
                "DUPO"
            ],
            "githubStars": 7308
        },
        "translation_title": "WebSailor-V2: 합성 데이터와 확장 가능한 강화 학습을 통한 독점 에이전트와의 간극을 메우다",
        "purpose": "정보 탐색 작업에서 독점 에이전트와 유사한 성능을 달성하기 위한 효과적인 방법론 개발",
        "method": [
            "고유의 정보를 다루기 위한 체계적인 사고 패턴을 학습시키기 위한 WebSailor라는 포괄적인 포스트 트레이닝 방법론을 도입함(Based on this insight, we introduce WebSailor, a complete post-training methodology designed to instill this crucial capability.)",
            "구조적 샘플링과 정보 숨기기를 통해 새로운 고불확실성 작업을 생성하고 이를 활용하여 에이전트의 RL 훈련 알고리즘인 DUPO를 적용함(Our approach involves generating novel, high-uncertainty tasks through structured sampling and information obfuscation, an efficient agentic RL training algorithm, Duplicating Sampling Policy Optimization (DUPO).)",
            "WebSailor의 통합 파이프라인을 통해 복잡한 정보 탐색 과제에서 모든 오픈 소스 에이전트보다 우수한 성능을 달성함(With this integrated pipeline, WebSailor significantly outperforms all open-source agents in complex information-seeking tasks.)"
        ],
        "conclusion": "WebSailor는 독점 에이전트 성능과 일치하는 결과를 달성하며, 기존 오픈 소스 모델들과의 성능 차이를 줄임.",
        "keywords": [
            "Natural Language Processing",
            "Reinforcement Learning",
            "Large Language Models"
        ]
    },
    {
        "paper": {
            "id": "2509.13311",
            "authors": [
                {
                    "_id": "68ca16c06e0073c09bd1de1d",
                    "name": "Runnan Fang",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de1e",
                    "name": "Shihao Cai",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de1f",
                    "name": "Baixuan Li",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de20",
                    "user": {
                        "_id": "644a4fbc2166258fccc664bc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/8k3b44MbhQiWuo6i8BnYl.jpeg",
                        "isPro": false,
                        "fullname": "Jialong Wu",
                        "user": "callanwu",
                        "type": "user"
                    },
                    "name": "Jialong Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-17T12:56:52.444Z",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de21",
                    "name": "Guangyu Li",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de22",
                    "name": "Wenbiao Yin",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de23",
                    "name": "Xinyu Wang",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de24",
                    "name": "Xiaobin Wang",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de25",
                    "user": {
                        "_id": "677f945ea82c316db164a180",
                        "avatarUrl": "/avatars/50ec99d971564944de3b1d9c17d50cfd.svg",
                        "isPro": false,
                        "fullname": "Liangcai Su",
                        "user": "HKU-Liangcai",
                        "type": "user"
                    },
                    "name": "Liangcai Su",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-17T12:56:56.416Z",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de26",
                    "name": "Zhen Zhang",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de27",
                    "name": "Shibin Wu",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de28",
                    "name": "Zhengwei Tao",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de29",
                    "name": "Yong Jiang",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de2a",
                    "name": "Pengjun Xie",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de2b",
                    "name": "Fei Huang",
                    "hidden": false
                },
                {
                    "_id": "68ca16c06e0073c09bd1de2c",
                    "name": "Jingren Zhou",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-16T17:57:20.000Z",
            "submittedOnDailyAt": "2025-09-17T00:32:53.838Z",
            "title": "Towards General Agentic Intelligence via Environment Scaling",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Advanced agentic intelligence is a prerequisite for deploying Large Language\nModels in practical, real-world applications. Diverse real-world APIs demand\nprecise, robust function-calling intelligence, which needs agents to develop\nthese capabilities through interaction in varied environments. The breadth of\nfunction-calling competence is closely tied to the diversity of environments in\nwhich agents are trained. In this work, we scale up environments as a step\ntowards advancing general agentic intelligence. This gives rise to two central\nchallenges: (i) how to scale environments in a principled manner, and (ii) how\nto effectively train agentic capabilities from experiences derived through\ninteractions with these environments. To address these, we design a scalable\nframework that automatically constructs heterogeneous environments that are\nfully simulated, systematically broadening the space of function-calling\nscenarios. We further adapt a two-phase agent fine-tuning strategy: first\nendowing agents with fundamental agentic capabilities, then specializing them\nfor domain-specific contexts. Extensive experiments on agentic benchmarks,\ntau-bench, tau2-Bench, and ACEBench, demonstrate that our trained model,\nAgentScaler, significantly enhances the function-calling capability of models.",
            "upvotes": 47,
            "discussionId": "68ca16c16e0073c09bd1de2d",
            "ai_summary": "A scalable framework and two-phase fine-tuning strategy enhance function-calling capabilities of agents in diverse environments, improving performance on agentic benchmarks.",
            "ai_keywords": [
                "agentic intelligence",
                "Large Language Models",
                "function-calling intelligence",
                "heterogeneous environments",
                "two-phase agent fine-tuning",
                "tau-bench",
                "tau2-Bench",
                "ACEBench",
                "AgentScaler"
            ]
        },
        "translation_title": "환경 확장을 통한 일반적 에이전트 지능 향상",
        "purpose": "실제 응용을 위해 대규모 언어 모델의 정확하고 강력한 기능 호출 능력을 개발하기 위한 연구",
        "method": [
            "상담을 통해 환경을 체계적으로 확장하기 위한 원칙적인 접근 방식을 설계함(To address these, we design a scalable framework that automatically constructs heterogeneous environments that are fully simulated.)",
            "에이전트에게 기본적인 에이전트 능력을 부여한 후, 도메인별 맥락에 맞게 전문화하는 두 단계의 세부 조정 전략을 채택함(We further adapt a two-phase agent fine-tuning strategy: first endowing agents with fundamental agentic capabilities, then specializing them for domain-specific contexts.)",
            "에이전트 벤치마크 tau-bench, tau2-Bench, ACEBench에서 광범위한 실험을 수행하여 에이전트 모델의 기능 호출 능력을 크게 향상시킴(Extensive experiments on agentic benchmarks, tau-bench, tau2-Bench, and ACEBench, demonstrate that our trained model, AgentScaler, significantly enhances the function-calling capability of models.)"
        ],
        "conclusion": "AgentScaler는 모델의 기능 호출 능력을 크게 향상시키는 데 성공하였음.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2509.13309",
            "authors": [
                {
                    "_id": "68ca171d6e0073c09bd1de39",
                    "name": "Zile Qiao",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de3a",
                    "name": "Guoxin Chen",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de3b",
                    "user": {
                        "_id": "65e6970d135c27ea806526fe",
                        "avatarUrl": "/avatars/4aced113d9cab055ae06f3945869a280.svg",
                        "isPro": false,
                        "fullname": "Xuanzhong Chen",
                        "user": "chenxz",
                        "type": "user"
                    },
                    "name": "Xuanzhong Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-17T12:55:38.926Z",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de3c",
                    "name": "Donglei Yu",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de3d",
                    "name": "Wenbiao Yin",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de3e",
                    "name": "Xinyu Wang",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de3f",
                    "name": "Zhen Zhang",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de40",
                    "name": "Baixuan Li",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de41",
                    "name": "Huifeng Yin",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de42",
                    "name": "Kuan Li",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de43",
                    "name": "Rui Min",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de44",
                    "name": "Minpeng Liao",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de45",
                    "name": "Yong Jiang",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de46",
                    "name": "Pengjun Xie",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de47",
                    "name": "Fei Huang",
                    "hidden": false
                },
                {
                    "_id": "68ca171d6e0073c09bd1de48",
                    "name": "Jingren Zhou",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-16T17:57:17.000Z",
            "submittedOnDailyAt": "2025-09-17T00:34:22.753Z",
            "title": "WebResearcher: Unleashing unbounded reasoning capability in Long-Horizon\n  Agents",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Recent advances in deep-research systems have demonstrated the potential for\nAI agents to autonomously discover and synthesize knowledge from external\nsources. In this paper, we introduce WebResearcher, a novel framework for\nbuilding such agents through two key components: (1) WebResearcher, an\niterative deep-research paradigm that reformulates deep research as a Markov\nDecision Process, where agents periodically consolidate findings into evolving\nreports while maintaining focused workspaces, overcoming the context\nsuffocation and noise contamination that plague existing mono-contextual\napproaches; and (2) WebFrontier, a scalable data synthesis engine that\ngenerates high-quality training data through tool-augmented complexity\nescalation, enabling systematic creation of research tasks that bridge the gap\nbetween passive knowledge recall and active knowledge construction. Notably, we\nfind that the training data from our paradigm significantly enhances tool-use\ncapabilities even for traditional mono-contextual methods. Furthermore, our\nparadigm naturally scales through parallel thinking, enabling concurrent\nmulti-agent exploration for more comprehensive conclusions. Extensive\nexperiments across 6 challenging benchmarks demonstrate that WebResearcher\nachieves state-of-the-art performance, even surpassing frontier proprietary\nsystems.",
            "upvotes": 45,
            "discussionId": "68ca171d6e0073c09bd1de49",
            "ai_summary": "WebResearcher, a deep-research framework, enhances AI agents' knowledge synthesis by reformulating research as a Markov Decision Process and using a scalable data synthesis engine, achieving superior performance across benchmarks.",
            "ai_keywords": [
                "deep-research systems",
                "AI agents",
                "Markov Decision Process",
                "WebResearcher",
                "WebFrontier",
                "data synthesis engine",
                "tool-augmented complexity escalation",
                "parallel thinking",
                "multi-agent exploration"
            ]
        },
        "translation_title": "WebResearcher: Long-Horizon Agents에서 무한한 추론 능력을 발휘하다",
        "purpose": "AI 에이전트가 외부 출처에서 자율적으로 지식을 발견하고 종합할 수 있는 새로운 프레임워크 연구",
        "method": [
            "WebResearcher라는 반복적 딥 리서치 패러다임을 도입하여 딥 리서치를 마르코프 결정 프로세스로 재구성함(we introduce WebResearcher, an iterative deep-research paradigm that reformulates deep research as a Markov Decision Process)",
            "WebFrontier라는 확장 가능한 데이터 합성 엔진을 통해 고품질 학습 데이터를 생성함(we introduce WebFrontier, a scalable data synthesis engine that generates high-quality training data through tool-augmented complexity escalation)",
            "훈련 데이터는 기존의 단일 문맥 접근법에서도 도구 사용 능력을 크게 향상시킴(we find that the training data from our paradigm significantly enhances tool-use capabilities even for traditional mono-contextual methods)"
        ],
        "conclusion": "WebResearcher는 6개의 도전적인 벤치마크에서 최첨단 성능을 달성하며, 기존의 독점 시스템도 초월하는 결과를 보임.",
        "keywords": [
            "Natural Language Processing",
            "Multimodal Learning",
            "Robotics"
        ]
    }
]