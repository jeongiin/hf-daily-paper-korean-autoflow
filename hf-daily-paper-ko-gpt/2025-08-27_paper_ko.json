[
    {
        "paper": {
            "id": "2508.17445",
            "authors": [
                {
                    "_id": "68ae7d1a364411bea07df7be",
                    "user": {
                        "_id": "6382252f54421460665ec501",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6382252f54421460665ec501/gW9fev3T5QPcNq4f9hqB1.jpeg",
                        "isPro": false,
                        "fullname": "Yizhi Li",
                        "user": "yizhilll",
                        "type": "user"
                    },
                    "name": "Yizhi Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T07:10:35.933Z",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7bf",
                    "name": "Qingshui Gu",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7c0",
                    "user": {
                        "_id": "6761461f6b3a8119fec25257",
                        "avatarUrl": "/avatars/027771ef8f6459f78d8f26f9b09fbed2.svg",
                        "isPro": false,
                        "fullname": "Maxwell Wen",
                        "user": "MaxwellWen",
                        "type": "user"
                    },
                    "name": "Zhoufutu Wen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T14:59:44.781Z",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7c1",
                    "name": "Ziniu Li",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7c2",
                    "name": "Tianshun Xing",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7c3",
                    "name": "Shuyue Guo",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7c4",
                    "user": {
                        "_id": "64ab99dcb76bfd863eba64c1",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ab99dcb76bfd863eba64c1/UBXwDPx17X-gl-SzBPvrc.jpeg",
                        "isPro": false,
                        "fullname": "TY.Zheng",
                        "user": "aaabiao",
                        "type": "user"
                    },
                    "name": "Tianyu Zheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T07:10:39.951Z",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7c5",
                    "name": "Xin Zhou",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7c6",
                    "name": "Xingwei Qu",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7c7",
                    "user": {
                        "_id": "628c8598ef14f971b698107f",
                        "avatarUrl": "/avatars/3a4ad87e6b5f9e836a1160d869df1447.svg",
                        "isPro": false,
                        "fullname": "Zhou",
                        "user": "Wangchunshu",
                        "type": "user"
                    },
                    "name": "Wangchunshu Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-08-27T15:09:37.920Z",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7c8",
                    "name": "Zheng Zhang",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7c9",
                    "name": "Wei Shen",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7ca",
                    "name": "Qian Liu",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7cb",
                    "user": {
                        "_id": "6442ba123610a28a4ad5382f",
                        "avatarUrl": "/avatars/97f2d3d2c10058ea41d7bf9087e1f619.svg",
                        "isPro": false,
                        "fullname": "Chenghua Lin",
                        "user": "chenghualin",
                        "type": "user"
                    },
                    "name": "Chenghua Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-08-27T15:09:54.726Z",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7cc",
                    "name": "Jian Yang",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7cd",
                    "user": {
                        "_id": "638efcf4c67af472d316d424",
                        "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
                        "isPro": false,
                        "fullname": "Ge Zhang",
                        "user": "zhangysk",
                        "type": "user"
                    },
                    "name": "Ge Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T07:10:37.920Z",
                    "hidden": false
                },
                {
                    "_id": "68ae7d1a364411bea07df7ce",
                    "name": "Wenhao Huang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-08-24T16:52:37.000Z",
            "submittedOnDailyAt": "2025-08-27T02:08:57.110Z",
            "title": "TreePO: Bridging the Gap of Policy Optimization and Efficacy and\n  Inference Efficiency with Heuristic Tree-based Modeling",
            "submittedOnDailyBy": {
                "_id": "638efcf4c67af472d316d424",
                "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
                "isPro": false,
                "fullname": "Ge Zhang",
                "user": "zhangysk",
                "type": "user"
            },
            "summary": "Recent advancements in aligning large language models via reinforcement\nlearning have achieved remarkable gains in solving complex reasoning problems,\nbut at the cost of expensive on-policy rollouts and limited exploration of\ndiverse reasoning paths. In this work, we introduce TreePO, involving a\nself-guided rollout algorithm that views sequence generation as a\ntree-structured searching process. Composed of dynamic tree sampling policy and\nfixed-length segment decoding, TreePO leverages local uncertainty to warrant\nadditional branches. By amortizing computation across common prefixes and\npruning low-value paths early, TreePO essentially reduces the per-update\ncompute burden while preserving or enhancing exploration diversity. Key\ncontributions include: (1) a segment-wise sampling algorithm that alleviates\nthe KV cache burden through contiguous segments and spawns new branches along\nwith an early-stop mechanism; (2) a tree-based segment-level advantage\nestimation that considers both global and local proximal policy optimization.\nand (3) analysis on the effectiveness of probability and quality-driven dynamic\ndivergence and fallback strategy. We empirically validate the performance gain\nof TreePO on a set reasoning benchmarks and the efficiency saving of GPU hours\nfrom 22\\% up to 43\\% of the sampling design for the trained models, meanwhile\nshowing up to 40\\% reduction at trajectory-level and 35\\% at token-level\nsampling compute for the existing models. While offering a free lunch of\ninference efficiency, TreePO reveals a practical path toward scaling RL-based\npost-training with fewer samples and less compute. Home page locates at\nhttps://m-a-p.ai/TreePO.",
            "upvotes": 47,
            "discussionId": "68ae7d1a364411bea07df7cf",
            "projectPage": "https://m-a-p.ai/TreePO",
            "githubRepo": "https://github.com/multimodal-art-projection/TreePO",
            "ai_summary": "TreePO, a self-guided rollout algorithm for sequence generation, reduces computational cost and enhances exploration diversity in reinforcement learning for large language models.",
            "ai_keywords": [
                "reinforcement learning",
                "sequence generation",
                "tree-structured searching",
                "dynamic tree sampling policy",
                "fixed-length segment decoding",
                "local uncertainty",
                "computation amortization",
                "low-value path pruning",
                "segment-wise sampling",
                "KV cache burden",
                "tree-based segment-level advantage estimation",
                "proximal policy optimization",
                "probability-driven dynamic divergence",
                "quality-driven fallback strategy",
                "trajectory-level sampling",
                "token-level sampling"
            ],
            "githubStars": 9
        },
        "translation_title": "TreePO: 정책 최적화와 효율성 및 추론 효율성의 격차를 해소하는 휴리스틱 트리 기반 모델링",
        "purpose": "정책 최적화의 부담을 줄이고 다양한 탐색을 가능하게 하여 강화 학습의 효율성을 높이기 위한 새로운 알고리즘 개발",
        "method": [
            "Tree 구조의 검색 과정으로 시퀀스 생성을 바라보는 자가 안내 롤아웃 알고리즘을 도입함(we introduce TreePO, involving a self-guided rollout algorithm that views sequence generation as a tree-structured searching process.)",
            "동적 트리 샘플링 정책과 고정 길이 세그먼트 디코딩을 통해 로컬 불확실성을 활용함(TreePO leverages local uncertainty to warrant additional branches.)",
            "공통 접두사 간의 계산을 분산시키고 초기 경로 제거를 통해 업데이트 당 계산 부담을 줄임(TreePO essentially reduces the per-update compute burden while preserving or enhancing exploration diversity.)"
        ],
        "conclusion": "TreePO는 추론 효율성을 높이는 동시에 정책 최적화의 성과를 개선하여 GPU 시간의 22%에서 43%까지 절약할 수 있음을 입증함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2508.19205",
            "authors": [
                {
                    "_id": "68ae6a0f364411bea07df70f",
                    "name": "Zhiliang Peng",
                    "hidden": false
                },
                {
                    "_id": "68ae6a0f364411bea07df710",
                    "name": "Jianwei Yu",
                    "hidden": false
                },
                {
                    "_id": "68ae6a0f364411bea07df711",
                    "name": "Wenhui Wang",
                    "hidden": false
                },
                {
                    "_id": "68ae6a0f364411bea07df712",
                    "name": "Yaoyao Chang",
                    "hidden": false
                },
                {
                    "_id": "68ae6a0f364411bea07df713",
                    "name": "Yutao Sun",
                    "hidden": false
                },
                {
                    "_id": "68ae6a0f364411bea07df714",
                    "user": {
                        "_id": "5df85abada6d0311fd3d5408",
                        "avatarUrl": "/avatars/2331cf703c1b5d3a62e2050b1a6eb108.svg",
                        "isPro": false,
                        "fullname": "Li Dong",
                        "user": "unilm",
                        "type": "user"
                    },
                    "name": "Li Dong",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T07:10:54.323Z",
                    "hidden": false
                },
                {
                    "_id": "68ae6a0f364411bea07df715",
                    "name": "Yi Zhu",
                    "hidden": false
                },
                {
                    "_id": "68ae6a0f364411bea07df716",
                    "name": "Weijiang Xu",
                    "hidden": false
                },
                {
                    "_id": "68ae6a0f364411bea07df717",
                    "name": "Hangbo Bao",
                    "hidden": false
                },
                {
                    "_id": "68ae6a0f364411bea07df718",
                    "name": "Zehua Wang",
                    "hidden": false
                },
                {
                    "_id": "68ae6a0f364411bea07df719",
                    "name": "Shaohan Huang",
                    "hidden": false
                },
                {
                    "_id": "68ae6a0f364411bea07df71a",
                    "name": "Yan Xia",
                    "hidden": false
                },
                {
                    "_id": "68ae6a0f364411bea07df71b",
                    "name": "Furu Wei",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/5df85abada6d0311fd3d5408/6tNh2DlU1e_nu7eznNjy1.png"
            ],
            "publishedAt": "2025-08-26T17:09:12.000Z",
            "submittedOnDailyAt": "2025-08-27T00:47:28.459Z",
            "title": "VibeVoice Technical Report",
            "submittedOnDailyBy": {
                "_id": "5df85abada6d0311fd3d5408",
                "avatarUrl": "/avatars/2331cf703c1b5d3a62e2050b1a6eb108.svg",
                "isPro": false,
                "fullname": "Li Dong",
                "user": "unilm",
                "type": "user"
            },
            "summary": "This report presents VibeVoice, a novel model designed to synthesize\nlong-form speech with multiple speakers by employing next-token diffusion,\nwhich is a unified method for modeling continuous data by autoregressively\ngenerating latent vectors via diffusion. To enable this, we introduce a novel\ncontinuous speech tokenizer that, when compared to the popular Encodec model,\nimproves data compression by 80 times while maintaining comparable performance.\nThe tokenizer effectively preserves audio fidelity while significantly boosting\ncomputational efficiency for processing long sequences. Thus, VibeVoice can\nsynthesize long-form speech for up to 90 minutes (in a 64K context window\nlength) with a maximum of 4 speakers, capturing the authentic conversational\n``vibe'' and surpassing open-source and proprietary dialogue models.",
            "upvotes": 36,
            "discussionId": "68ae6a0f364411bea07df71c",
            "projectPage": "https://microsoft.github.io/VibeVoice/",
            "githubRepo": "https://github.com/microsoft/VibeVoice",
            "ai_summary": "VibeVoice synthesizes long-form multi-speaker speech using next-token diffusion and a highly efficient continuous speech tokenizer, achieving superior performance and fidelity.",
            "ai_keywords": [
                "next-token diffusion",
                "continuous speech tokenizer",
                "Encodec",
                "audio fidelity",
                "computational efficiency",
                "long-form speech",
                "multi-speaker synthesis",
                "conversational vibe",
                "dialogue models"
            ],
            "githubStars": 2607
        },
        "translation_title": "VibeVoice 기술 보고서",
        "purpose": "다양한 화자가 있는 긴 형식의 음성을 합성하기 위한 새로운 모델 연구",
        "method": [
            "next-token diffusion이라는 방법을 사용하여 연속 데이터를 모델링하는 통합 기법을 개발함(To enable this, we introduce a novel continuous speech tokenizer that, when compared to the popular Encodec model, improves data compression by 80 times while maintaining comparable performance.)",
            "기존 Encodec 모델과 비교하여 데이터 압축을 80배 향상시키는 새로운 음성 토크나이저를 도입함(The tokenizer effectively preserves audio fidelity while significantly boosting computational efficiency for processing long sequences.)",
            "최대 4명의 화자로 90분까지 긴 형식의 음성을 합성할 수 있도록 설계함(VibeVoice can synthesize long-form speech for up to 90 minutes (in a 64K context window length) with a maximum of 4 speakers, capturing the authentic conversational 'vibe' and surpassing open-source and proprietary dialogue models.)"
        ],
        "conclusion": "VibeVoice는 기존의 오픈소스 및 상용 대화 모델을 초월하는 고품질의 긴 형식 음성을 효과적으로 합성할 수 있음.",
        "keywords": [
            "Natural Language Processing",
            "Speech Synthesis",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2508.18124",
            "authors": [
                {
                    "_id": "68ae7da2364411bea07df7d1",
                    "user": {
                        "_id": "661b9d96c153e4a0a25adc3e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/661b9d96c153e4a0a25adc3e/VRt7kCQ0KdJp-lhPLOajO.jpeg",
                        "isPro": false,
                        "fullname": "Weida Wang",
                        "user": "weidawang",
                        "type": "user"
                    },
                    "name": "Weida Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T07:10:33.081Z",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7d2",
                    "name": "Dongchen Huang",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7d3",
                    "name": "Jiatong Li",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7d4",
                    "name": "Tengchao Yang",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7d5",
                    "name": "Ziyang Zheng",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7d6",
                    "user": {
                        "_id": "64bce15bafd1e46c5504ad38",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64bce15bafd1e46c5504ad38/vkEjiu-mIagKlrXzDH75o.png",
                        "isPro": false,
                        "fullname": "Di Zhang",
                        "user": "di-zhang-fdu",
                        "type": "user"
                    },
                    "name": "Di Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T07:10:30.932Z",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7d7",
                    "name": "Dong Han",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7d8",
                    "name": "Benteng Chen",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7d9",
                    "name": "Binzhao Luo",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7da",
                    "name": "Zhiyu Liu",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7db",
                    "name": "Kunling Liu",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7dc",
                    "name": "Zhiyuan Gao",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7dd",
                    "name": "Shiqi Geng",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7de",
                    "user": {
                        "_id": "689d58bb635465616d75d302",
                        "avatarUrl": "/avatars/68797cb28dc87478c791d5152e62c52a.svg",
                        "isPro": false,
                        "fullname": "Wei Ma",
                        "user": "BoringMarsh",
                        "type": "user"
                    },
                    "name": "Wei Ma",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T07:10:28.667Z",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7df",
                    "name": "Jiaming Su",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7e0",
                    "name": "Xin Li",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7e1",
                    "user": {
                        "_id": "67348828c74a3af1aef4d3a2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67348828c74a3af1aef4d3a2/ToZ56JIM3ccAXIBNG4mx_.jpeg",
                        "isPro": false,
                        "fullname": "pushuchen",
                        "user": "komusama0930",
                        "type": "user"
                    },
                    "name": "Shuchen Pu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T10:02:16.074Z",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7e2",
                    "name": "Yuhan Shui",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7e3",
                    "name": "Qianjia Cheng",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7e4",
                    "name": "Zhihao Dou",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7e5",
                    "name": "Dongfei Cui",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7e6",
                    "name": "Changyong He",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7e7",
                    "name": "Jin Zeng",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7e8",
                    "name": "Zeke Xie",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7e9",
                    "name": "Mao Su",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7ea",
                    "name": "Dongzhan Zhou",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7eb",
                    "name": "Yuqiang Li",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7ec",
                    "name": "Wanli Ouyang",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7ed",
                    "name": "Yunqi Cai",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7ee",
                    "name": "Xi Dai",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7ef",
                    "name": "Shufei Zhang",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7f0",
                    "name": "Lei Bai",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7f1",
                    "name": "Jinguang Cheng",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7f2",
                    "name": "Zhong Fang",
                    "hidden": false
                },
                {
                    "_id": "68ae7da2364411bea07df7f3",
                    "name": "Hongming Weng",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-08-25T15:32:22.000Z",
            "submittedOnDailyAt": "2025-08-27T02:15:01.675Z",
            "title": "CMPhysBench: A Benchmark for Evaluating Large Language Models in\n  Condensed Matter Physics",
            "submittedOnDailyBy": {
                "_id": "661b9d96c153e4a0a25adc3e",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/661b9d96c153e4a0a25adc3e/VRt7kCQ0KdJp-lhPLOajO.jpeg",
                "isPro": false,
                "fullname": "Weida Wang",
                "user": "weidawang",
                "type": "user"
            },
            "summary": "We introduce CMPhysBench, designed to assess the proficiency of Large\nLanguage Models (LLMs) in Condensed Matter Physics, as a novel Benchmark.\nCMPhysBench is composed of more than 520 graduate-level meticulously curated\nquestions covering both representative subfields and foundational theoretical\nframeworks of condensed matter physics, such as magnetism, superconductivity,\nstrongly correlated systems, etc. To ensure a deep understanding of the\nproblem-solving process,we focus exclusively on calculation problems, requiring\nLLMs to independently generate comprehensive solutions. Meanwhile, leveraging\ntree-based representations of expressions, we introduce the Scalable Expression\nEdit Distance (SEED) score, which provides fine-grained (non-binary) partial\ncredit and yields a more accurate assessment of similarity between prediction\nand ground-truth. Our results show that even the best models, Grok-4, reach\nonly 36 average SEED score and 28% accuracy on CMPhysBench, underscoring a\nsignificant capability gap, especially for this practical and frontier domain\nrelative to traditional physics. The code anddataset are publicly available at\nhttps://github.com/CMPhysBench/CMPhysBench.",
            "upvotes": 36,
            "discussionId": "68ae7da2364411bea07df7f4",
            "githubRepo": "https://github.com/CMPhysBench/CMPhysBench",
            "ai_summary": "CMPhysBench evaluates LLMs in condensed matter physics using calculation problems and a new SEED score for partial credit assessment, revealing significant capability gaps.",
            "ai_keywords": [
                "Large Language Models (LLMs)",
                "Condensed Matter Physics",
                "Scalable Expression Edit Distance (SEED)",
                "tree-based representations",
                "Grok-4"
            ],
            "githubStars": 14
        },
        "translation_title": "CMPhysBench: 응집 물질 물리학에서 대형 언어 모델 평가를 위한 벤치마크",
        "purpose": "대형 언어 모델의 응집 물질 물리학 분야에서의 능력을 평가하기 위한 새로운 벤치마크 개발",
        "method": [
            "520개 이상의 대학원 수준 문제를 수집하여 응집 물질 물리학의 다양한 이론 틀과 하위 분야를 포괄함(CMPhysBench is composed of more than 520 graduate-level meticulously curated questions covering both representative subfields and foundational theoretical frameworks of condensed matter physics.)",
            "계산 문제에 집중하여 LLM이 독립적으로 포괄적인 해결책을 생성하도록 요구함(To ensure a deep understanding of the problem-solving process, we focus exclusively on calculation problems, requiring LLMs to independently generate comprehensive solutions.)",
            "Scalable Expression Edit Distance (SEED) 점수를 도입하여 예측과 실제 정답 간의 유사성을 보다 정확하게 평가함(leverage tree-based representations of expressions, we introduce the Scalable Expression Edit Distance (SEED) score, which provides fine-grained partial credit and yields a more accurate assessment of similarity)."
        ],
        "conclusion": "최고 모델인 Grok-4조차 평균 SEED 점수가 36에 불과하며 28%의 정확도를 기록, 응집 물질 물리학에서 전통 물리학에 비해 상당한 능력 차이를 나타냄.",
        "keywords": [
            "Large Language Models",
            "Document Parsing",
            "Natural Language Processing"
        ]
    },
    {
        "paper": {
            "id": "2508.19247",
            "authors": [
                {
                    "_id": "68ae6936364411bea07df706",
                    "user": {
                        "_id": "677c938c7d036e49073e2989",
                        "avatarUrl": "/avatars/6f308ddbbd8c8eba8ecffbc28f4c941b.svg",
                        "isPro": false,
                        "fullname": "Li Lin",
                        "user": "Nelipot",
                        "type": "user"
                    },
                    "name": "Lin Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T07:10:57.843Z",
                    "hidden": false
                },
                {
                    "_id": "68ae6936364411bea07df707",
                    "user": {
                        "_id": "6375d136dee28348a9c63cbf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6375d136dee28348a9c63cbf/gK465HBrQWIOZ-qtHb-Vh.jpeg",
                        "isPro": false,
                        "fullname": "zehuan-huang",
                        "user": "huanngzh",
                        "type": "user"
                    },
                    "name": "Zehuan Huang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T12:45:44.862Z",
                    "hidden": false
                },
                {
                    "_id": "68ae6936364411bea07df708",
                    "user": {
                        "_id": "65240d0ca801972b6eb12ed8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65240d0ca801972b6eb12ed8/hl2RAssBperb5JlgOIDvw.jpeg",
                        "isPro": false,
                        "fullname": "Haoran Feng",
                        "user": "fenghora",
                        "type": "user"
                    },
                    "name": "Haoran Feng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T07:11:01.785Z",
                    "hidden": false
                },
                {
                    "_id": "68ae6936364411bea07df709",
                    "name": "Gengxiong Zhuang",
                    "hidden": false
                },
                {
                    "_id": "68ae6936364411bea07df70a",
                    "name": "Rui Chen",
                    "hidden": false
                },
                {
                    "_id": "68ae6936364411bea07df70b",
                    "name": "Chunchao Guo",
                    "hidden": false
                },
                {
                    "_id": "68ae6936364411bea07df70c",
                    "user": {
                        "_id": "65b722dbe02a17f0f8d1cc6b",
                        "avatarUrl": "/avatars/65f20601ef9b8ebfdddadd737f9153d6.svg",
                        "isPro": false,
                        "fullname": "Lu Sheng",
                        "user": "lsheng2024",
                        "type": "user"
                    },
                    "name": "Lu Sheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T14:59:47.256Z",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/6375d136dee28348a9c63cbf/xB1n4tiK3oy96ElCeYlbY.mp4"
            ],
            "publishedAt": "2025-08-26T17:59:47.000Z",
            "submittedOnDailyAt": "2025-08-27T00:43:10.461Z",
            "title": "VoxHammer: Training-Free Precise and Coherent 3D Editing in Native 3D\n  Space",
            "submittedOnDailyBy": {
                "_id": "6375d136dee28348a9c63cbf",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6375d136dee28348a9c63cbf/gK465HBrQWIOZ-qtHb-Vh.jpeg",
                "isPro": false,
                "fullname": "zehuan-huang",
                "user": "huanngzh",
                "type": "user"
            },
            "summary": "3D local editing of specified regions is crucial for game industry and robot\ninteraction. Recent methods typically edit rendered multi-view images and then\nreconstruct 3D models, but they face challenges in precisely preserving\nunedited regions and overall coherence. Inspired by structured 3D generative\nmodels, we propose VoxHammer, a novel training-free approach that performs\nprecise and coherent editing in 3D latent space. Given a 3D model, VoxHammer\nfirst predicts its inversion trajectory and obtains its inverted latents and\nkey-value tokens at each timestep. Subsequently, in the denoising and editing\nphase, we replace the denoising features of preserved regions with the\ncorresponding inverted latents and cached key-value tokens. By retaining these\ncontextual features, this approach ensures consistent reconstruction of\npreserved areas and coherent integration of edited parts. To evaluate the\nconsistency of preserved regions, we constructed Edit3D-Bench, a\nhuman-annotated dataset comprising hundreds of samples, each with carefully\nlabeled 3D editing regions. Experiments demonstrate that VoxHammer\nsignificantly outperforms existing methods in terms of both 3D consistency of\npreserved regions and overall quality. Our method holds promise for\nsynthesizing high-quality edited paired data, thereby laying the data\nfoundation for in-context 3D generation. See our project page at\nhttps://huanngzh.github.io/VoxHammer-Page/.",
            "upvotes": 22,
            "discussionId": "68ae6936364411bea07df70d",
            "projectPage": "https://huanngzh.github.io/VoxHammer-Page/",
            "githubRepo": "https://github.com/Nelipot-Lee/VoxHammer",
            "ai_summary": "VoxHammer is a training-free method that performs precise and coherent 3D editing in latent space, ensuring consistency in preserved regions and high-quality overall results.",
            "ai_keywords": [
                "structured 3D generative models",
                "VoxHammer",
                "3D latent space",
                "inversion trajectory",
                "inverted latents",
                "key-value tokens",
                "denoising",
                "Edit3D-Bench",
                "3D consistency",
                "in-context 3D generation"
            ],
            "githubStars": 46
        },
        "translation_title": "VoxHammer: 훈련 없이 정확하고 일관된 네이티브 3D 편집",
        "purpose": "게임 산업과 로봇 상호작용을 위한 3D 지역 편집의 정확성과 일관성을 개선하기 위한 방법 연구",
        "method": [
            "VoxHammer는 훈련 없이 3D 잠재 공간에서 편집을 수행하는 혁신적인 접근법을 제안함(Inspired by structured 3D generative models, we propose VoxHammer, a novel training-free approach that performs precise and coherent editing in 3D latent space.)",
            "3D 모델의 반전 경로를 예측하고 각 타이밍에서 반전된 잠재 영역과 키-값 토큰을 획득함(Given a 3D model, VoxHammer first predicts its inversion trajectory and obtains its inverted latents and key-value tokens at each timestep.)",
            "보존된 지역의 디노이징 특징을 반전된 잠재영역으로 대체하여 일관된 복원을 보장함(Subsequently, in the denoising and editing phase, we replace the denoising features of preserved regions with the corresponding inverted latents and cached key-value tokens.)",
            "Edit3D-Bench라는 인적 주석이 달린 데이터셋을 통해 보존된 지역의 일관성을 평가함(To evaluate the consistency of preserved regions, we constructed Edit3D-Bench, a human-annotated dataset comprising hundreds of samples, each with carefully labeled 3D editing regions.)"
        ],
        "conclusion": "VoxHammer는 보존된 지역의 3D 일관성과 전반적인 품질에서 기존 방법보다 월등하게 성능을 발휘하여 고품질 편집된 쌍 데이터 합성을 위한 가능성을 보여줌.",
        "keywords": [
            "3D Vision",
            "Image Generation",
            "Robotics"
        ]
    },
    {
        "paper": {
            "id": "2508.17661",
            "authors": [
                {
                    "_id": "68ad25ab86b21a0e2e358dbe",
                    "user": {
                        "_id": "68ad3865c08be6c3fc6d3eda",
                        "avatarUrl": "/avatars/2b9850c4af1ef08b1ee8a72a32cfaf5a.svg",
                        "isPro": false,
                        "fullname": "Minhyeong Lee",
                        "user": "mhlee1022",
                        "type": "user"
                    },
                    "name": "Minhyeong Lee",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-26T09:49:42.549Z",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dbf",
                    "name": "Suyoung Hwang",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dc0",
                    "user": {
                        "_id": "683802887db23fa7271ac77d",
                        "avatarUrl": "/avatars/c5acf9e2bc039b9d78429b0d1f34575d.svg",
                        "isPro": false,
                        "fullname": "Seunghyun Moon",
                        "user": "MoonRainy21",
                        "type": "user"
                    },
                    "name": "Seunghyun Moon",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-26T09:49:46.298Z",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dc1",
                    "user": {
                        "_id": "68ad28861ef76caa8a336f4a",
                        "avatarUrl": "/avatars/e8d7aac8fd592eaf25968124de4a4dfa.svg",
                        "isPro": false,
                        "fullname": "Geonho Nah",
                        "user": "rallyduck1005",
                        "type": "user"
                    },
                    "name": "Geonho Nah",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T07:11:18.807Z",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dc2",
                    "user": {
                        "_id": "656184b8738013bf302cc8ba",
                        "avatarUrl": "/avatars/9a97be3ff98b77ab0008d1b7a46317eb.svg",
                        "isPro": false,
                        "fullname": "Donghyun Koh",
                        "user": "kohandy",
                        "type": "user"
                    },
                    "name": "Donghyun Koh",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-26T09:49:56.446Z",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dc3",
                    "user": {
                        "_id": "68ad266bb9f6659790765107",
                        "avatarUrl": "/avatars/9370a89b717bf2124d3d0795032de474.svg",
                        "isPro": false,
                        "fullname": "Youngjun Cho",
                        "user": "zerojun48",
                        "type": "user"
                    },
                    "name": "Youngjun Cho",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-26T09:49:35.313Z",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dc4",
                    "user": {
                        "_id": "68ad26522166e79cec22a0de",
                        "avatarUrl": "/avatars/fc14ed569cb8f1b242ad5d663c7a8689.svg",
                        "isPro": false,
                        "fullname": "Johyun Park",
                        "user": "jstring",
                        "type": "user"
                    },
                    "name": "Johyun Park",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-26T09:49:37.713Z",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dc5",
                    "user": {
                        "_id": "68ad29b78711ce479b260096",
                        "avatarUrl": "/avatars/8d2eccb6ee5385032e72f6e1ed20eafa.svg",
                        "isPro": false,
                        "fullname": "Hojin Yoo",
                        "user": "smileyhojin",
                        "type": "user"
                    },
                    "name": "Hojin Yoo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-26T09:49:51.088Z",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dc6",
                    "user": {
                        "_id": "644f9b4633ac8f46fa0c5e43",
                        "avatarUrl": "/avatars/d641b2ec1bebe449e1b3faa0be280dc4.svg",
                        "isPro": false,
                        "fullname": "Jiho Park",
                        "user": "coinmoles",
                        "type": "user"
                    },
                    "name": "Jiho Park",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-27T07:11:16.743Z",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dc7",
                    "user": {
                        "_id": "654587385cd5692b3a80c780",
                        "avatarUrl": "/avatars/6e9e533574651f678ab67f8b98e921dd.svg",
                        "isPro": false,
                        "fullname": "Haneul Choi",
                        "user": "caelum02",
                        "type": "user"
                    },
                    "name": "Haneul Choi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-26T09:49:48.884Z",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dc8",
                    "user": {
                        "_id": "644b8e407c95629d87da4952",
                        "avatarUrl": "/avatars/83f83ec454973cb52454c8c6f6fcafe2.svg",
                        "isPro": false,
                        "fullname": "Seunghyun Moon",
                        "user": "Rainy21",
                        "type": "user"
                    },
                    "name": "Sungbin Moon",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-26T09:49:53.953Z",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dc9",
                    "name": "Taehoon Hwang",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dca",
                    "name": "Seungwon Kim",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dcb",
                    "user": {
                        "_id": "66f3f780169b85adf963508d",
                        "avatarUrl": "/avatars/495ce69c478c332b5fafe897bf1ee80e.svg",
                        "isPro": false,
                        "fullname": "Jaeyeong Kim",
                        "user": "jy9394",
                        "type": "user"
                    },
                    "name": "Jaeyeong Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-26T09:49:39.585Z",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dcc",
                    "user": {
                        "_id": "68ad27d8321728c884e0643a",
                        "avatarUrl": "/avatars/38d00e607604495ba23d8547d0c2669c.svg",
                        "isPro": false,
                        "fullname": "Seongjun Kim",
                        "user": "sungjune222",
                        "type": "user"
                    },
                    "name": "Seongjun Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-08-26T10:34:43.089Z",
                    "hidden": false
                },
                {
                    "_id": "68ad25ab86b21a0e2e358dcd",
                    "name": "Juneau Jung",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-08-25T04:49:16.000Z",
            "submittedOnDailyAt": "2025-08-27T00:58:59.804Z",
            "title": "Spacer: Towards Engineered Scientific Inspiration",
            "submittedOnDailyBy": {
                "_id": "683802887db23fa7271ac77d",
                "avatarUrl": "/avatars/c5acf9e2bc039b9d78429b0d1f34575d.svg",
                "isPro": false,
                "fullname": "Seunghyun Moon",
                "user": "MoonRainy21",
                "type": "user"
            },
            "summary": "Recent advances in LLMs have made automated scientific research the next\nfrontline in the path to artificial superintelligence. However, these systems\nare bound either to tasks of narrow scope or the limited creative capabilities\nof LLMs. We propose Spacer, a scientific discovery system that develops\ncreative and factually grounded concepts without external intervention. Spacer\nattempts to achieve this via 'deliberate decontextualization,' an approach that\ndisassembles information into atomic units - keywords - and draws creativity\nfrom unexplored connections between them. Spacer consists of (i) Nuri, an\ninspiration engine that builds keyword sets, and (ii) the Manifesting Pipeline\nthat refines these sets into elaborate scientific statements. Nuri extracts\nnovel, high-potential keyword sets from a keyword graph built with 180,000\nacademic publications in biological fields. The Manifesting Pipeline finds\nlinks between keywords, analyzes their logical structure, validates their\nplausibility, and ultimately drafts original scientific concepts. According to\nour experiments, the evaluation metric of Nuri accurately classifies\nhigh-impact publications with an AUROC score of 0.737. Our Manifesting Pipeline\nalso successfully reconstructs core concepts from the latest top-journal\narticles solely from their keyword sets. An LLM-based scoring system estimates\nthat this reconstruction was sound for over 85% of the cases. Finally, our\nembedding space analysis shows that outputs from Spacer are significantly more\nsimilar to leading publications compared with those from SOTA LLMs.",
            "upvotes": 21,
            "discussionId": "68ad25ab86b21a0e2e358dce",
            "githubRepo": "https://github.com/Asteromorph-corp/Spacer",
            "ai_summary": "Spacer, a scientific discovery system, uses deliberate decontextualization to generate creative and factually grounded scientific concepts from keyword sets, achieving high accuracy and similarity to leading publications.",
            "ai_keywords": [
                "LLMs",
                "scientific discovery system",
                "deliberate decontextualization",
                "keyword sets",
                "inspiration engine",
                "Manifesting Pipeline",
                "keyword graph",
                "logical structure",
                "plausibility",
                "embedding space analysis",
                "SOTA LLMs"
            ],
            "githubStars": 22
        },
        "translation_title": "Spacer: 공학적 과학적 영감을 향하여",
        "purpose": "외부 개입 없이 창의적이고 사실에 근거한 과학적 개념을 개발하기 위한 시스템 연구",
        "method": [
            "Spacer라는 시스템을 통해 '의도적인 문맥 제거(deliberate decontextualization)' 방식을 채택하여 정보를 핵심 단위인 키워드로 분해함(Spacer attempts to achieve this via 'deliberate decontextualization,' an approach that disassembles information into atomic units - keywords.)",
            "Nuri라는 영감 엔진을 통해 18만 개의 생물학 관련 학술 출판물로부터 새로운 키워드 세트를 추출함(Nuri extracts novel, high-potential keyword sets from a keyword graph built with 180,000 academic publications in biological fields.)",
            "Manifesting Pipeline을 통해 키워드 간의 연관성을 찾아 과학적 개념을 초안함(The Manifesting Pipeline finds links between keywords, analyzes their logical structure, validates their plausibility, and ultimately drafts original scientific concepts.)"
        ],
        "conclusion": "Spacer는 최신 상위 저널 기사에서 핵심 개념을 성공적으로 재구성하였고, 그 출력물은 기존의 LLMs보다 저명한 출판물과 더 유사한 결과를 보임.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    }
]