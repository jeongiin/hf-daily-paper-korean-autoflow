[
    {
        "paper": {
            "id": "2509.02547",
            "authors": [
                {
                    "_id": "68b7bd09295f15ff60911362",
                    "name": "Guibin Zhang",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911363",
                    "name": "Hejia Geng",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911364",
                    "name": "Xiaohang Yu",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911365",
                    "user": {
                        "_id": "64e314ad24809d7fa0f20fbc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/bHE0w_hjDFvU-Aul0_E7g.jpeg",
                        "isPro": false,
                        "fullname": "Zhenfei Yin",
                        "user": "JeremyYin",
                        "type": "user"
                    },
                    "name": "Zhenfei Yin",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:26:40.112Z",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911366",
                    "name": "Zaibin Zhang",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911367",
                    "user": {
                        "_id": "670dd7c46183398eaa48f15a",
                        "avatarUrl": "/avatars/8957a177b645334e240ecdb928c91046.svg",
                        "isPro": false,
                        "fullname": "Zelin Tan",
                        "user": "Artemis0430",
                        "type": "user"
                    },
                    "name": "Zelin Tan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:26:44.577Z",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911368",
                    "user": {
                        "_id": "660d17d6c9be0dcd31a30b3d",
                        "avatarUrl": "/avatars/3743fe9b695c488ebe33f0d8fd607a8a.svg",
                        "isPro": false,
                        "fullname": "Zhou Heng",
                        "user": "henggg",
                        "type": "user"
                    },
                    "name": "Heng Zhou",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:26:42.323Z",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911369",
                    "name": "Zhongzhi Li",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff6091136a",
                    "name": "Xiangyuan Xue",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff6091136b",
                    "name": "Yijiang Li",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff6091136c",
                    "name": "Yifan Zhou",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff6091136d",
                    "name": "Yang Chen",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff6091136e",
                    "name": "Chen Zhang",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff6091136f",
                    "name": "Yutao Fan",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911370",
                    "name": "Zihu Wang",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911371",
                    "name": "Songtao Huang",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911372",
                    "name": "Yue Liao",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911373",
                    "name": "Hongru Wang",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911374",
                    "name": "Mengyue Yang",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911375",
                    "name": "Heng Ji",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911376",
                    "name": "Michael Littman",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911377",
                    "name": "Jun Wang",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911378",
                    "name": "Shuicheng Yan",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff60911379",
                    "name": "Philip Torr",
                    "hidden": false
                },
                {
                    "_id": "68b7bd09295f15ff6091137a",
                    "name": "Lei Bai",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-02T17:46:26.000Z",
            "submittedOnDailyAt": "2025-09-03T02:32:28.813Z",
            "title": "The Landscape of Agentic Reinforcement Learning for LLMs: A Survey",
            "submittedOnDailyBy": {
                "_id": "660d17d6c9be0dcd31a30b3d",
                "avatarUrl": "/avatars/3743fe9b695c488ebe33f0d8fd607a8a.svg",
                "isPro": false,
                "fullname": "Zhou Heng",
                "user": "henggg",
                "type": "user"
            },
            "summary": "The emergence of agentic reinforcement learning (Agentic RL) marks a paradigm\nshift from conventional reinforcement learning applied to large language models\n(LLM RL), reframing LLMs from passive sequence generators into autonomous,\ndecision-making agents embedded in complex, dynamic worlds. This survey\nformalizes this conceptual shift by contrasting the degenerate single-step\nMarkov Decision Processes (MDPs) of LLM-RL with the temporally extended,\npartially observable Markov decision processes (POMDPs) that define Agentic RL.\nBuilding on this foundation, we propose a comprehensive twofold taxonomy: one\norganized around core agentic capabilities, including planning, tool use,\nmemory, reasoning, self-improvement, and perception, and the other around their\napplications across diverse task domains. Central to our thesis is that\nreinforcement learning serves as the critical mechanism for transforming these\ncapabilities from static, heuristic modules into adaptive, robust agentic\nbehavior. To support and accelerate future research, we consolidate the\nlandscape of open-source environments, benchmarks, and frameworks into a\npractical compendium. By synthesizing over five hundred recent works, this\nsurvey charts the contours of this rapidly evolving field and highlights the\nopportunities and challenges that will shape the development of scalable,\ngeneral-purpose AI agents.",
            "upvotes": 58,
            "discussionId": "68b7bd09295f15ff6091137b",
            "githubRepo": "https://github.com/xhyumiracle/Awesome-AgenticLLM-RL-Papers",
            "ai_summary": "Agentic reinforcement learning transforms large language models into autonomous decision-making agents by leveraging temporally extended POMDPs, enhancing capabilities like planning and reasoning through reinforcement learning.",
            "ai_keywords": [
                "agentic reinforcement learning",
                "LLM RL",
                "Markov Decision Processes",
                "POMDPs",
                "planning",
                "tool use",
                "memory",
                "reasoning",
                "self-improvement",
                "perception",
                "reinforcement learning",
                "open-source environments",
                "benchmarks",
                "frameworks"
            ],
            "githubStars": 50
        },
        "translation_title": "LLMs를 위한 Agentic 강화 학습의 전경: 조사 연구",
        "purpose": "전통적인 강화 학습에서 벗어난 Agentic RL의 개념적 변화를 정립하고, 이를 통해 LLMs를 자율적인 의사결정 에이전트로 전환하려는 목표.",
        "method": [
            "Agentic RL의 개념적 변화를 정의하고 LLM-RL의 단일 단계 Markov Decision Processes (MDPs)와 비교함.(This survey formalizes this conceptual shift by contrasting the degenerate single-step Markov Decision Processes (MDPs) of LLM-RL with the temporally extended, partially observable Markov decision processes (POMDPs) that define Agentic RL.)",
            "기본 원칙에 기반하여 계획, 도구 사용, 기억, 추론, 자기 개선, 인식 등 핵심 에이전트 능력을 중심으로 하는 포괄적인 이중 분류 체계를 제안함.(Building on this foundation, we propose a comprehensive twofold taxonomy: one organized around core agentic capabilities, including planning, tool use, memory, reasoning, self-improvement, and perception.)",
            "500개 이상의 최근 연구를 종합하여 개방형 환경, 벤치마크 및 프레임워크의 맥락을 정리함으로써 향후 연구를 지원하고 가속화할 방법을 제시함.(By synthesizing over five hundred recent works, this survey charts the contours of this rapidly evolving field and highlights the opportunities and challenges that will shape the development of scalable, general-purpose AI agents.)"
        ],
        "conclusion": "Agentic RL이 LLMs의 행동을 강화하는 중요한 메커니즘으로 작용하며, 이를 통해 강력하고 적응 가능한 에이전트 행동으로 전환할 수 있음을 강조함.",
        "keywords": [
            "Large Language Models",
            "Reinforcement Learning",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2509.02479",
            "authors": [
                {
                    "_id": "68b7b9f8295f15ff6091130d",
                    "name": "Zhenghai Xue",
                    "hidden": false
                },
                {
                    "_id": "68b7b9f8295f15ff6091130e",
                    "name": "Longtao Zheng",
                    "hidden": false
                },
                {
                    "_id": "68b7b9f8295f15ff6091130f",
                    "name": "Qian Liu",
                    "hidden": false
                },
                {
                    "_id": "68b7b9f8295f15ff60911310",
                    "user": {
                        "_id": "67277d20eebb94a257cd6925",
                        "avatarUrl": "/avatars/c1f714b59fecb53770e28920c0c267cb.svg",
                        "isPro": false,
                        "fullname": "Yingru Li",
                        "user": "R1ch0rd",
                        "type": "user"
                    },
                    "name": "Yingru Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:27:12.625Z",
                    "hidden": false
                },
                {
                    "_id": "68b7b9f8295f15ff60911311",
                    "user": {
                        "_id": "6274a2315d12b3a734adebc9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6274a2315d12b3a734adebc9/zLQDbszAvWh0F2BjdKock.jpeg",
                        "isPro": false,
                        "fullname": "Xiaosen Zheng",
                        "user": "xszheng2020",
                        "type": "user"
                    },
                    "name": "Xiaosen Zheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:27:15.115Z",
                    "hidden": false
                },
                {
                    "_id": "68b7b9f8295f15ff60911312",
                    "name": "Zejun Ma",
                    "hidden": false
                },
                {
                    "_id": "68b7b9f8295f15ff60911313",
                    "name": "Bo An",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/612ee6a7b960e78c6d2319d4/8Ju5mD0aVNHopWdipRWTa.png"
            ],
            "publishedAt": "2025-09-02T16:30:19.000Z",
            "submittedOnDailyAt": "2025-09-03T02:21:40.676Z",
            "title": "SimpleTIR: End-to-End Reinforcement Learning for Multi-Turn\n  Tool-Integrated Reasoning",
            "submittedOnDailyBy": {
                "_id": "612ee6a7b960e78c6d2319d4",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/612ee6a7b960e78c6d2319d4/2Hu9BaAyXbyh1vt0v1Qui.jpeg",
                "isPro": false,
                "fullname": "Qian Liu",
                "user": "SivilTaram",
                "type": "user"
            },
            "summary": "Large Language Models (LLMs) can significantly improve their reasoning\ncapabilities by interacting with external tools, a paradigm known as\nTool-Integrated Reasoning (TIR). However, extending TIR to multi-turn scenarios\nusing Reinforcement Learning (RL) is often hindered by training instability and\nperformance collapse. We identify that such instability is primarily caused by\na distributional drift from external tool feedback, leading to the generation\nof low-probability tokens. This issue compounds over successive turns, causing\ncatastrophic gradient norm explosions that derail the training process. To\naddress this challenge, we introduce SimpleTIR , a plug-and-play algorithm that\nstabilizes multi-turn TIR training. Its core strategy is to identify and filter\nout trajectories containing void turns, i.e., turns that yield neither a code\nblock nor a final answer. By removing these problematic trajectories from the\npolicy update, SimpleTIR effectively blocks the harmful, high-magnitude\ngradients, thus stabilizing the learning dynamics. Extensive experiments show\nthat SimpleTIR achieves state-of-the-art performance on challenging math\nreasoning benchmarks, notably elevating the AIME24 score from a text-only\nbaseline of 22.1 to 50.5 when starting from the Qwen2.5-7B base model.\nFurthermore, by avoiding the constraints of supervised fine-tuning, SimpleTIR\nencourages the model to discover diverse and sophisticated reasoning patterns,\nsuch as self-correction and cross-validation.",
            "upvotes": 55,
            "discussionId": "68b7b9f8295f15ff60911314",
            "projectPage": "https://simpletir.notion.site/report",
            "githubRepo": "https://github.com/ltzheng/SimpleTIR",
            "ai_summary": "SimpleTIR stabilizes multi-turn Tool-Integrated Reasoning training by filtering out void turns, achieving state-of-the-art performance on math reasoning benchmarks.",
            "ai_keywords": [
                "Tool-Integrated Reasoning",
                "TIR",
                "Reinforcement Learning",
                "RL",
                "distributional drift",
                "low-probability tokens",
                "gradient norm explosions",
                "SimpleTIR",
                "void turns",
                "policy update",
                "AIME24",
                "Qwen2.5-7B",
                "self-correction",
                "cross-validation"
            ],
            "githubStars": 208
        },
        "translation_title": "SimpleTIR: 다중 턴 도구 통합 추론을 위한 엔드 투 엔드 강화 학습",
        "purpose": "다중 턴 상황에서 Tool-Integrated Reasoning을 안정화하고 성능을 향상시키기 위한 방법 연구",
        "method": [
            "강화 학습 중 훈련 불안정성을 일으키는 외부 도구 피드백의 분포 변화 문제를 파악함(We identify that such instability is primarily caused by a distributional drift from external tool feedback.)",
            "무의미한 턴(코드 블록이나 최종 답변이 없는 턴)을 포함하는 경로를 필터링하여 훈련의 안정성을 높임(SimpleTIR's core strategy is to identify and filter out trajectories containing void turns.)",
            "다양한 수학 추론 벤치마크에서 상태-of-the-art 성능을 달성함(Extensive experiments show that SimpleTIR achieves state-of-the-art performance on challenging math reasoning benchmarks.)"
        ],
        "conclusion": "SimpleTIR는 다중 턴 도구 통합 추론 훈련을 안정시켜, Qwen2.5-7B 기본 모델에서 AIME24 점수를 22.1에서 50.5로 증가시킴.",
        "keywords": [
            "Reinforcement Learning",
            "Natural Language Processing",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2509.02544",
            "authors": [
                {
                    "_id": "68b7c7ff295f15ff609113ed",
                    "user": {
                        "_id": "678a19ba39c63f336d24cc27",
                        "avatarUrl": "/avatars/5bec449236ac7d4a0936ef0dd4046761.svg",
                        "isPro": false,
                        "fullname": "Haoming Wang",
                        "user": "MingComplex",
                        "type": "user"
                    },
                    "name": "Haoming Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:26:26.703Z",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113ee",
                    "name": "Haoyang Zou",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113ef",
                    "name": "Huatong Song",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113f0",
                    "user": {
                        "_id": "649a95f951e1ea30f1475530",
                        "avatarUrl": "/avatars/d4d167c3985e702044e8290408dde661.svg",
                        "isPro": false,
                        "fullname": "Jamie Jiazhan Feng",
                        "user": "jzfeng",
                        "type": "user"
                    },
                    "name": "Jiazhan Feng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:26:24.633Z",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113f1",
                    "name": "Junjie Fang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113f2",
                    "name": "Junting Lu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113f3",
                    "name": "Longxiang Liu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113f4",
                    "name": "Qinyu Luo",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113f5",
                    "name": "Shihao Liang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113f6",
                    "user": {
                        "_id": "64ce05c631c655ff8a2e183c",
                        "avatarUrl": "/avatars/f2de7f8a1348b05f46946085e3e9718e.svg",
                        "isPro": false,
                        "fullname": "Shijue Huang",
                        "user": "JoeYing",
                        "type": "user"
                    },
                    "name": "Shijue Huang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:26:22.542Z",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113f7",
                    "name": "Wanjun Zhong",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113f8",
                    "name": "Yining Ye",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113f9",
                    "name": "Yujia Qin",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113fa",
                    "name": "Yuwen Xiong",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113fb",
                    "name": "Yuxin Song",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113fc",
                    "name": "Zhiyong Wu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113fd",
                    "name": "Bo Li",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113fe",
                    "name": "Chen Dun",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff609113ff",
                    "name": "Chong Liu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911400",
                    "name": "Fuxing Leng",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911401",
                    "name": "Hanbin Wang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911402",
                    "name": "Hao Yu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911403",
                    "name": "Haobin Chen",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911404",
                    "name": "Hongyi Guo",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911405",
                    "name": "Jing Su",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911406",
                    "name": "Jingjia Huang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911407",
                    "name": "Kai Shen",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911408",
                    "name": "Kaiyu Shi",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911409",
                    "name": "Lin Yan",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091140a",
                    "name": "Peiyao Zhao",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091140b",
                    "name": "Pengfei Liu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091140c",
                    "name": "Qinghao Ye",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091140d",
                    "name": "Renjie Zheng",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091140e",
                    "name": "Wayne Xin Zhao",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091140f",
                    "name": "Wen Heng",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911410",
                    "name": "Wenhao Huang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911411",
                    "name": "Wenqian Wang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911412",
                    "name": "Xiaobo Qin",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911413",
                    "name": "Yi Lin",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911414",
                    "name": "Youbin Wu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911415",
                    "name": "Zehui Chen",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911416",
                    "user": {
                        "_id": "642e8c99c1b0f8e4e76bcaab",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642e8c99c1b0f8e4e76bcaab/BOs9r0P9KyT9pEba9v0H4.png",
                        "isPro": false,
                        "fullname": "Zihao Wang",
                        "user": "zhwang4ai",
                        "type": "user"
                    },
                    "name": "Zihao Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:26:20.371Z",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911417",
                    "name": "Baoquan Zhong",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911418",
                    "name": "Xinchun Zhang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911419",
                    "name": "Xujing Li",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091141a",
                    "name": "Yuanfan Li",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091141b",
                    "name": "Zhongkai Zhao",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091141c",
                    "name": "Chengquan Jiang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091141d",
                    "name": "Faming Wu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091141e",
                    "name": "Haotian Zhou",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091141f",
                    "name": "Jinlin Pang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911420",
                    "name": "Li Han",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911421",
                    "name": "Qianli Ma",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911422",
                    "name": "Siyao Liu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911423",
                    "name": "Songhua Cai",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911424",
                    "name": "Wenqi Fu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911425",
                    "name": "Xin Liu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911426",
                    "name": "Zhi Zhang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911427",
                    "name": "Bo Zhou",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911428",
                    "name": "Guoliang Li",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911429",
                    "name": "Jiajun Shi",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091142a",
                    "name": "Jiale Yang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091142b",
                    "name": "Jie Tang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091142c",
                    "name": "Li Li",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091142d",
                    "name": "Taoran Lu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091142e",
                    "name": "Woyu Lin",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091142f",
                    "name": "Xiaokang Tong",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911430",
                    "name": "Xinyao Li",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911431",
                    "name": "Yichi Zhang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911432",
                    "name": "Yu Miao",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911433",
                    "name": "Zhengxuan Jiang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911434",
                    "name": "Zili Li",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911435",
                    "name": "Ziyuan Zhao",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911436",
                    "name": "Chenxin Li",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911437",
                    "name": "Dehua Ma",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911438",
                    "name": "Feng Lin",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911439",
                    "name": "Ge Zhang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091143a",
                    "name": "Haihua Yang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091143b",
                    "name": "Hangyu Guo",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091143c",
                    "name": "Hongda Zhu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091143d",
                    "name": "Jiaheng Liu",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091143e",
                    "name": "Junda Du",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091143f",
                    "name": "Kai Cai",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911440",
                    "name": "Kuanye Li",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911441",
                    "name": "Lichen Yuan",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911442",
                    "name": "Meilan Han",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911443",
                    "name": "Minchao Wang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911444",
                    "name": "Shuyue Guo",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911445",
                    "name": "Tianhao Cheng",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911446",
                    "name": "Xiaobo Ma",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911447",
                    "name": "Xiaojun Xiao",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911448",
                    "name": "Xiaolong Huang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911449",
                    "name": "Xinjie Chen",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091144a",
                    "name": "Yidi Du",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091144b",
                    "name": "Yilin Chen",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091144c",
                    "name": "Yiwen Wang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091144d",
                    "name": "Zhaojian Li",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091144e",
                    "name": "Zhenzhu Yang",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff6091144f",
                    "name": "Zhiyuan Zeng",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911450",
                    "name": "Chaolin Jin",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911451",
                    "name": "Chen Li",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911452",
                    "name": "Hao Chen",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911453",
                    "name": "Haoli Chen",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911454",
                    "name": "Jian Chen",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911455",
                    "name": "Qinghao Zhao",
                    "hidden": false
                },
                {
                    "_id": "68b7c7ff295f15ff60911456",
                    "name": "Guang Shi",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-02T17:44:45.000Z",
            "submittedOnDailyAt": "2025-09-03T03:16:36.062Z",
            "title": "UI-TARS-2 Technical Report: Advancing GUI Agent with Multi-Turn\n  Reinforcement Learning",
            "submittedOnDailyBy": {
                "_id": "64892d31cbda0d1cdb956897",
                "avatarUrl": "/avatars/3cdafe03a8295124636347d15a099aaf.svg",
                "isPro": false,
                "fullname": "Zehui Chen",
                "user": "lovesnowbest",
                "type": "user"
            },
            "summary": "The development of autonomous agents for graphical user interfaces (GUIs)\npresents major challenges in artificial intelligence. While recent advances in\nnative agent models have shown promise by unifying perception, reasoning,\naction, and memory through end-to-end learning, open problems remain in data\nscalability, multi-turn reinforcement learning (RL), the limitations of\nGUI-only operation, and environment stability. In this technical report, we\npresent UI-TARS-2, a native GUI-centered agent model that addresses these\nchallenges through a systematic training methodology: a data flywheel for\nscalable data generation, a stabilized multi-turn RL framework, a hybrid GUI\nenvironment that integrates file systems and terminals, and a unified sandbox\nplatform for large-scale rollouts. Empirical evaluation demonstrates that\nUI-TARS-2 achieves significant improvements over its predecessor UI-TARS-1.5.\nOn GUI benchmarks, it reaches 88.2 on Online-Mind2Web, 47.5 on OSWorld, 50.6 on\nWindowsAgentArena, and 73.3 on AndroidWorld, outperforming strong baselines\nsuch as Claude and OpenAI agents. In game environments, it attains a mean\nnormalized score of 59.8 across a 15-game suite-roughly 60% of human-level\nperformance-and remains competitive with frontier proprietary models (e.g.,\nOpenAI o3) on LMGame-Bench. Additionally, the model can generalize to\nlong-horizon information-seeking tasks and software engineering benchmarks,\nhighlighting its robustness across diverse agent tasks. Detailed analyses of\ntraining dynamics further provide insights into achieving stability and\nefficiency in large-scale agent RL. These results underscore UI-TARS-2's\npotential to advance the state of GUI agents and exhibit strong generalization\nto real-world interactive scenarios.",
            "upvotes": 54,
            "discussionId": "68b7c7ff295f15ff60911457",
            "ai_summary": "UI-TARS-2, a native GUI-centered agent model, addresses challenges in data scalability, multi-turn reinforcement learning, and environment stability, achieving significant improvements over its predecessor and strong baselines across various benchmarks.",
            "ai_keywords": [
                "reinforcement learning",
                "GUI",
                "data flywheel",
                "multi-turn RL",
                "hybrid GUI environment",
                "unified sandbox platform",
                "Online-Mind2Web",
                "OSWorld",
                "WindowsAgentArena",
                "AndroidWorld",
                "LMGame-Bench",
                "long-horizon information-seeking tasks",
                "software engineering benchmarks"
            ]
        },
        "translation_title": "UI-TARS-2 기술 보고서: 다중 턴 강화 학습을 통한 GUI 에이전트 발전",
        "purpose": "그래픽 사용자 인터페이스(GUI)를 위한 자율 에이전트의 성능 향상",
        "method": [
            "데이터 생성의 확장성을 높이기 위한 데이터 플라이휠 시스템 구축(Data flywheel for scalable data generation)",
            "안정적인 다중 턴 강화 학습 프레임워크 개발(Stabilized multi-turn RL framework)",
            "파일 시스템과 터미널을 통합한 하이브리드 GUI 환경 설계(Hybrid GUI environment that integrates file systems and terminals)",
            "대규모 배포를 위한 통합 샌드박스 플랫폼 구현(Unified sandbox platform for large-scale rollouts)"
        ],
        "conclusion": "UI-TARS-2는 이전 모델에 비해 큰 성과를 거두었으며, 다양한 에이전트 작업에서 강력한 일반화를 보여줍니다.",
        "keywords": [
            "Reinforcement Learning",
            "Robotics",
            "Computer Vision"
        ]
    },
    {
        "paper": {
            "id": "2508.21496",
            "authors": [
                {
                    "_id": "68b6d3de5aa065c912612750",
                    "user": {
                        "_id": "65c2bef1ce1be49b569745b8",
                        "avatarUrl": "/avatars/c3709a914220b353fad170ee12ec3172.svg",
                        "isPro": false,
                        "fullname": "luhao",
                        "user": "HLSv",
                        "type": "user"
                    },
                    "name": "Hao Lu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:28:39.009Z",
                    "hidden": false
                },
                {
                    "_id": "68b6d3de5aa065c912612751",
                    "user": {
                        "_id": "66bc7862aa7cdcb1c31a1efb",
                        "avatarUrl": "/avatars/4c2ab907247fe071ff5cdd71c404ca7c.svg",
                        "isPro": false,
                        "fullname": "wang jiahao",
                        "user": "datamonkey",
                        "type": "user"
                    },
                    "name": "Jiahao Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:28:36.907Z",
                    "hidden": false
                },
                {
                    "_id": "68b6d3de5aa065c912612752",
                    "user": {
                        "_id": "648d2e2e514bf0ce32ba729f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/648d2e2e514bf0ce32ba729f/VPL1rehLxkvixz5oRD6u_.jpeg",
                        "isPro": false,
                        "fullname": "Yaolun Zhang",
                        "user": "Mercury7353",
                        "type": "user"
                    },
                    "name": "Yaolun Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:28:34.641Z",
                    "hidden": false
                },
                {
                    "_id": "68b6d3de5aa065c912612753",
                    "name": "Ruohui Wang",
                    "hidden": false
                },
                {
                    "_id": "68b6d3de5aa065c912612754",
                    "name": "Xuanyu Zheng",
                    "hidden": false
                },
                {
                    "_id": "68b6d3de5aa065c912612755",
                    "name": "Yepeng Tang",
                    "hidden": false
                },
                {
                    "_id": "68b6d3de5aa065c912612756",
                    "name": "Dahua Lin",
                    "hidden": false
                },
                {
                    "_id": "68b6d3de5aa065c912612757",
                    "name": "Lewei Lu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-08-29T10:25:03.000Z",
            "submittedOnDailyAt": "2025-09-03T08:40:16.948Z",
            "title": "ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long\n  Video Understanding",
            "submittedOnDailyBy": {
                "_id": "65c2bef1ce1be49b569745b8",
                "avatarUrl": "/avatars/c3709a914220b353fad170ee12ec3172.svg",
                "isPro": false,
                "fullname": "luhao",
                "user": "HLSv",
                "type": "user"
            },
            "summary": "Video multimodal large language models (Video-MLLMs) have achieved remarkable\nprogress in video understanding. However, they remain vulnerable to\nhallucination-producing content inconsistent with or unrelated to video inputs.\nPrevious video hallucination benchmarks primarily focus on short-videos. They\nattribute hallucinations to factors such as strong language priors, missing\nframes, or vision-language biases introduced by the visual encoder. While these\ncauses indeed account for most hallucinations in short videos, they still\noversimplify the cause of hallucinations. Sometimes, models generate incorrect\noutputs but with correct frame-level semantics. We refer to this type of\nhallucination as Semantic Aggregation Hallucination (SAH), which arises during\nthe process of aggregating frame-level semantics into event-level semantic\ngroups. Given that SAH becomes particularly critical in long videos due to\nincreased semantic complexity across multiple events, it is essential to\nseparate and thoroughly investigate the causes of this type of hallucination.\nTo address the above issues, we introduce ELV-Halluc, the first benchmark\ndedicated to long-video hallucination, enabling a systematic investigation of\nSAH. Our experiments confirm the existence of SAH and show that it increases\nwith semantic complexity. Additionally, we find that models are more prone to\nSAH on rapidly changing semantics. Moreover, we discuss potential approaches to\nmitigate SAH. We demonstrate that positional encoding strategy contributes to\nalleviating SAH, and further adopt DPO strategy to enhance the model's ability\nto distinguish semantics within and across events. To support this, we curate a\ndataset of 8K adversarial data pairs and achieve improvements on both\nELV-Halluc and Video-MME, including a substantial 27.7% reduction in SAH ratio.",
            "upvotes": 46,
            "discussionId": "68b6d3de5aa065c912612758",
            "githubRepo": "https://github.com/hlsv02/ELV-Halluc",
            "ai_summary": "A benchmark for long-video hallucination identifies and investigates Semantic Aggregation Hallucination (SAH), showing its prevalence in complex and rapidly changing semantic contexts, and proposes strategies to mitigate it.",
            "ai_keywords": [
                "Video-MLLMs",
                "video understanding",
                "hallucination",
                "short-videos",
                "language priors",
                "missing frames",
                "vision-language biases",
                "visual encoder",
                "Semantic Aggregation Hallucination (SAH)",
                "frame-level semantics",
                "event-level semantic groups",
                "long videos",
                "ELV-Halluc",
                "positional encoding",
                "DPO strategy",
                "adversarial data pairs",
                "Video-MME"
            ],
            "githubStars": 4
        },
        "translation_title": "ELV-Halluc: 긴 비디오 이해에서 의미 집합 환각 벤치마킹",
        "purpose": "긴 비디오에서 발생하는 Semantic Aggregation Hallucination(SAH)을 체계적으로 조사하기 위한 벤치마크 개발",
        "method": [
            "비디오 멀티모달 대형 언어 모델의 한계를 해결하기 위해 ELV-Halluc라는 긴 비디오 환각 전용 벤치마크를 도입함(To address the above issues, we introduce ELV-Halluc, the first benchmark dedicated to long-video hallucination, enabling a systematic investigation of SAH.)",
            "SAH의 존재를 확인하고, 의미의 복잡성이 증가함에 따라 SAH 비율이 증가하는 것을 실험을 통해 보여줌(Our experiments confirm the existence of SAH and show that it increases with semantic complexity.)",
            "모델이 빠르게 변화하는 의미에 대해 SAH에 더 취약하다는 것을 발견하고, 이를 완화하기 위한 여러 접근 방안을 논의함(Moreover, we discuss potential approaches to mitigate SAH.)",
            "위치 인코딩 전략이 SAH 완화에 기여함을 입증하고, DPO 전략을 채택해 사건 내외의 의미 구별 능력을 향상시킴(We demonstrate that positional encoding strategy contributes to alleviating SAH, and further adopt DPO strategy to enhance the model's ability to distinguish semantics within and across events.)"
        ],
        "conclusion": "ELV-Halluc 데이터셋을 통해 SAH 비율을 27.7% 줄이는 성과를 달성하고, 긴 비디오의 의미 복잡성을 고려한 새로운 접근 방안을 제안함.",
        "keywords": [
            "Video Understanding",
            "Multimodal Learning",
            "Video Generation"
        ]
    },
    {
        "paper": {
            "id": "2509.00676",
            "authors": [
                {
                    "_id": "68b7c0f7295f15ff609113cb",
                    "user": {
                        "_id": "655fed9fdef5905d38b84af3",
                        "avatarUrl": "/avatars/2cda4182dfd11a1e94743639e62328ea.svg",
                        "isPro": false,
                        "fullname": "Xiyao Wang",
                        "user": "russwang",
                        "type": "user"
                    },
                    "name": "Xiyao Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:26:30.447Z",
                    "hidden": false
                },
                {
                    "_id": "68b7c0f7295f15ff609113cc",
                    "name": "Chunyuan Li",
                    "hidden": false
                },
                {
                    "_id": "68b7c0f7295f15ff609113cd",
                    "name": "Jianwei Yang",
                    "hidden": false
                },
                {
                    "_id": "68b7c0f7295f15ff609113ce",
                    "user": {
                        "_id": "63e0a50242591dda0b9dca5c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63e0a50242591dda0b9dca5c/c7cBPEBWQDFYimfGnO_SI.png",
                        "isPro": false,
                        "fullname": "Kai Zhang",
                        "user": "drogozhang",
                        "type": "user"
                    },
                    "name": "Kai Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T08:26:33.172Z",
                    "hidden": false
                },
                {
                    "_id": "68b7c0f7295f15ff609113cf",
                    "user": {
                        "_id": "635e3a76106f984574c36409",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1667120725800-635e3a76106f984574c36409.png",
                        "isPro": false,
                        "fullname": "Bo Liu",
                        "user": "Benjamin-eecs",
                        "type": "user"
                    },
                    "name": "Bo Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-03T09:31:39.922Z",
                    "hidden": false
                },
                {
                    "_id": "68b7c0f7295f15ff609113d0",
                    "name": "Tianyi Xiong",
                    "hidden": false
                },
                {
                    "_id": "68b7c0f7295f15ff609113d1",
                    "name": "Furong Huang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-08-31T03:08:02.000Z",
            "submittedOnDailyAt": "2025-09-03T02:45:59.278Z",
            "title": "LLaVA-Critic-R1: Your Critic Model is Secretly a Strong Policy Model",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "In vision-language modeling, critic models are typically trained to evaluate\noutputs -- assigning scalar scores or pairwise preferences -- rather than to\ngenerate responses. This separation from policy models, which produce the\nresponses, is so entrenched that critics are rarely considered for direct\npolicy use. In this work, we challenge this convention. We propose to\nreorganize preference-labeled critic datasets into verifiable training signals\nand perform reinforcement learning directly on a base generative model,\nproducing LLaVA-Critic-R1, a multimodal critic trained to optimize preference\njudgments while retaining full generation ability. Surprisingly,\nLLaVA-Critic-R1 emerges not only as a top-performing critic but also as a\ncompetitive policy model -- matching or surpassing specialized reasoning VLMs\ntrained with in-domain data across 26 visual reasoning and understanding\nbenchmarks, with an average gain of +5.7% over its base model (Qwen-2.5-VL-7B).\nExtending this approach to existing strong reasoning VLMs yields\nLLaVA-Critic-R1+, which further advances policy performance without sacrificing\ncritic quality, achieving a SoTA performance of 71.9 on MMMU at the 7B scale.\nFinally, we show that the enhanced critic ability benefits inference: applying\nself-critique at test time yields an average +13.8% improvement on five\nrepresentative reasoning tasks without additional training. Our results reveal\nthat RL training on critic data can produce a unified model excelling at both\nevaluation and generation, offering a simple path toward scalable,\nself-improving multimodal systems.",
            "upvotes": 40,
            "discussionId": "68b7c0f8295f15ff609113d2",
            "githubRepo": "https://github.com/LLaVA-VL/LLaVA-NeXT/tree/main/llava-critic-r1",
            "ai_summary": "Reinforcement learning on preference-labeled critic datasets enhances a generative model's performance, creating a unified multimodal system that excels in both evaluation and generation.",
            "ai_keywords": [
                "critic models",
                "preference-labeled datasets",
                "reinforcement learning",
                "generative model",
                "LLaVA-Critic-R1",
                "multimodal critic",
                "visual reasoning",
                "understanding benchmarks",
                "Qwen-2.5-VL-7B",
                "LLaVA-Critic-R1+",
                "self-critique",
                "MMMU"
            ],
            "githubStars": 4165
        },
        "translation_title": "LLaVA-Critic-R1: 당신의 비평 모델은 사실 강력한 정책 모델입니다",
        "purpose": "비평 모델의 평가와 생성 능력을 통합하여 더 효과적인 멀티모달 모델을 개발하기 위한 연구",
        "method": [
            "비평 모델 데이터셋을 재구성하여 강화 학습을 통해 기본 생성 모델에서 직접 학습함(we propose to reorganize preference-labeled critic datasets into verifiable training signals and perform reinforcement learning directly on a base generative model)",
            "LLaVA-Critic-R1이라는 멀티모달 비평 모델을 생성하여 비평 판단을 최적화하면서도 생성 능력을 유지함(producing LLaVA-Critic-R1, a multimodal critic trained to optimize preference judgments while retaining full generation ability)",
            "비평 모델이 기존 고성능 VLM과 비교해도 경쟁력을 가지도록 개선함(We show that LLaVA-Critic-R1 emerges not only as a top-performing critic but also as a competitive policy model)"
        ],
        "conclusion": "비평 데이터에서 강화 학습을 통해 평가와 생성을 모두 잘 수행하는 통합 모델이 생성되었으며, 이는 멀티모달 시스템의 확장 가능성과 자기 개선 가능성을 향상시킴.",
        "keywords": [
            "Multimodal Learning",
            "Vision-Language Models",
            "Natural Language Processing"
        ]
    }
]