[
    {
        "paper": {
            "id": "2506.13585",
            "authors": [
                {
                    "_id": "6850d0105e07650ecce89009",
                    "name": "MiniMax",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8900b",
                    "user": {
                        "_id": "63f86b099f87cc3e645b51d9",
                        "avatarUrl": "/avatars/27ca5ba425640bf67474cee871e8e53a.svg",
                        "isPro": false,
                        "fullname": "Ellie Chen",
                        "user": "sheep33333",
                        "type": "user"
                    },
                    "name": "Aili Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T07:21:27.223Z",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8900c",
                    "name": "Aonian Li",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8900d",
                    "name": "Bangwei Gong",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8900e",
                    "name": "Binyang Jiang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8900f",
                    "name": "Bo Fei",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89010",
                    "name": "Bo Yang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89011",
                    "name": "Boji Shan",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89012",
                    "name": "Changqing Yu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89013",
                    "name": "Chao Wang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89014",
                    "name": "Cheng Zhu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89015",
                    "name": "Chengjun Xiao",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89016",
                    "name": "Chengyu Du",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89017",
                    "name": "Chi Zhang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89018",
                    "name": "Chu Qiao",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89019",
                    "user": {
                        "_id": "642662fa22bddcea3d289f0a",
                        "avatarUrl": "/avatars/9b28e1325d866a24d33fdfafcaa85c4b.svg",
                        "isPro": false,
                        "fullname": "Enoch Zhang",
                        "user": "enochzhang",
                        "type": "user"
                    },
                    "name": "Chunhao Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T07:21:43.093Z",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8901a",
                    "name": "Chunhui Du",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8901b",
                    "name": "Congchao Guo",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8901c",
                    "name": "Da Chen",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8901d",
                    "name": "Deming Ding",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8901e",
                    "name": "Dianjun Sun",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8901f",
                    "name": "Dong Li",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89020",
                    "name": "Enwei Jiao",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89021",
                    "name": "Haigang Zhou",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89022",
                    "name": "Haimo Zhang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89023",
                    "name": "Han Ding",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89024",
                    "name": "Haohai Sun",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89025",
                    "name": "Haoyu Feng",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89026",
                    "name": "Huaiguang Cai",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89027",
                    "name": "Haichao Zhu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89028",
                    "name": "Jian Sun",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89029",
                    "name": "Jiaqi Zhuang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8902a",
                    "name": "Jiaren Cai",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8902b",
                    "name": "Jiayuan Song",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8902c",
                    "user": {
                        "_id": "665d5c955491b1e10dfc4097",
                        "avatarUrl": "/avatars/1d577113e407068d29e61f670e662f81.svg",
                        "isPro": false,
                        "fullname": "Jin Zhu",
                        "user": "GinZhu",
                        "type": "user"
                    },
                    "name": "Jin Zhu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T13:06:28.403Z",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8902d",
                    "name": "Jingyang Li",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8902e",
                    "name": "Jinhao Tian",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8902f",
                    "name": "Jinli Liu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89030",
                    "name": "Junhao Xu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89031",
                    "name": "Junjie Yan",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89032",
                    "name": "Junteng Liu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89033",
                    "name": "Junxian He",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89034",
                    "name": "Kaiyi Feng",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89035",
                    "name": "Ke Yang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89036",
                    "name": "Kecheng Xiao",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89037",
                    "name": "Le Han",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89038",
                    "name": "Leyang Wang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89039",
                    "name": "Lianfei Yu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8903a",
                    "name": "Liheng Feng",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8903b",
                    "name": "Lin Li",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8903c",
                    "name": "Lin Zheng",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8903d",
                    "name": "Linge Du",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8903e",
                    "name": "Lingyu Yang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8903f",
                    "name": "Lunbin Zeng",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89040",
                    "name": "Minghui Yu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89041",
                    "name": "Mingliang Tao",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89042",
                    "name": "Mingyuan Chi",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89043",
                    "name": "Mozhi Zhang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89044",
                    "user": {
                        "_id": "67ac4d69a122ac29aed98f3c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/5NBmaUAoutU4RA85qH8mw.png",
                        "isPro": false,
                        "fullname": "LINMUJIE",
                        "user": "LINMUJIE-judy",
                        "type": "user"
                    },
                    "name": "Mujie Lin",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T07:21:37.448Z",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89045",
                    "name": "Nan Hu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89046",
                    "name": "Nongyu Di",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89047",
                    "name": "Peng Gao",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89048",
                    "name": "Pengfei Li",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89049",
                    "name": "Pengyu Zhao",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8904a",
                    "name": "Qibing Ren",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8904b",
                    "name": "Qidi Xu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8904c",
                    "name": "Qile Li",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8904d",
                    "name": "Qin Wang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8904e",
                    "name": "Rong Tian",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8904f",
                    "name": "Ruitao Leng",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89050",
                    "name": "Shaoxiang Chen",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89051",
                    "name": "Shaoyu Chen",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89052",
                    "name": "Shengmin Shi",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89053",
                    "name": "Shitong Weng",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89054",
                    "name": "Shuchang Guan",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89055",
                    "name": "Shuqi Yu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89056",
                    "name": "Sichen Li",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89057",
                    "name": "Songquan Zhu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89058",
                    "name": "Tengfei Li",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89059",
                    "name": "Tianchi Cai",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8905a",
                    "name": "Tianrun Liang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8905b",
                    "name": "Weiyu Cheng",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8905c",
                    "name": "Weize Kong",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8905d",
                    "name": "Wenkai Li",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8905e",
                    "name": "Xiancai Chen",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8905f",
                    "name": "Xiangjun Song",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89060",
                    "user": {
                        "_id": "612741a391de43c1101df014",
                        "avatarUrl": "/avatars/1461b1c7d3cedd91cea6cf3b0ecb14ae.svg",
                        "isPro": false,
                        "fullname": "Rock Luo",
                        "user": "windlx",
                        "type": "user"
                    },
                    "name": "Xiao Luo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T07:21:57.356Z",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89061",
                    "name": "Xiao Su",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89062",
                    "user": {
                        "_id": "63dc802e270a8bb46ad31783",
                        "avatarUrl": "/avatars/c0584f86663e64d64d276a32fde9be49.svg",
                        "isPro": false,
                        "fullname": "晓波",
                        "user": "lixiabo12",
                        "type": "user"
                    },
                    "name": "Xiaobo Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T13:06:42.746Z",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89063",
                    "name": "Xiaodong Han",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89064",
                    "name": "Xinzhu Hou",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89065",
                    "name": "Xuan Lu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89066",
                    "name": "Xun Zou",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89067",
                    "name": "Xuyang Shen",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89068",
                    "name": "Yan Gong",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89069",
                    "user": {
                        "_id": "633fc70529b5a95f6e15a6b7",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633fc70529b5a95f6e15a6b7/Fzh7wWuqU-fBbzdupOUtF.jpeg",
                        "isPro": false,
                        "fullname": "Yan Ma",
                        "user": "ManTle",
                        "type": "user"
                    },
                    "name": "Yan Ma",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T07:21:39.279Z",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8906a",
                    "name": "Yang Wang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8906b",
                    "name": "Yiqi Shi",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8906c",
                    "name": "Yiran Zhong",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8906d",
                    "name": "Yonghong Duan",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8906e",
                    "name": "Yongxiang Fu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8906f",
                    "name": "Yongyi Hu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89070",
                    "name": "Yu Gao",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89071",
                    "name": "Yuanxiang Fan",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89072",
                    "name": "Yufeng Yang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89073",
                    "name": "Yuhao Li",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89074",
                    "name": "Yulin Hu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89075",
                    "name": "Yunan Huang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89076",
                    "name": "Yunji Li",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89077",
                    "name": "Yunzhi Xu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89078",
                    "name": "Yuxin Mao",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89079",
                    "name": "Yuxuan Shi",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8907a",
                    "name": "Yuze Wenren",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8907b",
                    "name": "Zehan Li",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8907c",
                    "name": "Zelin Li",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8907d",
                    "name": "Zhanxu Tian",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8907e",
                    "name": "Zhengmao Zhu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce8907f",
                    "name": "Zhenhua Fan",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89080",
                    "name": "Zhenzhen Wu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89081",
                    "name": "Zhichao Xu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89082",
                    "name": "Zhihang Yu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89083",
                    "name": "Zhiheng Lyu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89084",
                    "name": "Zhuo Jiang",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89085",
                    "user": {
                        "_id": "6690a4b6a4d0df7e51b93392",
                        "avatarUrl": "/avatars/6d3694c39344854221f6ca0ed3cf0557.svg",
                        "isPro": false,
                        "fullname": "gao zibo",
                        "user": "afhhl",
                        "type": "user"
                    },
                    "name": "Zibo Gao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T07:21:41.298Z",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89086",
                    "name": "Zijia Wu",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89087",
                    "name": "Zijian Song",
                    "hidden": false
                },
                {
                    "_id": "6850d0105e07650ecce89088",
                    "name": "Zijun Sun",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-06-16T15:08:02.000Z",
            "submittedOnDailyAt": "2025-06-17T00:48:14.831Z",
            "title": "MiniMax-M1: Scaling Test-Time Compute Efficiently with Lightning\n  Attention",
            "submittedOnDailyBy": {
                "_id": "676e38ad04af5bec20bc9faf",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/676e38ad04af5bec20bc9faf/AG8Q9wAUzGtPWyjd5QO2l.jpeg",
                "isPro": false,
                "fullname": "MiniMax",
                "user": "MiniMax-AI",
                "type": "user"
            },
            "summary": "We introduce MiniMax-M1, the world's first open-weight, large-scale\nhybrid-attention reasoning model. MiniMax-M1 is powered by a hybrid\nMixture-of-Experts (MoE) architecture combined with a lightning attention\nmechanism. The model is developed based on our previous MiniMax-Text-01 model,\nwhich contains a total of 456 billion parameters with 45.9 billion parameters\nactivated per token. The M1 model natively supports a context length of 1\nmillion tokens, 8x the context size of DeepSeek R1. Furthermore, the lightning\nattention mechanism in MiniMax-M1 enables efficient scaling of test-time\ncompute. These properties make M1 particularly suitable for complex tasks that\nrequire processing long inputs and thinking extensively. MiniMax-M1 is trained\nusing large-scale reinforcement learning (RL) on diverse problems including\nsandbox-based, real-world software engineering environments. In addition to\nM1's inherent efficiency advantage for RL training, we propose CISPO, a novel\nRL algorithm to further enhance RL efficiency. CISPO clips importance sampling\nweights rather than token updates, outperforming other competitive RL variants.\nCombining hybrid-attention and CISPO enables MiniMax-M1's full RL training on\n512 H800 GPUs to complete in only three weeks, with a rental cost of just\n$534,700. We release two versions of MiniMax-M1 models with 40K and 80K\nthinking budgets respectively, where the 40K model represents an intermediate\nphase of the 80K training. Experiments on standard benchmarks show that our\nmodels are comparable or superior to strong open-weight models such as the\noriginal DeepSeek-R1 and Qwen3-235B, with particular strengths in complex\nsoftware engineering, tool utilization, and long-context tasks. We publicly\nrelease MiniMax-M1 at https://github.com/MiniMax-AI/MiniMax-M1.",
            "upvotes": 173,
            "discussionId": "6850d0105e07650ecce89089",
            "projectPage": "https://huggingface.co/MiniMaxAI/MiniMax-M1-80k",
            "githubRepo": "https://github.com/MiniMax-AI/MiniMax-M1",
            "ai_summary": "A hybrid-attention reasoning model called MiniMax-M1, featuring a Mixture-of-Experts architecture and lightning attention mechanism, is introduced for efficient long-input processing and reinforcement learning.",
            "ai_keywords": [
                "Mixture-of-Experts (MoE)",
                "lightning attention mechanism",
                "reinforcement learning (RL)",
                "CISPO",
                "importance sampling weights",
                "token updates"
            ]
        },
        "translation_title": "MiniMax-M1: 효율적인 테스트 시간 컴퓨팅을 위한 스케일링 Lightning Attention",
        "purpose": "테스트 시간에 효율적인 컴퓨팅을 지원하는 대규모 하이브리드 주의력 모델 개발",
        "method": [
            "MiniMax-M1은 하이브리드 Mixture-of-Experts (MoE) 아키텍처와 lightning attention 메커니즘을 결합하여 설계됨(We introduce MiniMax-M1, the world's first open-weight, large-scale hybrid-attention reasoning model.)",
            "대규모 강화학습(RL)을 통해 다양한 문제를 해결하도록 훈련됨(MiniMax-M1 is trained using large-scale reinforcement learning (RL) on diverse problems including sandbox-based, real-world software engineering environments.)",
            "CISPO라는 새로운 RL 알고리즘을 제안하여 효율성을 더 높임(CISPO clips importance sampling weights rather than token updates, outperforming other competitive RL variants.)"
        ],
        "conclusion": "MiniMax-M1은 복잡한 작업에 특히 적합하며, 기존 모델들과 비교해 우수한 성능을 보임.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Reinforcement Learning"
        ]
    },
    {
        "paper": {
            "id": "2506.10521",
            "authors": [
                {
                    "_id": "684b8c603b733ba333686ffe",
                    "name": "Yuhao Zhou",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333686fff",
                    "name": "Yiheng Wang",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687000",
                    "name": "Xuming He",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687001",
                    "name": "Ruoyao Xiao",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687002",
                    "name": "Zhiwei Li",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687003",
                    "name": "Qiantai Feng",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687004",
                    "name": "Zijie Guo",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687005",
                    "name": "Yuejin Yang",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687006",
                    "name": "Hao Wu",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687007",
                    "user": {
                        "_id": "675118b088a927f8898f81b4",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/qVVgc2kuR37QqO5-Lu8Xq.png",
                        "isPro": false,
                        "fullname": "Wilson Huang",
                        "user": "WilsonHwang",
                        "type": "user"
                    },
                    "name": "Wenxuan Huang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T07:22:33.270Z",
                    "hidden": true
                },
                {
                    "_id": "684b8c603b733ba333687008",
                    "name": "Jiaqi Wei",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687009",
                    "name": "Dan Si",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba33368700a",
                    "name": "Xiuqi Yao",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba33368700b",
                    "name": "Jia Bu",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba33368700c",
                    "name": "Haiwen Huang",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba33368700d",
                    "name": "Tianfan Fu",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba33368700e",
                    "name": "Shixiang Tang",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba33368700f",
                    "name": "Ben Fei",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687010",
                    "name": "Dongzhan Zhou",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687011",
                    "name": "Fenghua Ling",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687012",
                    "name": "Yan Lu",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687013",
                    "user": {
                        "_id": "67d3a1a5943a965360fcae51",
                        "avatarUrl": "/avatars/165ed684b0750e7f57b9f2babfb47a8c.svg",
                        "isPro": false,
                        "fullname": "Siqi Sun",
                        "user": "siqisun",
                        "type": "user"
                    },
                    "name": "Siqi Sun",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T13:06:51.338Z",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687014",
                    "name": "Chenhui Li",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687015",
                    "name": "Guanjie Zheng",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687016",
                    "name": "Jiancheng Lv",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687017",
                    "name": "Wenlong Zhang",
                    "hidden": false
                },
                {
                    "_id": "684b8c603b733ba333687018",
                    "name": "Lei Bai",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-06-12T09:29:16.000Z",
            "submittedOnDailyAt": "2025-06-17T02:12:14.955Z",
            "title": "Scientists' First Exam: Probing Cognitive Abilities of MLLM via\n  Perception, Understanding, and Reasoning",
            "submittedOnDailyBy": {
                "_id": "6538b861613fe158bd581e35",
                "avatarUrl": "/avatars/6817dbfe903675721fd227058b0a91ac.svg",
                "isPro": false,
                "fullname": "Dongzhan Zhou",
                "user": "schrodingers-tiger",
                "type": "user"
            },
            "summary": "Scientific discoveries increasingly rely on complex multimodal reasoning\nbased on information-intensive scientific data and domain-specific expertise.\nEmpowered by expert-level scientific benchmarks, scientific Multimodal Large\nLanguage Models (MLLMs) hold the potential to significantly enhance this\ndiscovery process in realistic workflows. However, current scientific\nbenchmarks mostly focus on evaluating the knowledge understanding capabilities\nof MLLMs, leading to an inadequate assessment of their perception and reasoning\nabilities. To address this gap, we present the Scientists' First Exam (SFE)\nbenchmark, designed to evaluate the scientific cognitive capacities of MLLMs\nthrough three interconnected levels: scientific signal perception, scientific\nattribute understanding, scientific comparative reasoning. Specifically, SFE\ncomprises 830 expert-verified VQA pairs across three question types, spanning\n66 multimodal tasks across five high-value disciplines. Extensive experiments\nreveal that current state-of-the-art GPT-o3 and InternVL-3 achieve only 34.08%\nand 26.52% on SFE, highlighting significant room for MLLMs to improve in\nscientific realms. We hope the insights obtained in SFE will facilitate further\ndevelopments in AI-enhanced scientific discoveries.",
            "upvotes": 58,
            "discussionId": "684b8c603b733ba333687019",
            "ai_summary": "Scientists' First Exam (SFE) benchmark assesses scientific cognitive capacities of Multimodal Large Language Models through perception, understanding, and comparative reasoning.",
            "ai_keywords": [
                "Multimodal Large Language Models",
                "SFE benchmark",
                "scientific signal perception",
                "scientific attribute understanding",
                "scientific comparative reasoning",
                "expert-verified VQA",
                "GPT-o3",
                "InternVL-3"
            ]
        },
        "translation_title": "과학자들의 첫 시험: 인식, 이해 및 추리를 통한 MLLM의 인지 능력 평가",
        "purpose": "과학적 발견을 위한 MLLM의 인식 및 추리 능력을 평가하기 위한 새로운 벤치마크 개발",
        "method": [
            "과학적 신호 인식, 속성 이해 및 비교 추리의 세 가지 상호 연결된 수준을 통해 MLLM의 인지 능력을 평가하도록 설계된 Scientists' First Exam(SFE) 벤치마크를 제안함(To address this gap, we present the Scientists' First Exam (SFE) benchmark, designed to evaluate the scientific cognitive capacities of MLLMs through three interconnected levels: scientific signal perception, scientific attribute understanding, scientific comparative reasoning.)",
            "SFE는 830개의 전문가 검증 VQA 쌍과 5개의 고부가 가치 분야에서 66개의 다중 모달 작업을 포함함(SFE comprises 830 expert-verified VQA pairs across three question types, spanning 66 multimodal tasks across five high-value disciplines.)",
            "현재 최첨단 모델인 GPT-3와 InternVL-3의 성능을 평가하여 MLLM의 개선 가능성을 강조함(Extensive experiments reveal that current state-of-the-art GPT-3 and InternVL-3 achieve only 34.08% and 26.52% on SFE, highlighting significant room for MLLMs to improve in scientific realms.)"
        ],
        "conclusion": "SFE의 통찰력이 AI 기반 과학적 발견의 발전을 촉진할 수 있기를 기대함.",
        "keywords": [
            "Natural Language Processing",
            "Multimodal Learning",
            "Vision-Language Models"
        ]
    },
    {
        "paper": {
            "id": "2506.11763",
            "authors": [
                {
                    "_id": "684ff5051d9b438aa3957a7f",
                    "user": {
                        "_id": "646dbba74ad7f907279dd486",
                        "avatarUrl": "/avatars/fe2b95e9a55711164e9624e1d15e0af2.svg",
                        "isPro": false,
                        "fullname": "Mingxuan Du",
                        "user": "Ayanami0730",
                        "type": "user"
                    },
                    "name": "Mingxuan Du",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-16T12:56:12.158Z",
                    "hidden": false
                },
                {
                    "_id": "684ff5051d9b438aa3957a80",
                    "name": "Benfeng Xu",
                    "hidden": false
                },
                {
                    "_id": "684ff5051d9b438aa3957a81",
                    "user": {
                        "_id": "663b22a80966eef8686aadaf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/663b22a80966eef8686aadaf/iBzyQTyGZKf33RPVIFh9a.jpeg",
                        "isPro": false,
                        "fullname": "Chiwei Zhu",
                        "user": "IgnoraZ",
                        "type": "user"
                    },
                    "name": "Chiwei Zhu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-16T12:56:09.702Z",
                    "hidden": false
                },
                {
                    "_id": "684ff5051d9b438aa3957a82",
                    "name": "Xiaorui Wang",
                    "hidden": false
                },
                {
                    "_id": "684ff5051d9b438aa3957a83",
                    "name": "Zhendong Mao",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-06-13T13:17:32.000Z",
            "submittedOnDailyAt": "2025-06-17T00:31:26.473Z",
            "title": "DeepResearch Bench: A Comprehensive Benchmark for Deep Research Agents",
            "submittedOnDailyBy": {
                "_id": "646dbba74ad7f907279dd486",
                "avatarUrl": "/avatars/fe2b95e9a55711164e9624e1d15e0af2.svg",
                "isPro": false,
                "fullname": "Mingxuan Du",
                "user": "Ayanami0730",
                "type": "user"
            },
            "summary": "Deep Research Agents are a prominent category of LLM-based agents. By\nautonomously orchestrating multistep web exploration, targeted retrieval, and\nhigher-order synthesis, they transform vast amounts of online information into\nanalyst-grade, citation-rich reports--compressing hours of manual desk research\ninto minutes. However, a comprehensive benchmark for systematically evaluating\nthe capabilities of these agents remains absent. To bridge this gap, we present\nDeepResearch Bench, a benchmark consisting of 100 PhD-level research tasks,\neach meticulously crafted by domain experts across 22 distinct fields.\nEvaluating DRAs is inherently complex and labor-intensive. We therefore propose\ntwo novel methodologies that achieve strong alignment with human judgment. The\nfirst is a reference-based method with adaptive criteria to assess the quality\nof generated research reports. The other framework is introduced to evaluate\nDRA's information retrieval and collection capabilities by assessing its\neffective citation count and overall citation accuracy. We have open-sourced\nDeepResearch Bench and key components of these frameworks at\nhttps://github.com/Ayanami0730/deep_research_bench to accelerate the\ndevelopment of practical LLM-based agents.",
            "upvotes": 38,
            "discussionId": "684ff5051d9b438aa3957a84",
            "projectPage": "https://deepresearch-bench.github.io",
            "githubRepo": "https://github.com/Ayanami0730/deep_research_bench",
            "ai_summary": "DeepResearch Bench offers a benchmark framework to evaluate the capabilities of Deep Research Agents in terms of research quality and information retrieval accuracy across multiple fields.",
            "ai_keywords": [
                "Deep Research Agents",
                "LLM-based agents",
                "multistep web exploration",
                "targeted retrieval",
                "higher-order synthesis",
                "PhD-level research tasks",
                "reference-based method",
                "effective citation count",
                "citation accuracy"
            ]
        },
        "translation_title": "DeepResearch Bench: 딥 리서치 에이전트를 위한 종합 벤치마크",
        "purpose": "딥 리서치 에이전트의 성능을 체계적으로 평가하기 위한 종합 벤치마크 개발",
        "method": [
            "100개의 박사 수준 연구 과제를 포함하는 DeepResearch Bench를 제시함(we present DeepResearch Bench, a benchmark consisting of 100 PhD-level research tasks...)",
            "인간 판단과의 강한 정합성을 이룬 두 가지 새로운 방법론을 제안함(We therefore propose two novel methodologies that achieve strong alignment with human judgment.)",
            "첫 번째 방법은 생성된 연구 보고서의 품질을 평가하기 위한 적응 기준을 가진 참조 기반 방법임(The first is a reference-based method with adaptive criteria to assess the quality of generated research reports.)",
            "두 번째 방법은 DRA의 정보 검색 및 수집 기능을 평가하기 위해 효과적인 인용 수와 인용 정확성을 평가함(The other framework is introduced to evaluate DRA's information retrieval and collection capabilities...)"
        ],
        "conclusion": "DeepResearch Bench는 딥 리서치 에이전트의 개발을 촉진하기 위해 오픈 소스로 제공되며, LLM 기반 에이전트의 진화를 가속화함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Document Parsing"
        ]
    },
    {
        "paper": {
            "id": "2506.12571",
            "authors": [
                {
                    "_id": "6850cba15e07650ecce88fce",
                    "user": {
                        "_id": "62243664af5df9d9e5582f67",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62243664af5df9d9e5582f67/nAntUd0NVDcMYtwiunCU8.jpeg",
                        "isPro": false,
                        "fullname": "Saksorn Ruangtanusak",
                        "user": "saksornr",
                        "type": "user"
                    },
                    "name": "Saksorn Ruangtanusak",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T07:21:59.261Z",
                    "hidden": false
                },
                {
                    "_id": "6850cba15e07650ecce88fcf",
                    "name": "Natthapath Rungseesiripak",
                    "hidden": false
                },
                {
                    "_id": "6850cba15e07650ecce88fd0",
                    "user": {
                        "_id": "647d9e689bb822b5cd3cc752",
                        "avatarUrl": "/avatars/c97ae9fce3ff06f9ba48feb0ea95296e.svg",
                        "isPro": false,
                        "fullname": "Peerawat",
                        "user": "boat1603",
                        "type": "user"
                    },
                    "name": "Peerawat Rojratchadakorn",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T15:13:12.119Z",
                    "hidden": false
                },
                {
                    "_id": "6850cba15e07650ecce88fd1",
                    "user": {
                        "_id": "66c5a51e82dec44cc50bc23f",
                        "avatarUrl": "/avatars/afcdb138fbe40f55283b6fd7912d7097.svg",
                        "isPro": false,
                        "fullname": "Monthol Charattrakool",
                        "user": "montholscbx",
                        "type": "user"
                    },
                    "name": "Monthol Charattrakool",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-06-17T01:57:53.939Z",
                    "hidden": false
                },
                {
                    "_id": "6850cba15e07650ecce88fd2",
                    "user": {
                        "_id": "64705d3890482b0e0f6591ed",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64705d3890482b0e0f6591ed/HqOaaRjzkXrC8POGtZYwh.jpeg",
                        "isPro": false,
                        "fullname": "Natapong Nitarach (Schwyter)",
                        "user": "natnitaract",
                        "type": "user"
                    },
                    "name": "Natapong Nitarach",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-06-17T01:57:53.939Z",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/62243664af5df9d9e5582f67/CEw32qHWVcm9CaXt5778s.png",
                "https://cdn-uploads.huggingface.co/production/uploads/62243664af5df9d9e5582f67/0uJ9QrBOx5WgVxj2UC27j.png"
            ],
            "publishedAt": "2025-06-14T16:56:00.000Z",
            "submittedOnDailyAt": "2025-06-17T08:31:40.191Z",
            "title": "DoTA-RAG: Dynamic of Thought Aggregation RAG",
            "submittedOnDailyBy": {
                "_id": "62243664af5df9d9e5582f67",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62243664af5df9d9e5582f67/nAntUd0NVDcMYtwiunCU8.jpeg",
                "isPro": false,
                "fullname": "Saksorn Ruangtanusak",
                "user": "saksornr",
                "type": "user"
            },
            "summary": "In this paper, we introduce DoTA-RAG (Dynamic-of-Thought Aggregation RAG), a\nretrieval-augmented generation system optimized for high-throughput,\nlarge-scale web knowledge indexes. Traditional RAG pipelines often suffer from\nhigh latency and limited accuracy over massive, diverse datasets. DoTA-RAG\naddresses these challenges with a three-stage pipeline: query rewriting,\ndynamic routing to specialized sub-indexes, and multi-stage retrieval and\nranking. We further enhance retrieval by evaluating and selecting a superior\nembedding model, re-embedding the large FineWeb-10BT corpus. Moreover, we\ncreate a diverse Q&A dataset of 500 questions generated via the DataMorgana\nsetup across a broad range of WebOrganizer topics and formats. DoTA-RAG\nimproves the answer correctness score from 0.752 (baseline, using LiveRAG\npre-built vector store) to 1.478 while maintaining low latency, and it achieves\na 0.929 correctness score on the Live Challenge Day. These results highlight\nDoTA-RAG's potential for practical deployment in domains requiring fast,\nreliable access to large and evolving knowledge sources.",
            "upvotes": 34,
            "discussionId": "6850cba15e07650ecce88fd3",
            "githubRepo": "https://github.com/DoTA-RAG/dota-rag",
            "ai_summary": "DoTA-RAG improves retrieval and generation accuracy over massive web datasets using a dynamic routing pipeline and optimized embedding models, achieving high correctness scores while maintaining low latency.",
            "ai_keywords": [
                "RAG",
                "DoTA-RAG",
                "query rewriting",
                "dynamic routing",
                "specialized sub-indexes",
                "multi-stage retrieval",
                "ranking",
                "embedding models",
                "re-embedding",
                "FineWeb-10BT",
                "Q&A dataset",
                "DataMorgana",
                "LiveRAG",
                "Live Challenge Day"
            ]
        },
        "translation_title": "DoTA-RAG: 사고 집합 동역학 RAG",
        "purpose": "대규모 웹 지식 인덱스에서 고속의 정확한 정보 검색을 위한 시스템 개발",
        "method": [
            "세 가지 단계의 파이프라인을 통해 쿼리 재작성, 전문 서브 인덱스에 대한 동적 라우팅, 다단계 검색 및 순위를 수행함(In this paper, we introduce DoTA-RAG (Dynamic-of-Thought Aggregation RAG), a retrieval-augmented generation system optimized for high-throughput, large-scale web knowledge indexes.)",
            "대규모 FineWeb-10BT 코퍼스의 임베딩 모델을 평가하고 선택하여 데이터 검색을 향상시킴(We further enhance retrieval by evaluating and selecting a superior embedding model, re-embedding the large FineWeb-10BT corpus.)",
            "DataMorgana를 사용해 다양한 주제와 형식의 500개의 질문으로 구성된 Q&A 데이터셋을 생성함(Moreover, we create a diverse Q&A dataset of 500 questions generated via the DataMorgana setup across a broad range of WebOrganizer topics and formats.)"
        ],
        "conclusion": "DoTA-RAG는 응답 정확도를 0.752에서 1.478로 향상시키고, 낮은 지연 시간으로 빠르고 신뢰할 수 있는 지식 접근을 가능하게 함.",
        "keywords": [
            "Natural Language Processing",
            "Multimodal Learning",
            "Document Parsing"
        ]
    },
    {
        "paper": {
            "id": "2506.13654",
            "authors": [
                {
                    "_id": "6850e2a05e07650ecce89106",
                    "user": {
                        "_id": "6658d01c6f1a71ba56d6c273",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/tc4nZrMuZQLfgt5aVxtH4.jpeg",
                        "isPro": false,
                        "fullname": "Tian Shulin",
                        "user": "shulin16",
                        "type": "user"
                    },
                    "name": "Shulin Tian",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T07:21:00.696Z",
                    "hidden": false
                },
                {
                    "_id": "6850e2a05e07650ecce89107",
                    "user": {
                        "_id": "6303e551d14428368d194477",
                        "avatarUrl": "/avatars/b3c583e4525747b314379a7613e3b115.svg",
                        "isPro": false,
                        "fullname": "Ruiqi Wang",
                        "user": "ruiqiw",
                        "type": "user"
                    },
                    "name": "Ruiqi Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-06-17T07:21:03.098Z",
                    "hidden": false
                },
                {
                    "_id": "6850e2a05e07650ecce89108",
                    "name": "Hongming Guo",
                    "hidden": false
                },
                {
                    "_id": "6850e2a05e07650ecce89109",
                    "name": "Penghao Wu",
                    "hidden": false
                },
                {
                    "_id": "6850e2a05e07650ecce8910a",
                    "name": "Yuhao Dong",
                    "hidden": false
                },
                {
                    "_id": "6850e2a05e07650ecce8910b",
                    "name": "Xiuying Wang",
                    "hidden": false
                },
                {
                    "_id": "6850e2a05e07650ecce8910c",
                    "name": "Jingkang Yang",
                    "hidden": false
                },
                {
                    "_id": "6850e2a05e07650ecce8910d",
                    "name": "Hao Zhang",
                    "hidden": false
                },
                {
                    "_id": "6850e2a05e07650ecce8910e",
                    "name": "Hongyuan Zhu",
                    "hidden": false
                },
                {
                    "_id": "6850e2a05e07650ecce8910f",
                    "name": "Ziwei Liu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-06-16T16:17:08.000Z",
            "submittedOnDailyAt": "2025-06-17T02:14:02.144Z",
            "title": "Ego-R1: Chain-of-Tool-Thought for Ultra-Long Egocentric Video Reasoning",
            "submittedOnDailyBy": {
                "_id": "6658d01c6f1a71ba56d6c273",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/tc4nZrMuZQLfgt5aVxtH4.jpeg",
                "isPro": false,
                "fullname": "Tian Shulin",
                "user": "shulin16",
                "type": "user"
            },
            "summary": "We introduce Ego-R1, a novel framework for reasoning over ultra-long (i.e.,\nin days and weeks) egocentric videos, which leverages a structured\nChain-of-Tool-Thought (CoTT) process, orchestrated by an Ego-R1 Agent trained\nvia reinforcement learning (RL). Inspired by human problem-solving strategies,\nCoTT decomposes complex reasoning into modular steps, with the RL agent\ninvoking specific tools, one per step, to iteratively and collaboratively\nanswer sub-questions tackling such tasks as temporal retrieval and multi-modal\nunderstanding. We design a two-stage training paradigm involving supervised\nfinetuning (SFT) of a pretrained language model using CoTT data and RL to\nenable our agent to dynamically propose step-by-step tools for long-range\nreasoning. To facilitate training, we construct a dataset called Ego-R1 Data,\nwhich consists of Ego-CoTT-25K for SFT and Ego-QA-4.4K for RL. Furthermore, our\nEgo-R1 agent is evaluated on a newly curated week-long video QA benchmark,\nEgo-R1 Bench, which contains human-verified QA pairs from hybrid sources.\nExtensive results demonstrate that the dynamic, tool-augmented chain-of-thought\nreasoning by our Ego-R1 Agent can effectively tackle the unique challenges of\nunderstanding ultra-long egocentric videos, significantly extending the time\ncoverage from few hours to a week.",
            "upvotes": 27,
            "discussionId": "6850e2a05e07650ecce89110",
            "ai_summary": "Ego-R1, a reinforcement learning-based framework, uses a structured tool-augmented chain-of-thought process to reason over ultra-long egocentric videos, achieving better performance than existing methods by extending time coverage to a week.",
            "ai_keywords": [
                "Chain-of-Tool-Thought",
                "CoTT",
                "reinforcement learning",
                "RL",
                "pretrained language model",
                "supervised finetuning",
                "SFT",
                "Ego-CoTT-25K",
                "Ego-QA-4.4K",
                "Ego-R1 Bench",
                "video QA",
                "temporal retrieval",
                "multi-modal understanding"
            ]
        },
        "translation_title": "Ego-R1: 초장기 자기중심 비디오 추론을 위한 Tool-Thought 체계",
        "purpose": "초장기 자기중심 비디오에서 효과적인 추론을 위한 구조화된 방법론 개발",
        "method": [
            "Ego-R1 에이전트를 훈련시키기 위해 강화 학습(RL)을 활용하여 Tool-Thought(CoTT) 과정을 설계함(we introduce Ego-R1, a novel framework for reasoning over ultra-long egocentric videos, which leverages a structured Chain-of-Tool-Thought (CoTT) process, orchestrated by an Ego-R1 Agent trained via reinforcement learning (RL).)",
            "CoTT를 통해 복잡한 문제를 모듈 단계로 나누어 RL 에이전트가 단계별 특정 도구를 호출하여 질문을 해결하도록 함(Inspired by human problem-solving strategies, CoTT decomposes complex reasoning into modular steps, with the RL agent invoking specific tools, one per step, to iteratively and collaboratively answer sub-questions.)",
            "사전 훈련된 언어 모델을 CoTT 데이터로 감독 하에 미세 조정(SFT)하고, RL을 통해 에이전트가 단계별 도구를 제안하도록 하는 두 단계의 훈련 패러다임을 설계함(We design a two-stage training paradigm involving supervised finetuning (SFT) of a pretrained language model using CoTT data and RL to enable our agent to dynamically propose step-by-step tools for long-range reasoning.)"
        ],
        "conclusion": "Ego-R1 에이전트는 초장기 자기중심 비디오 이해에 효과적으로 대응할 수 있는 도구 증강 체계의 추론 능력을 입증하였으며, 시간 범위를 몇 시간에서 일주일로 확장함.",
        "keywords": [
            "Video Understanding",
            "Natural Language Processing",
            "Large Language Models"
        ]
    }
]