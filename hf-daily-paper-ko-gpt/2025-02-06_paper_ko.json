[
    {
        "paper": {
            "id": "2502.02737",
            "authors": [
                {
                    "_id": "67a446a9430e358f5d5ac4c3",
                    "user": {
                        "_id": "61c141342aac764ce1654e43",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61c141342aac764ce1654e43/81AwoT5IQ_Xdw0OVw7TKu.jpeg",
                        "isPro": false,
                        "fullname": "Loubna Ben Allal",
                        "user": "loubnabnl",
                        "type": "user"
                    },
                    "name": "Loubna Ben Allal",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-06T14:14:56.506Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4c4",
                    "user": {
                        "_id": "602e6dee60e3dd96631c906e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1613655355830-noauth.png",
                        "isPro": false,
                        "fullname": "Anton Lozhkov",
                        "user": "anton-l",
                        "type": "user"
                    },
                    "name": "Anton Lozhkov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-06T14:14:39.237Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4c5",
                    "user": {
                        "_id": "651e96991b97c9f33d26bde6",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651e96991b97c9f33d26bde6/-Bqs6qrmz0yCfwtB2e-6q.jpeg",
                        "isPro": false,
                        "fullname": "Elie Bakouch",
                        "user": "eliebak",
                        "type": "user"
                    },
                    "name": "Elie Bakouch",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-06T14:14:45.734Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4c6",
                    "user": {
                        "_id": "60f2fc91b92afccb7c34b8ed",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60f2fc91b92afccb7c34b8ed/W2-Nay12Ef4Ltyaf8EKE9.jpeg",
                        "isPro": false,
                        "fullname": "Gabriel Martín Blázquez",
                        "user": "gabrielmbmb",
                        "type": "user"
                    },
                    "name": "Gabriel Martín Blázquez",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-06T14:14:43.746Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4c7",
                    "user": {
                        "_id": "62596f9e1c0a084224b93e00",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62596f9e1c0a084224b93e00/X2aLkJ0ofhkXwAg7lXvxD.jpeg",
                        "isPro": false,
                        "fullname": "Guilherme Penedo",
                        "user": "guipenedo",
                        "type": "user"
                    },
                    "name": "Guilherme Penedo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-06T14:14:50.085Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4c8",
                    "user": {
                        "_id": "5f0c746619cb630495b814fd",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1594651707950-noauth.jpeg",
                        "isPro": true,
                        "fullname": "Lewis Tunstall",
                        "user": "lewtun",
                        "type": "user"
                    },
                    "name": "Lewis Tunstall",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:16:30.456Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4c9",
                    "user": {
                        "_id": "65d66b494bbd0d92b641cdbb",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d66b494bbd0d92b641cdbb/6-7dm7B-JxcoS1QlCPdMN.jpeg",
                        "isPro": false,
                        "fullname": "Andres Marafioti",
                        "user": "andito",
                        "type": "user"
                    },
                    "name": "Andrés Marafioti",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:16:37.742Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4ca",
                    "user": {
                        "_id": "626ede24d2fa9e7d598c8709",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626ede24d2fa9e7d598c8709/JKS8-Y2Jw87EgNQZBRswq.jpeg",
                        "isPro": true,
                        "fullname": "Hynek Kydlicek",
                        "user": "hynky",
                        "type": "user"
                    },
                    "name": "Hynek Kydlíček",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:16:43.590Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4cb",
                    "user": {
                        "_id": "6435d564a4bd75c62cc03701",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6435d564a4bd75c62cc03701/7P2G_wVNB6MISp2Phh427.jpeg",
                        "isPro": false,
                        "fullname": "Agustín Piqueres Lajarín",
                        "user": "plaguss",
                        "type": "user"
                    },
                    "name": "Agustín Piqueres Lajarín",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:16:49.324Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4cc",
                    "user": {
                        "_id": "61b85ce86eb1f2c5e6233736",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1655385361868-61b85ce86eb1f2c5e6233736.jpeg",
                        "isPro": true,
                        "fullname": "Vaibhav Srivastav",
                        "user": "reach-vb",
                        "type": "user"
                    },
                    "name": "Vaibhav Srivastav",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-06T14:14:52.239Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4cd",
                    "user": {
                        "_id": "61b253b7ac5ecaae3d1efe0c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61b253b7ac5ecaae3d1efe0c/hwiQ0uvz3t-L5a-NtBIO6.png",
                        "isPro": false,
                        "fullname": "Joshua",
                        "user": "Xenova",
                        "type": "user"
                    },
                    "name": "Joshua Lochner",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-06T14:14:36.878Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4ce",
                    "user": {
                        "_id": "648a374f00f7a3374ee64b99",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/648a374f00f7a3374ee64b99/YPwSOrronoozwHbJchPn3.jpeg",
                        "isPro": true,
                        "fullname": "Caleb Fahlgren",
                        "user": "cfahlgren1",
                        "type": "user"
                    },
                    "name": "Caleb Fahlgren",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:16:56.849Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4cf",
                    "user": {
                        "_id": "63ca214abedad7e2bf1d1517",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674191139776-noauth.png",
                        "isPro": false,
                        "fullname": "Xuan Son NGUYEN",
                        "user": "ngxson",
                        "type": "user"
                    },
                    "name": "Xuan-Son Nguyen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:17:02.477Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4d0",
                    "user": {
                        "_id": "6202a599216215a22221dea9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1644340617257-noauth.png",
                        "isPro": false,
                        "fullname": "Clémentine Fourrier",
                        "user": "clefourrier",
                        "type": "user"
                    },
                    "name": "Clémentine Fourrier",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-06T14:14:54.591Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4d1",
                    "user": {
                        "_id": "62d648291fa3e4e7ae3fa6e8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62d648291fa3e4e7ae3fa6e8/oatOwf8Xqe5eDbCSuYqCd.png",
                        "isPro": false,
                        "fullname": "ben burtenshaw",
                        "user": "burtenshaw",
                        "type": "user"
                    },
                    "name": "Ben Burtenshaw",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-06T14:14:41.918Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4d2",
                    "user": {
                        "_id": "641cc77c92cd25302998b740",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/641cc77c92cd25302998b740/5A81W5s3ecLaLXFir52Rw.jpeg",
                        "isPro": false,
                        "fullname": "Hugo Larcher",
                        "user": "hlarcher",
                        "type": "user"
                    },
                    "name": "Hugo Larcher",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:17:14.767Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4d3",
                    "user": {
                        "_id": "660ed80b1889bf2cd53cab7f",
                        "avatarUrl": "/avatars/93ee6ff00668c2698ad8b6fa6f072b92.svg",
                        "isPro": false,
                        "fullname": "Haojun Zhao",
                        "user": "zzhhjjj",
                        "type": "user"
                    },
                    "name": "Haojun Zhao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:17:33.798Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4d4",
                    "user": {
                        "_id": "66ba71a4447411b9c0e19d71",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/4f93ZrYdaKfK3F53IB51x.jpeg",
                        "isPro": false,
                        "fullname": "Cyril",
                        "user": "cyrilzakka",
                        "type": "user"
                    },
                    "name": "Cyril Zakka",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:17:43.679Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4d5",
                    "user": {
                        "_id": "664d7d1e4f54c9372970e121",
                        "avatarUrl": "/avatars/695a209d6951a4623eceedcd2eed3a68.svg",
                        "isPro": false,
                        "fullname": "Mathieu Morlon",
                        "user": "glutamatt",
                        "type": "user"
                    },
                    "name": "Mathieu Morlon",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:17:50.199Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4d6",
                    "user": {
                        "_id": "6079c29765b9d0165cb18392",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1618592397610-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Colin Raffel",
                        "user": "craffel",
                        "type": "user"
                    },
                    "name": "Colin Raffel",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:17:57.936Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4d7",
                    "user": {
                        "_id": "5e48005437cb5b49818287a5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5e48005437cb5b49818287a5/4uCXGGui-9QifAT4qelxU.png",
                        "isPro": false,
                        "fullname": "Leandro von Werra",
                        "user": "lvwerra",
                        "type": "user"
                    },
                    "name": "Leandro von Werra",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T11:03:02.572Z",
                    "hidden": false
                },
                {
                    "_id": "67a446a9430e358f5d5ac4d8",
                    "user": {
                        "_id": "5df7e9e5da6d0311fd3d53f9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1583857746553-5df7e9e5da6d0311fd3d53f9.jpeg",
                        "isPro": true,
                        "fullname": "Thomas Wolf",
                        "user": "thomwolf",
                        "type": "user"
                    },
                    "name": "Thomas Wolf",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:14:14.159Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-04T21:43:16.000Z",
            "title": "SmolLM2: When Smol Goes Big -- Data-Centric Training of a Small Language\n  Model",
            "summary": "While large language models have facilitated breakthroughs in many\napplications of artificial intelligence, their inherent largeness makes them\ncomputationally expensive and challenging to deploy in resource-constrained\nsettings. In this paper, we document the development of SmolLM2, a\nstate-of-the-art \"small\" (1.7 billion parameter) language model (LM). To attain\nstrong performance, we overtrain SmolLM2 on ~11 trillion tokens of data using a\nmulti-stage training process that mixes web text with specialized math, code,\nand instruction-following data. We additionally introduce new specialized\ndatasets (FineMath, Stack-Edu, and SmolTalk) at stages where we found existing\ndatasets to be problematically small or low-quality. To inform our design\ndecisions, we perform both small-scale ablations as well as a manual refinement\nprocess that updates the dataset mixing rates at each stage based on the\nperformance at the previous stage. Ultimately, we demonstrate that SmolLM2\noutperforms other recent small LMs including Qwen2.5-1.5B and Llama3.2-1B. To\nfacilitate future research on LM development as well as applications of small\nLMs, we release both SmolLM2 as well as all of the datasets we prepared in the\ncourse of this project.",
            "upvotes": 61,
            "discussionId": "67a446a9430e358f5d5ac4f8"
        },
        "translation_title": "SmolLM2: 작지만 임팩트 있는 데이터 중심의 작은 언어 모델 훈련",
        "purpose": "자원 제한 환경에서 효율적으로 활용할 수 있는 경량 언어 모델의 성능 향상",
        "method": [
            "약 11조 개의 토큰을 활용해 SmolLM2를 다단계 훈련 프로세스로 과훈련함(we overtrain SmolLM2 on ~11 trillion tokens of data using a multi-stage training process).",
            "기존 데이터셋의 문제를 해결하기 위해 새로운 전문 데이터셋(FineMath, Stack-Edu, SmolTalk)을 도입함(we additionally introduce new specialized datasets at stages where we found existing datasets to be problematically small or low-quality).",
            "성능 기반으로 데이터셋 혼합 비율을 조정하는 수동 정제 과정을 수행함(a manual refinement process that updates the dataset mixing rates at each stage based on the performance at the previous stage)."
        ],
        "conclusion": "SmolLM2는 Qwen2.5-1.5B 및 Llama3.2-1B와 같은 최근의 작은 LM들을 능가하는 성과를 보여줌.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2502.01506",
            "authors": [
                {
                    "_id": "67a4214f12b90b15dc5a648e",
                    "user": {
                        "_id": "63f622c69cbd6730302783eb",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63f622c69cbd6730302783eb/9cb96JVKiOm_JhF-shbFw.jpeg",
                        "isPro": false,
                        "fullname": "Yuzhe Yang",
                        "user": "TobyYang7",
                        "type": "user"
                    },
                    "name": "Yuzhe Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-06T14:15:03.582Z",
                    "hidden": false
                },
                {
                    "_id": "67a4214f12b90b15dc5a648f",
                    "user": {
                        "_id": "643c047326f177a3e41627b6",
                        "avatarUrl": "/avatars/ade75cebd049daf080ba80a80d516240.svg",
                        "isPro": false,
                        "fullname": "Yifei Zhang",
                        "user": "amstrongzyf",
                        "type": "user"
                    },
                    "name": "Yifei Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-06T14:15:05.578Z",
                    "hidden": false
                },
                {
                    "_id": "67a4214f12b90b15dc5a6490",
                    "user": {
                        "_id": "62d4bf8c97ab9eb08762a975",
                        "avatarUrl": "/avatars/73c6228e317cf37b4e3c3e7a4b3d8ae8.svg",
                        "isPro": false,
                        "fullname": "Minghao Wu",
                        "user": "minghaowu",
                        "type": "user"
                    },
                    "name": "Minghao Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:18:20.423Z",
                    "hidden": false
                },
                {
                    "_id": "67a4214f12b90b15dc5a6491",
                    "name": "Kaidi Zhang",
                    "hidden": false
                },
                {
                    "_id": "67a4214f12b90b15dc5a6492",
                    "name": "Yunmiao Zhang",
                    "hidden": false
                },
                {
                    "_id": "67a4214f12b90b15dc5a6493",
                    "name": "Honghai Yu",
                    "hidden": false
                },
                {
                    "_id": "67a4214f12b90b15dc5a6494",
                    "name": "Yan Hu",
                    "hidden": false
                },
                {
                    "_id": "67a4214f12b90b15dc5a6495",
                    "user": {
                        "_id": "637c6703ca8542a0ba900ccb",
                        "avatarUrl": "/avatars/288ed63a1efa566c3f01e850c6ba5dd5.svg",
                        "isPro": false,
                        "fullname": "Wang",
                        "user": "Benyou",
                        "type": "user"
                    },
                    "name": "Benyou Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:34:30.901Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T16:39:48.000Z",
            "title": "TwinMarket: A Scalable Behavioral and Social Simulation for Financial\n  Markets",
            "summary": "The study of social emergence has long been a central focus in social\nscience. Traditional modeling approaches, such as rule-based Agent-Based Models\n(ABMs), struggle to capture the diversity and complexity of human behavior,\nparticularly the irrational factors emphasized in behavioral economics.\nRecently, large language model (LLM) agents have gained traction as simulation\ntools for modeling human behavior in social science and role-playing\napplications. Studies suggest that LLMs can account for cognitive biases,\nemotional fluctuations, and other non-rational influences, enabling more\nrealistic simulations of socio-economic dynamics. In this work, we introduce\nTwinMarket, a novel multi-agent framework that leverages LLMs to simulate\nsocio-economic systems. Specifically, we examine how individual behaviors,\nthrough interactions and feedback mechanisms, give rise to collective dynamics\nand emergent phenomena. Through experiments in a simulated stock market\nenvironment, we demonstrate how individual actions can trigger group behaviors,\nleading to emergent outcomes such as financial bubbles and recessions. Our\napproach provides valuable insights into the complex interplay between\nindividual decision-making and collective socio-economic patterns.",
            "upvotes": 26,
            "discussionId": "67a4215212b90b15dc5a650a"
        },
        "translation_title": "TwinMarket: 금융 시장을 위한 확장 가능한 행동 및 사회 시뮬레이션",
        "purpose": "행동 경제학의 비합리적 요소를 포함한 인간 행동의 다양성과 복잡성을 포착하기 위한 새로운 시뮬레이션 도구 개발",
        "method": [
            "대규모 언어 모델(LLM)을 활용하여 개인의 행동이 집단 동학과 emergent 현상을 어떻게 형성하는지 연구함(We introduce TwinMarket, a novel multi-agent framework that leverages LLMs to simulate socio-economic systems.)",
            "주식 시장 환경에서 실험을 통해 개인 행동이 집단 행동을 유발하는 방식을 입증함(Through experiments in a simulated stock market environment, we demonstrate how individual actions can trigger group behaviors.)",
            "개인의 결정이 집단적인 사회경제적 패턴에 미치는 복잡한 상호 작용을 분석함(Our approach provides valuable insights into the complex interplay between individual decision-making and collective socio-economic patterns.)"
        ],
        "conclusion": "TwinMarket을 통해 개인 행동과 집단 동학 사이의 상호 작용을 보다 정교하게 이해할 수 있게 되었으며, 이는 금융 버블과 불황 같은 emergent 결과를 설명하는 데 기여함.",
        "keywords": [
            "Large Language Models",
            "Multimodal Learning",
            "Robotics"
        ]
    },
    {
        "paper": {
            "id": "2502.03373",
            "authors": [
                {
                    "_id": "67a42c079a4fb11b11cc4f6f",
                    "name": "Edward Yeo",
                    "hidden": false
                },
                {
                    "_id": "67a42c079a4fb11b11cc4f70",
                    "user": {
                        "_id": "6448e1fbe988635a3d6aa97d",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/eG4R9-3hgrimttP7ep3dN.jpeg",
                        "isPro": false,
                        "fullname": "Shawn/Yuxuan Tong",
                        "user": "tongyx361",
                        "type": "user"
                    },
                    "name": "Yuxuan Tong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:34:50.960Z",
                    "hidden": false
                },
                {
                    "_id": "67a42c079a4fb11b11cc4f71",
                    "user": {
                        "_id": "65bb14f139c4e7087640a91c",
                        "avatarUrl": "/avatars/dbf75dd161d22b4511e9fccff6afc515.svg",
                        "isPro": false,
                        "fullname": "Morry Niu",
                        "user": "bl1ndbot",
                        "type": "user"
                    },
                    "name": "Morry Niu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:34:57.424Z",
                    "hidden": false
                },
                {
                    "_id": "67a42c079a4fb11b11cc4f72",
                    "user": {
                        "_id": "60de14638bedd2315529d43f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1625166923504-noauth.png",
                        "isPro": false,
                        "fullname": "Graham Neubig",
                        "user": "gneubig",
                        "type": "user"
                    },
                    "name": "Graham Neubig",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:35:04.994Z",
                    "hidden": false
                },
                {
                    "_id": "67a42c079a4fb11b11cc4f73",
                    "user": {
                        "_id": "6230d750d93e84e233882dbc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
                        "isPro": false,
                        "fullname": "Xiang Yue",
                        "user": "yuexiang96",
                        "type": "user"
                    },
                    "name": "Xiang Yue",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:35:19.222Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-05T17:13:32.000Z",
            "title": "Demystifying Long Chain-of-Thought Reasoning in LLMs",
            "summary": "Scaling inference compute enhances reasoning in large language models (LLMs),\nwith long chains-of-thought (CoTs) enabling strategies like backtracking and\nerror correction. Reinforcement learning (RL) has emerged as a crucial method\nfor developing these capabilities, yet the conditions under which long CoTs\nemerge remain unclear, and RL training requires careful design choices. In this\nstudy, we systematically investigate the mechanics of long CoT reasoning,\nidentifying the key factors that enable models to generate long CoT\ntrajectories. Through extensive supervised fine-tuning (SFT) and RL\nexperiments, we present four main findings: (1) While SFT is not strictly\nnecessary, it simplifies training and improves efficiency; (2) Reasoning\ncapabilities tend to emerge with increased training compute, but their\ndevelopment is not guaranteed, making reward shaping crucial for stabilizing\nCoT length growth; (3) Scaling verifiable reward signals is critical for RL. We\nfind that leveraging noisy, web-extracted solutions with filtering mechanisms\nshows strong potential, particularly for out-of-distribution (OOD) tasks such\nas STEM reasoning; and (4) Core abilities like error correction are inherently\npresent in base models, but incentivizing these skills effectively for complex\ntasks via RL demands significant compute, and measuring their emergence\nrequires a nuanced approach. These insights provide practical guidance for\noptimizing training strategies to enhance long CoT reasoning in LLMs. Our code\nis available at: https://github.com/eddycmu/demystify-long-cot.",
            "upvotes": 18,
            "discussionId": "67a42c089a4fb11b11cc4fae"
        },
        "translation_title": "LLM의 긴 사고 과정을 해명하기",
        "purpose": "대형 언어 모델에서 긴 사고 과정(reasoning)의 메커니즘을 이해하고 최적화하는 방법을 연구하기 위해",
        "method": [
            "기계적 원리를 체계적으로 조사하여 긴 사고 과정을 생성하는 주요 요소를 식별함(we systematically investigate the mechanics of long CoT reasoning, identifying the key factors that enable models to generate long CoT trajectories.)",
            "광범위한 감독된 미세 조정(Supervised Fine-Tuning, SFT)과 강화 학습(Reinforcement Learning, RL) 실험을 수행함(Through extensive supervised fine-tuning and RL experiments, we present four main findings.)",
            "훈련 컴퓨팅을 증가시켰을 때 사고 능력이 나타나지만, 안정성을 위해 보상이 중요함을 발견함(Reasoning capabilities tend to emerge with increased training compute, but their development is not guaranteed, making reward shaping crucial for stabilizing CoT length growth.)"
        ],
        "conclusion": "이 연구는 LLM의 긴 사고 과정 개선을 위한 훈련 전략 최적화를 위한 실용적인 지침을 제공함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Reinforcement Learning"
        ]
    },
    {
        "paper": {
            "id": "2502.03387",
            "authors": [
                {
                    "_id": "67a445ccbdd74b63b4e52a7d",
                    "name": "Yixin Ye",
                    "hidden": false
                },
                {
                    "_id": "67a445ccbdd74b63b4e52a7e",
                    "user": {
                        "_id": "643581a4f3b08e267d990499",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/643581a4f3b08e267d990499/KRhB-48W4IPuB0bX16Ahj.png",
                        "isPro": false,
                        "fullname": "Zhen Huang",
                        "user": "ZhenHuang",
                        "type": "user"
                    },
                    "name": "Zhen Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:37:03.643Z",
                    "hidden": false
                },
                {
                    "_id": "67a445ccbdd74b63b4e52a7f",
                    "name": "Yang Xiao",
                    "hidden": false
                },
                {
                    "_id": "67a445ccbdd74b63b4e52a80",
                    "user": {
                        "_id": "64bb5f9d8e051085bace4d1e",
                        "avatarUrl": "/avatars/15ccbb78c6131dfe46b7a9d8e7d1a31f.svg",
                        "isPro": true,
                        "fullname": "Ethan Chern",
                        "user": "ethanchern",
                        "type": "user"
                    },
                    "name": "Ethan Chern",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:36:45.045Z",
                    "hidden": false
                },
                {
                    "_id": "67a445ccbdd74b63b4e52a81",
                    "user": {
                        "_id": "65900d4ff5a209eeac08b463",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65900d4ff5a209eeac08b463/PJNNBRJIk1qR24oaRLTex.jpeg",
                        "isPro": false,
                        "fullname": "shijie xia",
                        "user": "seven-cat",
                        "type": "user"
                    },
                    "name": "Shijie Xia",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-06T14:14:59.334Z",
                    "hidden": false
                },
                {
                    "_id": "67a445ccbdd74b63b4e52a82",
                    "user": {
                        "_id": "6144a0c4ff1146bbd84d9865",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1661715958139-6144a0c4ff1146bbd84d9865.png",
                        "isPro": true,
                        "fullname": "Pengfei Liu",
                        "user": "Pengfei",
                        "type": "user"
                    },
                    "name": "Pengfei Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:36:38.049Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-05T17:23:45.000Z",
            "title": "LIMO: Less is More for Reasoning",
            "summary": "We present a fundamental discovery that challenges our understanding of how\ncomplex reasoning emerges in large language models. While conventional wisdom\nsuggests that sophisticated reasoning tasks demand extensive training data\n(>100,000 examples), we demonstrate that complex mathematical reasoning\nabilities can be effectively elicited with surprisingly few examples. Through\ncomprehensive experiments, our proposed model LIMO demonstrates unprecedented\nperformance in mathematical reasoning. With merely 817 curated training\nsamples, LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH, improving from\nprevious SFT-based models' 6.5% and 59.2% respectively, while only using 1% of\nthe training data required by previous approaches. LIMO demonstrates\nexceptional out-of-distribution generalization, achieving 40.5% absolute\nimprovement across 10 diverse benchmarks, outperforming models trained on 100x\nmore data, challenging the notion that SFT leads to memorization rather than\ngeneralization. Based on these results, we propose the Less-Is-More Reasoning\nHypothesis (LIMO Hypothesis): In foundation models where domain knowledge has\nbeen comprehensively encoded during pre-training, sophisticated reasoning\ncapabilities can emerge through minimal but precisely orchestrated\ndemonstrations of cognitive processes. This hypothesis posits that the\nelicitation threshold for complex reasoning is determined by two key factors:\n(1) the completeness of the model's encoded knowledge foundation during\npre-training, and (2) the effectiveness of post-training examples as \"cognitive\ntemplates\" that show the model how to utilize its knowledge base to solve\ncomplex reasoning tasks. To facilitate reproducibility and future research in\ndata-efficient reasoning, we release LIMO as a comprehensive open-source suite\nat https://github.com/GAIR-NLP/LIMO.",
            "upvotes": 15,
            "discussionId": "67a445cdbdd74b63b4e52af7"
        },
        "translation_title": "LIMO: 적은 것이 더 많은 추론을 위한 방법",
        "purpose": "복잡한 추론 능력을 적은 데이터로도 효과적으로 끌어낼 수 있음을 밝히고, 데이터 효율적인 추론 연구 지원",
        "method": [
            "LIMO라는 모델을 통해 817개의 샘플로 AIME에서 57.1%, MATH에서 94.8%의 정확도를 달성함을 보여줌.(LIMO achieves 57.1% accuracy on AIME and 94.8% on MATH with merely 817 curated training samples.)",
            "이 모델은 기존의 SFT 기반 모델들이 요구했던 데이터의 1%로도 성능을 크게 향상시킴.(LIMO improves from previous SFT-based models' accuracy with only 1% of the training data required by previous approaches.)",
            "기존의 100배 더 많은 데이터로 훈련된 모델들보다 다양한 벤치마크에서 뛰어난 성능을 보임.(LIMO demonstrates exceptional out-of-distribution generalization, outperforming models trained on 100x more data.)"
        ],
        "conclusion": "LIMO 모델은 적은 데이터로도 복잡한 수학적 추론을 가능하게 하며, Less-Is-More Reasoning Hypothesis를 제안하여 기존의 추론 능력에 대한 이해를 도전함.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2502.02339",
            "authors": [
                {
                    "_id": "67a3262873bdaf626f1e9eab",
                    "user": {
                        "_id": "6747de57f8cab58c22ec94a2",
                        "avatarUrl": "/avatars/5bae0341862fac24564781c0fa32aac5.svg",
                        "isPro": false,
                        "fullname": "Jinyang Wu",
                        "user": "Jinyang23",
                        "type": "user"
                    },
                    "name": "Jinyang Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-06T14:15:16.426Z",
                    "hidden": false
                },
                {
                    "_id": "67a3262873bdaf626f1e9eac",
                    "user": {
                        "_id": "660d13b85e00095e45ee28e0",
                        "avatarUrl": "/avatars/8f06c01edc2a791266feadc775acb901.svg",
                        "isPro": false,
                        "fullname": "FengMingkuan",
                        "user": "fmk345",
                        "type": "user"
                    },
                    "name": "Mingkuan Feng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:37:21.287Z",
                    "hidden": false
                },
                {
                    "_id": "67a3262873bdaf626f1e9ead",
                    "name": "Shuai Zhang",
                    "hidden": false
                },
                {
                    "_id": "67a3262873bdaf626f1e9eae",
                    "user": {
                        "_id": "64be16d8ef8c0e42bf3d27f6",
                        "avatarUrl": "/avatars/6ae308088f6f196d9f470655dae0c14d.svg",
                        "isPro": false,
                        "fullname": "Ruihan Jin",
                        "user": "RuihanJin",
                        "type": "user"
                    },
                    "name": "Ruihan Jin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:37:48.323Z",
                    "hidden": false
                },
                {
                    "_id": "67a3262873bdaf626f1e9eaf",
                    "user": {
                        "_id": "63ef2de81e695b35aa4813a2",
                        "avatarUrl": "/avatars/6abd1918c1b94d927c7c976054e16322.svg",
                        "isPro": false,
                        "fullname": "feihu",
                        "user": "feihuchen",
                        "type": "user"
                    },
                    "name": "Feihu Che",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-06T14:37:55.510Z",
                    "hidden": false
                },
                {
                    "_id": "67a3262873bdaf626f1e9eb0",
                    "name": "Zengqi Wen",
                    "hidden": false
                },
                {
                    "_id": "67a3262873bdaf626f1e9eb1",
                    "name": "Jianhua Tao",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-04T14:18:29.000Z",
            "title": "Boosting Multimodal Reasoning with MCTS-Automated Structured Thinking",
            "summary": "Multimodal large language models (MLLMs) exhibit impressive capabilities but\nstill face challenges in complex visual reasoning. While recent efforts attempt\nto enhance MLLMs' reasoning by incorporating OpenAI o1-like structured thinking\nthrough explicit search structures or teacher-guided distillation, they often\nstruggle to balance performance and efficiency. A critical limitation is their\nheavy reliance on extensive data and search spaces, resulting in low-efficiency\nimplicit insight extraction and data utilization. To address this, we propose\nAStar, an Automated Structured thinking paradigm for multimodal reasoning via\nMonte Carlo Tree Search (MCTS). AStar automatically derives high-level\ncognitive reasoning patterns from limited data using MCTS-powered hierarchical\nstructures. Building on these explicit patterns, we design a unified reasoning\nframework that seamlessly integrates models' internal reasoning capabilities\nand external reasoning guidelines, enabling efficient inference with minimal\ntree iterations. This novel paradigm strikes a compelling balance between\nperformance and efficiency. Extensive experiments demonstrate AStar's\neffectiveness, achieving superior accuracy (54.0%) on the MathVerse\nbenchmark with a 7B backbone, surpassing GPT-4o (50.2%) while maintaining\nsubstantial data and computational efficiency.",
            "upvotes": 9,
            "discussionId": "67a3262973bdaf626f1e9edb"
        },
        "translation_title": "MCTS-자동화된 구조적 사고를 통한 다중 모달 추론 강화",
        "purpose": "다중 모달 대형 언어 모델(MLLMs)의 복잡한 시각적 추론 능력을 향상시키기 위한 효율적인 방법 개발",
        "method": [
            "Monte Carlo Tree Search(MCTS)를 이용하여 제한된 데이터에서 고급 인지 추론 패턴을 자동으로 도출함(To address this, we propose AStar, an Automated Structured thinking paradigm for multimodal reasoning via Monte Carlo Tree Search (MCTS).)",
            "MCTS 기반의 계층적 구조를 활용하여 명시적인 패턴을 설정한 후, 모델의 내부 추론 능력과 외부 추론 지침을 통합하는 통합 추론 프레임워크를 설계함(Building on these explicit patterns, we design a unified reasoning framework that seamlessly integrates models' internal reasoning capabilities and external reasoning guidelines.)",
            "최소한의 트리 반복을 통해 효율적인 추론을 가능하게 함(enabling efficient inference with minimal tree iterations.)"
        ],
        "conclusion": "AStar는 성능과 효율성 간의 균형을 잘 유지하여 MathVerse 벤치마크에서 54.0%의 높은 정확도를 달성하며 GPT-4o를 초월함.",
        "keywords": [
            "Multimodal Learning",
            "Large Language Models",
            "Vision-Language Models"
        ]
    }
]