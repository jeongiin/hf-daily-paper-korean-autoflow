[
    {
        "paper": {
            "id": "2505.16938",
            "authors": [
                {
                    "_id": "682fe3a565bac3ec3556fc6c",
                    "name": "NovelSeek Team",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc6d",
                    "name": "Bo Zhang",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc6e",
                    "name": "Shiyang Feng",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc6f",
                    "name": "Xiangchao Yan",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc70",
                    "name": "Jiakang Yuan",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc71",
                    "name": "Zhiyin Yu",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc72",
                    "name": "Xiaohan He",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc73",
                    "name": "Songtao Huang",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc74",
                    "name": "Shaowei Hou",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc75",
                    "name": "Zheng Nie",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc76",
                    "name": "Zhilong Wang",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc77",
                    "name": "Jinyao Liu",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc78",
                    "name": "Runmin Ma",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc79",
                    "name": "Tianshuo Peng",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc7a",
                    "name": "Peng Ye",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc7b",
                    "name": "Dongzhan Zhou",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc7c",
                    "name": "Shufei Zhang",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc7d",
                    "name": "Xiaosong Wang",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc7e",
                    "name": "Yilan Zhang",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc7f",
                    "name": "Meng Li",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc80",
                    "name": "Zhongying Tu",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc81",
                    "name": "Xiangyu Yue",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc82",
                    "name": "Wangli Ouyang",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc83",
                    "name": "Bowen Zhou",
                    "hidden": false
                },
                {
                    "_id": "682fe3a565bac3ec3556fc84",
                    "name": "Lei Bai",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-05-22T17:27:43.000Z",
            "submittedOnDailyAt": "2025-05-23T01:25:34.477Z",
            "title": "NovelSeek: When Agent Becomes the Scientist -- Building Closed-Loop\n  System from Hypothesis to Verification",
            "submittedOnDailyBy": {
                "_id": "643dfd235aafbdca3a5792c0",
                "avatarUrl": "/avatars/ce8553cf5936012c692e08054ee27937.svg",
                "isPro": false,
                "fullname": "Bo Zhang",
                "user": "BoZhang",
                "type": "user"
            },
            "summary": "Artificial Intelligence (AI) is accelerating the transformation of scientific\nresearch paradigms, not only enhancing research efficiency but also driving\ninnovation. We introduce NovelSeek, a unified closed-loop multi-agent framework\nto conduct Autonomous Scientific Research (ASR) across various scientific\nresearch fields, enabling researchers to tackle complicated problems in these\nfields with unprecedented speed and precision. NovelSeek highlights three key\nadvantages: 1) Scalability: NovelSeek has demonstrated its versatility across\n12 scientific research tasks, capable of generating innovative ideas to enhance\nthe performance of baseline code. 2) Interactivity: NovelSeek provides an\ninterface for human expert feedback and multi-agent interaction in automated\nend-to-end processes, allowing for the seamless integration of domain expert\nknowledge. 3) Efficiency: NovelSeek has achieved promising performance gains in\nseveral scientific fields with significantly less time cost compared to human\nefforts. For instance, in reaction yield prediction, it increased from 27.6% to\n35.4% in just 12 hours; in enhancer activity prediction, accuracy rose from\n0.52 to 0.79 with only 4 hours of processing; and in 2D semantic segmentation,\nprecision advanced from 78.8% to 81.0% in a mere 30 hours.",
            "upvotes": 74,
            "discussionId": "682fe3a865bac3ec3556fd21"
        },
        "translation_title": "NovelSeek: 에이전트가 과학자가 되는 것 -- 가설에서 검증까지의 폐쇄 루프 시스템 구축",
        "purpose": "Autonomous Scientific Research(ASR)를 통해 다양한 과학 연구 분야에서 복잡한 문제를 더욱 빠르고 정밀하게 해결하기 위한 목표",
        "method": [
            "NovelSeek라는 통합된 폐쇄 루프 다중 에이전트 프레임워크를 소개함(We introduce NovelSeek, a unified closed-loop multi-agent framework to conduct Autonomous Scientific Research (ASR) across various scientific research fields.)",
            "12가지의 과학 연구 과제에서 성능 향상을 위한 혁신적인 아이디어 생성을 시현함(NovelSeek has demonstrated its versatility across 12 scientific research tasks, capable of generating innovative ideas to enhance the performance of baseline code.)",
            "인간 전문가의 피드백을 통합하여 다중 에이전트가 상호작용하는 인터페이스 제공함(NovelSeek provides an interface for human expert feedback and multi-agent interaction in automated end-to-end processes.)",
            "다양한 과학 분야에서 적은 시간 비용으로 뛰어난 성과를 달성함(NovelSeek has achieved promising performance gains in several scientific fields with significantly less time cost compared to human efforts.)"
        ],
        "conclusion": "NovelSeek는 과학 연구에서 빠르고 효율적인 성과를 이끌어내며, 기존 인간 연구 작업 대비 성능을 크게 향상시켰음을 보여줌.",
        "keywords": [
            "Robotics",
            "Natural Language Processing",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2505.14810",
            "authors": [
                {
                    "_id": "682ea2b450671dc82688b8ad",
                    "user": {
                        "_id": "640ad17a1ee054d66a74783e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/640ad17a1ee054d66a74783e/u0PjIkyC-9HkGzEyUQ7JN.jpeg",
                        "isPro": false,
                        "fullname": "Tingchen Fu",
                        "user": "TingchenFu",
                        "type": "user"
                    },
                    "name": "Tingchen Fu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-05-22T07:15:44.217Z",
                    "hidden": false
                },
                {
                    "_id": "682ea2b450671dc82688b8ae",
                    "name": "Jiawei Gu",
                    "hidden": false
                },
                {
                    "_id": "682ea2b450671dc82688b8af",
                    "user": {
                        "_id": "63f3502a520c14618925825a",
                        "avatarUrl": "/avatars/e986a2a6625e7be6890616a417f908d2.svg",
                        "isPro": false,
                        "fullname": "Yafu Li",
                        "user": "yaful",
                        "type": "user"
                    },
                    "name": "Yafu Li",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-05-22T04:06:13.396Z",
                    "hidden": false
                },
                {
                    "_id": "682ea2b450671dc82688b8b0",
                    "name": "Xiaoye Qu",
                    "hidden": false
                },
                {
                    "_id": "682ea2b450671dc82688b8b1",
                    "name": "Yu Cheng",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-05-20T18:18:01.000Z",
            "submittedOnDailyAt": "2025-05-23T00:49:30.349Z",
            "title": "Scaling Reasoning, Losing Control: Evaluating Instruction Following in\n  Large Reasoning Models",
            "submittedOnDailyBy": {
                "_id": "64cb54da1af278541d663708",
                "avatarUrl": "/avatars/c44507cc92bb2e83154bad31b90ce6dd.svg",
                "isPro": false,
                "fullname": "Xiaoye Qu",
                "user": "Xiaoye08",
                "type": "user"
            },
            "summary": "Instruction-following is essential for aligning large language models (LLMs)\nwith user intent. While recent reasoning-oriented models exhibit impressive\nperformance on complex mathematical problems, their ability to adhere to\nnatural language instructions remains underexplored. In this work, we introduce\nMathIF, a dedicated benchmark for evaluating instruction-following in\nmathematical reasoning tasks. Our empirical analysis reveals a consistent\ntension between scaling up reasoning capacity and maintaining controllability,\nas models that reason more effectively often struggle to comply with user\ndirectives. We find that models tuned on distilled long chains-of-thought or\ntrained with reasoning-oriented reinforcement learning often degrade in\ninstruction adherence, especially when generation length increases.\nFurthermore, we show that even simple interventions can partially recover\nobedience, though at the cost of reasoning performance. These findings\nhighlight a fundamental tension in current LLM training paradigms and motivate\nthe need for more instruction-aware reasoning models. We release the code and\ndata at https://github.com/TingchenFu/MathIF.",
            "upvotes": 44,
            "discussionId": "682ea2b550671dc82688b8e2",
            "githubRepo": "https://github.com/TingchenFu/MathIF",
            "ai_summary": "An empirical analysis of MathIF identifies a tension between enhancing reasoning capacity and maintaining instruction adherence in large language models.",
            "ai_keywords": [
                "instruction-following",
                "reasoning-oriented models",
                "benchmarks",
                "chains-of-thought",
                "reinforcement learning",
                "instruction adherence"
            ]
        },
        "translation_title": "확장된 추론과 통제 상실: 대규모 추론 모델에서 지시 수행 평가",
        "purpose": "대규모 언어 모델을 사용자 의도에 맞게 조정하기 위한 지시 수행 능력 평가",
        "method": [
            "수학적 추론 과제를 평가하기 위해 MathIF라는 전용 벤치마크를 도입함(we introduce MathIF, a dedicated benchmark for evaluating instruction-following in mathematical reasoning tasks.)",
            "모델이 지시를 따르는 능력을 확인하기 위해 실증 분석을 수행함(Our empirical analysis reveals a consistent tension between scaling up reasoning capacity and maintaining controllability.)",
            "긴 사고의 흐름으로 조정된 모델이 사용자의 지시에 대한 준수에서 저하되는 경향을 발견함(we find that models tuned on distilled long chains-of-thought often degrade in instruction adherence.)"
        ],
        "conclusion": "현재의 LLM 훈련 방식에서 지시와 추론 성능 간의 근본적인 긴장이 존재하며, 지시를 인식하는 추론 모델의 필요성이 강조됨.",
        "keywords": [
            "Natural Language Processing",
            "Large Language Models",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2505.16410",
            "authors": [
                {
                    "_id": "682fd6045e83dc325675312b",
                    "name": "Guanting Dong",
                    "hidden": false
                },
                {
                    "_id": "682fd6045e83dc325675312c",
                    "name": "Yifei Chen",
                    "hidden": false
                },
                {
                    "_id": "682fd6045e83dc325675312d",
                    "name": "Xiaoxi Li",
                    "hidden": false
                },
                {
                    "_id": "682fd6045e83dc325675312e",
                    "name": "Jiajie Jin",
                    "hidden": false
                },
                {
                    "_id": "682fd6045e83dc325675312f",
                    "name": "Hongjin Qian",
                    "hidden": false
                },
                {
                    "_id": "682fd6045e83dc3256753130",
                    "name": "Yutao Zhu",
                    "hidden": false
                },
                {
                    "_id": "682fd6045e83dc3256753131",
                    "name": "Hangyu Mao",
                    "hidden": false
                },
                {
                    "_id": "682fd6045e83dc3256753132",
                    "name": "Guorui Zhou",
                    "hidden": false
                },
                {
                    "_id": "682fd6045e83dc3256753133",
                    "name": "Zhicheng Dou",
                    "hidden": false
                },
                {
                    "_id": "682fd6045e83dc3256753134",
                    "name": "Ji-Rong Wen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-05-22T09:00:19.000Z",
            "submittedOnDailyAt": "2025-05-23T00:31:41.669Z",
            "title": "Tool-Star: Empowering LLM-Brained Multi-Tool Reasoner via Reinforcement\n  Learning",
            "submittedOnDailyBy": {
                "_id": "61cd4b833dd34ba1985e0753",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61cd4b833dd34ba1985e0753/BfHfrwotoMESpXZOHiIe4.png",
                "isPro": false,
                "fullname": "KABI",
                "user": "dongguanting",
                "type": "user"
            },
            "summary": "Recently, large language models (LLMs) have shown remarkable reasoning\ncapabilities via large-scale reinforcement learning (RL). However, leveraging\nthe RL algorithm to empower effective multi-tool collaborative reasoning in\nLLMs remains an open challenge. In this paper, we introduce Tool-Star, an\nRL-based framework designed to empower LLMs to autonomously invoke multiple\nexternal tools during stepwise reasoning. Tool-Star integrates six types of\ntools and incorporates systematic designs in both data synthesis and training.\nTo address the scarcity of tool-use data, we propose a general tool-integrated\nreasoning data synthesis pipeline, which combines tool-integrated prompting\nwith hint-based sampling to automatically and scalably generate tool-use\ntrajectories. A subsequent quality normalization and difficulty-aware\nclassification process filters out low-quality samples and organizes the\ndataset from easy to hard. Furthermore, we propose a two-stage training\nframework to enhance multi-tool collaborative reasoning by: (1) cold-start\nfine-tuning, which guides LLMs to explore reasoning patterns via\ntool-invocation feedback; and (2) a multi-tool self-critic RL algorithm with\nhierarchical reward design, which reinforces reward understanding and promotes\neffective tool collaboration. Experimental analyses on over 10 challenging\nreasoning benchmarks highlight the effectiveness and efficiency of Tool-Star.\nThe code is available at https://github.com/dongguanting/Tool-Star.",
            "upvotes": 40,
            "discussionId": "682fd6055e83dc3256753187",
            "projectPage": "https://github.com/dongguanting/Tool-Star/",
            "githubRepo": "https://github.com/dongguanting/Tool-Star/",
            "ai_summary": "Tool-Star, an RL-based framework, enables LLMs to autonomously use multiple tools for stepwise reasoning, leveraging data synthesis and hierarchical reward design.",
            "ai_keywords": [
                "large language models",
                "LLMs",
                "large-scale reinforcement learning",
                "RL",
                "multi-tool collaborative reasoning",
                "tool-use data",
                "tool-integrated reasoning",
                "tool-invocation feedback",
                "multi-tool self-critic",
                "hierarchical reward design"
            ]
        },
        "translation_title": "Tool-Star: 강화 학습을 통한 LLM 기반 다중 도구 추론 강화",
        "purpose": "LLM이 다중 도구를 효과적으로 협업하여 추론할 수 있도록 하는 방법 개발",
        "method": [
            "RL 기반의 Tool-Star 프레임워크를 도입하여 LLM이 단계적 추론 중 여러 외부 도구를 자율적으로 호출할 수 있도록 설계함(we introduce Tool-Star, an RL-based framework designed to empower LLMs to autonomously invoke multiple external tools during stepwise reasoning.)",
            "도구 사용 데이터 부족 문제를 해결하기 위해 일반적인 도구 통합 추론 데이터 생성 파이프라인을 제안함(we propose a general tool-integrated reasoning data synthesis pipeline, which combines tool-integrated prompting with hint-based sampling to automatically and scalably generate tool-use trajectories.)",
            "다단계 학습 프레임워크를 통해 다중 도구 협업 추론을 강화함(Furthermore, we propose a two-stage training framework to enhance multi-tool collaborative reasoning by: ... )."
        ],
        "conclusion": "Tool-Star는 10개 이상의 도전적인 추론 벤치마크에서 효과성과 효율성을 입증하였으며, LLM의 다중 도구 간 협업을 강화하는 데 도움을 줌.",
        "keywords": [
            "Natural Language Processing",
            "Reinforcement Learning",
            "Multimodal Learning"
        ]
    },
    {
        "paper": {
            "id": "2505.16707",
            "authors": [
                {
                    "_id": "682fdd77e3102e71872d9b00",
                    "name": "Yongliang Wu",
                    "hidden": false
                },
                {
                    "_id": "682fdd77e3102e71872d9b01",
                    "name": "Zonghui Li",
                    "hidden": false
                },
                {
                    "_id": "682fdd77e3102e71872d9b02",
                    "name": "Xinting Hu",
                    "hidden": false
                },
                {
                    "_id": "682fdd77e3102e71872d9b03",
                    "name": "Xinyu Ye",
                    "hidden": false
                },
                {
                    "_id": "682fdd77e3102e71872d9b04",
                    "name": "Xianfang Zeng",
                    "hidden": false
                },
                {
                    "_id": "682fdd77e3102e71872d9b05",
                    "name": "Gang Yu",
                    "hidden": false
                },
                {
                    "_id": "682fdd77e3102e71872d9b06",
                    "name": "Wenbo Zhu",
                    "hidden": false
                },
                {
                    "_id": "682fdd77e3102e71872d9b07",
                    "name": "Bernt Schiele",
                    "hidden": false
                },
                {
                    "_id": "682fdd77e3102e71872d9b08",
                    "name": "Ming-Hsuan Yang",
                    "hidden": false
                },
                {
                    "_id": "682fdd77e3102e71872d9b09",
                    "name": "Xu Yang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-05-22T14:08:59.000Z",
            "submittedOnDailyAt": "2025-05-23T00:59:23.402Z",
            "title": "KRIS-Bench: Benchmarking Next-Level Intelligent Image Editing Models",
            "submittedOnDailyBy": {
                "_id": "66f6bc97980d52c75c300511",
                "avatarUrl": "/avatars/f7c23c4b09701580b533212ec9b6e306.svg",
                "isPro": false,
                "fullname": "Yongliang",
                "user": "Liang0223",
                "type": "user"
            },
            "summary": "Recent advances in multi-modal generative models have enabled significant\nprogress in instruction-based image editing. However, while these models\nproduce visually plausible outputs, their capacity for knowledge-based\nreasoning editing tasks remains under-explored. In this paper, we introduce\nKRIS-Bench (Knowledge-based Reasoning in Image-editing Systems Benchmark), a\ndiagnostic benchmark designed to assess models through a cognitively informed\nlens. Drawing from educational theory, KRIS-Bench categorizes editing tasks\nacross three foundational knowledge types: Factual, Conceptual, and Procedural.\nBased on this taxonomy, we design 22 representative tasks spanning 7 reasoning\ndimensions and release 1,267 high-quality annotated editing instances. To\nsupport fine-grained evaluation, we propose a comprehensive protocol that\nincorporates a novel Knowledge Plausibility metric, enhanced by knowledge hints\nand calibrated through human studies. Empirical results on 10 state-of-the-art\nmodels reveal significant gaps in reasoning performance, highlighting the need\nfor knowledge-centric benchmarks to advance the development of intelligent\nimage editing systems.",
            "upvotes": 36,
            "discussionId": "682fdd79e3102e71872d9b79",
            "projectPage": "https://yongliang-wu.github.io/kris_bench_project_page/",
            "githubRepo": "https://github.com/mercurystraw/Kris_Bench",
            "ai_summary": "KRIS-Bench assesses generative models' knowledge-based reasoning in image editing through a taxonomy of editing tasks and a Knowledge Plausibility metric.",
            "ai_keywords": [
                "multi-modal generative models",
                "instruction-based image editing",
                "knowledge-based reasoning",
                "KRIS-Bench",
                "cognitive assessment",
                "foundational knowledge types",
                "Factual",
                "Conceptual",
                "Procedural",
                "reasoning dimensions",
                "Knowledge Plausibility metric"
            ]
        },
        "translation_title": "KRIS-Bench: 차세대 지능형 이미지 편집 모델 벤치마킹",
        "purpose": "지식 기반 추론 편집 작업을 평가하기 위한 벤치마크 개발",
        "method": [
            "KRIS-Bench라는 진단 벤치마크를 도입하여 모델을 인지적으로 평가하도록 설계함(we introduce KRIS-Bench (Knowledge-based Reasoning in Image-editing Systems Benchmark), a diagnostic benchmark designed to assess models through a cognitively informed lens.)",
            "편집 작업을 사실적, 개념적, 절차적 등 세 가지 기본 지식 유형으로 분류함(KRIS-Bench categorizes editing tasks across three foundational knowledge types: Factual, Conceptual, and Procedural.)",
            "22개의 대표 과제를 설계하고 1,267개의 고품질 주석이 달린 편집 사례를 발표함(we design 22 representative tasks spanning 7 reasoning dimensions and release 1,267 high-quality annotated editing instances.)",
            "새로운 Knowledge Plausibility 메트릭을 제안하여 세밀한 평가를 지원함(we propose a comprehensive protocol that incorporates a novel Knowledge Plausibility metric, enhanced by knowledge hints and calibrated through human studies.)"
        ],
        "conclusion": "10개의 최첨단 모델에 대한 실험 결과 지식 기반 벤치마크의 필요성을 강조하며 지능형 이미지 편집 시스템의 발전을 위한 새로운 표준을 제시함.",
        "keywords": [
            "Image Editing",
            "Multimodal Learning",
            "Computer Vision"
        ]
    },
    {
        "paper": {
            "id": "2505.15966",
            "authors": [
                {
                    "_id": "682fe6bd5f80e910085b5116",
                    "name": "Alex Su",
                    "hidden": false
                },
                {
                    "_id": "682fe6bd5f80e910085b5117",
                    "name": "Haozhe Wang",
                    "hidden": false
                },
                {
                    "_id": "682fe6bd5f80e910085b5118",
                    "name": "Weimin Ren",
                    "hidden": false
                },
                {
                    "_id": "682fe6bd5f80e910085b5119",
                    "name": "Fangzhen Lin",
                    "hidden": false
                },
                {
                    "_id": "682fe6bd5f80e910085b511a",
                    "user": {
                        "_id": "6313a86154e6e5d9f0f94e04",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg",
                        "isPro": false,
                        "fullname": "Wenhu Chen",
                        "user": "wenhu",
                        "type": "user"
                    },
                    "name": "Wenhu Chen",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-05-23T03:08:46.964Z",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/6313a86154e6e5d9f0f94e04/pPkAUFC7KKDS7Q9fhZKmM.png"
            ],
            "publishedAt": "2025-05-21T19:35:08.000Z",
            "submittedOnDailyAt": "2025-05-23T01:39:51.922Z",
            "title": "Pixel Reasoner: Incentivizing Pixel-Space Reasoning with\n  Curiosity-Driven Reinforcement Learning",
            "submittedOnDailyBy": {
                "_id": "6313a86154e6e5d9f0f94e04",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg",
                "isPro": false,
                "fullname": "Wenhu Chen",
                "user": "wenhu",
                "type": "user"
            },
            "summary": "Chain-of-thought reasoning has significantly improved the performance of\nLarge Language Models (LLMs) across various domains. However, this reasoning\nprocess has been confined exclusively to textual space, limiting its\neffectiveness in visually intensive tasks. To address this limitation, we\nintroduce the concept of reasoning in the pixel-space. Within this novel\nframework, Vision-Language Models (VLMs) are equipped with a suite of visual\nreasoning operations, such as zoom-in and select-frame. These operations enable\nVLMs to directly inspect, interrogate, and infer from visual evidences, thereby\nenhancing reasoning fidelity for visual tasks. Cultivating such pixel-space\nreasoning capabilities in VLMs presents notable challenges, including the\nmodel's initially imbalanced competence and its reluctance to adopt the newly\nintroduced pixel-space operations. We address these challenges through a\ntwo-phase training approach. The first phase employs instruction tuning on\nsynthesized reasoning traces to familiarize the model with the novel visual\noperations. Following this, a reinforcement learning (RL) phase leverages a\ncuriosity-driven reward scheme to balance exploration between pixel-space\nreasoning and textual reasoning. With these visual operations, VLMs can\ninteract with complex visual inputs, such as information-rich images or videos\nto proactively gather necessary information. We demonstrate that this approach\nsignificantly improves VLM performance across diverse visual reasoning\nbenchmarks. Our 7B model, \\model, achieves 84\\% on V* bench, 74\\% on\nTallyQA-Complex, and 84\\% on InfographicsVQA, marking the highest accuracy\nachieved by any open-source model to date. These results highlight the\nimportance of pixel-space reasoning and the effectiveness of our framework.",
            "upvotes": 30,
            "discussionId": "682fe6bf5f80e910085b51ae",
            "ai_summary": "Introducing pixel-space reasoning in Vision-Language Models (VLMs) through visual operations like zoom-in and select-frame enhances their performance on visual tasks.",
            "ai_keywords": [
                "Vision-Language Models",
                "VLMs",
                "pixel-space reasoning",
                "visual reasoning operations",
                "zoom-in",
                "select-frame",
                "reinforcement learning",
                "RL",
                "curiosity-driven reward scheme",
                "V* bench",
                "TallyQA-Complex",
                "InfographicsVQA"
            ]
        },
        "translation_title": "Pixel Reasoner: 호기심 기반 강화 학습을 통한 픽셀 공간 추론 촉진",
        "purpose": "시각적 작업에서의 추론 능력을 향상시키기 위한 픽셀 공간 추론 개념 도입",
        "method": [
            "Vision-Language Models(VLMs)에 시각 추론 연산을 추가하여 직접적으로 시각적 증거를 검사하고 추론할 수 있도록 함(To address this limitation, we introduce the concept of reasoning in the pixel-space.)",
            "두 단계의 훈련 방식을 통해 모델이 새로운 시각적 작업에 익숙해지도록 하여 호기심 기반 보상 체계를 활용하여 픽셀과 텍스트 추론의 균형을 맞춤(We address these challenges through a two-phase training approach.)",
            "이러한 시각적 연산을 사용하여 복잡한 시각 입력들과 상호작용하여 필요한 정보를 능동적으로 수집함(With these visual operations, VLMs can interact with complex visual inputs, such as information-rich images or videos.)"
        ],
        "conclusion": "이 접근 방식이 VLM의 성능을 크게 향상시켰으며, 현재 존재하는 오픈 소스 모델 중에서 가장 높은 정확도를 달성했음을 보여줌.",
        "keywords": [
            "Computer Vision",
            "Vision-Language Models",
            "Image Understanding"
        ]
    }
]