[
    "{'paper': {'id': '2507.11097', 'authors': [{'_id': '687dd6672e8db0930be6f115', 'user': {'_id': '653b8c3e97a4d71d950e2f20', 'avatarUrl': '/avatars/b68880022e14556d0be58c69615db3be.svg', 'isPro': False, 'fullname': 'Zichen Wen', 'user': 'zichenwen', 'type': 'user'}, 'name': 'Zichen Wen', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-07-21T14:21:58.863Z', 'hidden': False}, {'_id': '687dd6672e8db0930be6f116', 'user': {'_id': '66b980d66d490d845f8a697e', 'avatarUrl': '/avatars/6ab2d08436851063f55baaadae8c4bc0.svg', 'isPro': False, 'fullname': 'Joshua Qu', 'user': 'Joshua999', 'type': 'user'}, 'name': 'Jiashu Qu', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-07-21T08:29:23.761Z', 'hidden': False}, {'_id': '687dd6672e8db0930be6f117', 'name': 'Dongrui Liu', 'hidden': False}, {'_id': '687dd6672e8db0930be6f118', 'name': 'Zhiyuan Liu', 'hidden': False}, {'_id': '687dd6672e8db0930be6f119', 'name': 'Ruixi Wu', 'hidden': False}, {'_id': '687dd6672e8db0930be6f11a', 'name': 'Yicun Yang', 'hidden': False}, {'_id': '687dd6672e8db0930be6f11b', 'name': 'Xiangqi Jin', 'hidden': False}, {'_id': '687dd6672e8db0930be6f11c', 'name': 'Haoyun Xu', 'hidden': False}, {'_id': '687dd6672e8db0930be6f11d', 'name': 'Xuyang Liu', 'hidden': False}, {'_id': '687dd6672e8db0930be6f11e', 'name': 'Weijia Li', 'hidden': False}, {'_id': '687dd6672e8db0930be6f11f', 'name': 'Chaochao Lu', 'hidden': False}, {'_id': '687dd6672e8db0930be6f120', 'name': 'Jing Shao', 'hidden': False}, {'_id': '687dd6672e8db0930be6f121', 'name': 'Conghui He', 'hidden': False}, {'_id': '687dd6672e8db0930be6f122', 'name': 'Linfeng Zhang', 'hidden': False}], 'publishedAt': '2025-07-15T08:44:46.000Z', 'submittedOnDailyAt': '2025-07-21T04:29:32.691Z', 'title': 'The Devil behind the mask: An emergent safety vulnerability of Diffusion\\n  LLMs', 'submittedOnDailyBy': {'_id': '653b8c3e97a4d71d950e2f20', 'avatarUrl': '/avatars/b68880022e14556d0be58c69615db3be.svg', 'isPro': False, 'fullname': 'Zichen Wen', 'user': 'zichenwen', 'type': 'user'}, 'summary': 'Diffusion-based large language models (dLLMs) have recently emerged as a\\npowerful alternative to autoregressive LLMs, offering faster inference and\\ngreater interactivity via parallel decoding and bidirectional modeling.\\nHowever, despite strong performance in code generation and text infilling, we\\nidentify a fundamental safety concern: existing alignment mechanisms fail to\\nsafeguard dLLMs against context-aware, masked-input adversarial prompts,\\nexposing novel vulnerabilities. To this end, we present DIJA, the first\\nsystematic study and jailbreak attack framework that exploits unique safety\\nweaknesses of dLLMs. Specifically, our proposed DIJA constructs adversarial\\ninterleaved mask-text prompts that exploit the text generation mechanisms of\\ndLLMs, i.e., bidirectional modeling and parallel decoding. Bidirectional\\nmodeling drives the model to produce contextually consistent outputs for masked\\nspans, even when harmful, while parallel decoding limits model dynamic\\nfiltering and rejection sampling of unsafe content. This causes standard\\nalignment mechanisms to fail, enabling harmful completions in alignment-tuned\\ndLLMs, even when harmful behaviors or unsafe instructions are directly exposed\\nin the prompt. Through comprehensive experiments, we demonstrate that DIJA\\nsignificantly outperforms existing jailbreak methods, exposing a previously\\noverlooked threat surface in dLLM architectures. Notably, our method achieves\\nup to 100% keyword-based ASR on Dream-Instruct, surpassing the strongest prior\\nbaseline, ReNeLLM, by up to 78.5% in evaluator-based ASR on JailbreakBench and\\nby 37.7 points in StrongREJECT score, while requiring no rewriting or hiding of\\nharmful content in the jailbreak prompt. Our findings underscore the urgent\\nneed for rethinking safety alignment in this emerging class of language models.\\nCode is available at https://github.com/ZichenWen1/DIJA.', 'upvotes': 35, 'discussionId': '687dd6672e8db0930be6f123', 'githubRepo': 'https://github.com/ZichenWen1/DIJA', 'ai_summary': 'DIJA is a framework that exploits safety weaknesses in diffusion-based large language models by constructing adversarial prompts, demonstrating significant vulnerabilities in their alignment mechanisms.', 'ai_keywords': ['diffusion-based large language models', 'dLLMs', 'autoregressive LLMs', 'parallel decoding', 'bidirectional modeling', 'adversarial prompts', 'DIJA', 'jailbreak attack framework', 'context-aware', 'masked-input', 'text generation mechanisms', 'dynamic filtering', 'rejection sampling', 'harmful completions', 'alignment-tuned dLLMs', 'keyword-based ASR', 'evaluator-based ASR', 'JailbreakBench', 'StrongREJECT score'], 'githubStars': 35}, 'publishedAt': '2025-07-15T04:44:46.000Z', 'title': 'The Devil behind the mask: An emergent safety vulnerability of Diffusion\\n  LLMs', 'summary': 'Diffusion-based large language models (dLLMs) have recently emerged as a\\npowerful alternative to autoregressive LLMs, offering faster inference and\\ngreater interactivity via parallel decoding and bidirectional modeling.\\nHowever, despite strong performance in code generation and text infilling, we\\nidentify a fundamental safety concern: existing alignment mechanisms fail to\\nsafeguard dLLMs against context-aware, masked-input adversarial prompts,\\nexposing novel vulnerabilities. To this end, we present DIJA, the first\\nsystematic study and jailbreak attack framework that exploits unique safety\\nweaknesses of dLLMs. Specifically, our proposed DIJA constructs adversarial\\ninterleaved mask-text prompts that exploit the text generation mechanisms of\\ndLLMs, i.e., bidirectional modeling and parallel decoding. Bidirectional\\nmodeling drives the model to produce contextually consistent outputs for masked\\nspans, even when harmful, while parallel decoding limits model dynamic\\nfiltering and rejection sampling of unsafe content. This causes standard\\nalignment mechanisms to fail, enabling harmful completions in alignment-tuned\\ndLLMs, even when harmful behaviors or unsafe instructions are directly exposed\\nin the prompt. Through comprehensive experiments, we demonstrate that DIJA\\nsignificantly outperforms existing jailbreak methods, exposing a previously\\noverlooked threat surface in dLLM architectures. Notably, our method achieves\\nup to 100% keyword-based ASR on Dream-Instruct, surpassing the strongest prior\\nbaseline, ReNeLLM, by up to 78.5% in evaluator-based ASR on JailbreakBench and\\nby 37.7 points in StrongREJECT score, while requiring no rewriting or hiding of\\nharmful content in the jailbreak prompt. Our findings underscore the urgent\\nneed for rethinking safety alignment in this emerging class of language models.\\nCode is available at https://github.com/ZichenWen1/DIJA.', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.11097.png', 'numComments': 1, 'submittedBy': {'_id': '653b8c3e97a4d71d950e2f20', 'avatarUrl': '/avatars/b68880022e14556d0be58c69615db3be.svg', 'fullname': 'Zichen Wen', 'name': 'zichenwen', 'type': 'user', 'isPro': False, 'isHf': False, 'isHfAdmin': False, 'isMod': False, 'followerCount': 6}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2507.13563', 'authors': [{'_id': '687e0fa92e8db0930be6f1b5', 'name': 'Kirill Borodin', 'hidden': False}, {'_id': '687e0fa92e8db0930be6f1b6', 'name': 'Nikita Vasiliev', 'hidden': False}, {'_id': '687e0fa92e8db0930be6f1b7', 'name': 'Vasiliy Kudryavtsev', 'hidden': False}, {'_id': '687e0fa92e8db0930be6f1b8', 'name': 'Maxim Maslov', 'hidden': False}, {'_id': '687e0fa92e8db0930be6f1b9', 'name': 'Mikhail Gorodnichev', 'hidden': False}, {'_id': '687e0fa92e8db0930be6f1ba', 'name': 'Oleg Rogov', 'hidden': False}, {'_id': '687e0fa92e8db0930be6f1bb', 'name': 'Grach Mkrtchian', 'hidden': False}], 'publishedAt': '2025-07-17T22:41:40.000Z', 'submittedOnDailyAt': '2025-07-21T08:36:55.760Z', 'title': 'A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges\\n  in Russian Speech Generative Models', 'submittedOnDailyBy': {'_id': '66d01df0f16d96c3ec3c38ce', 'avatarUrl': '/avatars/3d908e6e92736b38c85e352c77ba0102.svg', 'isPro': False, 'fullname': 'kiril', 'user': 'korallll', 'type': 'user'}, 'summary': 'Russian speech synthesis presents distinctive challenges, including vowel\\nreduction, consonant devoicing, variable stress patterns, homograph ambiguity,\\nand unnatural intonation. This paper introduces Balalaika, a novel dataset\\ncomprising more than 2,000 hours of studio-quality Russian speech with\\ncomprehensive textual annotations, including punctuation and stress markings.\\nExperimental results show that models trained on Balalaika significantly\\noutperform those trained on existing datasets in both speech synthesis and\\nenhancement tasks. We detail the dataset construction pipeline, annotation\\nmethodology, and results of comparative evaluations.', 'upvotes': 33, 'discussionId': '687e0faa2e8db0930be6f1bc', 'githubRepo': 'https://github.com/mtuciru/balalaika', 'ai_summary': 'Balalaika, a large Russian speech dataset with detailed annotations, improves performance in speech synthesis and enhancement tasks.', 'ai_keywords': ['speech synthesis', 'vowel reduction', 'consonant devoicing', 'stress patterns', 'homograph ambiguity', 'intonation', 'dataset', 'textual annotations', 'punctuation', 'stress markings', 'comparative evaluations'], 'githubStars': 1}, 'publishedAt': '2025-07-17T18:41:40.000Z', 'title': 'A Data-Centric Framework for Addressing Phonetic and Prosodic Challenges\\n  in Russian Speech Generative Models', 'summary': 'Russian speech synthesis presents distinctive challenges, including vowel\\nreduction, consonant devoicing, variable stress patterns, homograph ambiguity,\\nand unnatural intonation. This paper introduces Balalaika, a novel dataset\\ncomprising more than 2,000 hours of studio-quality Russian speech with\\ncomprehensive textual annotations, including punctuation and stress markings.\\nExperimental results show that models trained on Balalaika significantly\\noutperform those trained on existing datasets in both speech synthesis and\\nenhancement tasks. We detail the dataset construction pipeline, annotation\\nmethodology, and results of comparative evaluations.', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.13563.png', 'numComments': 1, 'submittedBy': {'_id': '66d01df0f16d96c3ec3c38ce', 'avatarUrl': '/avatars/3d908e6e92736b38c85e352c77ba0102.svg', 'fullname': 'kiril', 'name': 'korallll', 'type': 'user', 'isPro': False, 'isHf': False, 'isHfAdmin': False, 'isMod': False}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2507.14137', 'authors': [{'_id': '687de5df2e8db0930be6f14b', 'name': 'Shashanka Venkataramanan', 'hidden': False}, {'_id': '687de5df2e8db0930be6f14c', 'name': 'Valentinos Pariza', 'hidden': False}, {'_id': '687de5df2e8db0930be6f14d', 'name': 'Mohammadreza Salehi', 'hidden': False}, {'_id': '687de5df2e8db0930be6f14e', 'name': 'Lukas Knobel', 'hidden': False}, {'_id': '687de5df2e8db0930be6f14f', 'name': 'Spyros Gidaris', 'hidden': False}, {'_id': '687de5df2e8db0930be6f150', 'name': 'Elias Ramzi', 'hidden': False}, {'_id': '687de5df2e8db0930be6f151', 'name': 'Andrei Bursuc', 'hidden': False}, {'_id': '687de5df2e8db0930be6f152', 'name': 'Yuki M. Asano', 'hidden': False}], 'publishedAt': '2025-07-18T17:59:55.000Z', 'submittedOnDailyAt': '2025-07-21T05:31:52.139Z', 'title': 'Franca: Nested Matryoshka Clustering for Scalable Visual Representation\\n  Learning', 'submittedOnDailyBy': {'_id': '637d21239a5217b88b7549c3', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/637d21239a5217b88b7549c3/LrIGPiva5VGVZG87rTAJz.jpeg', 'isPro': False, 'fullname': 'Yuki Asano', 'user': 'yukimasano', 'type': 'user'}, 'summary': 'We present Franca (pronounced Fran-ka): free one; the first fully open-source\\n(data, code, weights) vision foundation model that matches and in many cases\\nsurpasses the performance of state-of-the-art proprietary models, e.g., DINOv2,\\nCLIP, SigLIPv2, etc. Our approach is grounded in a transparent training\\npipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K and\\na subset of ReLAION-2B. Beyond model release, we tackle critical limitations in\\nSSL clustering methods. While modern models rely on assigning image features to\\nlarge codebooks via clustering algorithms like Sinkhorn-Knopp, they fail to\\naccount for the inherent ambiguity in clustering semantics. To address this, we\\nintroduce a parameter-efficient, multi-head clustering projector based on\\nnested Matryoshka representations. This design progressively refines features\\ninto increasingly fine-grained clusters without increasing the model size,\\nenabling both performance and memory efficiency. Additionally, we propose a\\nnovel positional disentanglement strategy that explicitly removes positional\\nbiases from dense representations, thereby improving the encoding of semantic\\ncontent. This leads to consistent gains on several downstream benchmarks,\\ndemonstrating the utility of cleaner feature spaces. Our contributions\\nestablish a new standard for transparent, high-performance vision models and\\nopen a path toward more reproducible and generalizable foundation models for\\nthe broader AI community. The code and model checkpoints are available at\\nhttps://github.com/valeoai/Franca.', 'upvotes': 11, 'discussionId': '687de5df2e8db0930be6f153', 'githubRepo': 'https://github.com/valeoai/Franca', 'ai_summary': 'Franca, an open-source vision foundation model, achieves high performance using a transparent training pipeline and novel clustering and disentanglement techniques.', 'ai_keywords': ['Web-SSL', 'ImageNet-21K', 'ReLAION-2B', 'Sinkhorn-Knopp', 'parameter-efficient', 'multi-head clustering projector', 'nested Matryoshka representations', 'positional disentanglement strategy', 'semantic content', 'downstream benchmarks'], 'githubStars': 16}, 'publishedAt': '2025-07-18T13:59:55.000Z', 'title': 'Franca: Nested Matryoshka Clustering for Scalable Visual Representation\\n  Learning', 'summary': 'We present Franca (pronounced Fran-ka): free one; the first fully open-source\\n(data, code, weights) vision foundation model that matches and in many cases\\nsurpasses the performance of state-of-the-art proprietary models, e.g., DINOv2,\\nCLIP, SigLIPv2, etc. Our approach is grounded in a transparent training\\npipeline inspired by Web-SSL and uses publicly available data: ImageNet-21K and\\na subset of ReLAION-2B. Beyond model release, we tackle critical limitations in\\nSSL clustering methods. While modern models rely on assigning image features to\\nlarge codebooks via clustering algorithms like Sinkhorn-Knopp, they fail to\\naccount for the inherent ambiguity in clustering semantics. To address this, we\\nintroduce a parameter-efficient, multi-head clustering projector based on\\nnested Matryoshka representations. This design progressively refines features\\ninto increasingly fine-grained clusters without increasing the model size,\\nenabling both performance and memory efficiency. Additionally, we propose a\\nnovel positional disentanglement strategy that explicitly removes positional\\nbiases from dense representations, thereby improving the encoding of semantic\\ncontent. This leads to consistent gains on several downstream benchmarks,\\ndemonstrating the utility of cleaner feature spaces. Our contributions\\nestablish a new standard for transparent, high-performance vision models and\\nopen a path toward more reproducible and generalizable foundation models for\\nthe broader AI community. The code and model checkpoints are available at\\nhttps://github.com/valeoai/Franca.', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.14137.png', 'numComments': 1, 'submittedBy': {'_id': '637d21239a5217b88b7549c3', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/637d21239a5217b88b7549c3/LrIGPiva5VGVZG87rTAJz.jpeg', 'fullname': 'Yuki Asano', 'name': 'yukimasano', 'type': 'user', 'isPro': False, 'isHf': False, 'isHfAdmin': False, 'isMod': False, 'followerCount': 5}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2507.12566', 'authors': [{'_id': '687dd61e2e8db0930be6f107', 'name': 'Gen Luo', 'hidden': False}, {'_id': '687dd61e2e8db0930be6f108', 'name': 'Wenhan Dou', 'hidden': False}, {'_id': '687dd61e2e8db0930be6f109', 'name': 'Wenhao Li', 'hidden': False}, {'_id': '687dd61e2e8db0930be6f10a', 'user': {'_id': '665d4b515fdfe8f923e347a7', 'avatarUrl': '/avatars/d114b24c02dadfca0a8aee104755a8ec.svg', 'isPro': False, 'fullname': 'Zhaokai Wang', 'user': 'wzk1015', 'type': 'user'}, 'name': 'Zhaokai Wang', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-07-21T08:29:25.907Z', 'hidden': False}, {'_id': '687dd61e2e8db0930be6f10b', 'name': 'Xue Yang', 'hidden': False}, {'_id': '687dd61e2e8db0930be6f10c', 'name': 'Changyao Tian', 'hidden': False}, {'_id': '687dd61e2e8db0930be6f10d', 'name': 'Hao Li', 'hidden': False}, {'_id': '687dd61e2e8db0930be6f10e', 'name': 'Weiyun Wang', 'hidden': False}, {'_id': '687dd61e2e8db0930be6f10f', 'name': 'Wenhai Wang', 'hidden': False}, {'_id': '687dd61e2e8db0930be6f110', 'name': 'Xizhou Zhu', 'hidden': False}, {'_id': '687dd61e2e8db0930be6f111', 'name': 'Yu Qiao', 'hidden': False}, {'_id': '687dd61e2e8db0930be6f112', 'name': 'Jifeng Dai', 'hidden': False}], 'publishedAt': '2025-07-16T18:31:23.000Z', 'submittedOnDailyAt': '2025-07-21T04:27:04.470Z', 'title': 'Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal\\n  Large Language Models', 'submittedOnDailyBy': {'_id': '665d4b515fdfe8f923e347a7', 'avatarUrl': '/avatars/d114b24c02dadfca0a8aee104755a8ec.svg', 'isPro': False, 'fullname': 'Zhaokai Wang', 'user': 'wzk1015', 'type': 'user'}, 'summary': 'This paper focuses on monolithic Multimodal Large Language Models (MLLMs),\\nwhich integrate visual encoding and language decoding into a single model.\\nExisting structures and pre-training strategies for monolithic MLLMs often\\nsuffer from unstable optimization and catastrophic forgetting. To address these\\nchallenges, our key idea is to embed a new visual parameter space into a\\npre-trained LLM, enabling stable learning of visual knowledge from noisy data\\nvia delta tuning. Based on this principle, we first introduce Mono-InternVL, an\\nadvanced monolithic MLLM that incorporates a set of visual experts through a\\nmultimodal mixture-of-experts architecture. In addition, we design an\\ninnovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize\\nits visual capabilities via progressive learning. Mono-InternVL achieves\\ncompetitive performance against existing MLLMs but also leads to relatively\\nexpensive data cost. Therefore, we further present Mono-InternVL-1.5, a cheaper\\nand stronger monolithic MLLM equipped with an improved EViP (EViP++). EViP++\\nintroduces additional visual attention experts to Mono-InternVL-1.5 and\\nre-organizes the pre-training process in an efficient manner. During inference,\\nit includes a fused CUDA kernel to speed up its MoE operations. With these\\ndesigns, Mono-InternVL-1.5 significantly reduces training and inference costs,\\nwhile still maintaining competitive performance with Mono-InternVL. To evaluate\\nour approach, we conduct extensive experiments across 15 benchmarks. Results\\ndemonstrate that Mono-InternVL outperforms existing monolithic MLLMs on 12 out\\nof 15 benchmarks, e.g., +114-point improvement over Emu3 on OCRBench. Compared\\nto its modular counterpart, i.e., InternVL-1.5, Mono-InternVL-1.5 achieves\\nsimilar multimodal performance while reducing first-token latency by up to 69%.\\nCode and models are released at https://github.com/OpenGVLab/Mono-InternVL.', 'upvotes': 8, 'discussionId': '687dd61e2e8db0930be6f113', 'githubRepo': 'https://github.com/OpenGVLab/Mono-InternVL', 'ai_summary': 'Mono-InternVL, an advanced monolithic Multimodal Large Language Model, integrates visual experts and improved pre-training strategies to enhance visual learning and reduce computational costs while maintaining competitive performance.', 'ai_keywords': ['Multimodal Large Language Models', 'monolithic MLLMs', 'visual parameter space', 'delta tuning', 'multimodal mixture-of-experts architecture', 'Endogenous Visual Pre-training', 'EViP', 'EViP++', 'visual attention experts', 'fused CUDA kernel', 'MoE operations', 'OCRBench', 'first-token latency'], 'githubStars': 53}, 'publishedAt': '2025-07-16T14:31:23.000Z', 'title': 'Mono-InternVL-1.5: Towards Cheaper and Faster Monolithic Multimodal\\n  Large Language Models', 'summary': 'This paper focuses on monolithic Multimodal Large Language Models (MLLMs),\\nwhich integrate visual encoding and language decoding into a single model.\\nExisting structures and pre-training strategies for monolithic MLLMs often\\nsuffer from unstable optimization and catastrophic forgetting. To address these\\nchallenges, our key idea is to embed a new visual parameter space into a\\npre-trained LLM, enabling stable learning of visual knowledge from noisy data\\nvia delta tuning. Based on this principle, we first introduce Mono-InternVL, an\\nadvanced monolithic MLLM that incorporates a set of visual experts through a\\nmultimodal mixture-of-experts architecture. In addition, we design an\\ninnovative Endogenous Visual Pre-training (EViP) for Mono-InternVL to maximize\\nits visual capabilities via progressive learning. Mono-InternVL achieves\\ncompetitive performance against existing MLLMs but also leads to relatively\\nexpensive data cost. Therefore, we further present Mono-InternVL-1.5, a cheaper\\nand stronger monolithic MLLM equipped with an improved EViP (EViP++). EViP++\\nintroduces additional visual attention experts to Mono-InternVL-1.5 and\\nre-organizes the pre-training process in an efficient manner. During inference,\\nit includes a fused CUDA kernel to speed up its MoE operations. With these\\ndesigns, Mono-InternVL-1.5 significantly reduces training and inference costs,\\nwhile still maintaining competitive performance with Mono-InternVL. To evaluate\\nour approach, we conduct extensive experiments across 15 benchmarks. Results\\ndemonstrate that Mono-InternVL outperforms existing monolithic MLLMs on 12 out\\nof 15 benchmarks, e.g., +114-point improvement over Emu3 on OCRBench. Compared\\nto its modular counterpart, i.e., InternVL-1.5, Mono-InternVL-1.5 achieves\\nsimilar multimodal performance while reducing first-token latency by up to 69%.\\nCode and models are released at https://github.com/OpenGVLab/Mono-InternVL.', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.12566.png', 'numComments': 1, 'submittedBy': {'_id': '665d4b515fdfe8f923e347a7', 'avatarUrl': '/avatars/d114b24c02dadfca0a8aee104755a8ec.svg', 'fullname': 'Zhaokai Wang', 'name': 'wzk1015', 'type': 'user', 'isPro': False, 'isHf': False, 'isHfAdmin': False, 'isMod': False, 'followerCount': 4}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2507.13984', 'authors': [{'_id': '687d9e422e8db0930be6f0a3', 'user': {'_id': '637ce55e43fec4c21633f9ad', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/637ce55e43fec4c21633f9ad/yZTBQbvTatUw2zuxpp0nq.jpeg', 'isPro': False, 'fullname': 'Quang-Binh Nguyen', 'user': 'nqbinh', 'type': 'user'}, 'name': 'Quang-Binh Nguyen', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-07-21T08:29:38.282Z', 'hidden': False}, {'_id': '687d9e422e8db0930be6f0a4', 'name': 'Minh Luu', 'hidden': False}, {'_id': '687d9e422e8db0930be6f0a5', 'name': 'Quang Nguyen', 'hidden': False}, {'_id': '687d9e422e8db0930be6f0a6', 'name': 'Anh Tran', 'hidden': False}, {'_id': '687d9e422e8db0930be6f0a7', 'name': 'Khoi Nguyen', 'hidden': False}], 'mediaUrls': ['https://cdn-uploads.huggingface.co/production/uploads/637ce55e43fec4c21633f9ad/0i972bwXyZ3xS6RUc9xYw.qt'], 'publishedAt': '2025-07-18T14:45:48.000Z', 'submittedOnDailyAt': '2025-07-21T08:02:36.514Z', 'title': 'CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models', 'submittedOnDailyBy': {'_id': '637ce55e43fec4c21633f9ad', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/637ce55e43fec4c21633f9ad/yZTBQbvTatUw2zuxpp0nq.jpeg', 'isPro': False, 'fullname': 'Quang-Binh Nguyen', 'user': 'nqbinh', 'type': 'user'}, 'summary': 'Disentangling content and style from a single image, known as content-style\\ndecomposition (CSD), enables recontextualization of extracted content and\\nstylization of extracted styles, offering greater creative flexibility in\\nvisual synthesis. While recent personalization methods have explored the\\ndecomposition of explicit content style, they remain tailored for diffusion\\nmodels. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a\\npromising alternative with a next-scale prediction paradigm, achieving\\nperformance comparable to that of diffusion models. In this paper, we explore\\nVAR as a generative framework for CSD, leveraging its scale-wise generation\\nprocess for improved disentanglement. To this end, we propose CSD-VAR, a novel\\nmethod that introduces three key innovations: (1) a scale-aware alternating\\noptimization strategy that aligns content and style representation with their\\nrespective scales to enhance separation, (2) an SVD-based rectification method\\nto mitigate content leakage into style representations, and (3) an Augmented\\nKey-Value (K-V) memory enhancing content identity preservation. To benchmark\\nthis task, we introduce CSD-100, a dataset specifically designed for\\ncontent-style decomposition, featuring diverse subjects rendered in various\\nartistic styles. Experiments demonstrate that CSD-VAR outperforms prior\\napproaches, achieving superior content preservation and stylization fidelity.', 'upvotes': 6, 'discussionId': '687d9e422e8db0930be6f0a8', 'ai_summary': 'CSD-VAR, a Visual Autoregressive Modeling approach, enhances content-style decomposition by introducing scale-aware optimization, SVD-based rectification, and augmented K-V memory, outperforming diffusion models in content preservation and stylization.', 'ai_keywords': ['content-style decomposition', 'Visual Autoregressive Modeling', 'scale-aware alternating optimization', 'SVD-based rectification', 'Augmented Key-Value memory', 'CSD-100 dataset']}, 'publishedAt': '2025-07-18T10:45:48.000Z', 'title': 'CSD-VAR: Content-Style Decomposition in Visual Autoregressive Models', 'summary': 'Disentangling content and style from a single image, known as content-style\\ndecomposition (CSD), enables recontextualization of extracted content and\\nstylization of extracted styles, offering greater creative flexibility in\\nvisual synthesis. While recent personalization methods have explored the\\ndecomposition of explicit content style, they remain tailored for diffusion\\nmodels. Meanwhile, Visual Autoregressive Modeling (VAR) has emerged as a\\npromising alternative with a next-scale prediction paradigm, achieving\\nperformance comparable to that of diffusion models. In this paper, we explore\\nVAR as a generative framework for CSD, leveraging its scale-wise generation\\nprocess for improved disentanglement. To this end, we propose CSD-VAR, a novel\\nmethod that introduces three key innovations: (1) a scale-aware alternating\\noptimization strategy that aligns content and style representation with their\\nrespective scales to enhance separation, (2) an SVD-based rectification method\\nto mitigate content leakage into style representations, and (3) an Augmented\\nKey-Value (K-V) memory enhancing content identity preservation. To benchmark\\nthis task, we introduce CSD-100, a dataset specifically designed for\\ncontent-style decomposition, featuring diverse subjects rendered in various\\nartistic styles. Experiments demonstrate that CSD-VAR outperforms prior\\napproaches, achieving superior content preservation and stylization fidelity.', 'mediaUrls': ['https://cdn-uploads.huggingface.co/production/uploads/637ce55e43fec4c21633f9ad/0i972bwXyZ3xS6RUc9xYw.qt'], 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.13984.png', 'numComments': 3, 'submittedBy': {'_id': '637ce55e43fec4c21633f9ad', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/637ce55e43fec4c21633f9ad/yZTBQbvTatUw2zuxpp0nq.jpeg', 'fullname': 'Quang-Binh Nguyen', 'name': 'nqbinh', 'type': 'user', 'isPro': False, 'isHf': False, 'isHfAdmin': False, 'isMod': False}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2507.10605', 'authors': [{'_id': '687da15e2e8db0930be6f0aa', 'user': {'_id': '65328aa39326d6da5ff19b52', 'avatarUrl': '/avatars/5c3de984cd6eba69616bb608796865c5.svg', 'isPro': False, 'fullname': 'Fei Zhao', 'user': 'Hiiamein', 'type': 'user'}, 'name': 'Fei Zhao', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-07-21T08:29:35.346Z', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0ab', 'name': 'Chonggang Lu', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0ac', 'name': 'Yue Wang', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0ad', 'name': 'Zheyong Xie', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0ae', 'name': 'Ziyan Liu', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0af', 'name': 'Haofu Qian', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0b0', 'name': 'JianZhao Huang', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0b1', 'name': 'Fangcheng Shi', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0b2', 'name': 'Zijie Meng', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0b3', 'name': 'Hongcheng Guo', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0b4', 'name': 'Mingqian He', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0b5', 'name': 'Xinze Lyu', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0b6', 'name': 'Yiming Lu', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0b7', 'name': 'Ziyang Xiang', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0b8', 'name': 'Zheyu Ye', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0b9', 'name': 'Chengqiang Lu', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0ba', 'name': 'Zhe Xu', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0bb', 'name': 'Yi Wu', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0bc', 'name': 'Yao Hu', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0bd', 'name': 'Yan Gao', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0be', 'name': 'Jun Fan', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0bf', 'name': 'Xiaolong Jiang', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0c0', 'name': 'Weiting Liu', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0c1', 'name': 'Boyang Wang', 'hidden': False}, {'_id': '687da15e2e8db0930be6f0c2', 'name': 'Shaosheng Cao', 'hidden': False}], 'publishedAt': '2025-07-13T02:22:59.000Z', 'submittedOnDailyAt': '2025-07-21T00:42:35.284Z', 'title': 'RedOne: Revealing Domain-specific LLM Post-Training in Social Networking\\n  Services', 'submittedOnDailyBy': {'_id': '65328aa39326d6da5ff19b52', 'avatarUrl': '/avatars/5c3de984cd6eba69616bb608796865c5.svg', 'isPro': False, 'fullname': 'Fei Zhao', 'user': 'Hiiamein', 'type': 'user'}, 'summary': 'As a primary medium for modern information dissemination, social networking\\nservices (SNS) have experienced rapid growth, which has proposed significant\\nchallenges for platform content management and interaction quality improvement.\\nRecently, the development of large language models (LLMs) has offered potential\\nsolutions but existing studies focus on isolated tasks, which not only\\nencounter diminishing benefit from the data scaling within individual scenarios\\nbut also fail to flexibly adapt to diverse real-world context. To address these\\nchallenges, we introduce RedOne, a domain-specific LLM designed to break the\\nperformance bottleneck of single-task baselines and establish a comprehensive\\nfoundation for the SNS. RedOne was developed through a three-stage training\\nstrategy consisting of continue pretraining, supervised fine-tuning, and\\npreference optimization, using a large-scale real-world dataset. Through\\nextensive experiments, RedOne maintains strong general capabilities, and\\nachieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56%\\nin SNS bilingual evaluation benchmark, compared with base models. Furthermore,\\nthrough online testing, RedOne reduced the exposure rate in harmful content\\ndetection by 11.23% and improved the click page rate in post-view search by\\n14.95% compared with single-tasks finetuned baseline models. These results\\nestablish RedOne as a robust domain-specific LLM for SNS, demonstrating\\nexcellent generalization across various tasks and promising applicability in\\nreal-world scenarios.', 'upvotes': 4, 'discussionId': '687da15f2e8db0930be6f0c3', 'ai_summary': 'RedOne, a domain-specific LLM, enhances performance across multiple SNS tasks through a three-stage training strategy, improving generalization and reducing harmful content exposure.', 'ai_keywords': ['large language models', 'LLMs', 'domain-specific LLM', 'continue pretraining', 'supervised fine-tuning', 'preference optimization', 'SNS tasks', 'bilingual evaluation benchmark', 'harmful content detection', 'click page rate', 'post-view search']}, 'publishedAt': '2025-07-12T22:22:59.000Z', 'title': 'RedOne: Revealing Domain-specific LLM Post-Training in Social Networking\\n  Services', 'summary': 'As a primary medium for modern information dissemination, social networking\\nservices (SNS) have experienced rapid growth, which has proposed significant\\nchallenges for platform content management and interaction quality improvement.\\nRecently, the development of large language models (LLMs) has offered potential\\nsolutions but existing studies focus on isolated tasks, which not only\\nencounter diminishing benefit from the data scaling within individual scenarios\\nbut also fail to flexibly adapt to diverse real-world context. To address these\\nchallenges, we introduce RedOne, a domain-specific LLM designed to break the\\nperformance bottleneck of single-task baselines and establish a comprehensive\\nfoundation for the SNS. RedOne was developed through a three-stage training\\nstrategy consisting of continue pretraining, supervised fine-tuning, and\\npreference optimization, using a large-scale real-world dataset. Through\\nextensive experiments, RedOne maintains strong general capabilities, and\\nachieves an average improvement up to 14.02% across 8 major SNS tasks and 7.56%\\nin SNS bilingual evaluation benchmark, compared with base models. Furthermore,\\nthrough online testing, RedOne reduced the exposure rate in harmful content\\ndetection by 11.23% and improved the click page rate in post-view search by\\n14.95% compared with single-tasks finetuned baseline models. These results\\nestablish RedOne as a robust domain-specific LLM for SNS, demonstrating\\nexcellent generalization across various tasks and promising applicability in\\nreal-world scenarios.', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.10605.png', 'numComments': 2, 'submittedBy': {'_id': '65328aa39326d6da5ff19b52', 'avatarUrl': '/avatars/5c3de984cd6eba69616bb608796865c5.svg', 'fullname': 'Fei Zhao', 'name': 'Hiiamein', 'type': 'user', 'isPro': False, 'isHf': False, 'isHfAdmin': False, 'isMod': False, 'followerCount': 2}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2507.13158', 'authors': [{'_id': '687e2995d5ffc3b4b0fa7751', 'name': 'Hao Sun', 'hidden': False}, {'_id': '687e2995d5ffc3b4b0fa7752', 'name': 'Mihaela van der Schaar', 'hidden': False}], 'publishedAt': '2025-07-17T14:22:24.000Z', 'submittedOnDailyAt': '2025-07-21T10:21:27.798Z', 'title': 'Inverse Reinforcement Learning Meets Large Language Model Post-Training:\\n  Basics, Advances, and Opportunities', 'submittedOnDailyBy': {'_id': '64de3b7b293d686360302549', 'avatarUrl': '/avatars/b68af8fa86614796c6e8036379dee228.svg', 'isPro': False, 'fullname': 'Hao Sun', 'user': 'Holarissun', 'type': 'user'}, 'summary': 'In the era of Large Language Models (LLMs), alignment has emerged as a\\nfundamental yet challenging problem in the pursuit of more reliable,\\ncontrollable, and capable machine intelligence. The recent success of reasoning\\nmodels and conversational AI systems has underscored the critical role of\\nreinforcement learning (RL) in enhancing these systems, driving increased\\nresearch interest at the intersection of RL and LLM alignment. This paper\\nprovides a comprehensive review of recent advances in LLM alignment through the\\nlens of inverse reinforcement learning (IRL), emphasizing the distinctions\\nbetween RL techniques employed in LLM alignment and those in conventional RL\\ntasks. In particular, we highlight the necessity of constructing neural reward\\nmodels from human data and discuss the formal and practical implications of\\nthis paradigm shift. We begin by introducing fundamental concepts in RL to\\nprovide a foundation for readers unfamiliar with the field. We then examine\\nrecent advances in this research agenda, discussing key challenges and\\nopportunities in conducting IRL for LLM alignment. Beyond methodological\\nconsiderations, we explore practical aspects, including datasets, benchmarks,\\nevaluation metrics, infrastructure, and computationally efficient training and\\ninference techniques. Finally, we draw insights from the literature on\\nsparse-reward RL to identify open questions and potential research directions.\\nBy synthesizing findings from diverse studies, we aim to provide a structured\\nand critical overview of the field, highlight unresolved challenges, and\\noutline promising future directions for improving LLM alignment through RL and\\nIRL techniques.', 'upvotes': 2, 'discussionId': '687e2995d5ffc3b4b0fa7753', 'ai_summary': 'A review of advancements in aligning large language models using inverse reinforcement learning, emphasizing challenges and opportunities in neural reward modeling and sparse-reward reinforcement learning.', 'ai_keywords': ['Large Language Models', 'alignment', 'reinforcement learning', 'inverse reinforcement learning', 'neural reward models', 'sparse-reward RL']}, 'publishedAt': '2025-07-17T10:22:24.000Z', 'title': 'Inverse Reinforcement Learning Meets Large Language Model Post-Training:\\n  Basics, Advances, and Opportunities', 'summary': 'In the era of Large Language Models (LLMs), alignment has emerged as a\\nfundamental yet challenging problem in the pursuit of more reliable,\\ncontrollable, and capable machine intelligence. The recent success of reasoning\\nmodels and conversational AI systems has underscored the critical role of\\nreinforcement learning (RL) in enhancing these systems, driving increased\\nresearch interest at the intersection of RL and LLM alignment. This paper\\nprovides a comprehensive review of recent advances in LLM alignment through the\\nlens of inverse reinforcement learning (IRL), emphasizing the distinctions\\nbetween RL techniques employed in LLM alignment and those in conventional RL\\ntasks. In particular, we highlight the necessity of constructing neural reward\\nmodels from human data and discuss the formal and practical implications of\\nthis paradigm shift. We begin by introducing fundamental concepts in RL to\\nprovide a foundation for readers unfamiliar with the field. We then examine\\nrecent advances in this research agenda, discussing key challenges and\\nopportunities in conducting IRL for LLM alignment. Beyond methodological\\nconsiderations, we explore practical aspects, including datasets, benchmarks,\\nevaluation metrics, infrastructure, and computationally efficient training and\\ninference techniques. Finally, we draw insights from the literature on\\nsparse-reward RL to identify open questions and potential research directions.\\nBy synthesizing findings from diverse studies, we aim to provide a structured\\nand critical overview of the field, highlight unresolved challenges, and\\noutline promising future directions for improving LLM alignment through RL and\\nIRL techniques.', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.13158.png', 'numComments': 1, 'submittedBy': {'_id': '64de3b7b293d686360302549', 'avatarUrl': '/avatars/b68af8fa86614796c6e8036379dee228.svg', 'fullname': 'Hao Sun', 'name': 'Holarissun', 'type': 'user', 'isPro': False, 'isHf': False, 'isHfAdmin': False, 'isMod': False, 'followerCount': 1}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2507.12455', 'authors': [{'_id': '687e0ea52e8db0930be6f1af', 'user': {'_id': '66b6df9d512dac2ac07cf0c9', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/z0w4X-CdeEoFnwvgrsO9Z.jpeg', 'isPro': False, 'fullname': 'Peng Shangpin', 'user': 'psp-dada', 'type': 'user'}, 'name': 'Shangpin Peng', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-07-21T14:21:53.355Z', 'hidden': False}, {'_id': '687e0ea52e8db0930be6f1b0', 'name': 'Senqiao Yang', 'hidden': False}, {'_id': '687e0ea52e8db0930be6f1b1', 'name': 'Li Jiang', 'hidden': False}, {'_id': '687e0ea52e8db0930be6f1b2', 'name': 'Zhuotao Tian', 'hidden': False}], 'publishedAt': '2025-07-16T17:55:43.000Z', 'submittedOnDailyAt': '2025-07-21T08:48:34.799Z', 'title': 'Mitigating Object Hallucinations via Sentence-Level Early Intervention', 'submittedOnDailyBy': {'_id': '66b6df9d512dac2ac07cf0c9', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/z0w4X-CdeEoFnwvgrsO9Z.jpeg', 'isPro': False, 'fullname': 'Peng Shangpin', 'user': 'psp-dada', 'type': 'user'}, 'summary': 'Multimodal large language models (MLLMs) have revolutionized cross-modal\\nunderstanding but continue to struggle with hallucinations - fabricated content\\ncontradicting visual inputs. Existing hallucination mitigation methods either\\nincur prohibitive computational costs or introduce distribution mismatches\\nbetween training data and model outputs. We identify a critical insight:\\nhallucinations predominantly emerge at the early stages of text generation and\\npropagate through subsequent outputs. To address this, we propose **SENTINEL**\\n(**S**entence-level **E**arly i**N**tervention **T**hrough **IN**-domain\\npr**E**ference **L**earning), a framework that eliminates dependency on human\\nannotations. Specifically, we first bootstrap high-quality in-domain preference\\npairs by iteratively sampling model outputs, validating object existence\\nthrough cross-checking with two open-vocabulary detectors, and classifying\\nsentences into hallucinated/non-hallucinated categories. Subsequently, we use\\ncontext-coherent positive samples and hallucinated negative samples to build\\ncontext-aware preference data iteratively. Finally, we train models using a\\ncontext-aware preference loss (C-DPO) that emphasizes discriminative learning\\nat the sentence level where hallucinations initially manifest. Experimental\\nresults show that SENTINEL can reduce hallucinations by over 90\\\\% compared to\\nthe original model and outperforms the previous state-of-the-art method on both\\nhallucination benchmarks and general capabilities benchmarks, demonstrating its\\nsuperiority and generalization ability. The models, datasets, and code are\\navailable at https://github.com/pspdada/SENTINEL.', 'upvotes': 2, 'discussionId': '687e0ea62e8db0930be6f1b3', 'githubRepo': 'https://github.com/pspdada/SENTINEL', 'ai_summary': 'SENTINEL reduces hallucinations in multimodal large language models by iteratively generating and validating sentence-level outputs using in-domain preference learning and context-aware preference loss.', 'ai_keywords': ['multimodal large language models', 'hallucinations', 'cross-modal understanding', 'in-domain preference learning', 'open-vocabulary detectors', 'context-aware preference data', 'context-aware preference loss', 'discriminative learning'], 'githubStars': 1}, 'publishedAt': '2025-07-16T13:55:43.000Z', 'title': 'Mitigating Object Hallucinations via Sentence-Level Early Intervention', 'summary': 'Multimodal large language models (MLLMs) have revolutionized cross-modal\\nunderstanding but continue to struggle with hallucinations - fabricated content\\ncontradicting visual inputs. Existing hallucination mitigation methods either\\nincur prohibitive computational costs or introduce distribution mismatches\\nbetween training data and model outputs. We identify a critical insight:\\nhallucinations predominantly emerge at the early stages of text generation and\\npropagate through subsequent outputs. To address this, we propose **SENTINEL**\\n(**S**entence-level **E**arly i**N**tervention **T**hrough **IN**-domain\\npr**E**ference **L**earning), a framework that eliminates dependency on human\\nannotations. Specifically, we first bootstrap high-quality in-domain preference\\npairs by iteratively sampling model outputs, validating object existence\\nthrough cross-checking with two open-vocabulary detectors, and classifying\\nsentences into hallucinated/non-hallucinated categories. Subsequently, we use\\ncontext-coherent positive samples and hallucinated negative samples to build\\ncontext-aware preference data iteratively. Finally, we train models using a\\ncontext-aware preference loss (C-DPO) that emphasizes discriminative learning\\nat the sentence level where hallucinations initially manifest. Experimental\\nresults show that SENTINEL can reduce hallucinations by over 90\\\\% compared to\\nthe original model and outperforms the previous state-of-the-art method on both\\nhallucination benchmarks and general capabilities benchmarks, demonstrating its\\nsuperiority and generalization ability. The models, datasets, and code are\\navailable at https://github.com/pspdada/SENTINEL.', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.12455.png', 'numComments': 1, 'submittedBy': {'_id': '66b6df9d512dac2ac07cf0c9', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/z0w4X-CdeEoFnwvgrsO9Z.jpeg', 'fullname': 'Peng Shangpin', 'name': 'psp-dada', 'type': 'user', 'isPro': False, 'isHf': False, 'isHfAdmin': False, 'isMod': False}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2507.13302', 'authors': [{'_id': '687df30d2e8db0930be6f168', 'name': 'Carlos Arriaga', 'hidden': False}, {'_id': '687df30d2e8db0930be6f169', 'name': 'Gonzalo Martínez', 'hidden': False}, {'_id': '687df30d2e8db0930be6f16a', 'name': 'Eneko Sendin', 'hidden': False}, {'_id': '687df30d2e8db0930be6f16b', 'name': 'Javier Conde', 'hidden': False}, {'_id': '687df30d2e8db0930be6f16c', 'name': 'Pedro Reviriego', 'hidden': False}], 'publishedAt': '2025-07-17T17:11:14.000Z', 'submittedOnDailyAt': '2025-07-21T06:29:41.248Z', 'title': 'The Generative Energy Arena (GEA): Incorporating Energy Awareness in\\n  Large Language Model (LLM) Human Evaluations', 'submittedOnDailyBy': {'_id': '64f31365ed48e3bb9c487d5d', 'avatarUrl': '/avatars/979c1979eadbd4529c95b925bbb58d78.svg', 'isPro': False, 'fullname': 'Gonzalo', 'user': 'gonzmart', 'type': 'user'}, 'summary': 'The evaluation of large language models is a complex task, in which several\\napproaches have been proposed. The most common is the use of automated\\nbenchmarks in which LLMs have to answer multiple-choice questions of different\\ntopics. However, this method has certain limitations, being the most\\nconcerning, the poor correlation with the humans. An alternative approach, is\\nto have humans evaluate the LLMs. This poses scalability issues as there is a\\nlarge and growing number of models to evaluate making it impractical (and\\ncostly) to run traditional studies based on recruiting a number of evaluators\\nand having them rank the responses of the models. An alternative approach is\\nthe use of public arenas, such as the popular LM arena, on which any user can\\nfreely evaluate models on any question and rank the responses of two models.\\nThe results are then elaborated into a model ranking. An increasingly important\\naspect of LLMs is their energy consumption and, therefore, evaluating how\\nenergy awareness influences the decisions of humans in selecting a model is of\\ninterest. In this paper, we present GEA, the Generative Energy Arena, an arena\\nthat incorporates information on the energy consumption of the model in the\\nevaluation process. Preliminary results obtained with GEA are also presented,\\nshowing that for most questions, when users are aware of the energy\\nconsumption, they favor smaller and more energy efficient models. This suggests\\nthat for most user interactions, the extra cost and energy incurred by the more\\ncomplex and top-performing models do not provide an increase in the perceived\\nquality of the responses that justifies their use.', 'upvotes': 1, 'discussionId': '687df30d2e8db0930be6f16d', 'ai_summary': 'GEA, a public arena that includes energy consumption data, shows that users often prefer smaller, more energy-efficient language models over larger, more complex ones.', 'ai_keywords': ['large language models', 'automated benchmarks', 'multiple-choice questions', 'human evaluation', 'scalability issues', 'public arenas', 'LM arena', 'energy consumption', 'energy awareness', 'model ranking', 'generative energy arena', 'GEA']}, 'publishedAt': '2025-07-17T13:11:14.000Z', 'title': 'The Generative Energy Arena (GEA): Incorporating Energy Awareness in\\n  Large Language Model (LLM) Human Evaluations', 'summary': 'The evaluation of large language models is a complex task, in which several\\napproaches have been proposed. The most common is the use of automated\\nbenchmarks in which LLMs have to answer multiple-choice questions of different\\ntopics. However, this method has certain limitations, being the most\\nconcerning, the poor correlation with the humans. An alternative approach, is\\nto have humans evaluate the LLMs. This poses scalability issues as there is a\\nlarge and growing number of models to evaluate making it impractical (and\\ncostly) to run traditional studies based on recruiting a number of evaluators\\nand having them rank the responses of the models. An alternative approach is\\nthe use of public arenas, such as the popular LM arena, on which any user can\\nfreely evaluate models on any question and rank the responses of two models.\\nThe results are then elaborated into a model ranking. An increasingly important\\naspect of LLMs is their energy consumption and, therefore, evaluating how\\nenergy awareness influences the decisions of humans in selecting a model is of\\ninterest. In this paper, we present GEA, the Generative Energy Arena, an arena\\nthat incorporates information on the energy consumption of the model in the\\nevaluation process. Preliminary results obtained with GEA are also presented,\\nshowing that for most questions, when users are aware of the energy\\nconsumption, they favor smaller and more energy efficient models. This suggests\\nthat for most user interactions, the extra cost and energy incurred by the more\\ncomplex and top-performing models do not provide an increase in the perceived\\nquality of the responses that justifies their use.', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.13302.png', 'numComments': 1, 'submittedBy': {'_id': '64f31365ed48e3bb9c487d5d', 'avatarUrl': '/avatars/979c1979eadbd4529c95b925bbb58d78.svg', 'fullname': 'Gonzalo', 'name': 'gonzmart', 'type': 'user', 'isPro': False, 'isHf': False, 'isHfAdmin': False, 'isMod': False}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2507.13391', 'authors': [{'_id': '687ded2d2e8db0930be6f159', 'user': {'_id': '65919c75a33889b27fb77762', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/65919c75a33889b27fb77762/kf2V5opQJgxDmgS21AJRq.png', 'isPro': False, 'fullname': 'Finbarrs Oketunji', 'user': '0xnu', 'type': 'user'}, 'name': 'Abiodun Finbarrs Oketunji', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-07-21T08:29:21.525Z', 'hidden': False}], 'publishedAt': '2025-07-16T08:24:14.000Z', 'submittedOnDailyAt': '2025-07-21T06:05:57.531Z', 'title': 'Quantitative Risk Management in Volatile Markets with an Expectile-Based\\n  Framework for the FTSE Index', 'submittedOnDailyBy': {'_id': '65919c75a33889b27fb77762', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/65919c75a33889b27fb77762/kf2V5opQJgxDmgS21AJRq.png', 'isPro': False, 'fullname': 'Finbarrs Oketunji', 'user': '0xnu', 'type': 'user'}, 'summary': 'This research presents a framework for quantitative risk management in\\nvolatile markets, specifically focusing on expectile-based methodologies\\napplied to the FTSE 100 index. Traditional risk measures such as Value-at-Risk\\n(VaR) have demonstrated significant limitations during periods of market\\nstress, as evidenced during the 2008 financial crisis and subsequent volatile\\nperiods. This study develops an advanced expectile-based framework that\\naddresses the shortcomings of conventional quantile-based approaches by\\nproviding greater sensitivity to tail losses and improved stability in extreme\\nmarket conditions. The research employs a dataset spanning two decades of FTSE\\n100 returns, incorporating periods of high volatility, market crashes, and\\nrecovery phases. Our methodology introduces novel mathematical formulations for\\nexpectile regression models, enhanced threshold determination techniques using\\ntime series analysis, and robust backtesting procedures. The empirical results\\ndemonstrate that expectile-based Value-at-Risk (EVaR) consistently outperforms\\ntraditional VaR measures across various confidence levels and market\\nconditions. The framework exhibits superior performance during volatile\\nperiods, with reduced model risk and enhanced predictive accuracy. Furthermore,\\nthe study establishes practical implementation guidelines for financial\\ninstitutions and provides evidence-based recommendations for regulatory\\ncompliance and portfolio management. The findings contribute significantly to\\nthe literature on financial risk management and offer practical tools for\\npractitioners dealing with volatile market environments.', 'upvotes': 0, 'discussionId': '687ded2d2e8db0930be6f15a'}, 'publishedAt': '2025-07-16T04:24:14.000Z', 'title': 'Quantitative Risk Management in Volatile Markets with an Expectile-Based\\n  Framework for the FTSE Index', 'summary': 'This research presents a framework for quantitative risk management in\\nvolatile markets, specifically focusing on expectile-based methodologies\\napplied to the FTSE 100 index. Traditional risk measures such as Value-at-Risk\\n(VaR) have demonstrated significant limitations during periods of market\\nstress, as evidenced during the 2008 financial crisis and subsequent volatile\\nperiods. This study develops an advanced expectile-based framework that\\naddresses the shortcomings of conventional quantile-based approaches by\\nproviding greater sensitivity to tail losses and improved stability in extreme\\nmarket conditions. The research employs a dataset spanning two decades of FTSE\\n100 returns, incorporating periods of high volatility, market crashes, and\\nrecovery phases. Our methodology introduces novel mathematical formulations for\\nexpectile regression models, enhanced threshold determination techniques using\\ntime series analysis, and robust backtesting procedures. The empirical results\\ndemonstrate that expectile-based Value-at-Risk (EVaR) consistently outperforms\\ntraditional VaR measures across various confidence levels and market\\nconditions. The framework exhibits superior performance during volatile\\nperiods, with reduced model risk and enhanced predictive accuracy. Furthermore,\\nthe study establishes practical implementation guidelines for financial\\ninstitutions and provides evidence-based recommendations for regulatory\\ncompliance and portfolio management. The findings contribute significantly to\\nthe literature on financial risk management and offer practical tools for\\npractitioners dealing with volatile market environments.', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2507.13391.png', 'numComments': 1, 'submittedBy': {'_id': '65919c75a33889b27fb77762', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/65919c75a33889b27fb77762/kf2V5opQJgxDmgS21AJRq.png', 'fullname': 'Finbarrs Oketunji', 'name': '0xnu', 'type': 'user', 'isPro': False, 'isHf': False, 'isHfAdmin': False, 'isMod': False, 'followerCount': 1}, 'isAuthorParticipating': True}"
]