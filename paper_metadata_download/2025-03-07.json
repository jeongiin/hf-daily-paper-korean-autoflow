[
    "{'paper': {'id': '2503.04625', 'authors': [{'_id': '67ca670d3e81e3344dc4c2d9', 'user': {'_id': '65294b334d7cf551ac50d6a6', 'avatarUrl': '/avatars/75d21e20b711b871616ef3850bb900b7.svg', 'isPro': False, 'fullname': 'ChengpengLi', 'user': 'ChengpengLi', 'type': 'user'}, 'name': 'Chengpeng Li', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:12:37.350Z', 'hidden': False}, {'_id': '67ca670d3e81e3344dc4c2da', 'user': {'_id': '5f8946925d083370c711f296', 'avatarUrl': '/avatars/14246aae3b1f8b7ad050f8ff2c8b260e.svg', 'isPro': False, 'fullname': 'Mingfeng Xue', 'user': 'mingfengxue', 'type': 'user'}, 'name': 'Mingfeng Xue', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:12:28.354Z', 'hidden': False}, {'_id': '67ca670d3e81e3344dc4c2db', 'user': {'_id': '64704e973601bb7b06643e98', 'avatarUrl': '/avatars/52e51f4d1be6769e4397b8be2799cf32.svg', 'isPro': False, 'fullname': 'Zhang', 'user': 'Zhenru', 'type': 'user'}, 'name': 'Zhenru Zhang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:12:48.194Z', 'hidden': False}, {'_id': '67ca670d3e81e3344dc4c2dc', 'user': {'_id': '646df403ad20c6fa4f30b7ec', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/646df403ad20c6fa4f30b7ec/Q64-XMghOcBoo3itZDGYA.jpeg', 'isPro': False, 'fullname': 'Jiaxi Yang', 'user': 'jx-yang', 'type': 'user'}, 'name': 'Jiaxi Yang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:12:57.082Z', 'hidden': False}, {'_id': '67ca670d3e81e3344dc4c2dd', 'user': {'_id': '64b93578ee257c3a4cfceed1', 'avatarUrl': '/avatars/e6188562254f75a09b4048b800860016.svg', 'isPro': False, 'fullname': 'Beichen Zhang', 'user': 'BeichenZhang', 'type': 'user'}, 'name': 'Beichen Zhang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:13:11.641Z', 'hidden': False}, {'_id': '67ca670d3e81e3344dc4c2de', 'name': 'Xiang Wang', 'hidden': False}, {'_id': '67ca670d3e81e3344dc4c2df', 'user': {'_id': '6583ab7983a9e1460c67d876', 'avatarUrl': '/avatars/74400bc448c3f07e23a4cd53d68a6af7.svg', 'isPro': False, 'fullname': 'bowen', 'user': 'bowenYu', 'type': 'user'}, 'name': 'Bowen Yu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:13:30.530Z', 'hidden': False}, {'_id': '67ca670d3e81e3344dc4c2e0', 'user': {'_id': '61e4c4ca1ab24785ac11ba69', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/61e4c4ca1ab24785ac11ba69/1Q1zhhyGSJ9RJG9MzwxVv.jpeg', 'isPro': False, 'fullname': 'Binyuan Hui', 'user': 'huybery', 'type': 'user'}, 'name': 'Binyuan Hui', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:13:37.341Z', 'hidden': False}, {'_id': '67ca670d3e81e3344dc4c2e1', 'user': {'_id': '620760a26e3b7210c2ff1943', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/620760a26e3b7210c2ff1943/VC-rKqimF6yxGESNVlPoR.jpeg', 'isPro': False, 'fullname': 'Junyang Lin', 'user': 'JustinLin610', 'type': 'user'}, 'name': 'Junyang Lin', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:13:44.084Z', 'hidden': False}, {'_id': '67ca670d3e81e3344dc4c2e2', 'user': {'_id': '6434d4989bd5a84b5dd0b0f5', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/6434d4989bd5a84b5dd0b0f5/0Elf9qbfG9Hkgypm9pTGm.jpeg', 'isPro': False, 'fullname': 'Dayiheng Liu', 'user': 'Losin94', 'type': 'user'}, 'name': 'Dayiheng Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:13:52.711Z', 'hidden': False}], 'publishedAt': '2025-03-06T17:11:51.000Z', 'title': 'START: Self-taught Reasoner with Tools', 'summary': \"Large reasoning models (LRMs) like OpenAI-o1 and DeepSeek-R1 have\\ndemonstrated remarkable capabilities in complex reasoning tasks through the\\nutilization of long Chain-of-thought (CoT). However, these models often suffer\\nfrom hallucinations and inefficiencies due to their reliance solely on internal\\nreasoning processes. In this paper, we introduce START (Self-Taught Reasoner\\nwith Tools), a novel tool-integrated long CoT reasoning LLM that significantly\\nenhances reasoning capabilities by leveraging external tools. Through code\\nexecution, START is capable of performing complex computations, self-checking,\\nexploring diverse methods, and self-debugging, thereby addressing the\\nlimitations of LRMs. The core innovation of START lies in its self-learning\\nframework, which comprises two key techniques: 1) Hint-infer: We demonstrate\\nthat inserting artificially designed hints (e.g., ``Wait, maybe using Python\\nhere is a good idea.'') during the inference process of a LRM effectively\\nstimulates its ability to utilize external tools without the need for any\\ndemonstration data. Hint-infer can also serve as a simple and effective\\nsequential test-time scaling method; 2) Hint Rejection Sampling Fine-Tuning\\n(Hint-RFT): Hint-RFT combines Hint-infer and RFT by scoring, filtering, and\\nmodifying the reasoning trajectories with tool invocation generated by a LRM\\nvia Hint-infer, followed by fine-tuning the LRM. Through this framework, we\\nhave fine-tuned the QwQ-32B model to achieve START. On PhD-level science QA\\n(GPQA), competition-level math benchmarks (AMC23, AIME24, AIME25), and the\\ncompetition-level code benchmark (LiveCodeBench), START achieves accuracy rates\\nof 63.6%, 95.0%, 66.7%, 47.1%, and 47.3%, respectively. It significantly\\noutperforms the base QwQ-32B and achieves performance comparable to the\\nstate-of-the-art open-weight model R1-Distill-Qwen-32B and the proprietary\\nmodel o1-Preview.\", 'upvotes': 42, 'discussionId': '67ca67103e81e3344dc4c366'}, 'publishedAt': '2025-03-06T22:35:47.725Z', 'title': 'START: Self-taught Reasoner with Tools', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04625.png', 'numComments': 2, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 6300}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2503.04724', 'authors': [{'_id': '67cacfd85dc0bf8f5e6fc803', 'name': 'Sambal Shikhar', 'hidden': False}, {'_id': '67cacfd85dc0bf8f5e6fc804', 'user': {'_id': '650289dbc130d99814b34dc5', 'avatarUrl': '/avatars/ff0cf5add144cd79c41a255f41f34efb.svg', 'isPro': False, 'fullname': 'K Mohammed Irfan', 'user': 'k-m-irfan', 'type': 'user'}, 'name': 'Mohammed Irfan Kurpath', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T13:37:55.973Z', 'hidden': False}, {'_id': '67cacfd85dc0bf8f5e6fc805', 'user': {'_id': '62e23c7f555a866437a53cd0', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62e23c7f555a866437a53cd0/UaAsYZQXuwb4NSG5WnvdG.jpeg', 'isPro': False, 'fullname': 'Sahal Shaji', 'user': 'sahalshajim', 'type': 'user'}, 'name': 'Sahal Shaji Mullappilly', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T13:37:53.972Z', 'hidden': False}, {'_id': '67cacfd85dc0bf8f5e6fc806', 'name': 'Jean Lahoud', 'hidden': False}, {'_id': '67cacfd85dc0bf8f5e6fc807', 'name': 'Fahad Khan', 'hidden': False}, {'_id': '67cacfd85dc0bf8f5e6fc808', 'name': 'Rao Muhammad Anwer', 'hidden': False}, {'_id': '67cacfd85dc0bf8f5e6fc809', 'name': 'Salman Khan', 'hidden': False}, {'_id': '67cacfd85dc0bf8f5e6fc80a', 'name': 'Hisham Cholakkal', 'hidden': False}], 'publishedAt': '2025-03-06T18:59:38.000Z', 'title': 'LLMVoX: Autoregressive Streaming Text-to-Speech Model for Any LLM', 'summary': 'Recent advancements in speech-to-speech dialogue systems leverage LLMs for\\nmultimodal interactions, yet they remain hindered by fine-tuning requirements,\\nhigh computational overhead, and text-speech misalignment. Existing\\nspeech-enabled LLMs often degrade conversational quality by modifying the LLM,\\nthereby compromising its linguistic capabilities. In contrast, we propose\\nLLMVoX, a lightweight 30M-parameter, LLM-agnostic, autoregressive streaming TTS\\nsystem that generates high-quality speech with low latency, while fully\\npreserving the capabilities of the base LLM. Our approach achieves a\\nsignificantly lower Word Error Rate compared to speech-enabled LLMs, while\\noperating at comparable latency and UTMOS score. By decoupling speech synthesis\\nfrom LLM processing via a multi-queue token streaming system, LLMVoX supports\\nseamless, infinite-length dialogues. Its plug-and-play design also facilitates\\nextension to various tasks with different backbones. Furthermore, LLMVoX\\ngeneralizes to new languages with only dataset adaptation, attaining a low\\nCharacter Error Rate on an Arabic speech task. Additionally, we have integrated\\nLLMVoX with a Vision-Language Model to create an omni-model with speech, text,\\nand vision capabilities, without requiring additional multimodal training. Our\\ncode base and project page is available at https://mbzuai-oryx.github.io/LLMVoX .', 'upvotes': 20, 'discussionId': '67cacfd95dc0bf8f5e6fc84e', 'projectPage': 'https://mbzuai-oryx.github.io/LLMVoX/', 'githubRepo': 'https://github.com/mbzuai-oryx/LLMVoX'}, 'publishedAt': '2025-03-07T08:19:28.468Z', 'title': 'LLMVoX: Autoregressive Streaming Text-to-Speech Model for Any LLM', 'mediaUrls': ['https://cdn-uploads.huggingface.co/production/uploads/62e23c7f555a866437a53cd0/U7FKBmztay9dXvOZF6C8N.mp4', 'https://cdn-uploads.huggingface.co/production/uploads/62e23c7f555a866437a53cd0/d7sIq8oPVeGIhNCwraN6X.mp4', 'https://cdn-uploads.huggingface.co/production/uploads/62e23c7f555a866437a53cd0/b3v1UoiggsqMzjd6KY6n4.mp4', 'https://cdn-uploads.huggingface.co/production/uploads/62e23c7f555a866437a53cd0/jSicTrZ923k7_p5h9MUQK.mp4'], 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04724.png', 'numComments': 1, 'submittedBy': {'_id': '62e23c7f555a866437a53cd0', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62e23c7f555a866437a53cd0/UaAsYZQXuwb4NSG5WnvdG.jpeg', 'fullname': 'Sahal Shaji', 'name': 'sahalshajim', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 1}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2503.03803', 'authors': [{'_id': '67ca874c3ac187dbbed924d6', 'user': {'_id': '62b5777f593a2c49da69dc02', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1658152070753-62b5777f593a2c49da69dc02.jpeg', 'isPro': False, 'fullname': 'Jingkang Yang', 'user': 'Jingkang', 'type': 'user'}, 'name': 'Jingkang Yang', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T09:09:32.949Z', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924d7', 'user': {'_id': '64f7f5b54101c731ca84ae05', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/64f7f5b54101c731ca84ae05/13DwdxOo3tWbxKDLd44B9.jpeg', 'isPro': False, 'fullname': 'Shuai Liu', 'user': 'Choiszt', 'type': 'user'}, 'name': 'Shuai Liu', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T13:38:04.320Z', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924d8', 'name': 'Hongming Guo', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924d9', 'user': {'_id': '652965773a416e1f2173443b', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/652965773a416e1f2173443b/y9MB8YgHzbwCXAc4EI9T3.jpeg', 'isPro': False, 'fullname': 'Yuhao Dong', 'user': 'THUdyh', 'type': 'user'}, 'name': 'Yuhao Dong', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:15:21.671Z', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924da', 'name': 'Xiamengwei Zhang', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924db', 'user': {'_id': '63f87c42b0ae1748524a9cfb', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/63f87c42b0ae1748524a9cfb/I5ukv6iWoJVToWmcERmvx.jpeg', 'isPro': False, 'fullname': 'Sicheng Zhang', 'user': 'fesvhtr', 'type': 'user'}, 'name': 'Sicheng Zhang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:15:37.377Z', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924dc', 'user': {'_id': '62f113d3b58090c873d66481', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1659966415211-noauth.jpeg', 'isPro': False, 'fullname': 'Pengyun Wang', 'user': 'Alarak', 'type': 'user'}, 'name': 'Pengyun Wang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:15:44.290Z', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924dd', 'user': {'_id': '668eb3a1a2f3f9d5edf029eb', 'avatarUrl': '/avatars/383636e449f5e48c790f428818dd6863.svg', 'isPro': False, 'fullname': 'zhou zitang', 'user': 'Zzitang', 'type': 'user'}, 'name': 'Zitang Zhou', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:15:56.178Z', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924de', 'user': {'_id': '63f886a99f87cc3e645c99a8', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/63f886a99f87cc3e645c99a8/qwj16BrFaDjN0DPFsJ-6v.jpeg', 'isPro': False, 'fullname': 'Binzhu Xie', 'user': 'Nicous', 'type': 'user'}, 'name': 'Binzhu Xie', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:16:02.570Z', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924df', 'name': 'Ziyue Wang', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924e0', 'name': 'Bei Ouyang', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924e1', 'name': 'Zhengyu Lin', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924e2', 'name': 'Marco Cominelli', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924e3', 'user': {'_id': '652d06833b5997ed71ce5c46', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/xZTXEcnEogEmBm_ledJQr.jpeg', 'isPro': False, 'fullname': 'Zhongang Cai', 'user': 'caizhongang', 'type': 'user'}, 'name': 'Zhongang Cai', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:16:33.666Z', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924e4', 'user': {'_id': '62a993d80472c0b7f94027df', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62a993d80472c0b7f94027df/j5vp-IwLA2YBexylUHiQU.png', 'isPro': False, 'fullname': 'Zhang Yuanhan', 'user': 'ZhangYuanhan', 'type': 'user'}, 'name': 'Yuanhan Zhang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:16:45.989Z', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924e5', 'user': {'_id': '63565cc56d7fcf1bedb7d347', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/63565cc56d7fcf1bedb7d347/XGcHP4VkO_oieA1gZ4IAX.jpeg', 'isPro': False, 'fullname': 'Zhang Peiyuan', 'user': 'PY007', 'type': 'user'}, 'name': 'Peiyuan Zhang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:16:57.532Z', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924e6', 'user': {'_id': '67443675924e80c3c8807b40', 'avatarUrl': '/avatars/fb45422391e51d2ad641f09c8535653c.svg', 'isPro': False, 'fullname': 'fangzhou HONG', 'user': 'h12345678', 'type': 'user'}, 'name': 'Fangzhou Hong', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:17:05.845Z', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924e7', 'name': 'Joerg Widmer', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924e8', 'name': 'Francesco Gringoli', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924e9', 'name': 'Lei Yang', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924ea', 'name': 'Bo Li', 'hidden': False}, {'_id': '67ca874c3ac187dbbed924eb', 'user': {'_id': '62ab1ac1d48b4d8b048a3473', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png', 'isPro': False, 'fullname': 'Ziwei Liu', 'user': 'liuziwei7', 'type': 'user'}, 'name': 'Ziwei Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:15:05.677Z', 'hidden': False}], 'publishedAt': '2025-03-05T18:54:16.000Z', 'title': 'EgoLife: Towards Egocentric Life Assistant', 'summary': 'We introduce EgoLife, a project to develop an egocentric life assistant that\\naccompanies and enhances personal efficiency through AI-powered wearable\\nglasses. To lay the foundation for this assistant, we conducted a comprehensive\\ndata collection study where six participants lived together for one week,\\ncontinuously recording their daily activities - including discussions,\\nshopping, cooking, socializing, and entertainment - using AI glasses for\\nmultimodal egocentric video capture, along with synchronized third-person-view\\nvideo references. This effort resulted in the EgoLife Dataset, a comprehensive\\n300-hour egocentric, interpersonal, multiview, and multimodal daily life\\ndataset with intensive annotation. Leveraging this dataset, we introduce\\nEgoLifeQA, a suite of long-context, life-oriented question-answering tasks\\ndesigned to provide meaningful assistance in daily life by addressing practical\\nquestions such as recalling past relevant events, monitoring health habits, and\\noffering personalized recommendations. To address the key technical challenges\\nof (1) developing robust visual-audio models for egocentric data, (2) enabling\\nidentity recognition, and (3) facilitating long-context question answering over\\nextensive temporal information, we introduce EgoButler, an integrated system\\ncomprising EgoGPT and EgoRAG. EgoGPT is an omni-modal model trained on\\negocentric datasets, achieving state-of-the-art performance on egocentric video\\nunderstanding. EgoRAG is a retrieval-based component that supports answering\\nultra-long-context questions. Our experimental studies verify their working\\nmechanisms and reveal critical factors and bottlenecks, guiding future\\nimprovements. By releasing our datasets, models, and benchmarks, we aim to\\nstimulate further research in egocentric AI assistants.', 'upvotes': 15, 'discussionId': '67ca874f3ac187dbbed925cc', 'projectPage': 'https://egolife-ai.github.io/', 'githubRepo': 'https://github.com/EvolvingLMMs-Lab/EgoLife'}, 'publishedAt': '2025-03-07T00:44:13.546Z', 'title': 'EgoLife: Towards Egocentric Life Assistant', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.03803.png', 'numComments': 1, 'submittedBy': {'_id': '62b5777f593a2c49da69dc02', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1658152070753-62b5777f593a2c49da69dc02.jpeg', 'fullname': 'Jingkang Yang', 'name': 'Jingkang', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 7}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2502.20258', 'authors': [{'_id': '67ca7b557436e6327ca877ff', 'user': {'_id': '655efd24afee0e00788bb589', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/655efd24afee0e00788bb589/22guLxIWNybbJR3jI-c4w.jpeg', 'isPro': False, 'fullname': 'Amr Mohamed', 'user': 'amr-mohamed', 'type': 'user'}, 'name': 'Amr Mohamed', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T09:09:41.298Z', 'hidden': False}, {'_id': '67ca7b557436e6327ca87800', 'user': {'_id': '67890323f8796231c857231e', 'avatarUrl': '/avatars/f5ccd5186968d880fee9c36324a5f713.svg', 'isPro': False, 'fullname': 'Mingmeng Geng', 'user': 'mgeng', 'type': 'user'}, 'name': 'Mingmeng Geng', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:34:23.443Z', 'hidden': False}, {'_id': '67ca7b557436e6327ca87801', 'name': 'Michalis Vazirgiannis', 'hidden': False}, {'_id': '67ca7b557436e6327ca87802', 'user': {'_id': '6087e598e2b7cc3a117b0dc5', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/6087e598e2b7cc3a117b0dc5/Ctz_W-uo1gOQRBHXalD1P.png', 'isPro': False, 'fullname': 'Guokan Shang', 'user': 'guokan-shang', 'type': 'user'}, 'name': 'Guokan Shang', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T09:09:38.933Z', 'hidden': False}], 'publishedAt': '2025-02-27T16:46:23.000Z', 'title': 'LLM as a Broken Telephone: Iterative Generation Distorts Information', 'summary': 'As large language models are increasingly responsible for online content,\\nconcerns arise about the impact of repeatedly processing their own outputs.\\nInspired by the \"broken telephone\" effect in chained human communication, this\\nstudy investigates whether LLMs similarly distort information through iterative\\ngeneration. Through translation-based experiments, we find that distortion\\naccumulates over time, influenced by language choice and chain complexity.\\nWhile degradation is inevitable, it can be mitigated through strategic\\nprompting techniques. These findings contribute to discussions on the long-term\\neffects of AI-mediated information propagation, raising important questions\\nabout the reliability of LLM-generated content in iterative workflows.', 'upvotes': 14, 'discussionId': '67ca7b577436e6327ca878ec', 'githubRepo': 'https://github.com/amr-mohamedd/LLM-as-a-Broken-Telephone'}, 'publishedAt': '2025-03-06T23:56:18.841Z', 'title': 'LLM as a Broken Telephone: Iterative Generation Distorts Information', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20258.png', 'numComments': 1, 'submittedBy': {'_id': '655efd24afee0e00788bb589', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/655efd24afee0e00788bb589/22guLxIWNybbJR3jI-c4w.jpeg', 'fullname': 'Amr Mohamed', 'name': 'amr-mohamed', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 7}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2503.02972', 'authors': [{'_id': '67c96a61df4d64bfebd396d4', 'name': 'Jude Khouja', 'hidden': False}, {'_id': '67c96a61df4d64bfebd396d5', 'user': {'_id': '64b92ae4ee257c3a4cfbc07a', 'avatarUrl': '/avatars/c4f91978749309c7805e3df1ced115b2.svg', 'isPro': False, 'fullname': 'Karolina Korgul', 'user': 'karotka', 'type': 'user'}, 'name': 'Karolina Korgul', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T13:38:07.551Z', 'hidden': False}, {'_id': '67c96a61df4d64bfebd396d6', 'name': 'Simi Hellsten', 'hidden': False}, {'_id': '67c96a61df4d64bfebd396d7', 'name': 'Lingyi Yang', 'hidden': False}, {'_id': '67c96a61df4d64bfebd396d8', 'name': 'Vlad Neacs', 'hidden': False}, {'_id': '67c96a61df4d64bfebd396d9', 'name': 'Harry Mayne', 'hidden': False}, {'_id': '67c96a61df4d64bfebd396da', 'user': {'_id': '6751ea855b1cc8f5a14dcc27', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/Vw5XZptgrzw2en-xQekAs.png', 'isPro': False, 'fullname': 'Ryan Othniel Kearns', 'user': 'ryanothk', 'type': 'user'}, 'name': 'Ryan Kearns', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T13:38:05.914Z', 'hidden': False}, {'_id': '67c96a61df4d64bfebd396db', 'name': 'Andrew Bean', 'hidden': False}, {'_id': '67c96a61df4d64bfebd396dc', 'name': 'Adam Mahdi', 'hidden': False}], 'publishedAt': '2025-03-04T19:57:47.000Z', 'title': 'LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic\\n  Templatisation and Orthographic Obfuscation', 'summary': 'Effective evaluation of the reasoning capabilities of large language models\\n(LLMs) are susceptible to overestimation due to data exposure of evaluation\\nbenchmarks. We introduce a framework for producing linguistic reasoning\\nproblems that reduces the effect of memorisation in model performance estimates\\nand apply this framework to develop LINGOLY-TOO, a challenging evaluation\\nbenchmark for linguistic reasoning. By developing orthographic templates, we\\ndynamically obfuscate the writing systems of real languages to generate\\nnumerous question variations. These variations preserve the reasoning steps\\nrequired for each solution while reducing the likelihood of specific problem\\ninstances appearing in model training data. Our experiments demonstrate that\\nfrontier models, including OpenAI o1-preview and DeepSeem R1, struggle with\\nadvanced reasoning. Our analysis also shows that LLMs exhibit noticeable\\nvariance in accuracy across permutations of the same problem, and on average\\nperform better on questions appearing in their original orthography. Our\\nfindings highlight the opaque nature of response generation in LLMs and provide\\nevidence that prior data exposure contributes to overestimating the reasoning\\ncapabilities of frontier models.', 'upvotes': 12, 'discussionId': '67c96a62df4d64bfebd3976e', 'projectPage': 'https://huggingface.co/spaces/jkhouja/lingoly-too', 'githubRepo': 'https://github.com/jkhouja/L2'}, 'publishedAt': '2025-03-07T04:50:00.681Z', 'title': 'LINGOLY-TOO: Disentangling Memorisation from Reasoning with Linguistic Templatisation and Orthographic Obfuscation', 'mediaUrls': ['https://cdn-uploads.huggingface.co/production/uploads/671d7763572a9cfd9a6ea053/apKiu-1ILDtcrTYqiP53g.png'], 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02972.png', 'numComments': 1, 'submittedBy': {'_id': '671d7763572a9cfd9a6ea053', 'avatarUrl': '/avatars/0a0225b50d949bb7ab0971bec531fc92.svg', 'fullname': 'Jude Khouja', 'name': 'jkhouja', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2503.04130', 'authors': [{'_id': '67ca7baf6d5c2eafede56d35', 'user': {'_id': '6449e5a3df4e6cb7eaefd2b8', 'avatarUrl': '/avatars/a671cb507d5e02b238d8cd631e71649d.svg', 'isPro': False, 'fullname': 'Jindong Jiang', 'user': 'jdps', 'type': 'user'}, 'name': 'Jindong Jiang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:34:59.750Z', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d36', 'user': {'_id': '644570ba2d91b15b4c7f6311', 'avatarUrl': '/avatars/d5e66012066d0c330b8f23718b1499d8.svg', 'isPro': False, 'fullname': 'Xiuyu Li', 'user': 'xiuyul', 'type': 'user'}, 'name': 'Xiuyu Li', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:35:06.739Z', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d37', 'user': {'_id': '650dac79b959b0e1d41d7378', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/650dac79b959b0e1d41d7378/mzbN0MFk3k8b94FQ40I7L.jpeg', 'isPro': False, 'fullname': 'Zhijian Liu', 'user': 'zhijianliu', 'type': 'user'}, 'name': 'Zhijian Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:35:13.834Z', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d38', 'user': {'_id': '66d8b322cf789857d384e5c4', 'avatarUrl': '/avatars/1276726b27d312f48e69f5ae982daa24.svg', 'isPro': False, 'fullname': 'Muyang Li', 'user': 'MuyangLI', 'type': 'user'}, 'name': 'Muyang Li', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:37:06.962Z', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d39', 'name': 'Guo Chen', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d3a', 'user': {'_id': '672aae13b2f2dc21e18570e0', 'avatarUrl': '/avatars/0253107a2116d197dc0fe18660c2af90.svg', 'isPro': False, 'fullname': 'Zhiqi Li', 'user': 'zhiqilinv', 'type': 'user'}, 'name': 'Zhiqi Li', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:36:57.283Z', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d3b', 'user': {'_id': '641d1c5ec3983aa94915c162', 'avatarUrl': '/avatars/127985b837ecf61e43c835deee578b5e.svg', 'isPro': False, 'fullname': 'De-An Huang', 'user': 'deahuang', 'type': 'user'}, 'name': 'De-An Huang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:36:27.913Z', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d3c', 'user': {'_id': '6656eb16e50d7c40881a14f0', 'avatarUrl': '/avatars/c6822a51c8d5918debf6ee1d25fe1825.svg', 'isPro': False, 'fullname': 'GuilinLiu', 'user': 'GuilinLiu', 'type': 'user'}, 'name': 'Guilin Liu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:36:17.904Z', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d3d', 'user': {'_id': '66c8037c737ba92ae3fe0322', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/66c8037c737ba92ae3fe0322/WR_Yh5DWOVVh7IFlF24NM.jpeg', 'isPro': False, 'fullname': 'Zhiding Yu', 'user': 'Zhiding', 'type': 'user'}, 'name': 'Zhiding Yu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:36:09.646Z', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d3e', 'user': {'_id': '6251bf4b183aa4266924ad91', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1678041834400-6251bf4b183aa4266924ad91.jpeg', 'isPro': True, 'fullname': 'Kurt Keutzer', 'user': 'kurtkeutzer', 'type': 'user'}, 'name': 'Kurt Keutzer', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:36:02.351Z', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d3f', 'user': {'_id': '60e1d6d3de3cd4c1bfb0c208', 'avatarUrl': '/avatars/0bc59ede9074557f15447d2457aaf07b.svg', 'isPro': False, 'fullname': 'Sungjin Ahn', 'user': 'sdstony', 'type': 'user'}, 'name': 'Sungjin Ahn', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:35:54.160Z', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d40', 'name': 'Jan Kautz', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d41', 'user': {'_id': '65a8b7f69aec1645994e7a15', 'avatarUrl': '/avatars/debc086f3fea029db22847bde80799a0.svg', 'isPro': False, 'fullname': 'Hongxu Yin', 'user': 'yinhongxu', 'type': 'user'}, 'name': 'Hongxu Yin', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:35:40.242Z', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d42', 'name': 'Yao Lu', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d43', 'name': 'Song Han', 'hidden': False}, {'_id': '67ca7baf6d5c2eafede56d44', 'user': {'_id': '66bf958296583c59b049085b', 'avatarUrl': '/avatars/04df8dd45835b7ea0991e242784e7810.svg', 'isPro': False, 'fullname': 'Wonmin Byeon', 'user': 'wbyeon', 'type': 'user'}, 'name': 'Wonmin Byeon', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:35:32.527Z', 'hidden': False}], 'publishedAt': '2025-03-06T06:17:38.000Z', 'title': 'Token-Efficient Long Video Understanding for Multimodal LLMs', 'summary': 'Recent advances in video-based multimodal large language models (Video-LLMs)\\nhave significantly improved video understanding by processing videos as\\nsequences of image frames. However, many existing methods treat frames\\nindependently in the vision backbone, lacking explicit temporal modeling, which\\nlimits their ability to capture dynamic patterns and efficiently handle long\\nvideos. To address these limitations, we introduce STORM\\n(Spatiotemporal TOken Reduction for\\nMultimodal LLMs), a novel architecture incorporating a dedicated\\ntemporal encoder between the image encoder and the LLM. Our temporal encoder\\nleverages the Mamba State Space Model to integrate temporal information into\\nimage tokens, generating enriched representations that preserve inter-frame\\ndynamics across the entire video sequence. This enriched encoding not only\\nenhances video reasoning capabilities but also enables effective token\\nreduction strategies, including test-time sampling and training-based temporal\\nand spatial pooling, substantially reducing computational demands on the LLM\\nwithout sacrificing key temporal information. By integrating these techniques,\\nour approach simultaneously reduces training and inference latency while\\nimproving performance, enabling efficient and robust video understanding over\\nextended temporal contexts. Extensive evaluations show that STORM achieves\\nstate-of-the-art results across various long video understanding benchmarks\\n(more than 5\\\\% improvement on MLVU and LongVideoBench) while reducing the\\ncomputation costs by up to 8times and the decoding latency by\\n2.4-2.9times for the fixed numbers of input frames. Project page is\\navailable at https://research.nvidia.com/labs/lpr/storm', 'upvotes': 9, 'discussionId': '67ca7bb16d5c2eafede56df1', 'projectPage': 'https://research.nvidia.com/labs/lpr/storm/'}, 'publishedAt': '2025-03-06T23:53:09.588Z', 'title': 'Token-Efficient Long Video Understanding for Multimodal LLMs', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04130.png', 'numComments': 1, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 6300}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2503.04598', 'authors': [{'_id': '67ca69063a6e3e8656bcc1d2', 'user': {'_id': '66335b9c95c5b79ebf306f30', 'avatarUrl': '/avatars/d57784ee65cbef014360c9bac1ad4119.svg', 'isPro': False, 'fullname': 'Zhijian Zhuo', 'user': 'BryceZhuo', 'type': 'user'}, 'name': 'Zhijian Zhuo', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:27:08.401Z', 'hidden': False}, {'_id': '67ca69063a6e3e8656bcc1d3', 'user': {'_id': '6371128eafbe42caa5a5222b', 'avatarUrl': '/avatars/c3b2ab35949c38aa3dfb2657a1300aac.svg', 'isPro': False, 'fullname': 'Yutao Zeng', 'user': 'Taoer', 'type': 'user'}, 'name': 'Yutao Zeng', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T09:09:43.334Z', 'hidden': False}, {'_id': '67ca69063a6e3e8656bcc1d4', 'name': 'Ya Wang', 'hidden': False}, {'_id': '67ca69063a6e3e8656bcc1d5', 'name': 'Sijun Zhang', 'hidden': False}, {'_id': '67ca69063a6e3e8656bcc1d6', 'name': 'Jian Yang', 'hidden': False}, {'_id': '67ca69063a6e3e8656bcc1d7', 'user': {'_id': '64648638351adef1a847a7ad', 'avatarUrl': '/avatars/7518e058fcf81ee81a06c96e996531e9.svg', 'isPro': False, 'fullname': 'Xiaoqing Li', 'user': 'LLIXQ', 'type': 'user'}, 'name': 'Xiaoqing Li', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:26:45.058Z', 'hidden': False}, {'_id': '67ca69063a6e3e8656bcc1d8', 'name': 'Xun Zhou', 'hidden': False}, {'_id': '67ca69063a6e3e8656bcc1d9', 'user': {'_id': '663a684d08778abaf0556df8', 'avatarUrl': '/avatars/d95b517df5b80a8b42bac2b171604742.svg', 'isPro': False, 'fullname': 'Majinwen', 'user': 'Breeze0417', 'type': 'user'}, 'name': 'Jinwen Ma', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:27:23.639Z', 'hidden': False}], 'publishedAt': '2025-03-06T16:40:48.000Z', 'title': 'HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid\\n  Normalization', 'summary': 'Transformers have become the de facto architecture for a wide range of\\nmachine learning tasks, particularly in large language models (LLMs). Despite\\ntheir remarkable performance, challenges remain in training deep transformer\\nnetworks, especially regarding the location of layer normalization. While\\nPre-Norm structures facilitate easier training due to their more prominent\\nidentity path, they often yield suboptimal performance compared to Post-Norm.\\nIn this paper, we propose HybridNorm, a straightforward yet\\neffective hybrid normalization strategy that integrates the advantages of both\\nPre-Norm and Post-Norm approaches. Specifically, HybridNorm employs QKV\\nnormalization within the attention mechanism and Post-Norm in the feed-forward\\nnetwork (FFN) of each transformer block. This design not only stabilizes\\ntraining but also enhances performance, particularly in the context of LLMs.\\nComprehensive experiments in both dense and sparse architectures show that\\nHybridNorm consistently outperforms both Pre-Norm and Post-Norm approaches,\\nachieving state-of-the-art results across various benchmarks. These findings\\nhighlight the potential of HybridNorm as a more stable and effective technique\\nfor improving the training and performance of deep transformer models. %Code\\nwill be made publicly available. Code is available at\\nhttps://github.com/BryceZhuo/HybridNorm.', 'upvotes': 9, 'discussionId': '67ca69073a6e3e8656bcc244', 'projectPage': 'https://github.com/BryceZhuo/HybridNorm', 'githubRepo': 'https://github.com/BryceZhuo/HybridNorm'}, 'publishedAt': '2025-03-06T23:04:06.421Z', 'title': 'HybridNorm: Towards Stable and Efficient Transformer Training via Hybrid Normalization', 'mediaUrls': ['https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/DB_sfuRG7M-k8w6UVTgXy.png', 'https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/F0lAhIiju8M-0fKBaPATA.png', 'https://cdn-uploads.huggingface.co/production/uploads/6371128eafbe42caa5a5222b/g_741Ez-YVcMK69EqCsPa.png'], 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04598.png', 'numComments': 4, 'submittedBy': {'_id': '6371128eafbe42caa5a5222b', 'avatarUrl': '/avatars/c3b2ab35949c38aa3dfb2657a1300aac.svg', 'fullname': 'Yutao Zeng', 'name': 'Taoer', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 1}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2503.04094', 'authors': [{'_id': '67ca7bcc06501013d727a5d7', 'user': {'_id': '6658e1c8ce1b2838885b2d7f', 'avatarUrl': '/avatars/8623555f14b62f40fd372da20cb59ccc.svg', 'isPro': False, 'fullname': 'Seth Karten', 'user': 'milkkarten', 'type': 'user'}, 'name': 'Seth Karten', 'status': 'extracted_confirmed', 'statusLastChangedAt': '2025-03-07T06:07:26.564Z', 'hidden': False}, {'_id': '67ca7bcc06501013d727a5d8', 'name': 'Andy Luu Nguyen', 'hidden': False}, {'_id': '67ca7bcc06501013d727a5d9', 'user': {'_id': '66749c510974bbc971139f6a', 'avatarUrl': '/avatars/bfab9d8d8bc589bb9bd49925b76e04a4.svg', 'isPro': False, 'fullname': 'Chi Jin', 'user': 'chijin', 'type': 'user'}, 'name': 'Chi Jin', 'status': 'extracted_pending', 'statusLastChangedAt': '2025-03-07T04:53:33.942Z', 'hidden': False}], 'publishedAt': '2025-03-06T05:06:27.000Z', 'title': 'PokéChamp: an Expert-level Minimax Language Agent', 'summary': \"We introduce Pok\\\\'eChamp, a minimax agent powered by Large Language Models\\n(LLMs) for Pok\\\\'emon battles. Built on a general framework for two-player\\ncompetitive games, Pok\\\\'eChamp leverages the generalist capabilities of LLMs to\\nenhance minimax tree search. Specifically, LLMs replace three key modules: (1)\\nplayer action sampling, (2) opponent modeling, and (3) value function\\nestimation, enabling the agent to effectively utilize gameplay history and\\nhuman knowledge to reduce the search space and address partial observability.\\nNotably, our framework requires no additional LLM training. We evaluate\\nPok\\\\'eChamp in the popular Gen 9 OU format. When powered by GPT-4o, it achieves\\na win rate of 76% against the best existing LLM-based bot and 84% against the\\nstrongest rule-based bot, demonstrating its superior performance. Even with an\\nopen-source 8-billion-parameter Llama 3.1 model, Pok\\\\'eChamp consistently\\noutperforms the previous best LLM-based bot, Pok\\\\'ellmon powered by GPT-4o,\\nwith a 64% win rate. Pok\\\\'eChamp attains a projected Elo of 1300-1500 on the\\nPok\\\\'emon Showdown online ladder, placing it among the top 30%-10% of human\\nplayers. In addition, this work compiles the largest real-player Pok\\\\'emon\\nbattle dataset, featuring over 3 million games, including more than 500k\\nhigh-Elo matches. Based on this dataset, we establish a series of battle\\nbenchmarks and puzzles to evaluate specific battling skills. We further provide\\nkey updates to the local game engine. We hope this work fosters further\\nresearch that leverage Pok\\\\'emon battle as benchmark to integrate LLM\\ntechnologies with game-theoretic algorithms addressing general multiagent\\nproblems. Videos, code, and dataset available at\\nhttps://sites.google.com/view/pokechamp-llm.\", 'upvotes': 7, 'discussionId': '67ca7bcd06501013d727a668', 'projectPage': 'https://sites.google.com/view/pokechamp-llm', 'githubRepo': 'https://github.com/sethkarten/pokechamp'}, 'publishedAt': '2025-03-06T23:53:38.838Z', 'title': 'PokéChamp: an Expert-level Minimax Language Agent', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04094.png', 'numComments': 1, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 6300}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2503.04222', 'authors': [{'_id': '67ca64cdd153739fa9b9dbe6', 'user': {'_id': '64c9b0f28d2d187c24d1e6c1', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/1CPnAaB3gsupdpiNWaoDc.png', 'isPro': False, 'fullname': 'ZiYi Yang', 'user': 'AALF', 'type': 'user'}, 'name': 'Ziyi Yang', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T09:09:46.287Z', 'hidden': False}, {'_id': '67ca64cdd153739fa9b9dbe7', 'user': {'_id': '62ecbffd99112e99c5f7fded', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62ecbffd99112e99c5f7fded/U6iXAJbpm2vaC5qksEPiH.png', 'isPro': False, 'fullname': 'Fanqi Wan', 'user': 'Wanfq', 'type': 'user'}, 'name': 'Fanqi Wan', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:33:34.691Z', 'hidden': False}, {'_id': '67ca64cdd153739fa9b9dbe8', 'user': {'_id': '62b6d20416ff90e6198301b6', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1656148456743-noauth.png', 'isPro': False, 'fullname': 'Longguang Zhong', 'user': 'GGLS', 'type': 'user'}, 'name': 'Longguang Zhong', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:33:41.092Z', 'hidden': False}, {'_id': '67ca64cdd153739fa9b9dbe9', 'user': {'_id': '63b93e6921add32ac6190b5c', 'avatarUrl': '/avatars/7aa6a94d48e7f7c2bc56f8734d6c4e3d.svg', 'isPro': False, 'fullname': 'Canbin Huang', 'user': 'OnewayLab', 'type': 'user'}, 'name': 'Canbin Huang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:33:47.458Z', 'hidden': False}, {'_id': '67ca64cdd153739fa9b9dbea', 'name': 'Guosheng Liang', 'hidden': False}, {'_id': '67ca64cdd153739fa9b9dbeb', 'user': {'_id': '63b57d75bda8d44adf2ff3ff', 'avatarUrl': '/avatars/8a387036758b2f7fc7d7529dea206669.svg', 'isPro': False, 'fullname': 'Xiaojun Quan', 'user': 'passerqxj', 'type': 'user'}, 'name': 'Xiaojun Quan', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:34:05.521Z', 'hidden': False}], 'publishedAt': '2025-03-06T09:03:36.000Z', 'title': 'FuseChat-3.0: Preference Optimization Meets Heterogeneous Model Fusion', 'summary': 'We introduce FuseChat-3.0, a suite of large language models (LLMs) developed\\nby integrating the strengths of heterogeneous source LLMs into more compact\\ntarget LLMs. Our source models include the powerful Gemma-2-27B-it,\\nMistral-Large-Instruct-2407, Qwen-2.5-72B-Instruct, and Llama-3.1-70B-Instruct.\\nFor target models, we focus on three widely-used smaller\\nvariants-Llama-3.1-8B-Instruct, Gemma-2-9B-it, and Qwen-2.5-7B-Instruct-along\\nwith two ultra-compact options, Llama-3.2-3B-Instruct and\\nLlama-3.2-1B-Instruct. To leverage the diverse capabilities of these source\\nmodels, we develop a specialized data construction protocol tailored to various\\ntasks and domains. The FuseChat-3.0 training pipeline consists of two key\\nstages: (1) supervised fine-tuning (SFT) to align the target and source model\\ndistributions, and (2) Direct Preference Optimization (DPO) to apply\\npreferences from multiple source LLMs to fine-tune the target model. The\\nresulting FuseChat-3.0 models exhibit significant performance gains across\\ntasks such as instruction following, general knowledge, mathematics, and\\ncoding. As illustrated in Figure 1, using Llama-3.1-8B-Instruct as the target\\nmodel, our fusion approach achieves an average improvement of 6.8 points across\\n14 benchmarks. Moreover, it demonstrates remarkable gains of 37.1 points and\\n30.1 points on the instruction-following benchmarks AlpacaEval-2 and\\nArena-Hard, respectively. Our code, models, and datasets are available at\\nhttps://github.com/SLIT-AI/FuseChat-3.0.', 'upvotes': 7, 'discussionId': '67ca64ced153739fa9b9dc1b', 'projectPage': 'https://slit-ai.github.io/FuseChat-3.0/', 'githubRepo': 'https://github.com/SLIT-AI/FuseChat-3.0'}, 'publishedAt': '2025-03-06T22:20:34.462Z', 'title': 'FuseChat-3.0: Preference Optimization Meets Heterogeneous Model Fusion', 'mediaUrls': ['https://cdn-uploads.huggingface.co/production/uploads/62ecbffd99112e99c5f7fded/nmr7w6NOioBYwMmNfezcf.png'], 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04222.png', 'numComments': 1, 'submittedBy': {'_id': '62ecbffd99112e99c5f7fded', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62ecbffd99112e99c5f7fded/U6iXAJbpm2vaC5qksEPiH.png', 'fullname': 'Fanqi Wan', 'name': 'Wanfq', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 29}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2503.03983', 'authors': [{'_id': '67ca66c1cb7e422997cbd148', 'user': {'_id': '627a354cc488a8ce15a2dec5', 'avatarUrl': '/avatars/0d99a2fea8b193993fe5b9b7e5b74f40.svg', 'isPro': True, 'fullname': 'Sreyan Ghosh', 'user': 'SreyanG-NVIDIA', 'type': 'user'}, 'name': 'Sreyan Ghosh', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:40:39.324Z', 'hidden': False}, {'_id': '67ca66c1cb7e422997cbd149', 'user': {'_id': '652a4dfc36f031c5e6f8b8a6', 'avatarUrl': '/avatars/9fb56b025dc25f91ca6c31136eaf74b2.svg', 'isPro': False, 'fullname': 'Zhifeng Kong', 'user': 'ZhifengKong', 'type': 'user'}, 'name': 'Zhifeng Kong', 'status': 'extracted_pending', 'statusLastChangedAt': '2025-03-07T03:23:47.395Z', 'hidden': False}, {'_id': '67ca66c1cb7e422997cbd14a', 'name': 'Sonal Kumar', 'hidden': False}, {'_id': '67ca66c1cb7e422997cbd14b', 'name': 'S Sakshi', 'hidden': False}, {'_id': '67ca66c1cb7e422997cbd14c', 'user': {'_id': '63fc1124a3c067e62897a73f', 'avatarUrl': '/avatars/aa63337a7cd73181b7c1e92decf635f4.svg', 'isPro': False, 'fullname': 'Jaehyeon Kim', 'user': 'firecomputer', 'type': 'user'}, 'name': 'Jaehyeon Kim', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:41:17.053Z', 'hidden': False}, {'_id': '67ca66c1cb7e422997cbd14d', 'name': 'Wei Ping', 'hidden': False}, {'_id': '67ca66c1cb7e422997cbd14e', 'user': {'_id': '6440ddd65d600fb09518daa8', 'avatarUrl': '/avatars/ac5898afd2082d230e2ebf6fb867ad4f.svg', 'isPro': False, 'fullname': 'Rafael Valle', 'user': 'rafaelvalle', 'type': 'user'}, 'name': 'Rafael Valle', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:41:08.488Z', 'hidden': False}, {'_id': '67ca66c1cb7e422997cbd14f', 'user': {'_id': '6537a569568d8be8fa096b8c', 'avatarUrl': '/avatars/bfda5cb252d8b5bc3ad737d99c0d7f49.svg', 'isPro': False, 'fullname': 'Dinesh Manocha', 'user': 'manocha', 'type': 'user'}, 'name': 'Dinesh Manocha', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:41:01.710Z', 'hidden': False}, {'_id': '67ca66c1cb7e422997cbd150', 'user': {'_id': '6311021788942700629e6247', 'avatarUrl': '/avatars/e7adc1632b76e80e7e4a590033d1c20a.svg', 'isPro': False, 'fullname': 'Bryan Catanzaro', 'user': 'ctnzr', 'type': 'user'}, 'name': 'Bryan Catanzaro', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:40:55.626Z', 'hidden': False}], 'publishedAt': '2025-03-06T00:10:26.000Z', 'title': 'Audio Flamingo 2: An Audio-Language Model with Long-Audio Understanding\\n  and Expert Reasoning Abilities', 'summary': 'Understanding and reasoning over non-speech sounds and music are crucial for\\nboth humans and AI agents to interact effectively with their environments. In\\nthis paper, we introduce Audio Flamingo 2 (AF2), an Audio-Language Model (ALM)\\nwith advanced audio understanding and reasoning capabilities. AF2 leverages (i)\\na custom CLAP model, (ii) synthetic Audio QA data for fine-grained audio\\nreasoning, and (iii) a multi-stage curriculum learning strategy. AF2 achieves\\nstate-of-the-art performance with only a 3B parameter small language model,\\nsurpassing large open-source and proprietary models across over 20 benchmarks.\\nNext, for the first time, we extend audio understanding to long audio segments\\n(30 secs to 5 mins) and propose LongAudio, a large and novel dataset for\\ntraining ALMs on long audio captioning and question-answering tasks.\\nFine-tuning AF2 on LongAudio leads to exceptional performance on our proposed\\nLongAudioBench, an expert annotated benchmark for evaluating ALMs on long audio\\nunderstanding capabilities. We conduct extensive ablation studies to confirm\\nthe efficacy of our approach. Project Website:\\nhttps://research.nvidia.com/labs/adlr/AF2/.', 'upvotes': 6, 'discussionId': '67ca66c3cb7e422997cbd178', 'projectPage': 'https://huggingface.co/spaces/nvidia/audio-flamingo-2', 'githubRepo': 'https://github.com/NVIDIA/audio-flamingo'}, 'publishedAt': '2025-03-07T00:12:47.515Z', 'title': 'Audio Flamingo 2: An Audio-Language Model with Long-Audio Understanding and Expert Reasoning Abilities', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.03983.png', 'numComments': 1, 'submittedBy': {'_id': '62c9664eb34e600d7eaa4beb', 'avatarUrl': '/avatars/ca23ecdec2d31c99ecce97d9b180ae0c.svg', 'fullname': 'Ghosh', 'name': 'Sreyan88', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 2}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2503.04644', 'authors': [{'_id': '67ca5d2783ac16a063a56241', 'user': {'_id': '64dc29d9b5d625e0e9a6ecb9', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/QxGBsnk1cNsBEPqSx4ae-.jpeg', 'isPro': False, 'fullname': 'Tingyu Song', 'user': 'songtingyu', 'type': 'user'}, 'name': 'Tingyu Song', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:53:24.813Z', 'hidden': False}, {'_id': '67ca5d2783ac16a063a56242', 'user': {'_id': '65dfeee3d16fb170031df293', 'avatarUrl': '/avatars/05e6fe0e61d4bb87536554c782385dac.svg', 'isPro': False, 'fullname': 'gan', 'user': 'guo9', 'type': 'user'}, 'name': 'Guo Gan', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T09:09:52.646Z', 'hidden': False}, {'_id': '67ca5d2783ac16a063a56243', 'name': 'Mingsheng Shang', 'hidden': False}, {'_id': '67ca5d2783ac16a063a56244', 'user': {'_id': '62f662bcc58915315c4eccea', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/62f662bcc58915315c4eccea/zOAQLONfMP88zr70sxHK-.jpeg', 'isPro': True, 'fullname': 'Yilun', 'user': 'yilunzhao', 'type': 'user'}, 'name': 'Yilun Zhao', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:52:59.499Z', 'hidden': False}], 'publishedAt': '2025-03-06T17:32:22.000Z', 'title': 'IFIR: A Comprehensive Benchmark for Evaluating Instruction-Following in\\n  Expert-Domain Information Retrieval', 'summary': 'We introduce IFIR, the first comprehensive benchmark designed to evaluate\\ninstruction-following information retrieval (IR) in expert domains. IFIR\\nincludes 2,426 high-quality examples and covers eight subsets across four\\nspecialized domains: finance, law, healthcare, and science literature. Each\\nsubset addresses one or more domain-specific retrieval tasks, replicating\\nreal-world scenarios where customized instructions are critical. IFIR enables a\\ndetailed analysis of instruction-following retrieval capabilities by\\nincorporating instructions at different levels of complexity. We also propose a\\nnovel LLM-based evaluation method to provide a more precise and reliable\\nassessment of model performance in following instructions. Through extensive\\nexperiments on 15 frontier retrieval models, including those based on LLMs, our\\nresults reveal that current models face significant challenges in effectively\\nfollowing complex, domain-specific instructions. We further provide in-depth\\nanalyses to highlight these limitations, offering valuable insights to guide\\nfuture advancements in retriever development.', 'upvotes': 4, 'discussionId': '67ca5d2983ac16a063a562a1'}, 'publishedAt': '2025-03-07T04:37:52.576Z', 'title': 'IFIR: A Comprehensive Benchmark for Evaluating Instruction-Following in Expert-Domain Information Retrieval', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04644.png', 'numComments': 1, 'submittedBy': {'_id': '65dfeee3d16fb170031df293', 'avatarUrl': '/avatars/05e6fe0e61d4bb87536554c782385dac.svg', 'fullname': 'gan', 'name': 'guo9', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2503.01901', 'authors': [{'_id': '67c90398ae4b9276f2d03643', 'user': {'_id': '67bf67ade43da88cdfc1348e', 'avatarUrl': '/avatars/7bd900ade802d99db7c562ad6c2f6661.svg', 'isPro': False, 'fullname': 'Yuezhou Hu', 'user': 'yuezhouhu', 'type': 'user'}, 'name': 'Yuezhou Hu', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:45:37.578Z', 'hidden': False}, {'_id': '67c90398ae4b9276f2d03644', 'name': 'Weiyu Huang', 'hidden': False}, {'_id': '67c90398ae4b9276f2d03645', 'user': {'_id': '67286718746a95c09d04cb1d', 'avatarUrl': '/avatars/317efa8459cca08c2ff56c3ab116e15c.svg', 'isPro': False, 'fullname': 'Zichen Liang', 'user': 'zcliang22', 'type': 'user'}, 'name': 'Zichen Liang', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:45:50.605Z', 'hidden': False}, {'_id': '67c90398ae4b9276f2d03646', 'name': 'Chang Chen', 'hidden': False}, {'_id': '67c90398ae4b9276f2d03647', 'user': {'_id': '66c0a08bac74db25de8427ec', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/66c0a08bac74db25de8427ec/9D-piDBZqSt6KNkHImmkv.jpeg', 'isPro': False, 'fullname': 'Jintao Zhang', 'user': 'jt-zhang', 'type': 'user'}, 'name': 'Jintao Zhang', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T09:26:51.606Z', 'hidden': False}, {'_id': '67c90398ae4b9276f2d03648', 'name': 'Jun Zhu', 'hidden': False}, {'_id': '67c90398ae4b9276f2d03649', 'user': {'_id': '65fcad0ba0d7adc40b54fac2', 'avatarUrl': '/avatars/7564b5642378fddb46ec3b5ae57c0402.svg', 'isPro': False, 'fullname': 'Jianfei Chen', 'user': 'surfingtomchen', 'type': 'user'}, 'name': 'Jianfei Chen', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:46:07.369Z', 'hidden': False}], 'publishedAt': '2025-02-28T07:04:19.000Z', 'title': 'Identifying Sensitive Weights via Post-quantization Integral', 'summary': \"Serving Large Language Models (LLMs) is costly. However, post-training weight\\nquantization can address this problem by both compressing their sizes for\\nlimited memory and saving bandwidth for acceleration. As not all weight\\ndimensions are equally important, those methods typically rely on a sensitivity\\nmetric, which indicates the element-wise influence of weights on loss function\\nand is used to preprocess original weights for better quantization. In this\\nwork, we conduct an empirical study on the accuracy of the sensitivity metric,\\nand find that existing gradient and Hessian based metrics are very inaccurate:\\nthey underestimate quantization's impact on the loss function by orders of\\nmagnitude, mainly due to the small convergence radius of local 2nd order\\napproximation, \\\\ie, gradient and Hessian term in Taylor's formula. To tackle\\nthis problem, we propose Post-quantization Integral (PQI), an accurate metric\\nto estimate posterior sensitivity in a fine-grained manner. To leverage this\\naccurate metric, we further propose ReQuant, a simple yet powerful framework\\nthat mainly consists of two Dense-and-Sparse detach components: self-adaptive\\noutlier selection and step-wise significant weights detach. Results show that\\nReQuant boosts state-of-the-art post-training quantization methods, with a\\npronounced improvement of 2.66 perplexity gain on Llama 3.2 1B with QTIP.\", 'upvotes': 4, 'discussionId': '67c90399ae4b9276f2d03671'}, 'publishedAt': '2025-03-07T04:23:41.486Z', 'title': 'Identifying Sensitive Weights via Post-quantization Integral', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01901.png', 'numComments': 1, 'submittedBy': {'_id': '66c0a08bac74db25de8427ec', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/66c0a08bac74db25de8427ec/9D-piDBZqSt6KNkHImmkv.jpeg', 'fullname': 'Jintao Zhang', 'name': 'jt-zhang', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 3}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2503.04725', 'authors': [{'_id': '67ca9092ba1ee2b914e3fa4a', 'user': {'_id': '65e0027c960938e63e4a0157', 'avatarUrl': '/avatars/c8ca0b082ee8e8004f47a23d9393df67.svg', 'isPro': False, 'fullname': 'Zhuo Chen', 'user': 'zhuoc3', 'type': 'user'}, 'name': 'Zhuo Chen', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T09:09:31.232Z', 'hidden': False}, {'_id': '67ca9092ba1ee2b914e3fa4b', 'user': {'_id': '66e0619714d7a7711c6fc139', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/66e0619714d7a7711c6fc139/IZxEQ6Iv62DDHpCxFM-QG.jpeg', 'isPro': False, 'fullname': 'Oriol Mayné i Comas', 'user': 'oriolmayne', 'type': 'user'}, 'name': 'Oriol Mayné i Comas', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:37:41.309Z', 'hidden': False}, {'_id': '67ca9092ba1ee2b914e3fa4c', 'name': 'Zhuotao Jin', 'hidden': False}, {'_id': '67ca9092ba1ee2b914e3fa4d', 'name': 'Di Luo', 'hidden': False}, {'_id': '67ca9092ba1ee2b914e3fa4e', 'name': 'Marin Soljačić', 'hidden': False}], 'publishedAt': '2025-03-06T18:59:48.000Z', 'title': 'L^2M: Mutual Information Scaling Law for Long-Context Language\\n  Modeling', 'summary': \"We rigorously establish a bipartite mutual information scaling law in natural\\nlanguage that governs long-range dependencies. This scaling law, which we show\\nis distinct from and scales independently of the conventional two-point mutual\\ninformation, is the key to understanding long-context language modeling. Using\\nthis scaling law, we formulate the Long-context Language Modeling (L^2M)\\ncondition, which relates a model's capacity for effective long context length\\nmodeling to the scaling of its latent state size for storing past information.\\nOur results are validated through experiments on both transformers and state\\nspace models. This work establishes a theoretical foundation that guides the\\ndevelopment of large language models toward longer context lengths.\", 'upvotes': 4, 'discussionId': '67ca90c1ba1ee2b914e405b9', 'projectPage': 'https://github.com/LSquaredM/mutual_info_scaling_law', 'githubRepo': 'https://github.com/LSquaredM/mutual_info_scaling_law'}, 'publishedAt': '2025-03-07T01:42:13.847Z', 'title': 'L$^2$M: Mutual Information Scaling Law for Long-Context Language Modeling', 'mediaUrls': ['https://cdn-uploads.huggingface.co/production/uploads/65e0027c960938e63e4a0157/lMxohK6cMFgsw39hn0jga.jpeg', 'https://cdn-uploads.huggingface.co/production/uploads/65e0027c960938e63e4a0157/EqSl1OwTeggMI59pVQzeR.jpeg'], 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04725.png', 'numComments': 1, 'submittedBy': {'_id': '65e0027c960938e63e4a0157', 'avatarUrl': '/avatars/c8ca0b082ee8e8004f47a23d9393df67.svg', 'fullname': 'Zhuo Chen', 'name': 'zhuoc3', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2503.04606', 'authors': [{'_id': '67ca7b8a2a2c299d98944909', 'name': 'Aoxiong Yin', 'hidden': False}, {'_id': '67ca7b8a2a2c299d9894490a', 'name': 'Kai Shen', 'hidden': False}, {'_id': '67ca7b8a2a2c299d9894490b', 'user': {'_id': '64a0347b528a9bbe59d6e08c', 'avatarUrl': '/avatars/6dd0bad84d711d1048a0a4169e621773.svg', 'isPro': False, 'fullname': 'Yichong Leng', 'user': 'ustcscallion', 'type': 'user'}, 'name': 'Yichong Leng', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:41:57.733Z', 'hidden': False}, {'_id': '67ca7b8a2a2c299d9894490c', 'name': 'Xu Tan', 'hidden': False}, {'_id': '67ca7b8a2a2c299d9894490d', 'name': 'Xinyu Zhou', 'hidden': False}, {'_id': '67ca7b8a2a2c299d9894490e', 'user': {'_id': '67bc247b593452cc18965cb1', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/EA3kTYaaff0Hr7-dGiOOj.png', 'isPro': False, 'fullname': 'JUNCHENG LI', 'user': 'JunchengLi', 'type': 'user'}, 'name': 'Juncheng Li', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:42:06.818Z', 'hidden': False}, {'_id': '67ca7b8a2a2c299d9894490f', 'name': 'Siliang Tang', 'hidden': False}], 'publishedAt': '2025-03-06T16:53:14.000Z', 'title': 'The Best of Both Worlds: Integrating Language Models and Diffusion\\n  Models for Video Generation', 'summary': 'Recent advancements in text-to-video (T2V) generation have been driven by two\\ncompeting paradigms: autoregressive language models and diffusion models.\\nHowever, each paradigm has intrinsic limitations: language models struggle with\\nvisual quality and error accumulation, while diffusion models lack semantic\\nunderstanding and causal modeling. In this work, we propose LanDiff, a hybrid\\nframework that synergizes the strengths of both paradigms through\\ncoarse-to-fine generation. Our architecture introduces three key innovations:\\n(1) a semantic tokenizer that compresses 3D visual features into compact 1D\\ndiscrete representations through efficient semantic compression, achieving a\\nsim14,000times compression ratio; (2) a language model that generates\\nsemantic tokens with high-level semantic relationships; (3) a streaming\\ndiffusion model that refines coarse semantics into high-fidelity videos.\\nExperiments show that LanDiff, a 5B model, achieves a score of 85.43 on the\\nVBench T2V benchmark, surpassing the state-of-the-art open-source models\\nHunyuan Video (13B) and other commercial models such as Sora, Keling, and\\nHailuo. Furthermore, our model also achieves state-of-the-art performance in\\nlong video generation, surpassing other open-source models in this field. Our\\ndemo can be viewed at https://landiff.github.io/.', 'upvotes': 4, 'discussionId': '67ca7b8d2a2c299d989449a8'}, 'publishedAt': '2025-03-06T23:52:33.338Z', 'title': 'The Best of Both Worlds: Integrating Language Models and Diffusion Models for Video Generation', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04606.png', 'numComments': 1, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 6300}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2503.04369', 'authors': [{'_id': '67cac954f3efd1be73a870ca', 'user': {'_id': '63f3502a520c14618925825a', 'avatarUrl': '/avatars/e986a2a6625e7be6890616a417f908d2.svg', 'isPro': False, 'fullname': 'Yafu Li', 'user': 'yaful', 'type': 'user'}, 'name': 'Yafu Li', 'status': 'extracted_pending', 'statusLastChangedAt': '2025-03-07T10:24:21.804Z', 'hidden': False}, {'_id': '67cac954f3efd1be73a870cb', 'name': 'Ronghao Zhang', 'hidden': False}, {'_id': '67cac954f3efd1be73a870cc', 'name': 'Zhilin Wang', 'hidden': False}, {'_id': '67cac954f3efd1be73a870cd', 'name': 'Huajian Zhang', 'hidden': False}, {'_id': '67cac954f3efd1be73a870ce', 'name': 'Leyang Cui', 'hidden': False}, {'_id': '67cac954f3efd1be73a870cf', 'name': 'Yongjing Yin', 'hidden': False}, {'_id': '67cac954f3efd1be73a870d0', 'name': 'Tong Xiao', 'hidden': False}, {'_id': '67cac954f3efd1be73a870d1', 'name': 'Yue Zhang', 'hidden': False}], 'publishedAt': '2025-03-06T12:14:45.000Z', 'title': 'Lost in Literalism: How Supervised Training Shapes Translationese in\\n  LLMs', 'summary': 'Large language models (LLMs) have achieved remarkable success in machine\\ntranslation, demonstrating impressive performance across diverse languages.\\nHowever, translationese, characterized by overly literal and unnatural\\ntranslations, remains a persistent challenge in LLM-based translation systems.\\nDespite their pre-training on vast corpora of natural utterances, LLMs exhibit\\ntranslationese errors and generate unexpected unnatural translations, stemming\\nfrom biases introduced during supervised fine-tuning (SFT). In this work, we\\nsystematically evaluate the prevalence of translationese in LLM-generated\\ntranslations and investigate its roots during supervised training. We introduce\\nmethods to mitigate these biases, including polishing golden references and\\nfiltering unnatural training instances. Empirical evaluations demonstrate that\\nthese approaches significantly reduce translationese while improving\\ntranslation naturalness, validated by human evaluations and automatic metrics.\\nOur findings highlight the need for training-aware adjustments to optimize LLM\\ntranslation outputs, paving the way for more fluent and\\ntarget-language-consistent translations. We release the data and code at\\nhttps://github.com/yafuly/LLM_Translationese.', 'upvotes': 3, 'discussionId': '67cac955f3efd1be73a87108'}, 'publishedAt': '2025-03-07T05:25:00.355Z', 'title': 'Lost in Literalism: How Supervised Training Shapes Translationese in LLMs', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04369.png', 'numComments': 1, 'submittedBy': {'_id': '63f3502a520c14618925825a', 'avatarUrl': '/avatars/e986a2a6625e7be6890616a417f908d2.svg', 'fullname': 'Yafu Li', 'name': 'yaful', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2503.04378', 'authors': [{'_id': '67ca637e4cb4283da8ae2979', 'name': 'Zhilin Wang', 'hidden': False}, {'_id': '67ca637e4cb4283da8ae297a', 'name': 'Jiaqi Zeng', 'hidden': False}, {'_id': '67ca637e4cb4283da8ae297b', 'user': {'_id': '6556379e10428134ff235afd', 'avatarUrl': '/avatars/ec569729870d7392e806e59a02f37d0c.svg', 'isPro': False, 'fullname': 'Olivier Delalleau', 'user': 'odelalleau', 'type': 'user'}, 'name': 'Olivier Delalleau', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:51:28.127Z', 'hidden': False}, {'_id': '67ca637e4cb4283da8ae297c', 'name': 'Daniel Egert', 'hidden': False}, {'_id': '67ca637e4cb4283da8ae297d', 'name': 'Ellie Evans', 'hidden': False}, {'_id': '67ca637e4cb4283da8ae297e', 'name': 'Hoo-Chang Shin', 'hidden': False}, {'_id': '67ca637e4cb4283da8ae297f', 'name': 'Felipe Soares', 'hidden': False}, {'_id': '67ca637e4cb4283da8ae2980', 'name': 'Yi Dong', 'hidden': False}, {'_id': '67ca637e4cb4283da8ae2981', 'name': 'Oleksii Kuchaiev', 'hidden': False}], 'publishedAt': '2025-03-06T12:30:24.000Z', 'title': 'Dedicated Feedback and Edit Models Empower Inference-Time Scaling for\\n  Open-Ended General-Domain Tasks', 'summary': 'Inference-Time Scaling has been critical to the success of recent models such\\nas OpenAI o1 and DeepSeek R1. However, many techniques used to train models for\\ninference-time scaling require tasks to have answers that can be verified,\\nlimiting their application to domains such as math, coding and logical\\nreasoning. We take inspiration from how humans make first attempts, ask for\\ndetailed feedback from others and make improvements based on such feedback\\nacross a wide spectrum of open-ended endeavors. To this end, we collect data\\nfor and train dedicated Feedback and Edit Models that are capable of performing\\ninference-time scaling for open-ended general-domain tasks. In our setup, one\\nmodel generates an initial response, which are given feedback by a second\\nmodel, that are then used by a third model to edit the response. We show that\\nperformance on Arena Hard, a benchmark strongly predictive of Chatbot Arena Elo\\ncan be boosted by scaling the number of initial response drafts, effective\\nfeedback and edited responses. When scaled optimally, our setup based on 70B\\nmodels from the Llama 3 family can reach SoTA performance on Arena Hard at 92.7\\nas of 5 Mar 2025, surpassing OpenAI o1-preview-2024-09-12 with 90.4 and\\nDeepSeek R1 with 92.3.', 'upvotes': 3, 'discussionId': '67ca63804cb4283da8ae29da'}, 'publishedAt': '2025-03-06T22:10:18.014Z', 'title': 'Dedicated Feedback and Edit Models Empower Inference-Time Scaling for Open-Ended General-Domain Tasks', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.04378.png', 'numComments': 1, 'submittedBy': {'_id': '60f1abe7544c2adfd699860c', 'avatarUrl': 'https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg', 'fullname': 'AK', 'name': 'akhaliq', 'type': 'user', 'isPro': False, 'isHf': True, 'isMod': False, 'followerCount': 6300}, 'isAuthorParticipating': False}",
    "{'paper': {'id': '2503.02495', 'authors': [{'_id': '67c9e3b7668d5bddb4d36a46', 'user': {'_id': '67a480dadba32bb665f5aeae', 'avatarUrl': '/avatars/ee8d9481a9e86f5e9803bd934a095d61.svg', 'isPro': False, 'fullname': 'Yujiao Yang', 'user': 'yjyangwork', 'type': 'user'}, 'name': 'Yujiao Yang', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T09:10:00.268Z', 'hidden': False}, {'_id': '67c9e3b7668d5bddb4d36a47', 'name': 'Jing Lian', 'hidden': False}, {'_id': '67c9e3b7668d5bddb4d36a48', 'name': 'Linhui Li', 'hidden': False}], 'publishedAt': '2025-03-04T11:01:25.000Z', 'title': 'Union of Experts: Adapting Hierarchical Routing to Equivalently\\n  Decomposed Transformer', 'summary': \"Mixture-of-Experts (MoE) enhances model performance while maintaining\\ncomputational efficiency, making it well-suited for large-scale applications.\\nHowever, expert in exist MoE paradigm works as an individual, thereby lacking\\nhigh-quality expert interactions. Moreover, they have not been effectively\\nextended to attention block, which constrains further efficiency improvements.\\nTo tackle these issues, we propose Union-of-Experts (UoE), which decomposes\\ntransformer into an equitant group of experts, and then implement dynamic\\nrouting on input data and experts. Our approach advances MoE design with three\\nkey innovations: (1) We conducted equitant expert decomposition on both MLP\\nblocks and attention blocks based on matrix partition in tensor parallelism.\\n(2) We developed two routing paradigms: patch wise data selection and expert\\nselection, to apply routing across different levels. (3) We design the\\narchitecture of UoE model, including Selective Multi-Head Attention (SMHA) and\\nUnion-of-MLP-Experts (UoME). (4) We develop parallel implementation of UoE's\\nrouting and computation operation, and optimize efficiency based on the\\nhardware processing analysis. The experiments demonstrate that the model\\nemployed with UoE surpass Full Attention, state-of-art MoEs and efficient\\ntransformers in several tasks across image and natural language domains. The\\nsource codes are available at https://github.com/YujiaoYang-work/UoE.\", 'upvotes': 2, 'discussionId': '67c9e3b7668d5bddb4d36a73', 'githubRepo': 'https://github.com/YujiaoYang-work/UoE'}, 'publishedAt': '2025-03-07T06:08:09.555Z', 'title': 'Union of Experts: Adapting Hierarchical Routing to Equivalently Decomposed Transformer', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02495.png', 'numComments': 1, 'submittedBy': {'_id': '67a480dadba32bb665f5aeae', 'avatarUrl': '/avatars/ee8d9481a9e86f5e9803bd934a095d61.svg', 'fullname': 'Yujiao Yang', 'name': 'yjyangwork', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2503.01375', 'authors': [{'_id': '67c6bdf644c2f41804ca95c6', 'user': {'_id': '64e57772b15cf1b5d017b8ee', 'avatarUrl': '/avatars/24653ae6259a706d9d4ed63692eac5b7.svg', 'isPro': False, 'fullname': 'Daniil Sherki', 'user': 'dsherki', 'type': 'user'}, 'name': 'Daniil Sherki', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-04T09:44:52.446Z', 'hidden': False}, {'_id': '67c6bdf644c2f41804ca95c7', 'user': {'_id': '6169a581d05945bfd8718dfa', 'avatarUrl': '/avatars/1892ab06a7ddb557232777de3cbec470.svg', 'isPro': False, 'fullname': 'Ivan Oseledets', 'user': 'oseledets', 'type': 'user'}, 'name': 'Ivan Oseledets', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:46:17.295Z', 'hidden': False}, {'_id': '67c6bdf644c2f41804ca95c8', 'name': 'Ekaterina Muravleva', 'hidden': False}], 'publishedAt': '2025-03-03T10:17:56.000Z', 'title': 'Combining Flow Matching and Transformers for Efficient Solution of\\n  Bayesian Inverse Problems', 'summary': 'Solving Bayesian inverse problems efficiently remains a significant challenge\\ndue to the complexity of posterior distributions and the computational cost of\\ntraditional sampling methods. Given a series of observations and the forward\\nmodel, we want to recover the distribution of the parameters, conditioned on\\nobserved experimental data. We show, that combining Conditional Flow Mathching\\n(CFM) with transformer-based architecture, we can efficiently sample from such\\nkind of distribution, conditioned on variable number of observations.', 'upvotes': 2, 'discussionId': '67c6bdf744c2f41804ca960a'}, 'publishedAt': '2025-03-07T02:51:01.486Z', 'title': 'Combining Flow Matching and Transformers for Efficient Solution of Bayesian Inverse Problems', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01375.png', 'numComments': 1, 'submittedBy': {'_id': '64e57772b15cf1b5d017b8ee', 'avatarUrl': '/avatars/24653ae6259a706d9d4ed63692eac5b7.svg', 'fullname': 'Daniil Sherki', 'name': 'dsherki', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False, 'followerCount': 1}, 'isAuthorParticipating': True}",
    "{'paper': {'id': '2503.02191', 'authors': [{'_id': '67ca7fe72a83a60adcb6611a', 'user': {'_id': '6331c3f618711776b468e9ec', 'avatarUrl': '/avatars/af2c4bba031e474bf4fd2ea19e415aaf.svg', 'isPro': False, 'fullname': 'Mia Mohammad Imran', 'user': 'imranraad', 'type': 'user'}, 'name': 'Mia Mohammad Imran', 'status': 'claimed_verified', 'statusLastChangedAt': '2025-03-07T09:09:36.214Z', 'hidden': False}, {'_id': '67ca7fe72a83a60adcb6611b', 'name': 'Robert Zita', 'hidden': False}, {'_id': '67ca7fe72a83a60adcb6611c', 'name': 'Rebekah Copeland', 'hidden': False}, {'_id': '67ca7fe72a83a60adcb6611d', 'name': 'Preetha Chatterjee', 'hidden': False}, {'_id': '67ca7fe72a83a60adcb6611e', 'user': {'_id': '64085e1992033c150739aa74', 'avatarUrl': '/avatars/621a5ef8aaf27d9c322c4a22c7bbcf5b.svg', 'isPro': False, 'fullname': 'Rahat Rizvi Rahman', 'user': 'rahat-rizvi', 'type': 'user'}, 'name': 'Rahat Rizvi Rahman', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:48:32.885Z', 'hidden': False}, {'_id': '67ca7fe72a83a60adcb6611f', 'user': {'_id': '64ca97e1d469fc2cf822d9f6', 'avatarUrl': '/avatars/efec75e454ada7026e8497137de5bceb.svg', 'isPro': False, 'fullname': 'Kostadin Damevski', 'user': 'kdamevski', 'type': 'user'}, 'name': 'Kostadin Damevski', 'status': 'admin_assigned', 'statusLastChangedAt': '2025-03-07T09:48:25.771Z', 'hidden': False}], 'publishedAt': '2025-03-04T02:01:37.000Z', 'title': 'Understanding and Predicting Derailment in Toxic Conversations on GitHub', 'summary': 'Software projects thrive on the involvement and contributions of individuals\\nfrom different backgrounds. However, toxic language and negative interactions\\ncan hinder the participation and retention of contributors and alienate\\nnewcomers. Proactive moderation strategies aim to prevent toxicity from\\noccurring by addressing conversations that have derailed from their intended\\npurpose. This study aims to understand and predict conversational derailment\\nleading to toxicity on GitHub.\\n  To facilitate this research, we curate a novel dataset comprising 202 toxic\\nconversations from GitHub with annotated derailment points, along with 696\\nnon-toxic conversations as a baseline. Based on this dataset, we identify\\nunique characteristics of toxic conversations and derailment points, including\\nlinguistic markers such as second-person pronouns, negation terms, and tones of\\nBitter Frustration and Impatience, as well as patterns in conversational\\ndynamics between project contributors and external participants.\\n  Leveraging these empirical observations, we propose a proactive moderation\\napproach to automatically detect and address potentially harmful conversations\\nbefore escalation. By utilizing modern LLMs, we develop a conversation\\ntrajectory summary technique that captures the evolution of discussions and\\nidentifies early signs of derailment. Our experiments demonstrate that LLM\\nprompts tailored to provide summaries of GitHub conversations achieve 69%\\nF1-Score in predicting conversational derailment, strongly improving over a set\\nof baseline approaches.', 'upvotes': 2, 'discussionId': '67ca7fe82a83a60adcb6615b', 'githubRepo': 'https://github.com/imranraad07/derailment-oss-replication'}, 'publishedAt': '2025-03-07T00:11:25.116Z', 'title': 'Understanding and Predicting Derailment in Toxic Conversations on GitHub', 'thumbnail': 'https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.02191.png', 'numComments': 1, 'submittedBy': {'_id': '6331c3f618711776b468e9ec', 'avatarUrl': '/avatars/af2c4bba031e474bf4fd2ea19e415aaf.svg', 'fullname': 'Mia Mohammad Imran', 'name': 'imranraad', 'type': 'user', 'isPro': False, 'isHf': False, 'isMod': False}, 'isAuthorParticipating': True}"
]